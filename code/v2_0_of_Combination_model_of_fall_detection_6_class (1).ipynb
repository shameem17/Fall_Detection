{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPJnnDoljq8Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sklearn\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout\n",
        "\n",
        "import warnings\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVOHS1L-BD3d",
        "outputId": "d4de4807-7038-4474-91a6-3801a98732dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phJfvlKkl6he",
        "outputId": "121f0b0a-e0ed-4498-a105-262ed3298ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/Colab': No such file or directory\n",
            "cp: cannot stat 'Notebooks/CSV': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cp -r /content/drive/MyDrive/Colab Notebooks/CSV /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPKYItpMLxq7"
      },
      "outputs": [],
      "source": [
        "ac_col=['time','ac_x','ac_y','ac_z','a_ac']\n",
        "gy_col=['time','gy_x','gy_y','gy_z','a_gy']\n",
        "features=['ac_x','ac_y','ac_z','a_ac','gy_x','gy_y','gy_z','a_gy','jac_x','jac_y','jac_z','ja_ac','jgy_x','jgy_y','jgy_z','ja_gy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXxSvsZuT3YH"
      },
      "outputs": [],
      "source": [
        "##### Number of data ###########\n",
        "f_s=1\n",
        "f_e=206\n",
        "fall_number=205\n",
        "w_s=1\n",
        "w_e=222\n",
        "walk_number=221\n",
        "s_s=1\n",
        "s_e=250\n",
        "sit_number=249\n",
        "bsc_s=1\n",
        "bsc_e=253\n",
        "bsc_number=252\n",
        "laying_s=1\n",
        "laying_e=247\n",
        "laying_number=246\n",
        "standing_s=1\n",
        "standing_e=218\n",
        "stand_number=217\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLrWaEF65F_c"
      },
      "source": [
        "Data Processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XabbV6fXTaOn"
      },
      "outputs": [],
      "source": [
        "keep_cols=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrrQxEkPq218"
      },
      "source": [
        "Feature Map construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJm4sta7FjjQ"
      },
      "outputs": [],
      "source": [
        "#### Feature Map construction (Fall) #####\n",
        "mi_score=[]\n",
        "partial_mi_score=[]\n",
        "mean_f=[]\n",
        "xcorr=[]\n",
        "pearson_corr=[]\n",
        "ffm=\"xcorr_\"\n",
        "for i in range(0,fall_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  xcorr.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"pearson_corr_\"\n",
        "for i in range(0,fall_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  pearson_corr.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"mi_\"\n",
        "for i in range(0,fall_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  mi_score.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"pmi_\"\n",
        "for i in range(0,fall_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  partial_mi_score.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"mean_\"\n",
        "for i in range(0,fall_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  mean_f.append(np.array(df).astype(float))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dirUf0F7OxQY",
        "outputId": "8d451e65-4f8d-468c-aced-2732a8b1a67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "205\n"
          ]
        }
      ],
      "source": [
        "print(len(xcorr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIK80unfm1hP"
      },
      "outputs": [],
      "source": [
        "def heat_map(x):\n",
        "  #plt.figure(figsize=(15,8))\n",
        "  f,ax = plt.subplots(figsize=(15, 8))\n",
        "  sns.heatmap(x, annot=False, linewidths=0.0,ax=ax)\n",
        "  #sns.heatmap(x,cmap=\"Greens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bROu-i5BqD_m"
      },
      "source": [
        "Walk Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NW48X2VqDVg"
      },
      "outputs": [],
      "source": [
        "#### Feature Map construction (Fall) #####\n",
        "mi_score_walk=[]\n",
        "partial_mi_score_walk=[]\n",
        "mean_f_walk=[]\n",
        "xcorr_walk=[]\n",
        "pearson_corr_walk=[]\n",
        "ffm=\"xcorr_walk_\"\n",
        "for i in range(0,walk_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  xcorr_walk.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"pearson_corr_walk_\"\n",
        "for i in range(0,walk_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  pearson_corr_walk.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"mi_walk_\"\n",
        "for i in range(0,walk_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  mi_score_walk.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"pmi_walk_\"\n",
        "for i in range(0,walk_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  partial_mi_score_walk.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"mean_walk_\"\n",
        "for i in range(0,walk_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  mean_f_walk.append(np.array(df).astype(float))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqVuro3DZz2M"
      },
      "outputs": [],
      "source": [
        "######Sitting feature map\n",
        "\n",
        "mi_score_sit=[]\n",
        "partial_mi_score_sit=[]\n",
        "mean_f_sit=[]\n",
        "xcorr_sit=[]\n",
        "pearson_corr_sit=[]\n",
        "ffm=\"xcorr_sit_\"\n",
        "for i in range(0,sit_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  xcorr_sit.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"pearson_corr_sit_\"\n",
        "for i in range(0,sit_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  pearson_corr_sit.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"mi_sit_\"\n",
        "for i in range(0,sit_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  mi_score_sit.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"pmi_sit_\"\n",
        "for i in range(0,sit_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  partial_mi_score_sit.append(np.array(df).astype(float))\n",
        "\n",
        "\n",
        "ffm=\"mean_sit_\"\n",
        "for i in range(0,sit_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  mean_f_sit.append(np.array(df).astype(float))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdtL68A_tAAx"
      },
      "outputs": [],
      "source": [
        "###### BSC feature map\n",
        "\n",
        "\n",
        "mi_score_bsc=[]\n",
        "partial_mi_score_bsc=[]\n",
        "mean_f_bsc=[]\n",
        "xcorr_bsc=[]\n",
        "pearson_corr_bsc=[]\n",
        "ffm=\"xcorr_bsc_\"\n",
        "for i in range(0,bsc_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  xcorr_bsc.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"pearson_corr_bsc_\"\n",
        "for i in range(0,bsc_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  pearson_corr_bsc.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"mi_bsc_\"\n",
        "for i in range(0,bsc_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  mi_score_bsc.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"pmi_bsc_\"\n",
        "for i in range(0,bsc_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  partial_mi_score_bsc.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"mean_bsc_\"\n",
        "for i in range(0,bsc_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  mean_f_bsc.append(np.array(df).astype(float))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe5FKixstgCK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57gi-mAitgrY"
      },
      "outputs": [],
      "source": [
        "######Standting feature map\n",
        "\n",
        "mi_score_stand=[]\n",
        "partial_mi_score_stand=[]\n",
        "mean_f_stand=[]\n",
        "xcorr_stand=[]\n",
        "pearson_corr_stand=[]\n",
        "ffm=\"xcorr_stand_\"\n",
        "for i in range(0,stand_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  xcorr_stand.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"pearson_corr_stand_\"\n",
        "for i in range(0,stand_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  pearson_corr_stand.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"mi_stand_\"\n",
        "for i in range(0,stand_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  mi_score_stand.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"pmi_stand_\"\n",
        "for i in range(0,stand_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  partial_mi_score_stand.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"mean_stand_\"\n",
        "for i in range(0,stand_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  mean_f_stand.append(np.array(df).astype(float))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU1PagVrt6cP"
      },
      "outputs": [],
      "source": [
        "######Layingting feature map\n",
        "\n",
        "mi_score_laying=[]\n",
        "partial_mi_score_laying=[]\n",
        "mean_f_laying=[]\n",
        "xcorr_laying=[]\n",
        "pearson_corr_laying=[]\n",
        "ffm=\"xcorr_laying_\"\n",
        "for i in range(0,laying_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  xcorr_laying.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"pearson_corr_laying_\"\n",
        "for i in range(0,laying_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  pearson_corr_laying.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"mi_laying_\"\n",
        "for i in range(0,laying_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  mi_score_laying.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"pmi_laying_\"\n",
        "for i in range(0,laying_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  partial_mi_score_laying.append(np.array(df).astype(float))\n",
        "\n",
        "ffm=\"mean_laying_\"\n",
        "for i in range(0,laying_number):\n",
        "  extra=str(i)+\".csv\"\n",
        "  path='/content/drive/MyDrive/Colab Notebooks/Data/'+ffm+extra\n",
        "  df=pd.read_csv(path,header=None,skiprows=1,usecols=keep_cols)\n",
        "  mean_f_laying.append(np.array(df).astype(float))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR6COz_CchZP"
      },
      "outputs": [],
      "source": [
        "X_data_xcorr=[]\n",
        "X_data_pccr=[]\n",
        "X_data_mi=[]\n",
        "X_data_pmi=[]\n",
        "X_data_mean=[]\n",
        "y_data_xcorr=[]\n",
        "y_data_pccr=[]\n",
        "y_data_mi=[]\n",
        "y_data_pmi=[]\n",
        "y_data_mean=[]\n",
        "X_data=[]\n",
        "y_data=[]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbgZJ3CBFvxt"
      },
      "outputs": [],
      "source": [
        "def add_noise(data, mean=0, std=0.1):\n",
        "    \"\"\"\n",
        "    Add Gaussian noise to the input data.\n",
        "    \"\"\"\n",
        "    noise = np.random.normal(mean, std, data.shape)\n",
        "    augmented_data = data + noise\n",
        "    return augmented_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSqUUJOg6JbF"
      },
      "outputs": [],
      "source": [
        "pccr_xcorr=[]\n",
        "pccr_mi=[]\n",
        "pccr_nmi=[]\n",
        "pccr_mean=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27h8_SJAnYGX"
      },
      "outputs": [],
      "source": [
        "#### data test construction ############\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i in range(0,fall_number):\n",
        "  pccr_xcorr_temp=[]\n",
        "  pccr_mi_temp=[]\n",
        "  pccr_nmi_temp=[]\n",
        "  pccr_mean_temp=[]\n",
        "  xcorr[i]=scaler.fit_transform(xcorr[i])\n",
        "  mi_score[i]=scaler.fit_transform(mi_score[i])\n",
        "  partial_mi_score[i]=scaler.fit_transform(partial_mi_score[i])\n",
        "  mean_f[i]=scaler.fit_transform(mean_f[i])\n",
        "  pearson_corr[i]=scaler.fit_transform(pearson_corr[i])\n",
        "\n",
        "  pccr_xcorr_temp.append(pearson_corr[i])\n",
        "  pccr_xcorr_temp.append(xcorr[i])\n",
        "\n",
        "  pccr_mi_temp.append(pearson_corr[i])\n",
        "  pccr_mi_temp.append(mi_score[i])\n",
        "\n",
        "  pccr_nmi_temp.append(pearson_corr[i])\n",
        "  pccr_nmi_temp.append(partial_mi_score[i])\n",
        "\n",
        "  pccr_mean_temp.append(pearson_corr[i])\n",
        "  pccr_mean_temp.append(mean_f[i])\n",
        "\n",
        "  pccr_xcorr.append(pccr_xcorr_temp)\n",
        "  pccr_mi.append(pccr_mi_temp)\n",
        "  pccr_nmi.append(pccr_nmi_temp)\n",
        "  pccr_mean.append(pccr_mean_temp)\n",
        "\n",
        "  y_data.append(\"Fall\")\n",
        "  #fall_temp.append(\"Fall\")\n",
        "\n",
        "  #walk_temp=np.stack((xcorr_walk[i],pearson_corr_walk[i],mi_score_walk[i],partial_mi_score_walk[i],mean_f_walk[i]),axis=0)\n",
        "for i in range(0,walk_number):\n",
        "  pccr_xcorr_temp=[]\n",
        "  pccr_mi_temp=[]\n",
        "  pccr_nmi_temp=[]\n",
        "  pccr_mean_temp=[]\n",
        "\n",
        "  xcorr_walk[i]=scaler.fit_transform(xcorr_walk[i])\n",
        "  mi_score_walk[i]=scaler.fit_transform(mi_score_walk[i])\n",
        "  partial_mi_score_walk[i]=scaler.fit_transform(partial_mi_score_walk[i])\n",
        "  mean_f_walk[i]=scaler.fit_transform(mean_f_walk[i])\n",
        "  pearson_corr_walk[i]=scaler.fit_transform(pearson_corr_walk[i])\n",
        "\n",
        "  pccr_xcorr_temp.append(pearson_corr_walk[i])\n",
        "  pccr_xcorr_temp.append(xcorr_walk[i])\n",
        "\n",
        "  pccr_mi_temp.append(pearson_corr_walk[i])\n",
        "  pccr_mi_temp.append(mi_score_walk[i])\n",
        "\n",
        "  pccr_nmi_temp.append(pearson_corr_walk[i])\n",
        "  pccr_nmi_temp.append(partial_mi_score_walk[i])\n",
        "\n",
        "  pccr_mean_temp.append(pearson_corr_walk[i])\n",
        "  pccr_mean_temp.append(mean_f_walk[i])\n",
        "\n",
        "  pccr_xcorr.append(pccr_xcorr_temp)\n",
        "  pccr_mi.append(pccr_mi_temp)\n",
        "  pccr_nmi.append(pccr_nmi_temp)\n",
        "  pccr_mean.append(pccr_mean_temp)\n",
        "\n",
        "  y_data.append('Walk')\n",
        "\n",
        "for i in range(0,sit_number):\n",
        "  pccr_xcorr_temp=[]\n",
        "  pccr_mi_temp=[]\n",
        "  pccr_nmi_temp=[]\n",
        "  pccr_mean_temp=[]\n",
        "\n",
        "  xcorr_sit[i]=scaler.fit_transform(xcorr_sit[i])\n",
        "  mi_score_sit[i]=scaler.fit_transform(mi_score_sit[i])\n",
        "  partial_mi_score_sit[i]=scaler.fit_transform(partial_mi_score_sit[i])\n",
        "  mean_f_sit[i]=scaler.fit_transform(mean_f_sit[i])\n",
        "  pearson_corr_sit[i]=scaler.fit_transform(pearson_corr_sit[i])\n",
        "\n",
        "  pccr_xcorr_temp.append(pearson_corr_sit[i])\n",
        "  pccr_xcorr_temp.append(xcorr_sit[i])\n",
        "\n",
        "  pccr_mi_temp.append(pearson_corr_sit[i])\n",
        "  pccr_mi_temp.append(mi_score_sit[i])\n",
        "\n",
        "  pccr_nmi_temp.append(pearson_corr_sit[i])\n",
        "  pccr_nmi_temp.append(partial_mi_score_sit[i])\n",
        "\n",
        "  pccr_mean_temp.append(pearson_corr_sit[i])\n",
        "  pccr_mean_temp.append(mean_f_sit[i])\n",
        "\n",
        "  pccr_xcorr.append(pccr_xcorr_temp)\n",
        "  pccr_mi.append(pccr_mi_temp)\n",
        "  pccr_nmi.append(pccr_nmi_temp)\n",
        "  pccr_mean.append(pccr_mean_temp)\n",
        "\n",
        "  y_data.append('Sitting')\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,bsc_number):\n",
        "  pccr_xcorr_temp=[]\n",
        "  pccr_mi_temp=[]\n",
        "  pccr_nmi_temp=[]\n",
        "  pccr_mean_temp=[]\n",
        "\n",
        "  xcorr_bsc[i]=scaler.fit_transform(xcorr_bsc[i])\n",
        "  mi_score_bsc[i]=scaler.fit_transform(mi_score_bsc[i])\n",
        "  partial_mi_score_bsc[i]=scaler.fit_transform(partial_mi_score_bsc[i])\n",
        "  mean_f_bsc[i]=scaler.fit_transform(mean_f_bsc[i])\n",
        "  pearson_corr_bsc[i]=scaler.fit_transform(pearson_corr_bsc[i])\n",
        "\n",
        "\n",
        "  pccr_xcorr_temp.append(pearson_corr_bsc[i])\n",
        "  pccr_xcorr_temp.append(xcorr_bsc[i])\n",
        "\n",
        "  pccr_mi_temp.append(pearson_corr_bsc[i])\n",
        "  pccr_mi_temp.append(mi_score_bsc[i])\n",
        "\n",
        "  pccr_nmi_temp.append(pearson_corr_bsc[i])\n",
        "  pccr_nmi_temp.append(partial_mi_score_bsc[i])\n",
        "\n",
        "  pccr_mean_temp.append(pearson_corr_bsc[i])\n",
        "  pccr_mean_temp.append(mean_f_bsc[i])\n",
        "\n",
        "  pccr_xcorr.append(pccr_xcorr_temp)\n",
        "  pccr_mi.append(pccr_mi_temp)\n",
        "  pccr_nmi.append(pccr_nmi_temp)\n",
        "  pccr_mean.append(pccr_mean_temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  y_data.append('BSC')\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,stand_number):\n",
        "  pccr_xcorr_temp=[]\n",
        "  pccr_mi_temp=[]\n",
        "  pccr_nmi_temp=[]\n",
        "  pccr_mean_temp=[]\n",
        "\n",
        "  xcorr_stand[i]=scaler.fit_transform(xcorr_stand[i])\n",
        "  mi_score_stand[i]=scaler.fit_transform(mi_score_stand[i])\n",
        "  partial_mi_score_stand[i]=scaler.fit_transform(partial_mi_score_stand[i])\n",
        "  mean_f_stand[i]=scaler.fit_transform(mean_f_stand[i])\n",
        "  pearson_corr_stand[i]=scaler.fit_transform(pearson_corr_stand[i])\n",
        "\n",
        "  pccr_xcorr_temp.append(pearson_corr_stand[i])\n",
        "  pccr_xcorr_temp.append(xcorr_stand[i])\n",
        "\n",
        "  pccr_mi_temp.append(pearson_corr_stand[i])\n",
        "  pccr_mi_temp.append(mi_score_stand[i])\n",
        "\n",
        "  pccr_nmi_temp.append(pearson_corr_stand[i])\n",
        "  pccr_nmi_temp.append(partial_mi_score_stand[i])\n",
        "\n",
        "  pccr_mean_temp.append(pearson_corr_stand[i])\n",
        "  pccr_mean_temp.append(mean_f_stand[i])\n",
        "\n",
        "  pccr_xcorr.append(pccr_xcorr_temp)\n",
        "  pccr_mi.append(pccr_mi_temp)\n",
        "  pccr_nmi.append(pccr_nmi_temp)\n",
        "  pccr_mean.append(pccr_mean_temp)\n",
        "\n",
        "\n",
        "  y_data.append('Standing')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,laying_number):\n",
        "  pccr_xcorr_temp=[]\n",
        "  pccr_mi_temp=[]\n",
        "  pccr_nmi_temp=[]\n",
        "  pccr_mean_temp=[]\n",
        "\n",
        "  xcorr_laying[i]=scaler.fit_transform(xcorr_laying[i])\n",
        "  mi_score_laying[i]=scaler.fit_transform(mi_score_laying[i])\n",
        "  partial_mi_score_laying[i]=scaler.fit_transform(partial_mi_score_laying[i])\n",
        "  mean_f_laying[i]=scaler.fit_transform(mean_f_laying[i])\n",
        "  pearson_corr_laying[i]=scaler.fit_transform(pearson_corr_laying[i])\n",
        "\n",
        "\n",
        "  pccr_xcorr_temp.append(pearson_corr_laying[i])\n",
        "  pccr_xcorr_temp.append(xcorr_laying[i])\n",
        "\n",
        "  pccr_mi_temp.append(pearson_corr_laying[i])\n",
        "  pccr_mi_temp.append(mi_score_laying[i])\n",
        "\n",
        "  pccr_nmi_temp.append(pearson_corr_laying[i])\n",
        "  pccr_nmi_temp.append(partial_mi_score_laying[i])\n",
        "\n",
        "  pccr_mean_temp.append(pearson_corr_laying[i])\n",
        "  pccr_mean_temp.append(mean_f_laying[i])\n",
        "\n",
        "  pccr_xcorr.append(pccr_xcorr_temp)\n",
        "  pccr_mi.append(pccr_mi_temp)\n",
        "  pccr_nmi.append(pccr_nmi_temp)\n",
        "  pccr_mean.append(pccr_mean_temp)\n",
        "  y_data.append('Laying')\n",
        "\n",
        "\n",
        "#X_data=pd.DataFrame(data=X_data,columns=[['Xcorr','Pearson','MI','NMI','Mean']])\n",
        "#y_data=pd.DataFrame(data=y_data,columns=['Label'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2yPauVTcr2V",
        "outputId": "5ebf9d40-acb9-4795-c862-f285d9ea0672"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(X_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7floXxyhumr"
      },
      "outputs": [],
      "source": [
        "####### TEST data train data processing #################\n",
        "pccr_xcorr=np.array(pccr_xcorr)\n",
        "pccr_mi=np.array(pccr_mi)\n",
        "pccr_nmi=np.array(pccr_nmi)\n",
        "pccr_mean=np.array(pccr_mean)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs1oaoVwvp71",
        "outputId": "6beefa70-ad2b-4b72-a2df-de4ea26b08a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras.layers import Conv3D, MaxPool3D\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-smNz4XhjFgA"
      },
      "outputs": [],
      "source": [
        "y_temp=y_data\n",
        "yenc = sklearn.preprocessing.LabelEncoder()\n",
        "y_data = yenc.fit_transform(y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U_SHJtMLcIu",
        "outputId": "23c07b85-7da3-4021-e756-af3acd4dcc79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1390, 2, 16, 16)\n",
            "(1390,)\n"
          ]
        }
      ],
      "source": [
        "print(pccr_mean.shape)\n",
        "print(y_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INeEgoSTC-8V"
      },
      "outputs": [],
      "source": [
        "class_names=yenc.classes_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o5U7YNStx2t"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy(history, epochs, srt):\n",
        "  # Plot training & validation accuracy values\n",
        "  srt='Model accuracy using feature: '+srt\n",
        "  epoch_range = range(1, epochs+1)\n",
        "  plt.figure(figsize=(16,7))\n",
        "  plt.plot(epoch_range, history.history['accuracy'])\n",
        "  plt.plot(epoch_range, history.history['val_accuracy'])\n",
        "  plt.title(srt)\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Val'], loc='upper left')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss(history,epochs,srt):\n",
        "  # Plot training & validation loss values\n",
        "  srt='Model loss using feature: '+srt\n",
        "  epoch_range = range(1, epochs+1)\n",
        "  plt.figure(figsize=(16,7))\n",
        "  plt.plot(epoch_range, history.history['loss'])\n",
        "  plt.plot(epoch_range, history.history['val_loss'])\n",
        "  plt.title(srt)\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Val'], loc='upper left')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def calculate_classification_metrics(y_actual, y_pred, labels):\n",
        "\n",
        "  cm = tf.math.confusion_matrix(y_actual, y_pred)\n",
        "  tp = np.diag(cm) # Diagonal represents true positives\n",
        "  precision = dict()\n",
        "  recall = dict()\n",
        "  for i in range(len(labels)):\n",
        "    col = cm[:, i]\n",
        "    fp = np.sum(col) - tp[i] # Sum of column minus true positive is false negative\n",
        "\n",
        "    row = cm[i, :]\n",
        "    fn = np.sum(row) - tp[i] # Sum of row minus true positive, is false negative\n",
        "\n",
        "    precision[labels[i]] = tp[i] / (tp[i] + fp) # Precision\n",
        "\n",
        "    recall[labels[i]] = tp[i] / (tp[i] + fn) # Recall\n",
        "\n",
        "  return precision, recall\n",
        "\n",
        "def get_actual_predicted_labels(x_test,y_test,model):\n",
        "  \"\"\"\n",
        "    Create a list of actual ground truth values and the predictions from the model.\n",
        "\n",
        "    Args:\n",
        "      dataset: An iterable data structure, such as a TensorFlow Dataset, with features and labels.\n",
        "\n",
        "    Return:\n",
        "      Ground truth and predicted values for a particular dataset.\n",
        "  \"\"\"\n",
        "  actual = y_test\n",
        "  predicted = model.predict(x_test)\n",
        "\n",
        "  actual = tf.stack(actual, axis=0)\n",
        "  predicted = tf.concat(predicted, axis=0)\n",
        "  predicted = tf.argmax(predicted, axis=1)\n",
        "\n",
        "  return actual, predicted\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, labels, ds_type):\n",
        "  ds_type=\"Confusion Matrix for \"+ds_type\n",
        "#  cm = tf.math.confusion_matrix(actual, predicted)\n",
        "  ax = sns.heatmap(cm, annot=True, fmt='g')\n",
        "  sns.set(rc={'figure.figsize':(12, 12)})\n",
        "  sns.set(font_scale=1.4)\n",
        "  ax.set_title( ds_type)\n",
        "  ax.set_xlabel('Predicted Action')\n",
        "  ax.set_ylabel('Actual Action')\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.yticks(rotation=0)\n",
        "  ax.xaxis.set_ticklabels(labels)\n",
        "  ax.yaxis.set_ticklabels(labels)\n",
        "\n",
        "def conf_mat(y_pred,y_test,class_names):\n",
        "  plt.figure(figsize=(16, 8))\n",
        "  sns.set(font=\"Times New Roman\", font_scale=1.25)\n",
        "  sns.heatmap(sklearn.metrics.confusion_matrix(y_test, y_pred),  annot=True, xticklabels=class_names, yticklabels=class_names, linewidths=0.1, set_xlabel='Predicted', set_ylabel=\"Actual\",\n",
        "           fmt='g')\n",
        "  plt.title('Confusion Matrix: CNN', fontsize=15);\n",
        "\n",
        "\n",
        "def conf_mat2(mat,class_names,title):\n",
        "  plt.figure(figsize=(16, 8))\n",
        "  sns.set( font_scale=1.25)\n",
        "  sns.heatmap(mat,  annot=True, xticklabels=class_names, yticklabels=class_names, linewidths=0.1,\n",
        "           fmt='g')\n",
        "  plt.title(title, fontsize=15);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "def get_3d():\n",
        "  model1 = Sequential()\n",
        "  model1.add(Conv3D(16, (2, 7,7),kernel_initializer='normal', activation = 'relu', input_shape = (2,16,16,1)))\n",
        "\n",
        "\n",
        "  model1.add(Conv3D(128, (1, 7,7), activation='relu'))\n",
        "  model1.add(Dropout(0.25))\n",
        "\n",
        "  model1.add(Conv3D(128, (1, 3,3), activation='relu'))\n",
        "  model1.add(Dropout(0.25))\n",
        "\n",
        "  model1.add(MaxPool3D((1, 2,2)))\n",
        "  model1.add(BatchNormalization())\n",
        "\n",
        "  model1.add(Flatten())\n",
        "\n",
        "  model1.add(Dense(256, activation = 'relu'))\n",
        "  model1.add(Dropout(0.25))\n",
        "\n",
        "  model1.add(Dense(6, activation='softmax',kernel_regularizer=l2(0.01)))\n",
        "  return model1"
      ],
      "metadata": {
        "id": "ghTW0Z-_UXCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eYckixhxtEH"
      },
      "outputs": [],
      "source": [
        "no_of_epoch=5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8JSWYe4uZbQ"
      },
      "outputs": [],
      "source": [
        "def confusion(y_pred,y_test):\n",
        "\n",
        "  c0=[0,0,0,0,0,0]\n",
        "  c1=[0,0,0,0,0,0]\n",
        "  c2=[0,0,0,0,0,0]\n",
        "  c3=[0,0,0,0,0,0]\n",
        "  c4=[0,0,0,0,0,0]\n",
        "  c5=[0,0,0,0,0,0]\n",
        "\n",
        "  n=len(y_test)\n",
        "  for i in range (0,n):\n",
        "    p=y_pred[i]\n",
        "    q=y_test[i]\n",
        "    if(p==0):\n",
        "      c0[q]=c0[q]+1\n",
        "    elif(p==1):\n",
        "      c1[q]=c1[q]+1\n",
        "    elif(p==2):\n",
        "      c2[q]=c2[q]+1\n",
        "    elif(p==3):\n",
        "      c3[q]=c3[q]+1\n",
        "    elif(p==4):\n",
        "      c4[q]=c4[q]+1\n",
        "    elif(p==5):\n",
        "      c5[q]=c5[q]+1\n",
        "  cm=[]\n",
        "  cm.append(c0)\n",
        "  cm.append(c1)\n",
        "  cm.append(c2)\n",
        "  cm.append(c3)\n",
        "  cm.append(c4)\n",
        "  cm.append(c5)\n",
        "  return cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdkKQSb4CImb"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"pccr_mean.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "#es = EarlyStopping(monitor='val_loss', patience=100, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K38iHktiCMem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0fbc179-de5c-4796-e65c-6e4cf58533b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 1, 10, 10, 16)     1584      \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 1, 4, 4, 128)      100480    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 4, 4, 128)      0         \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 1, 2, 2, 128)      147584    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1, 2, 2, 128)      0         \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 1, 1, 1, 128)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 1, 1, 1, 128)     512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 284,726\n",
            "Trainable params: 284,470\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model4=get_3d()\n",
        "model4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49TLYA1ZHXO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19849c0a-9826-4f6f-a4ac-d3d1afb53430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1112, 2, 16, 16, 1)\n"
          ]
        }
      ],
      "source": [
        "y_data=y_temp\n",
        "yenc = sklearn.preprocessing.LabelEncoder()\n",
        "y_data = yenc.fit_transform(y_data)\n",
        "X_train, X_test, y_train, y_test = train_test_split(pccr_mean, y_data, test_size = 0.20, random_state = 42)\n",
        "\n",
        "#X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.10, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 2,16, 16,1)\n",
        "X_test = X_test.reshape(X_test.shape[0],2, 16,16,1)\n",
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZI2nTc8CQ09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f475b10-63bf-4785-f0a2-5db26f989269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3751/5000\n",
            "\n",
            "Epoch 3751: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2645e-04 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3752/5000\n",
            "\n",
            "Epoch 3752: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4610e-04 - accuracy: 1.0000 - val_loss: 0.6901 - val_accuracy: 0.8345 - 2s/epoch - 45ms/step\n",
            "Epoch 3753/5000\n",
            "\n",
            "Epoch 3753: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2148e-04 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.8345 - 2s/epoch - 45ms/step\n",
            "Epoch 3754/5000\n",
            "\n",
            "Epoch 3754: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8591e-04 - accuracy: 1.0000 - val_loss: 0.6604 - val_accuracy: 0.8417 - 2s/epoch - 49ms/step\n",
            "Epoch 3755/5000\n",
            "\n",
            "Epoch 3755: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.1664e-04 - accuracy: 1.0000 - val_loss: 0.6570 - val_accuracy: 0.8381 - 3s/epoch - 77ms/step\n",
            "Epoch 3756/5000\n",
            "\n",
            "Epoch 3756: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0541e-04 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.8417 - 2s/epoch - 53ms/step\n",
            "Epoch 3757/5000\n",
            "\n",
            "Epoch 3757: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.7741 - val_accuracy: 0.8237 - 2s/epoch - 45ms/step\n",
            "Epoch 3758/5000\n",
            "\n",
            "Epoch 3758: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0059 - accuracy: 0.9973 - val_loss: 0.7422 - val_accuracy: 0.8417 - 2s/epoch - 46ms/step\n",
            "Epoch 3759/5000\n",
            "\n",
            "Epoch 3759: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3760/5000\n",
            "\n",
            "Epoch 3760: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.8453 - 2s/epoch - 46ms/step\n",
            "Epoch 3761/5000\n",
            "\n",
            "Epoch 3761: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.9999e-04 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 3762/5000\n",
            "\n",
            "Epoch 3762: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.8489 - 2s/epoch - 57ms/step\n",
            "Epoch 3763/5000\n",
            "\n",
            "Epoch 3763: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.8453 - 3s/epoch - 80ms/step\n",
            "Epoch 3764/5000\n",
            "\n",
            "Epoch 3764: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.5174e-04 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3765/5000\n",
            "\n",
            "Epoch 3765: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.5614e-04 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 3766/5000\n",
            "\n",
            "Epoch 3766: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.4231e-04 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 3767/5000\n",
            "\n",
            "Epoch 3767: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.7634e-04 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 3768/5000\n",
            "\n",
            "Epoch 3768: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0019 - accuracy: 0.9991 - val_loss: 0.7096 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3769/5000\n",
            "\n",
            "Epoch 3769: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.6130e-04 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 3770/5000\n",
            "\n",
            "Epoch 3770: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6897 - val_accuracy: 0.8345 - 2s/epoch - 68ms/step\n",
            "Epoch 3771/5000\n",
            "\n",
            "Epoch 3771: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8345 - 2s/epoch - 70ms/step\n",
            "Epoch 3772/5000\n",
            "\n",
            "Epoch 3772: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.0947e-04 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.8309 - 2s/epoch - 45ms/step\n",
            "Epoch 3773/5000\n",
            "\n",
            "Epoch 3773: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8887e-04 - accuracy: 1.0000 - val_loss: 0.6848 - val_accuracy: 0.8381 - 2s/epoch - 46ms/step\n",
            "Epoch 3774/5000\n",
            "\n",
            "Epoch 3774: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7955e-04 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 3775/5000\n",
            "\n",
            "Epoch 3775: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7209e-04 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 3776/5000\n",
            "\n",
            "Epoch 3776: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.7969e-04 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 3777/5000\n",
            "\n",
            "Epoch 3777: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.5476e-04 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3778/5000\n",
            "\n",
            "Epoch 3778: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 9.1989e-04 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.8453 - 3s/epoch - 77ms/step\n",
            "Epoch 3779/5000\n",
            "\n",
            "Epoch 3779: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6284e-04 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.8453 - 2s/epoch - 60ms/step\n",
            "Epoch 3780/5000\n",
            "\n",
            "Epoch 3780: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8962e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3781/5000\n",
            "\n",
            "Epoch 3781: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9330e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3782/5000\n",
            "\n",
            "Epoch 3782: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.1201e-04 - accuracy: 1.0000 - val_loss: 0.7490 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 3783/5000\n",
            "\n",
            "Epoch 3783: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6860e-04 - accuracy: 1.0000 - val_loss: 0.7354 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3784/5000\n",
            "\n",
            "Epoch 3784: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7576e-04 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3785/5000\n",
            "\n",
            "Epoch 3785: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7855e-04 - accuracy: 1.0000 - val_loss: 0.7170 - val_accuracy: 0.8489 - 2s/epoch - 50ms/step\n",
            "Epoch 3786/5000\n",
            "\n",
            "Epoch 3786: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.4418e-04 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8453 - 3s/epoch - 79ms/step\n",
            "Epoch 3787/5000\n",
            "\n",
            "Epoch 3787: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6581e-04 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.8489 - 2s/epoch - 52ms/step\n",
            "Epoch 3788/5000\n",
            "\n",
            "Epoch 3788: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8005e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3789/5000\n",
            "\n",
            "Epoch 3789: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8972e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3790/5000\n",
            "\n",
            "Epoch 3790: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8795e-04 - accuracy: 1.0000 - val_loss: 0.7076 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3791/5000\n",
            "\n",
            "Epoch 3791: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7969e-04 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8597 - 2s/epoch - 45ms/step\n",
            "Epoch 3792/5000\n",
            "\n",
            "Epoch 3792: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6647 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 3793/5000\n",
            "\n",
            "Epoch 3793: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8753e-04 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 0.8417 - 2s/epoch - 59ms/step\n",
            "Epoch 3794/5000\n",
            "\n",
            "Epoch 3794: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 8.3596e-04 - accuracy: 1.0000 - val_loss: 0.6600 - val_accuracy: 0.8453 - 3s/epoch - 78ms/step\n",
            "Epoch 3795/5000\n",
            "\n",
            "Epoch 3795: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.0093e-04 - accuracy: 1.0000 - val_loss: 0.6594 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3796/5000\n",
            "\n",
            "Epoch 3796: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.0987e-04 - accuracy: 1.0000 - val_loss: 0.6613 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3797/5000\n",
            "\n",
            "Epoch 3797: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9927e-04 - accuracy: 1.0000 - val_loss: 0.6669 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3798/5000\n",
            "\n",
            "Epoch 3798: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9873e-04 - accuracy: 1.0000 - val_loss: 0.6766 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3799/5000\n",
            "\n",
            "Epoch 3799: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4836e-04 - accuracy: 1.0000 - val_loss: 0.6788 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3800/5000\n",
            "\n",
            "Epoch 3800: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.3768e-04 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3801/5000\n",
            "\n",
            "Epoch 3801: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4268e-04 - accuracy: 1.0000 - val_loss: 0.6844 - val_accuracy: 0.8525 - 2s/epoch - 69ms/step\n",
            "Epoch 3802/5000\n",
            "\n",
            "Epoch 3802: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6665e-04 - accuracy: 1.0000 - val_loss: 0.6855 - val_accuracy: 0.8489 - 2s/epoch - 69ms/step\n",
            "Epoch 3803/5000\n",
            "\n",
            "Epoch 3803: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1263e-04 - accuracy: 1.0000 - val_loss: 0.6827 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3804/5000\n",
            "\n",
            "Epoch 3804: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2742e-04 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3805/5000\n",
            "\n",
            "Epoch 3805: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4119e-04 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3806/5000\n",
            "\n",
            "Epoch 3806: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4692e-04 - accuracy: 1.0000 - val_loss: 0.6813 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3807/5000\n",
            "\n",
            "Epoch 3807: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6754e-04 - accuracy: 1.0000 - val_loss: 0.6778 - val_accuracy: 0.8489 - 2s/epoch - 48ms/step\n",
            "Epoch 3808/5000\n",
            "\n",
            "Epoch 3808: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9782e-04 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 0.8417 - 2s/epoch - 47ms/step\n",
            "Epoch 3809/5000\n",
            "\n",
            "Epoch 3809: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.6987e-04 - accuracy: 1.0000 - val_loss: 0.6766 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 3810/5000\n",
            "\n",
            "Epoch 3810: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.3365e-04 - accuracy: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.8489 - 2s/epoch - 57ms/step\n",
            "Epoch 3811/5000\n",
            "\n",
            "Epoch 3811: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6225e-04 - accuracy: 1.0000 - val_loss: 0.6825 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3812/5000\n",
            "\n",
            "Epoch 3812: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8555e-04 - accuracy: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3813/5000\n",
            "\n",
            "Epoch 3813: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9889e-04 - accuracy: 1.0000 - val_loss: 0.6811 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3814/5000\n",
            "\n",
            "Epoch 3814: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0914e-04 - accuracy: 1.0000 - val_loss: 0.6813 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3815/5000\n",
            "\n",
            "Epoch 3815: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2144e-04 - accuracy: 1.0000 - val_loss: 0.6799 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3816/5000\n",
            "\n",
            "Epoch 3816: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3509e-04 - accuracy: 1.0000 - val_loss: 0.6808 - val_accuracy: 0.8489 - 2s/epoch - 55ms/step\n",
            "Epoch 3817/5000\n",
            "\n",
            "Epoch 3817: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.8771e-04 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8489 - 3s/epoch - 79ms/step\n",
            "Epoch 3818/5000\n",
            "\n",
            "Epoch 3818: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0719e-04 - accuracy: 1.0000 - val_loss: 0.6799 - val_accuracy: 0.8489 - 2s/epoch - 47ms/step\n",
            "Epoch 3819/5000\n",
            "\n",
            "Epoch 3819: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5289e-04 - accuracy: 1.0000 - val_loss: 0.6754 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3820/5000\n",
            "\n",
            "Epoch 3820: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1486e-04 - accuracy: 1.0000 - val_loss: 0.6771 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3821/5000\n",
            "\n",
            "Epoch 3821: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2620e-04 - accuracy: 1.0000 - val_loss: 0.6774 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3822/5000\n",
            "\n",
            "Epoch 3822: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5615e-04 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3823/5000\n",
            "\n",
            "Epoch 3823: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.3048e-04 - accuracy: 1.0000 - val_loss: 0.6664 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 3824/5000\n",
            "\n",
            "Epoch 3824: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0940e-04 - accuracy: 1.0000 - val_loss: 0.6750 - val_accuracy: 0.8381 - 2s/epoch - 62ms/step\n",
            "Epoch 3825/5000\n",
            "\n",
            "Epoch 3825: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.5989e-04 - accuracy: 1.0000 - val_loss: 0.6775 - val_accuracy: 0.8417 - 3s/epoch - 75ms/step\n",
            "Epoch 3826/5000\n",
            "\n",
            "Epoch 3826: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1719e-04 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3827/5000\n",
            "\n",
            "Epoch 3827: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7405e-04 - accuracy: 1.0000 - val_loss: 0.6647 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3828/5000\n",
            "\n",
            "Epoch 3828: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2021e-04 - accuracy: 1.0000 - val_loss: 0.6666 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3829/5000\n",
            "\n",
            "Epoch 3829: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2666e-04 - accuracy: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 3830/5000\n",
            "\n",
            "Epoch 3830: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0410e-04 - accuracy: 1.0000 - val_loss: 0.6812 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3831/5000\n",
            "\n",
            "Epoch 3831: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.0172e-04 - accuracy: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.8453 - 2s/epoch - 43ms/step\n",
            "Epoch 3832/5000\n",
            "\n",
            "Epoch 3832: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4391e-04 - accuracy: 1.0000 - val_loss: 0.6806 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 3833/5000\n",
            "\n",
            "Epoch 3833: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0219e-04 - accuracy: 1.0000 - val_loss: 0.6838 - val_accuracy: 0.8561 - 2s/epoch - 67ms/step\n",
            "Epoch 3834/5000\n",
            "\n",
            "Epoch 3834: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1325e-04 - accuracy: 1.0000 - val_loss: 0.6786 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3835/5000\n",
            "\n",
            "Epoch 3835: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9721e-04 - accuracy: 1.0000 - val_loss: 0.6804 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3836/5000\n",
            "\n",
            "Epoch 3836: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1871e-04 - accuracy: 1.0000 - val_loss: 0.6852 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3837/5000\n",
            "\n",
            "Epoch 3837: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9554e-04 - accuracy: 1.0000 - val_loss: 0.6819 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3838/5000\n",
            "\n",
            "Epoch 3838: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0039e-04 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3839/5000\n",
            "\n",
            "Epoch 3839: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9515e-04 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3840/5000\n",
            "\n",
            "Epoch 3840: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.8814e-04 - accuracy: 1.0000 - val_loss: 0.6832 - val_accuracy: 0.8525 - 3s/epoch - 77ms/step\n",
            "Epoch 3841/5000\n",
            "\n",
            "Epoch 3841: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8317e-04 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.8489 - 2s/epoch - 59ms/step\n",
            "Epoch 3842/5000\n",
            "\n",
            "Epoch 3842: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2015e-04 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3843/5000\n",
            "\n",
            "Epoch 3843: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6365e-04 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3844/5000\n",
            "\n",
            "Epoch 3844: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2445e-04 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 3845/5000\n",
            "\n",
            "Epoch 3845: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9490e-04 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3846/5000\n",
            "\n",
            "Epoch 3846: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7732e-04 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3847/5000\n",
            "\n",
            "Epoch 3847: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0944e-04 - accuracy: 1.0000 - val_loss: 0.6821 - val_accuracy: 0.8525 - 2s/epoch - 47ms/step\n",
            "Epoch 3848/5000\n",
            "\n",
            "Epoch 3848: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.6162e-04 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 3849/5000\n",
            "\n",
            "Epoch 3849: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8674e-04 - accuracy: 1.0000 - val_loss: 0.6805 - val_accuracy: 0.8453 - 2s/epoch - 53ms/step\n",
            "Epoch 3850/5000\n",
            "\n",
            "Epoch 3850: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1253e-04 - accuracy: 1.0000 - val_loss: 0.6808 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 3851/5000\n",
            "\n",
            "Epoch 3851: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2975e-04 - accuracy: 1.0000 - val_loss: 0.6875 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 3852/5000\n",
            "\n",
            "Epoch 3852: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1551e-04 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3853/5000\n",
            "\n",
            "Epoch 3853: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1358e-04 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3854/5000\n",
            "\n",
            "Epoch 3854: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6583e-04 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3855/5000\n",
            "\n",
            "Epoch 3855: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0676e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8525 - 2s/epoch - 55ms/step\n",
            "Epoch 3856/5000\n",
            "\n",
            "Epoch 3856: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.7128e-04 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8525 - 3s/epoch - 79ms/step\n",
            "Epoch 3857/5000\n",
            "\n",
            "Epoch 3857: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1107e-04 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.8489 - 2s/epoch - 48ms/step\n",
            "Epoch 3858/5000\n",
            "\n",
            "Epoch 3858: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0267e-04 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3859/5000\n",
            "\n",
            "Epoch 3859: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2516e-04 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3860/5000\n",
            "\n",
            "Epoch 3860: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8706e-04 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3861/5000\n",
            "\n",
            "Epoch 3861: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9081e-04 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3862/5000\n",
            "\n",
            "Epoch 3862: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0634e-04 - accuracy: 1.0000 - val_loss: 0.6883 - val_accuracy: 0.8525 - 2s/epoch - 46ms/step\n",
            "Epoch 3863/5000\n",
            "\n",
            "Epoch 3863: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8958e-04 - accuracy: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.8561 - 2s/epoch - 66ms/step\n",
            "Epoch 3864/5000\n",
            "\n",
            "Epoch 3864: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.0093e-04 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 3865/5000\n",
            "\n",
            "Epoch 3865: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3593e-04 - accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.8525 - 2s/epoch - 47ms/step\n",
            "Epoch 3866/5000\n",
            "\n",
            "Epoch 3866: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7707e-04 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3867/5000\n",
            "\n",
            "Epoch 3867: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1970e-04 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3868/5000\n",
            "\n",
            "Epoch 3868: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2758e-04 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3869/5000\n",
            "\n",
            "Epoch 3869: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7440e-04 - accuracy: 1.0000 - val_loss: 0.6774 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3870/5000\n",
            "\n",
            "Epoch 3870: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6298e-04 - accuracy: 1.0000 - val_loss: 0.6654 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3871/5000\n",
            "\n",
            "Epoch 3871: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.7738e-04 - accuracy: 1.0000 - val_loss: 0.6650 - val_accuracy: 0.8489 - 3s/epoch - 77ms/step\n",
            "Epoch 3872/5000\n",
            "\n",
            "Epoch 3872: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1523e-04 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.8489 - 2s/epoch - 60ms/step\n",
            "Epoch 3873/5000\n",
            "\n",
            "Epoch 3873: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1928e-04 - accuracy: 1.0000 - val_loss: 0.7002 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3874/5000\n",
            "\n",
            "Epoch 3874: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8273e-04 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 3875/5000\n",
            "\n",
            "Epoch 3875: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2627e-04 - accuracy: 1.0000 - val_loss: 0.6616 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3876/5000\n",
            "\n",
            "Epoch 3876: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.2829e-04 - accuracy: 1.0000 - val_loss: 0.6401 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3877/5000\n",
            "\n",
            "Epoch 3877: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2529e-04 - accuracy: 1.0000 - val_loss: 0.6833 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 3878/5000\n",
            "\n",
            "Epoch 3878: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0448e-04 - accuracy: 1.0000 - val_loss: 0.6815 - val_accuracy: 0.8597 - 2s/epoch - 50ms/step\n",
            "Epoch 3879/5000\n",
            "\n",
            "Epoch 3879: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.3173e-04 - accuracy: 1.0000 - val_loss: 0.6757 - val_accuracy: 0.8453 - 3s/epoch - 79ms/step\n",
            "Epoch 3880/5000\n",
            "\n",
            "Epoch 3880: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1200e-04 - accuracy: 1.0000 - val_loss: 0.6660 - val_accuracy: 0.8525 - 2s/epoch - 52ms/step\n",
            "Epoch 3881/5000\n",
            "\n",
            "Epoch 3881: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7694e-04 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3882/5000\n",
            "\n",
            "Epoch 3882: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9235e-04 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3883/5000\n",
            "\n",
            "Epoch 3883: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7377e-04 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3884/5000\n",
            "\n",
            "Epoch 3884: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9340e-04 - accuracy: 1.0000 - val_loss: 0.6676 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3885/5000\n",
            "\n",
            "Epoch 3885: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4044e-04 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 3886/5000\n",
            "\n",
            "Epoch 3886: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0691e-04 - accuracy: 1.0000 - val_loss: 0.7060 - val_accuracy: 0.8453 - 2s/epoch - 57ms/step\n",
            "Epoch 3887/5000\n",
            "\n",
            "Epoch 3887: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.2208e-04 - accuracy: 1.0000 - val_loss: 0.7230 - val_accuracy: 0.8453 - 3s/epoch - 80ms/step\n",
            "Epoch 3888/5000\n",
            "\n",
            "Epoch 3888: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4324e-04 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3889/5000\n",
            "\n",
            "Epoch 3889: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8947e-04 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3890/5000\n",
            "\n",
            "Epoch 3890: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8080e-04 - accuracy: 1.0000 - val_loss: 0.6850 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3891/5000\n",
            "\n",
            "Epoch 3891: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9574e-04 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3892/5000\n",
            "\n",
            "Epoch 3892: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2711e-04 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3893/5000\n",
            "\n",
            "Epoch 3893: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3288e-04 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3894/5000\n",
            "\n",
            "Epoch 3894: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2226e-04 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8417 - 2s/epoch - 67ms/step\n",
            "Epoch 3895/5000\n",
            "\n",
            "Epoch 3895: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8972e-04 - accuracy: 1.0000 - val_loss: 0.6919 - val_accuracy: 0.8561 - 2s/epoch - 70ms/step\n",
            "Epoch 3896/5000\n",
            "\n",
            "Epoch 3896: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7057e-04 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.8561 - 2s/epoch - 45ms/step\n",
            "Epoch 3897/5000\n",
            "\n",
            "Epoch 3897: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2400e-04 - accuracy: 1.0000 - val_loss: 0.6996 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3898/5000\n",
            "\n",
            "Epoch 3898: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8365e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3899/5000\n",
            "\n",
            "Epoch 3899: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5980e-04 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3900/5000\n",
            "\n",
            "Epoch 3900: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8984e-04 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3901/5000\n",
            "\n",
            "Epoch 3901: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5617e-04 - accuracy: 1.0000 - val_loss: 0.6951 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3902/5000\n",
            "\n",
            "Epoch 3902: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.5365e-04 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.8489 - 3s/epoch - 75ms/step\n",
            "Epoch 3903/5000\n",
            "\n",
            "Epoch 3903: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8677e-04 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8525 - 2s/epoch - 61ms/step\n",
            "Epoch 3904/5000\n",
            "\n",
            "Epoch 3904: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0449e-04 - accuracy: 1.0000 - val_loss: 0.6949 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3905/5000\n",
            "\n",
            "Epoch 3905: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9522e-04 - accuracy: 1.0000 - val_loss: 0.6821 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3906/5000\n",
            "\n",
            "Epoch 3906: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2468e-04 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3907/5000\n",
            "\n",
            "Epoch 3907: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9054e-04 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3908/5000\n",
            "\n",
            "Epoch 3908: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6569e-04 - accuracy: 1.0000 - val_loss: 0.6815 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3909/5000\n",
            "\n",
            "Epoch 3909: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4297e-04 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8453 - 2s/epoch - 49ms/step\n",
            "Epoch 3910/5000\n",
            "\n",
            "Epoch 3910: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.0452e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8381 - 3s/epoch - 79ms/step\n",
            "Epoch 3911/5000\n",
            "\n",
            "Epoch 3911: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.5386e-04 - accuracy: 1.0000 - val_loss: 0.7344 - val_accuracy: 0.8417 - 2s/epoch - 54ms/step\n",
            "Epoch 3912/5000\n",
            "\n",
            "Epoch 3912: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0527e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3913/5000\n",
            "\n",
            "Epoch 3913: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0183e-04 - accuracy: 1.0000 - val_loss: 0.6759 - val_accuracy: 0.8525 - 2s/epoch - 46ms/step\n",
            "Epoch 3914/5000\n",
            "\n",
            "Epoch 3914: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2843e-04 - accuracy: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3915/5000\n",
            "\n",
            "Epoch 3915: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1119e-04 - accuracy: 1.0000 - val_loss: 0.6768 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3916/5000\n",
            "\n",
            "Epoch 3916: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8677e-04 - accuracy: 1.0000 - val_loss: 0.6821 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3917/5000\n",
            "\n",
            "Epoch 3917: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7039e-04 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.8453 - 2s/epoch - 57ms/step\n",
            "Epoch 3918/5000\n",
            "\n",
            "Epoch 3918: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.8103e-04 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.8489 - 3s/epoch - 79ms/step\n",
            "Epoch 3919/5000\n",
            "\n",
            "Epoch 3919: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7026e-04 - accuracy: 1.0000 - val_loss: 0.6733 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3920/5000\n",
            "\n",
            "Epoch 3920: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1301e-04 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.8597 - 2s/epoch - 45ms/step\n",
            "Epoch 3921/5000\n",
            "\n",
            "Epoch 3921: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8059e-04 - accuracy: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 3922/5000\n",
            "\n",
            "Epoch 3922: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8398e-04 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 3923/5000\n",
            "\n",
            "Epoch 3923: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4375e-04 - accuracy: 1.0000 - val_loss: 0.6795 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3924/5000\n",
            "\n",
            "Epoch 3924: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3127e-04 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3925/5000\n",
            "\n",
            "Epoch 3925: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1604e-04 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.8417 - 2s/epoch - 67ms/step\n",
            "Epoch 3926/5000\n",
            "\n",
            "Epoch 3926: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.5272e-04 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 3927/5000\n",
            "\n",
            "Epoch 3927: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.3254e-04 - accuracy: 1.0000 - val_loss: 0.6722 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 3928/5000\n",
            "\n",
            "Epoch 3928: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.4453e-04 - accuracy: 1.0000 - val_loss: 0.7433 - val_accuracy: 0.8309 - 2s/epoch - 45ms/step\n",
            "Epoch 3929/5000\n",
            "\n",
            "Epoch 3929: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.4635e-04 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 3930/5000\n",
            "\n",
            "Epoch 3930: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9854e-04 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8525 - 2s/epoch - 46ms/step\n",
            "Epoch 3931/5000\n",
            "\n",
            "Epoch 3931: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2008e-04 - accuracy: 1.0000 - val_loss: 0.6766 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3932/5000\n",
            "\n",
            "Epoch 3932: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4217e-04 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3933/5000\n",
            "\n",
            "Epoch 3933: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.3439e-04 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 3934/5000\n",
            "\n",
            "Epoch 3934: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1566e-04 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8489 - 2s/epoch - 62ms/step\n",
            "Epoch 3935/5000\n",
            "\n",
            "Epoch 3935: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3136e-04 - accuracy: 1.0000 - val_loss: 0.6780 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 3936/5000\n",
            "\n",
            "Epoch 3936: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6984e-04 - accuracy: 1.0000 - val_loss: 0.6758 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3937/5000\n",
            "\n",
            "Epoch 3937: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9185e-04 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3938/5000\n",
            "\n",
            "Epoch 3938: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8036e-04 - accuracy: 1.0000 - val_loss: 0.6832 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3939/5000\n",
            "\n",
            "Epoch 3939: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6906e-04 - accuracy: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3940/5000\n",
            "\n",
            "Epoch 3940: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2339e-04 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.8561 - 2s/epoch - 55ms/step\n",
            "Epoch 3941/5000\n",
            "\n",
            "Epoch 3941: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.6731e-04 - accuracy: 1.0000 - val_loss: 0.6872 - val_accuracy: 0.8561 - 3s/epoch - 79ms/step\n",
            "Epoch 3942/5000\n",
            "\n",
            "Epoch 3942: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7563e-04 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8561 - 2s/epoch - 49ms/step\n",
            "Epoch 3943/5000\n",
            "\n",
            "Epoch 3943: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0899e-04 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3944/5000\n",
            "\n",
            "Epoch 3944: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1304e-04 - accuracy: 1.0000 - val_loss: 0.6570 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3945/5000\n",
            "\n",
            "Epoch 3945: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.7456e-04 - accuracy: 1.0000 - val_loss: 0.6235 - val_accuracy: 0.8417 - 2s/epoch - 47ms/step\n",
            "Epoch 3946/5000\n",
            "\n",
            "Epoch 3946: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7010e-04 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 0.8561 - 2s/epoch - 45ms/step\n",
            "Epoch 3947/5000\n",
            "\n",
            "Epoch 3947: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7085e-04 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3948/5000\n",
            "\n",
            "Epoch 3948: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.0607e-04 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.8417 - 2s/epoch - 63ms/step\n",
            "Epoch 3949/5000\n",
            "\n",
            "Epoch 3949: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 8.1576e-04 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8417 - 3s/epoch - 73ms/step\n",
            "Epoch 3950/5000\n",
            "\n",
            "Epoch 3950: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7416 - val_accuracy: 0.8129 - 2s/epoch - 44ms/step\n",
            "Epoch 3951/5000\n",
            "\n",
            "Epoch 3951: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3952/5000\n",
            "\n",
            "Epoch 3952: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.6619e-04 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 3953/5000\n",
            "\n",
            "Epoch 3953: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.1837e-04 - accuracy: 1.0000 - val_loss: 0.7341 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 3954/5000\n",
            "\n",
            "Epoch 3954: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5909e-04 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3955/5000\n",
            "\n",
            "Epoch 3955: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.0694e-04 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3956/5000\n",
            "\n",
            "Epoch 3956: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 8.1178e-04 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.8417 - 3s/epoch - 74ms/step\n",
            "Epoch 3957/5000\n",
            "\n",
            "Epoch 3957: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4499e-04 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.8381 - 2s/epoch - 63ms/step\n",
            "Epoch 3958/5000\n",
            "\n",
            "Epoch 3958: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1613e-04 - accuracy: 1.0000 - val_loss: 0.7176 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3959/5000\n",
            "\n",
            "Epoch 3959: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7385e-04 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 3960/5000\n",
            "\n",
            "Epoch 3960: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0096e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3961/5000\n",
            "\n",
            "Epoch 3961: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2578e-04 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3962/5000\n",
            "\n",
            "Epoch 3962: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0693e-04 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3963/5000\n",
            "\n",
            "Epoch 3963: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8403e-04 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8417 - 2s/epoch - 47ms/step\n",
            "Epoch 3964/5000\n",
            "\n",
            "Epoch 3964: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.9513e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8453 - 3s/epoch - 79ms/step\n",
            "Epoch 3965/5000\n",
            "\n",
            "Epoch 3965: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7499e-04 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.8489 - 2s/epoch - 53ms/step\n",
            "Epoch 3966/5000\n",
            "\n",
            "Epoch 3966: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9168e-04 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 3967/5000\n",
            "\n",
            "Epoch 3967: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2742e-04 - accuracy: 1.0000 - val_loss: 0.6940 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3968/5000\n",
            "\n",
            "Epoch 3968: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2587e-04 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 3969/5000\n",
            "\n",
            "Epoch 3969: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7218e-04 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8417 - 2s/epoch - 46ms/step\n",
            "Epoch 3970/5000\n",
            "\n",
            "Epoch 3970: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7010e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 3971/5000\n",
            "\n",
            "Epoch 3971: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6656e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8489 - 2s/epoch - 53ms/step\n",
            "Epoch 3972/5000\n",
            "\n",
            "Epoch 3972: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.8300e-04 - accuracy: 1.0000 - val_loss: 0.6982 - val_accuracy: 0.8453 - 3s/epoch - 78ms/step\n",
            "Epoch 3973/5000\n",
            "\n",
            "Epoch 3973: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.8381 - 2s/epoch - 50ms/step\n",
            "Epoch 3974/5000\n",
            "\n",
            "Epoch 3974: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.3484e-04 - accuracy: 1.0000 - val_loss: 0.6897 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 3975/5000\n",
            "\n",
            "Epoch 3975: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.3774e-04 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 3976/5000\n",
            "\n",
            "Epoch 3976: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6175e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 3977/5000\n",
            "\n",
            "Epoch 3977: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.8273 - 2s/epoch - 44ms/step\n",
            "Epoch 3978/5000\n",
            "\n",
            "Epoch 3978: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8381 - 2s/epoch - 43ms/step\n",
            "Epoch 3979/5000\n",
            "\n",
            "Epoch 3979: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.6417e-04 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.8345 - 2s/epoch - 61ms/step\n",
            "Epoch 3980/5000\n",
            "\n",
            "Epoch 3980: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 8.5775e-04 - accuracy: 1.0000 - val_loss: 0.7538 - val_accuracy: 0.8381 - 3s/epoch - 76ms/step\n",
            "Epoch 3981/5000\n",
            "\n",
            "Epoch 3981: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3231e-04 - accuracy: 1.0000 - val_loss: 0.7484 - val_accuracy: 0.8381 - 2s/epoch - 43ms/step\n",
            "Epoch 3982/5000\n",
            "\n",
            "Epoch 3982: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.6770e-04 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.8309 - 2s/epoch - 43ms/step\n",
            "Epoch 3983/5000\n",
            "\n",
            "Epoch 3983: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9729e-04 - accuracy: 1.0000 - val_loss: 0.7470 - val_accuracy: 0.8273 - 2s/epoch - 44ms/step\n",
            "Epoch 3984/5000\n",
            "\n",
            "Epoch 3984: val_accuracy did not improve from 0.86331\n",
            "35/35 - 1s - loss: 8.1908e-04 - accuracy: 1.0000 - val_loss: 0.7366 - val_accuracy: 0.8345 - 1s/epoch - 43ms/step\n",
            "Epoch 3985/5000\n",
            "\n",
            "Epoch 3985: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5433e-04 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 3986/5000\n",
            "\n",
            "Epoch 3986: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5380e-04 - accuracy: 1.0000 - val_loss: 0.7349 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 3987/5000\n",
            "\n",
            "Epoch 3987: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.7650e-04 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.8453 - 2s/epoch - 64ms/step\n",
            "Epoch 3988/5000\n",
            "\n",
            "Epoch 3988: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3989/5000\n",
            "\n",
            "Epoch 3989: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.2399e-04 - accuracy: 1.0000 - val_loss: 0.7625 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 3990/5000\n",
            "\n",
            "Epoch 3990: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6743e-04 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 3991/5000\n",
            "\n",
            "Epoch 3991: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5253e-04 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 3992/5000\n",
            "\n",
            "Epoch 3992: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7948e-04 - accuracy: 1.0000 - val_loss: 0.7179 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3993/5000\n",
            "\n",
            "Epoch 3993: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4609e-04 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3994/5000\n",
            "\n",
            "Epoch 3994: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9746e-04 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 3995/5000\n",
            "\n",
            "Epoch 3995: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2708e-04 - accuracy: 1.0000 - val_loss: 0.6811 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 3996/5000\n",
            "\n",
            "Epoch 3996: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8254e-04 - accuracy: 1.0000 - val_loss: 0.6783 - val_accuracy: 0.8525 - 2s/epoch - 65ms/step\n",
            "Epoch 3997/5000\n",
            "\n",
            "Epoch 3997: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8071e-04 - accuracy: 1.0000 - val_loss: 0.6804 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 3998/5000\n",
            "\n",
            "Epoch 3998: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8594e-04 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8561 - 2s/epoch - 45ms/step\n",
            "Epoch 3999/5000\n",
            "\n",
            "Epoch 3999: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0133e-04 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.8561 - 2s/epoch - 45ms/step\n",
            "Epoch 4000/5000\n",
            "\n",
            "Epoch 4000: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5824e-04 - accuracy: 1.0000 - val_loss: 0.6878 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4001/5000\n",
            "\n",
            "Epoch 4001: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9249e-04 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4002/5000\n",
            "\n",
            "Epoch 4002: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7888e-04 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.8417 - 2s/epoch - 46ms/step\n",
            "Epoch 4003/5000\n",
            "\n",
            "Epoch 4003: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.0535e-04 - accuracy: 1.0000 - val_loss: 0.6860 - val_accuracy: 0.8453 - 3s/epoch - 78ms/step\n",
            "Epoch 4004/5000\n",
            "\n",
            "Epoch 4004: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8690e-04 - accuracy: 1.0000 - val_loss: 0.6897 - val_accuracy: 0.8417 - 2s/epoch - 56ms/step\n",
            "Epoch 4005/5000\n",
            "\n",
            "Epoch 4005: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4763e-04 - accuracy: 1.0000 - val_loss: 0.6849 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4006/5000\n",
            "\n",
            "Epoch 4006: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.0629e-04 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4007/5000\n",
            "\n",
            "Epoch 4007: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8567e-04 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4008/5000\n",
            "\n",
            "Epoch 4008: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.7378 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4009/5000\n",
            "\n",
            "Epoch 4009: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7589 - val_accuracy: 0.8309 - 2s/epoch - 43ms/step\n",
            "Epoch 4010/5000\n",
            "\n",
            "Epoch 4010: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7388 - val_accuracy: 0.8381 - 2s/epoch - 49ms/step\n",
            "Epoch 4011/5000\n",
            "\n",
            "Epoch 4011: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.6934 - val_accuracy: 0.8273 - 3s/epoch - 79ms/step\n",
            "Epoch 4012/5000\n",
            "\n",
            "Epoch 4012: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.8345 - 2s/epoch - 52ms/step\n",
            "Epoch 4013/5000\n",
            "\n",
            "Epoch 4013: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.9596e-04 - accuracy: 1.0000 - val_loss: 0.7273 - val_accuracy: 0.8381 - 2s/epoch - 43ms/step\n",
            "Epoch 4014/5000\n",
            "\n",
            "Epoch 4014: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.8309 - 2s/epoch - 45ms/step\n",
            "Epoch 4015/5000\n",
            "\n",
            "Epoch 4015: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.5113e-04 - accuracy: 1.0000 - val_loss: 0.6967 - val_accuracy: 0.8381 - 2s/epoch - 43ms/step\n",
            "Epoch 4016/5000\n",
            "\n",
            "Epoch 4016: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5652e-04 - accuracy: 1.0000 - val_loss: 0.6982 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4017/5000\n",
            "\n",
            "Epoch 4017: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.0661e-04 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4018/5000\n",
            "\n",
            "Epoch 4018: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5662e-04 - accuracy: 1.0000 - val_loss: 0.7048 - val_accuracy: 0.8417 - 2s/epoch - 52ms/step\n",
            "Epoch 4019/5000\n",
            "\n",
            "Epoch 4019: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.3486e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.8381 - 3s/epoch - 79ms/step\n",
            "Epoch 4020/5000\n",
            "\n",
            "Epoch 4020: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.5701e-04 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.8345 - 2s/epoch - 48ms/step\n",
            "Epoch 4021/5000\n",
            "\n",
            "Epoch 4021: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6638e-04 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4022/5000\n",
            "\n",
            "Epoch 4022: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1616e-04 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.8381 - 2s/epoch - 43ms/step\n",
            "Epoch 4023/5000\n",
            "\n",
            "Epoch 4023: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8054e-04 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.8381 - 2s/epoch - 43ms/step\n",
            "Epoch 4024/5000\n",
            "\n",
            "Epoch 4024: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0064e-04 - accuracy: 1.0000 - val_loss: 0.7032 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4025/5000\n",
            "\n",
            "Epoch 4025: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3544e-04 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4026/5000\n",
            "\n",
            "Epoch 4026: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3671e-04 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.8417 - 2s/epoch - 55ms/step\n",
            "Epoch 4027/5000\n",
            "\n",
            "Epoch 4027: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 8.0652e-04 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 4028/5000\n",
            "\n",
            "Epoch 4028: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7523e-04 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4029/5000\n",
            "\n",
            "Epoch 4029: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0826e-04 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.8489 - 2s/epoch - 43ms/step\n",
            "Epoch 4030/5000\n",
            "\n",
            "Epoch 4030: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1537e-04 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4031/5000\n",
            "\n",
            "Epoch 4031: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.1772e-04 - accuracy: 1.0000 - val_loss: 0.7227 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4032/5000\n",
            "\n",
            "Epoch 4032: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.8753e-04 - accuracy: 1.0000 - val_loss: 0.7285 - val_accuracy: 0.8597 - 2s/epoch - 44ms/step\n",
            "Epoch 4033/5000\n",
            "\n",
            "Epoch 4033: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1605e-04 - accuracy: 1.0000 - val_loss: 0.7150 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4034/5000\n",
            "\n",
            "Epoch 4034: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4296e-04 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8525 - 2s/epoch - 58ms/step\n",
            "Epoch 4035/5000\n",
            "\n",
            "Epoch 4035: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.8835e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8489 - 3s/epoch - 76ms/step\n",
            "Epoch 4036/5000\n",
            "\n",
            "Epoch 4036: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8407e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4037/5000\n",
            "\n",
            "Epoch 4037: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8601e-04 - accuracy: 1.0000 - val_loss: 0.7032 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4038/5000\n",
            "\n",
            "Epoch 4038: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2317e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4039/5000\n",
            "\n",
            "Epoch 4039: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1360e-04 - accuracy: 1.0000 - val_loss: 0.7043 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4040/5000\n",
            "\n",
            "Epoch 4040: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.5632e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4041/5000\n",
            "\n",
            "Epoch 4041: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2344e-04 - accuracy: 1.0000 - val_loss: 0.6992 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4042/5000\n",
            "\n",
            "Epoch 4042: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.8453 - 2s/epoch - 65ms/step\n",
            "Epoch 4043/5000\n",
            "\n",
            "Epoch 4043: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.5493e-04 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4044/5000\n",
            "\n",
            "Epoch 4044: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4487e-04 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4045/5000\n",
            "\n",
            "Epoch 4045: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5050e-04 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4046/5000\n",
            "\n",
            "Epoch 4046: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8273e-04 - accuracy: 1.0000 - val_loss: 0.7086 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4047/5000\n",
            "\n",
            "Epoch 4047: val_accuracy did not improve from 0.86331\n",
            "35/35 - 1s - loss: 7.0140e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8453 - 1s/epoch - 43ms/step\n",
            "Epoch 4048/5000\n",
            "\n",
            "Epoch 4048: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9403e-04 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4049/5000\n",
            "\n",
            "Epoch 4049: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0635e-04 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4050/5000\n",
            "\n",
            "Epoch 4050: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9695e-04 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.8453 - 2s/epoch - 69ms/step\n",
            "Epoch 4051/5000\n",
            "\n",
            "Epoch 4051: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8969e-04 - accuracy: 1.0000 - val_loss: 0.7093 - val_accuracy: 0.8417 - 2s/epoch - 65ms/step\n",
            "Epoch 4052/5000\n",
            "\n",
            "Epoch 4052: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7476e-04 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4053/5000\n",
            "\n",
            "Epoch 4053: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3307e-04 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4054/5000\n",
            "\n",
            "Epoch 4054: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9388e-04 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.8453 - 2s/epoch - 43ms/step\n",
            "Epoch 4055/5000\n",
            "\n",
            "Epoch 4055: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5127e-04 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4056/5000\n",
            "\n",
            "Epoch 4056: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4266e-04 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4057/5000\n",
            "\n",
            "Epoch 4057: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6523e-04 - accuracy: 1.0000 - val_loss: 0.7145 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4058/5000\n",
            "\n",
            "Epoch 4058: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.5239e-04 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.8489 - 3s/epoch - 73ms/step\n",
            "Epoch 4059/5000\n",
            "\n",
            "Epoch 4059: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5709e-04 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.8453 - 2s/epoch - 61ms/step\n",
            "Epoch 4060/5000\n",
            "\n",
            "Epoch 4060: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1147e-04 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4061/5000\n",
            "\n",
            "Epoch 4061: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6696e-04 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4062/5000\n",
            "\n",
            "Epoch 4062: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4888e-04 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4063/5000\n",
            "\n",
            "Epoch 4063: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7744e-04 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4064/5000\n",
            "\n",
            "Epoch 4064: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5357e-04 - accuracy: 1.0000 - val_loss: 0.7055 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4065/5000\n",
            "\n",
            "Epoch 4065: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8956e-04 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4066/5000\n",
            "\n",
            "Epoch 4066: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.7222e-04 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.8453 - 3s/epoch - 77ms/step\n",
            "Epoch 4067/5000\n",
            "\n",
            "Epoch 4067: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8120e-04 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.8417 - 2s/epoch - 58ms/step\n",
            "Epoch 4068/5000\n",
            "\n",
            "Epoch 4068: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7989e-04 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4069/5000\n",
            "\n",
            "Epoch 4069: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8623e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4070/5000\n",
            "\n",
            "Epoch 4070: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5234e-04 - accuracy: 1.0000 - val_loss: 0.6996 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4071/5000\n",
            "\n",
            "Epoch 4071: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3399e-04 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4072/5000\n",
            "\n",
            "Epoch 4072: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5854e-04 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4073/5000\n",
            "\n",
            "Epoch 4073: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5617e-04 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.8525 - 2s/epoch - 48ms/step\n",
            "Epoch 4074/5000\n",
            "\n",
            "Epoch 4074: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.4067e-04 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8525 - 3s/epoch - 79ms/step\n",
            "Epoch 4075/5000\n",
            "\n",
            "Epoch 4075: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7066e-04 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.8489 - 2s/epoch - 52ms/step\n",
            "Epoch 4076/5000\n",
            "\n",
            "Epoch 4076: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5257e-04 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4077/5000\n",
            "\n",
            "Epoch 4077: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4351e-04 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4078/5000\n",
            "\n",
            "Epoch 4078: val_accuracy did not improve from 0.86331\n",
            "35/35 - 1s - loss: 6.3657e-04 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.8489 - 1s/epoch - 43ms/step\n",
            "Epoch 4079/5000\n",
            "\n",
            "Epoch 4079: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6789e-04 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4080/5000\n",
            "\n",
            "Epoch 4080: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.2206e-04 - accuracy: 1.0000 - val_loss: 0.6631 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4081/5000\n",
            "\n",
            "Epoch 4081: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9003e-04 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.8417 - 2s/epoch - 54ms/step\n",
            "Epoch 4082/5000\n",
            "\n",
            "Epoch 4082: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.9393e-04 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8417 - 3s/epoch - 83ms/step\n",
            "Epoch 4083/5000\n",
            "\n",
            "Epoch 4083: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0826e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8453 - 2s/epoch - 43ms/step\n",
            "Epoch 4084/5000\n",
            "\n",
            "Epoch 4084: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7889 - val_accuracy: 0.8309 - 2s/epoch - 44ms/step\n",
            "Epoch 4085/5000\n",
            "\n",
            "Epoch 4085: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1168e-04 - accuracy: 1.0000 - val_loss: 0.7224 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4086/5000\n",
            "\n",
            "Epoch 4086: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.7984e-04 - accuracy: 1.0000 - val_loss: 0.6808 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4087/5000\n",
            "\n",
            "Epoch 4087: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.7198 - val_accuracy: 0.8201 - 2s/epoch - 45ms/step\n",
            "Epoch 4088/5000\n",
            "\n",
            "Epoch 4088: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4089/5000\n",
            "\n",
            "Epoch 4089: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.7740 - val_accuracy: 0.8309 - 2s/epoch - 62ms/step\n",
            "Epoch 4090/5000\n",
            "\n",
            "Epoch 4090: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.8345 - 3s/epoch - 72ms/step\n",
            "Epoch 4091/5000\n",
            "\n",
            "Epoch 4091: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9798e-04 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4092/5000\n",
            "\n",
            "Epoch 4092: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.0799e-04 - accuracy: 1.0000 - val_loss: 0.7311 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4093/5000\n",
            "\n",
            "Epoch 4093: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.8074e-04 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4094/5000\n",
            "\n",
            "Epoch 4094: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6743e-04 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4095/5000\n",
            "\n",
            "Epoch 4095: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2534e-04 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4096/5000\n",
            "\n",
            "Epoch 4096: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6110e-04 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4097/5000\n",
            "\n",
            "Epoch 4097: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5584e-04 - accuracy: 1.0000 - val_loss: 0.7269 - val_accuracy: 0.8417 - 2s/epoch - 67ms/step\n",
            "Epoch 4098/5000\n",
            "\n",
            "Epoch 4098: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5646e-04 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.8417 - 2s/epoch - 67ms/step\n",
            "Epoch 4099/5000\n",
            "\n",
            "Epoch 4099: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7272 - val_accuracy: 0.8309 - 2s/epoch - 44ms/step\n",
            "Epoch 4100/5000\n",
            "\n",
            "Epoch 4100: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9300e-04 - accuracy: 1.0000 - val_loss: 0.7076 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4101/5000\n",
            "\n",
            "Epoch 4101: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1135e-04 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4102/5000\n",
            "\n",
            "Epoch 4102: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1343e-04 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4103/5000\n",
            "\n",
            "Epoch 4103: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5971e-04 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4104/5000\n",
            "\n",
            "Epoch 4104: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8022e-04 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4105/5000\n",
            "\n",
            "Epoch 4105: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.4702e-04 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.8453 - 3s/epoch - 73ms/step\n",
            "Epoch 4106/5000\n",
            "\n",
            "Epoch 4106: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.5061e-04 - accuracy: 1.0000 - val_loss: 0.7256 - val_accuracy: 0.8453 - 2s/epoch - 62ms/step\n",
            "Epoch 4107/5000\n",
            "\n",
            "Epoch 4107: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3392e-04 - accuracy: 1.0000 - val_loss: 0.7224 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4108/5000\n",
            "\n",
            "Epoch 4108: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.4558e-04 - accuracy: 1.0000 - val_loss: 0.7151 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4109/5000\n",
            "\n",
            "Epoch 4109: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9518e-04 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4110/5000\n",
            "\n",
            "Epoch 4110: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.4653e-04 - accuracy: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.8381 - 2s/epoch - 46ms/step\n",
            "Epoch 4111/5000\n",
            "\n",
            "Epoch 4111: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8992e-04 - accuracy: 1.0000 - val_loss: 0.6982 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4112/5000\n",
            "\n",
            "Epoch 4112: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7430 - val_accuracy: 0.8237 - 2s/epoch - 47ms/step\n",
            "Epoch 4113/5000\n",
            "\n",
            "Epoch 4113: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.8979e-04 - accuracy: 1.0000 - val_loss: 0.7308 - val_accuracy: 0.8345 - 3s/epoch - 77ms/step\n",
            "Epoch 4114/5000\n",
            "\n",
            "Epoch 4114: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8757e-04 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.8345 - 2s/epoch - 56ms/step\n",
            "Epoch 4115/5000\n",
            "\n",
            "Epoch 4115: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7196e-04 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.8345 - 2s/epoch - 45ms/step\n",
            "Epoch 4116/5000\n",
            "\n",
            "Epoch 4116: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7742e-04 - accuracy: 1.0000 - val_loss: 0.7256 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4117/5000\n",
            "\n",
            "Epoch 4117: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2327e-04 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.8309 - 2s/epoch - 45ms/step\n",
            "Epoch 4118/5000\n",
            "\n",
            "Epoch 4118: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7428e-04 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4119/5000\n",
            "\n",
            "Epoch 4119: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.8018 - val_accuracy: 0.8201 - 2s/epoch - 45ms/step\n",
            "Epoch 4120/5000\n",
            "\n",
            "Epoch 4120: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.3996e-04 - accuracy: 1.0000 - val_loss: 0.7556 - val_accuracy: 0.8417 - 2s/epoch - 53ms/step\n",
            "Epoch 4121/5000\n",
            "\n",
            "Epoch 4121: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.8345 - 3s/epoch - 79ms/step\n",
            "Epoch 4122/5000\n",
            "\n",
            "Epoch 4122: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1391e-04 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8381 - 2s/epoch - 49ms/step\n",
            "Epoch 4123/5000\n",
            "\n",
            "Epoch 4123: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.1441e-04 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4124/5000\n",
            "\n",
            "Epoch 4124: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1504e-04 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4125/5000\n",
            "\n",
            "Epoch 4125: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6340e-04 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4126/5000\n",
            "\n",
            "Epoch 4126: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.5735e-04 - accuracy: 1.0000 - val_loss: 0.7245 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4127/5000\n",
            "\n",
            "Epoch 4127: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4987e-04 - accuracy: 1.0000 - val_loss: 0.7218 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4128/5000\n",
            "\n",
            "Epoch 4128: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9857e-04 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.8417 - 2s/epoch - 59ms/step\n",
            "Epoch 4129/5000\n",
            "\n",
            "Epoch 4129: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.5227e-04 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.8489 - 3s/epoch - 77ms/step\n",
            "Epoch 4130/5000\n",
            "\n",
            "Epoch 4130: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0696e-04 - accuracy: 1.0000 - val_loss: 0.7195 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4131/5000\n",
            "\n",
            "Epoch 4131: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5945e-04 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4132/5000\n",
            "\n",
            "Epoch 4132: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5443e-04 - accuracy: 1.0000 - val_loss: 0.7150 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4133/5000\n",
            "\n",
            "Epoch 4133: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7816e-04 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4134/5000\n",
            "\n",
            "Epoch 4134: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4809e-04 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4135/5000\n",
            "\n",
            "Epoch 4135: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6509e-04 - accuracy: 1.0000 - val_loss: 0.7015 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4136/5000\n",
            "\n",
            "Epoch 4136: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7037e-04 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.8525 - 2s/epoch - 68ms/step\n",
            "Epoch 4137/5000\n",
            "\n",
            "Epoch 4137: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4451e-04 - accuracy: 1.0000 - val_loss: 0.7066 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4138/5000\n",
            "\n",
            "Epoch 4138: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9114e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4139/5000\n",
            "\n",
            "Epoch 4139: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8575e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4140/5000\n",
            "\n",
            "Epoch 4140: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8389e-04 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4141/5000\n",
            "\n",
            "Epoch 4141: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6872e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8489 - 2s/epoch - 43ms/step\n",
            "Epoch 4142/5000\n",
            "\n",
            "Epoch 4142: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7212e-04 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4143/5000\n",
            "\n",
            "Epoch 4143: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5831e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4144/5000\n",
            "\n",
            "Epoch 4144: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.5095e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8453 - 3s/epoch - 75ms/step\n",
            "Epoch 4145/5000\n",
            "\n",
            "Epoch 4145: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9935e-04 - accuracy: 1.0000 - val_loss: 0.7060 - val_accuracy: 0.8525 - 2s/epoch - 62ms/step\n",
            "Epoch 4146/5000\n",
            "\n",
            "Epoch 4146: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6613e-04 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4147/5000\n",
            "\n",
            "Epoch 4147: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4808e-04 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4148/5000\n",
            "\n",
            "Epoch 4148: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3783e-04 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4149/5000\n",
            "\n",
            "Epoch 4149: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2147e-04 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4150/5000\n",
            "\n",
            "Epoch 4150: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3755e-04 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4151/5000\n",
            "\n",
            "Epoch 4151: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.7069e-04 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.8417 - 2s/epoch - 48ms/step\n",
            "Epoch 4152/5000\n",
            "\n",
            "Epoch 4152: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.7244e-04 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8525 - 3s/epoch - 78ms/step\n",
            "Epoch 4153/5000\n",
            "\n",
            "Epoch 4153: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3966e-04 - accuracy: 1.0000 - val_loss: 0.6844 - val_accuracy: 0.8453 - 2s/epoch - 55ms/step\n",
            "Epoch 4154/5000\n",
            "\n",
            "Epoch 4154: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4477e-04 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4155/5000\n",
            "\n",
            "Epoch 4155: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0044e-04 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4156/5000\n",
            "\n",
            "Epoch 4156: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7704e-04 - accuracy: 1.0000 - val_loss: 0.6848 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4157/5000\n",
            "\n",
            "Epoch 4157: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5798e-04 - accuracy: 1.0000 - val_loss: 0.6996 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4158/5000\n",
            "\n",
            "Epoch 4158: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8226e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4159/5000\n",
            "\n",
            "Epoch 4159: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.9437e-04 - accuracy: 1.0000 - val_loss: 0.7274 - val_accuracy: 0.8489 - 2s/epoch - 50ms/step\n",
            "Epoch 4160/5000\n",
            "\n",
            "Epoch 4160: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.9809e-04 - accuracy: 1.0000 - val_loss: 0.7218 - val_accuracy: 0.8453 - 3s/epoch - 78ms/step\n",
            "Epoch 4161/5000\n",
            "\n",
            "Epoch 4161: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2490e-04 - accuracy: 1.0000 - val_loss: 0.7152 - val_accuracy: 0.8453 - 2s/epoch - 50ms/step\n",
            "Epoch 4162/5000\n",
            "\n",
            "Epoch 4162: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.3007e-04 - accuracy: 1.0000 - val_loss: 0.6967 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4163/5000\n",
            "\n",
            "Epoch 4163: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6056e-04 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4164/5000\n",
            "\n",
            "Epoch 4164: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4694e-04 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.8489 - 2s/epoch - 46ms/step\n",
            "Epoch 4165/5000\n",
            "\n",
            "Epoch 4165: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6041e-04 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4166/5000\n",
            "\n",
            "Epoch 4166: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4151e-04 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4167/5000\n",
            "\n",
            "Epoch 4167: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5812e-04 - accuracy: 1.0000 - val_loss: 0.7066 - val_accuracy: 0.8525 - 2s/epoch - 58ms/step\n",
            "Epoch 4168/5000\n",
            "\n",
            "Epoch 4168: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.3556e-04 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8525 - 3s/epoch - 77ms/step\n",
            "Epoch 4169/5000\n",
            "\n",
            "Epoch 4169: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6269e-04 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4170/5000\n",
            "\n",
            "Epoch 4170: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6640e-04 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4171/5000\n",
            "\n",
            "Epoch 4171: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5098e-04 - accuracy: 1.0000 - val_loss: 0.6919 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4172/5000\n",
            "\n",
            "Epoch 4172: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1598e-04 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4173/5000\n",
            "\n",
            "Epoch 4173: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5289e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8489 - 2s/epoch - 46ms/step\n",
            "Epoch 4174/5000\n",
            "\n",
            "Epoch 4174: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2867e-04 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4175/5000\n",
            "\n",
            "Epoch 4175: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9769e-04 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8489 - 2s/epoch - 67ms/step\n",
            "Epoch 4176/5000\n",
            "\n",
            "Epoch 4176: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8509e-04 - accuracy: 1.0000 - val_loss: 0.6716 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4177/5000\n",
            "\n",
            "Epoch 4177: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9205e-04 - accuracy: 1.0000 - val_loss: 0.6820 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4178/5000\n",
            "\n",
            "Epoch 4178: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3373e-04 - accuracy: 1.0000 - val_loss: 0.6854 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4179/5000\n",
            "\n",
            "Epoch 4179: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8122e-04 - accuracy: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4180/5000\n",
            "\n",
            "Epoch 4180: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7121e-04 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4181/5000\n",
            "\n",
            "Epoch 4181: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2909e-04 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8561 - 2s/epoch - 45ms/step\n",
            "Epoch 4182/5000\n",
            "\n",
            "Epoch 4182: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9323e-04 - accuracy: 1.0000 - val_loss: 0.6785 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4183/5000\n",
            "\n",
            "Epoch 4183: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.0062e-04 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.8525 - 3s/epoch - 76ms/step\n",
            "Epoch 4184/5000\n",
            "\n",
            "Epoch 4184: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1635e-04 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8525 - 2s/epoch - 61ms/step\n",
            "Epoch 4185/5000\n",
            "\n",
            "Epoch 4185: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3534e-04 - accuracy: 1.0000 - val_loss: 0.6944 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4186/5000\n",
            "\n",
            "Epoch 4186: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5744e-04 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.8561 - 2s/epoch - 45ms/step\n",
            "Epoch 4187/5000\n",
            "\n",
            "Epoch 4187: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7312e-04 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4188/5000\n",
            "\n",
            "Epoch 4188: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3556e-04 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4189/5000\n",
            "\n",
            "Epoch 4189: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3665e-04 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4190/5000\n",
            "\n",
            "Epoch 4190: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4644e-04 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.8525 - 2s/epoch - 48ms/step\n",
            "Epoch 4191/5000\n",
            "\n",
            "Epoch 4191: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.5001e-04 - accuracy: 1.0000 - val_loss: 0.6850 - val_accuracy: 0.8525 - 3s/epoch - 79ms/step\n",
            "Epoch 4192/5000\n",
            "\n",
            "Epoch 4192: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4634e-04 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.8561 - 2s/epoch - 53ms/step\n",
            "Epoch 4193/5000\n",
            "\n",
            "Epoch 4193: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1581e-04 - accuracy: 1.0000 - val_loss: 0.6882 - val_accuracy: 0.8561 - 2s/epoch - 45ms/step\n",
            "Epoch 4194/5000\n",
            "\n",
            "Epoch 4194: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4783e-04 - accuracy: 1.0000 - val_loss: 0.6835 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4195/5000\n",
            "\n",
            "Epoch 4195: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1066e-04 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4196/5000\n",
            "\n",
            "Epoch 4196: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4691e-04 - accuracy: 1.0000 - val_loss: 0.6839 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4197/5000\n",
            "\n",
            "Epoch 4197: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1913e-04 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4198/5000\n",
            "\n",
            "Epoch 4198: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1135e-04 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.8417 - 2s/epoch - 55ms/step\n",
            "Epoch 4199/5000\n",
            "\n",
            "Epoch 4199: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.1847e-04 - accuracy: 1.0000 - val_loss: 0.6845 - val_accuracy: 0.8453 - 3s/epoch - 79ms/step\n",
            "Epoch 4200/5000\n",
            "\n",
            "Epoch 4200: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3427e-04 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8453 - 2s/epoch - 47ms/step\n",
            "Epoch 4201/5000\n",
            "\n",
            "Epoch 4201: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5240e-04 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4202/5000\n",
            "\n",
            "Epoch 4202: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8646e-04 - accuracy: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4203/5000\n",
            "\n",
            "Epoch 4203: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4774e-04 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4204/5000\n",
            "\n",
            "Epoch 4204: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6367e-04 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4205/5000\n",
            "\n",
            "Epoch 4205: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5230e-04 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4206/5000\n",
            "\n",
            "Epoch 4206: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3609e-04 - accuracy: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.8453 - 2s/epoch - 63ms/step\n",
            "Epoch 4207/5000\n",
            "\n",
            "Epoch 4207: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.2404e-04 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8453 - 3s/epoch - 73ms/step\n",
            "Epoch 4208/5000\n",
            "\n",
            "Epoch 4208: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6923e-04 - accuracy: 1.0000 - val_loss: 0.6683 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4209/5000\n",
            "\n",
            "Epoch 4209: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3492e-04 - accuracy: 1.0000 - val_loss: 0.6596 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4210/5000\n",
            "\n",
            "Epoch 4210: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5654e-04 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4211/5000\n",
            "\n",
            "Epoch 4211: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0035e-04 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4212/5000\n",
            "\n",
            "Epoch 4212: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6779e-04 - accuracy: 1.0000 - val_loss: 0.6930 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4213/5000\n",
            "\n",
            "Epoch 4213: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6567e-04 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4214/5000\n",
            "\n",
            "Epoch 4214: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6034e-04 - accuracy: 1.0000 - val_loss: 0.7031 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4215/5000\n",
            "\n",
            "Epoch 4215: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4459e-04 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.8417 - 2s/epoch - 65ms/step\n",
            "Epoch 4216/5000\n",
            "\n",
            "Epoch 4216: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5961e-04 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4217/5000\n",
            "\n",
            "Epoch 4217: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3555e-04 - accuracy: 1.0000 - val_loss: 0.6903 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4218/5000\n",
            "\n",
            "Epoch 4218: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4046e-04 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4219/5000\n",
            "\n",
            "Epoch 4219: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9252e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4220/5000\n",
            "\n",
            "Epoch 4220: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1626e-04 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4221/5000\n",
            "\n",
            "Epoch 4221: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8894e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4222/5000\n",
            "\n",
            "Epoch 4222: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 9.6335e-04 - accuracy: 1.0000 - val_loss: 0.6883 - val_accuracy: 0.8417 - 3s/epoch - 78ms/step\n",
            "Epoch 4223/5000\n",
            "\n",
            "Epoch 4223: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.8381 - 2s/epoch - 58ms/step\n",
            "Epoch 4224/5000\n",
            "\n",
            "Epoch 4224: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.7928 - val_accuracy: 0.8237 - 2s/epoch - 44ms/step\n",
            "Epoch 4225/5000\n",
            "\n",
            "Epoch 4225: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7729 - val_accuracy: 0.8237 - 2s/epoch - 44ms/step\n",
            "Epoch 4226/5000\n",
            "\n",
            "Epoch 4226: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.8430e-04 - accuracy: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.8237 - 2s/epoch - 44ms/step\n",
            "Epoch 4227/5000\n",
            "\n",
            "Epoch 4227: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.1280e-04 - accuracy: 1.0000 - val_loss: 0.7762 - val_accuracy: 0.8237 - 2s/epoch - 44ms/step\n",
            "Epoch 4228/5000\n",
            "\n",
            "Epoch 4228: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5507e-04 - accuracy: 1.0000 - val_loss: 0.7758 - val_accuracy: 0.8237 - 2s/epoch - 44ms/step\n",
            "Epoch 4229/5000\n",
            "\n",
            "Epoch 4229: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7554 - val_accuracy: 0.8309 - 2s/epoch - 50ms/step\n",
            "Epoch 4230/5000\n",
            "\n",
            "Epoch 4230: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 8.4547e-04 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.8273 - 3s/epoch - 78ms/step\n",
            "Epoch 4231/5000\n",
            "\n",
            "Epoch 4231: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9163e-04 - accuracy: 1.0000 - val_loss: 0.7585 - val_accuracy: 0.8273 - 2s/epoch - 52ms/step\n",
            "Epoch 4232/5000\n",
            "\n",
            "Epoch 4232: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9019e-04 - accuracy: 1.0000 - val_loss: 0.7558 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4233/5000\n",
            "\n",
            "Epoch 4233: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9460e-04 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.8345 - 2s/epoch - 43ms/step\n",
            "Epoch 4234/5000\n",
            "\n",
            "Epoch 4234: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7071e-04 - accuracy: 1.0000 - val_loss: 0.7474 - val_accuracy: 0.8345 - 2s/epoch - 46ms/step\n",
            "Epoch 4235/5000\n",
            "\n",
            "Epoch 4235: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9507e-04 - accuracy: 1.0000 - val_loss: 0.7437 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4236/5000\n",
            "\n",
            "Epoch 4236: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3844e-04 - accuracy: 1.0000 - val_loss: 0.7425 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4237/5000\n",
            "\n",
            "Epoch 4237: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7422e-04 - accuracy: 1.0000 - val_loss: 0.7408 - val_accuracy: 0.8381 - 2s/epoch - 54ms/step\n",
            "Epoch 4238/5000\n",
            "\n",
            "Epoch 4238: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.7285e-04 - accuracy: 1.0000 - val_loss: 0.7403 - val_accuracy: 0.8381 - 3s/epoch - 77ms/step\n",
            "Epoch 4239/5000\n",
            "\n",
            "Epoch 4239: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5832e-04 - accuracy: 1.0000 - val_loss: 0.7335 - val_accuracy: 0.8381 - 2s/epoch - 47ms/step\n",
            "Epoch 4240/5000\n",
            "\n",
            "Epoch 4240: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6455e-04 - accuracy: 1.0000 - val_loss: 0.7299 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4241/5000\n",
            "\n",
            "Epoch 4241: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4401e-04 - accuracy: 1.0000 - val_loss: 0.7272 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4242/5000\n",
            "\n",
            "Epoch 4242: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6664e-04 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4243/5000\n",
            "\n",
            "Epoch 4243: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7104e-04 - accuracy: 1.0000 - val_loss: 0.7297 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4244/5000\n",
            "\n",
            "Epoch 4244: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8365e-04 - accuracy: 1.0000 - val_loss: 0.7256 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4245/5000\n",
            "\n",
            "Epoch 4245: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5744e-04 - accuracy: 1.0000 - val_loss: 0.7279 - val_accuracy: 0.8417 - 2s/epoch - 58ms/step\n",
            "Epoch 4246/5000\n",
            "\n",
            "Epoch 4246: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.2550e-04 - accuracy: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.8417 - 3s/epoch - 79ms/step\n",
            "Epoch 4247/5000\n",
            "\n",
            "Epoch 4247: val_accuracy did not improve from 0.86331\n",
            "35/35 - 1s - loss: 7.0715e-04 - accuracy: 1.0000 - val_loss: 0.7303 - val_accuracy: 0.8453 - 1s/epoch - 43ms/step\n",
            "Epoch 4248/5000\n",
            "\n",
            "Epoch 4248: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4961e-04 - accuracy: 1.0000 - val_loss: 0.7376 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4249/5000\n",
            "\n",
            "Epoch 4249: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6099e-04 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.8453 - 2s/epoch - 43ms/step\n",
            "Epoch 4250/5000\n",
            "\n",
            "Epoch 4250: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2748e-04 - accuracy: 1.0000 - val_loss: 0.7404 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4251/5000\n",
            "\n",
            "Epoch 4251: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5151e-04 - accuracy: 1.0000 - val_loss: 0.7396 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4252/5000\n",
            "\n",
            "Epoch 4252: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2336e-04 - accuracy: 1.0000 - val_loss: 0.7423 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4253/5000\n",
            "\n",
            "Epoch 4253: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4541e-04 - accuracy: 1.0000 - val_loss: 0.7391 - val_accuracy: 0.8381 - 2s/epoch - 63ms/step\n",
            "Epoch 4254/5000\n",
            "\n",
            "Epoch 4254: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.4842e-04 - accuracy: 1.0000 - val_loss: 0.7350 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 4255/5000\n",
            "\n",
            "Epoch 4255: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7479e-04 - accuracy: 1.0000 - val_loss: 0.7346 - val_accuracy: 0.8381 - 2s/epoch - 43ms/step\n",
            "Epoch 4256/5000\n",
            "\n",
            "Epoch 4256: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6241e-04 - accuracy: 1.0000 - val_loss: 0.7319 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4257/5000\n",
            "\n",
            "Epoch 4257: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5197e-04 - accuracy: 1.0000 - val_loss: 0.7324 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4258/5000\n",
            "\n",
            "Epoch 4258: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2603e-04 - accuracy: 1.0000 - val_loss: 0.7370 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4259/5000\n",
            "\n",
            "Epoch 4259: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7351e-04 - accuracy: 1.0000 - val_loss: 0.7234 - val_accuracy: 0.8453 - 2s/epoch - 43ms/step\n",
            "Epoch 4260/5000\n",
            "\n",
            "Epoch 4260: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1684e-04 - accuracy: 1.0000 - val_loss: 0.7129 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4261/5000\n",
            "\n",
            "Epoch 4261: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3045e-04 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.8417 - 2s/epoch - 64ms/step\n",
            "Epoch 4262/5000\n",
            "\n",
            "Epoch 4262: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6055e-04 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8417 - 2s/epoch - 69ms/step\n",
            "Epoch 4263/5000\n",
            "\n",
            "Epoch 4263: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3385e-04 - accuracy: 1.0000 - val_loss: 0.7208 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4264/5000\n",
            "\n",
            "Epoch 4264: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3950e-04 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4265/5000\n",
            "\n",
            "Epoch 4265: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0674e-04 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4266/5000\n",
            "\n",
            "Epoch 4266: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1250e-04 - accuracy: 1.0000 - val_loss: 0.7369 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4267/5000\n",
            "\n",
            "Epoch 4267: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1405e-04 - accuracy: 1.0000 - val_loss: 0.7337 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4268/5000\n",
            "\n",
            "Epoch 4268: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2722e-04 - accuracy: 1.0000 - val_loss: 0.7333 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4269/5000\n",
            "\n",
            "Epoch 4269: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8589e-04 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.8417 - 2s/epoch - 69ms/step\n",
            "Epoch 4270/5000\n",
            "\n",
            "Epoch 4270: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3699e-04 - accuracy: 1.0000 - val_loss: 0.7265 - val_accuracy: 0.8417 - 2s/epoch - 66ms/step\n",
            "Epoch 4271/5000\n",
            "\n",
            "Epoch 4271: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3344e-04 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4272/5000\n",
            "\n",
            "Epoch 4272: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1771e-04 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4273/5000\n",
            "\n",
            "Epoch 4273: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3524e-04 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4274/5000\n",
            "\n",
            "Epoch 4274: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1709e-04 - accuracy: 1.0000 - val_loss: 0.7376 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4275/5000\n",
            "\n",
            "Epoch 4275: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2965e-04 - accuracy: 1.0000 - val_loss: 0.7319 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4276/5000\n",
            "\n",
            "Epoch 4276: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6698e-04 - accuracy: 1.0000 - val_loss: 0.7269 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4277/5000\n",
            "\n",
            "Epoch 4277: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 8.1789e-04 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8345 - 3s/epoch - 72ms/step\n",
            "Epoch 4278/5000\n",
            "\n",
            "Epoch 4278: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4123e-04 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.8345 - 2s/epoch - 62ms/step\n",
            "Epoch 4279/5000\n",
            "\n",
            "Epoch 4279: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6051e-04 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4280/5000\n",
            "\n",
            "Epoch 4280: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2893e-04 - accuracy: 1.0000 - val_loss: 0.7256 - val_accuracy: 0.8273 - 2s/epoch - 44ms/step\n",
            "Epoch 4281/5000\n",
            "\n",
            "Epoch 4281: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6412e-04 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4282/5000\n",
            "\n",
            "Epoch 4282: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1435e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8381 - 2s/epoch - 43ms/step\n",
            "Epoch 4283/5000\n",
            "\n",
            "Epoch 4283: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6686e-04 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4284/5000\n",
            "\n",
            "Epoch 4284: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2688e-04 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8453 - 2s/epoch - 43ms/step\n",
            "Epoch 4285/5000\n",
            "\n",
            "Epoch 4285: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.4027e-04 - accuracy: 1.0000 - val_loss: 0.6919 - val_accuracy: 0.8453 - 3s/epoch - 77ms/step\n",
            "Epoch 4286/5000\n",
            "\n",
            "Epoch 4286: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7432e-04 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8453 - 2s/epoch - 59ms/step\n",
            "Epoch 4287/5000\n",
            "\n",
            "Epoch 4287: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3686e-04 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4288/5000\n",
            "\n",
            "Epoch 4288: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7670e-04 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4289/5000\n",
            "\n",
            "Epoch 4289: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1440e-04 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4290/5000\n",
            "\n",
            "Epoch 4290: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4122e-04 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4291/5000\n",
            "\n",
            "Epoch 4291: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6086e-04 - accuracy: 1.0000 - val_loss: 0.6995 - val_accuracy: 0.8489 - 2s/epoch - 43ms/step\n",
            "Epoch 4292/5000\n",
            "\n",
            "Epoch 4292: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1845e-04 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8489 - 2s/epoch - 48ms/step\n",
            "Epoch 4293/5000\n",
            "\n",
            "Epoch 4293: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.1080e-04 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.8525 - 3s/epoch - 79ms/step\n",
            "Epoch 4294/5000\n",
            "\n",
            "Epoch 4294: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0020e-04 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.8525 - 2s/epoch - 53ms/step\n",
            "Epoch 4295/5000\n",
            "\n",
            "Epoch 4295: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4334e-04 - accuracy: 1.0000 - val_loss: 0.6901 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4296/5000\n",
            "\n",
            "Epoch 4296: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3213e-04 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4297/5000\n",
            "\n",
            "Epoch 4297: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6567e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4298/5000\n",
            "\n",
            "Epoch 4298: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2214e-04 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4299/5000\n",
            "\n",
            "Epoch 4299: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5807e-04 - accuracy: 1.0000 - val_loss: 0.7113 - val_accuracy: 0.8453 - 2s/epoch - 46ms/step\n",
            "Epoch 4300/5000\n",
            "\n",
            "Epoch 4300: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4247e-04 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.8417 - 2s/epoch - 53ms/step\n",
            "Epoch 4301/5000\n",
            "\n",
            "Epoch 4301: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.1644e-04 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 4302/5000\n",
            "\n",
            "Epoch 4302: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0855e-04 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8525 - 2s/epoch - 47ms/step\n",
            "Epoch 4303/5000\n",
            "\n",
            "Epoch 4303: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3607e-04 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4304/5000\n",
            "\n",
            "Epoch 4304: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4352e-04 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4305/5000\n",
            "\n",
            "Epoch 4305: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0993e-04 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4306/5000\n",
            "\n",
            "Epoch 4306: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0017e-04 - accuracy: 1.0000 - val_loss: 0.7161 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4307/5000\n",
            "\n",
            "Epoch 4307: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9821e-04 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4308/5000\n",
            "\n",
            "Epoch 4308: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1109e-04 - accuracy: 1.0000 - val_loss: 0.7109 - val_accuracy: 0.8525 - 2s/epoch - 57ms/step\n",
            "Epoch 4309/5000\n",
            "\n",
            "Epoch 4309: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.3757e-04 - accuracy: 1.0000 - val_loss: 0.7060 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 4310/5000\n",
            "\n",
            "Epoch 4310: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3136e-04 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4311/5000\n",
            "\n",
            "Epoch 4311: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0834e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4312/5000\n",
            "\n",
            "Epoch 4312: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.2449e-04 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4313/5000\n",
            "\n",
            "Epoch 4313: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5516e-04 - accuracy: 1.0000 - val_loss: 0.7104 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4314/5000\n",
            "\n",
            "Epoch 4314: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2129e-04 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4315/5000\n",
            "\n",
            "Epoch 4315: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6776e-04 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4316/5000\n",
            "\n",
            "Epoch 4316: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8827 - val_accuracy: 0.8165 - 2s/epoch - 64ms/step\n",
            "Epoch 4317/5000\n",
            "\n",
            "Epoch 4317: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6714 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4318/5000\n",
            "\n",
            "Epoch 4318: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8806e-04 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4319/5000\n",
            "\n",
            "Epoch 4319: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.0599e-04 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4320/5000\n",
            "\n",
            "Epoch 4320: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4980e-04 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4321/5000\n",
            "\n",
            "Epoch 4321: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1026e-04 - accuracy: 1.0000 - val_loss: 0.6850 - val_accuracy: 0.8525 - 2s/epoch - 47ms/step\n",
            "Epoch 4322/5000\n",
            "\n",
            "Epoch 4322: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6865e-04 - accuracy: 1.0000 - val_loss: 0.6886 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4323/5000\n",
            "\n",
            "Epoch 4323: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2552e-04 - accuracy: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4324/5000\n",
            "\n",
            "Epoch 4324: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 8.3443e-04 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8561 - 3s/epoch - 74ms/step\n",
            "Epoch 4325/5000\n",
            "\n",
            "Epoch 4325: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0357e-04 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.8381 - 2s/epoch - 62ms/step\n",
            "Epoch 4326/5000\n",
            "\n",
            "Epoch 4326: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4435e-04 - accuracy: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4327/5000\n",
            "\n",
            "Epoch 4327: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1852e-04 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4328/5000\n",
            "\n",
            "Epoch 4328: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7802e-04 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4329/5000\n",
            "\n",
            "Epoch 4329: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8324e-04 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4330/5000\n",
            "\n",
            "Epoch 4330: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7248e-04 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4331/5000\n",
            "\n",
            "Epoch 4331: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6768e-04 - accuracy: 1.0000 - val_loss: 0.7055 - val_accuracy: 0.8489 - 2s/epoch - 46ms/step\n",
            "Epoch 4332/5000\n",
            "\n",
            "Epoch 4332: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.6175e-04 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.8453 - 3s/epoch - 80ms/step\n",
            "Epoch 4333/5000\n",
            "\n",
            "Epoch 4333: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2116e-04 - accuracy: 1.0000 - val_loss: 0.6894 - val_accuracy: 0.8417 - 2s/epoch - 54ms/step\n",
            "Epoch 4334/5000\n",
            "\n",
            "Epoch 4334: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9494e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4335/5000\n",
            "\n",
            "Epoch 4335: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3301e-04 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4336/5000\n",
            "\n",
            "Epoch 4336: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3695e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4337/5000\n",
            "\n",
            "Epoch 4337: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2829e-04 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4338/5000\n",
            "\n",
            "Epoch 4338: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5071e-04 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4339/5000\n",
            "\n",
            "Epoch 4339: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2587e-04 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.8489 - 2s/epoch - 52ms/step\n",
            "Epoch 4340/5000\n",
            "\n",
            "Epoch 4340: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.4347e-04 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.8489 - 3s/epoch - 79ms/step\n",
            "Epoch 4341/5000\n",
            "\n",
            "Epoch 4341: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2521e-04 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8489 - 2s/epoch - 49ms/step\n",
            "Epoch 4342/5000\n",
            "\n",
            "Epoch 4342: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9143e-04 - accuracy: 1.0000 - val_loss: 0.6644 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4343/5000\n",
            "\n",
            "Epoch 4343: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8036e-04 - accuracy: 1.0000 - val_loss: 0.6675 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4344/5000\n",
            "\n",
            "Epoch 4344: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2342e-04 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.8489 - 2s/epoch - 47ms/step\n",
            "Epoch 4345/5000\n",
            "\n",
            "Epoch 4345: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2096e-04 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4346/5000\n",
            "\n",
            "Epoch 4346: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0642e-04 - accuracy: 1.0000 - val_loss: 0.6750 - val_accuracy: 0.8417 - 2s/epoch - 47ms/step\n",
            "Epoch 4347/5000\n",
            "\n",
            "Epoch 4347: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1085e-04 - accuracy: 1.0000 - val_loss: 0.6778 - val_accuracy: 0.8453 - 2s/epoch - 62ms/step\n",
            "Epoch 4348/5000\n",
            "\n",
            "Epoch 4348: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.7421e-04 - accuracy: 1.0000 - val_loss: 0.7055 - val_accuracy: 0.8417 - 3s/epoch - 75ms/step\n",
            "Epoch 4349/5000\n",
            "\n",
            "Epoch 4349: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7939e-04 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4350/5000\n",
            "\n",
            "Epoch 4350: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0832e-04 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4351/5000\n",
            "\n",
            "Epoch 4351: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1674e-04 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4352/5000\n",
            "\n",
            "Epoch 4352: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1349e-04 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4353/5000\n",
            "\n",
            "Epoch 4353: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9322e-04 - accuracy: 1.0000 - val_loss: 0.6854 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4354/5000\n",
            "\n",
            "Epoch 4354: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5902e-04 - accuracy: 1.0000 - val_loss: 0.6883 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4355/5000\n",
            "\n",
            "Epoch 4355: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2421e-04 - accuracy: 1.0000 - val_loss: 0.6821 - val_accuracy: 0.8381 - 2s/epoch - 68ms/step\n",
            "Epoch 4356/5000\n",
            "\n",
            "Epoch 4356: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4827e-04 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.8453 - 2s/epoch - 68ms/step\n",
            "Epoch 4357/5000\n",
            "\n",
            "Epoch 4357: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2367e-04 - accuracy: 1.0000 - val_loss: 0.6855 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4358/5000\n",
            "\n",
            "Epoch 4358: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0798e-04 - accuracy: 1.0000 - val_loss: 0.6839 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4359/5000\n",
            "\n",
            "Epoch 4359: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4008e-04 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4360/5000\n",
            "\n",
            "Epoch 4360: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1550e-04 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4361/5000\n",
            "\n",
            "Epoch 4361: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8762e-04 - accuracy: 1.0000 - val_loss: 0.6779 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4362/5000\n",
            "\n",
            "Epoch 4362: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9485e-04 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4363/5000\n",
            "\n",
            "Epoch 4363: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.3117e-04 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.8489 - 3s/epoch - 74ms/step\n",
            "Epoch 4364/5000\n",
            "\n",
            "Epoch 4364: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8018e-04 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.8525 - 2s/epoch - 62ms/step\n",
            "Epoch 4365/5000\n",
            "\n",
            "Epoch 4365: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2049e-04 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4366/5000\n",
            "\n",
            "Epoch 4366: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6690e-04 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4367/5000\n",
            "\n",
            "Epoch 4367: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1391e-04 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4368/5000\n",
            "\n",
            "Epoch 4368: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0305e-04 - accuracy: 1.0000 - val_loss: 0.6928 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4369/5000\n",
            "\n",
            "Epoch 4369: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7593e-04 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4370/5000\n",
            "\n",
            "Epoch 4370: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0745e-04 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.8489 - 2s/epoch - 47ms/step\n",
            "Epoch 4371/5000\n",
            "\n",
            "Epoch 4371: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.1026e-04 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.8453 - 3s/epoch - 79ms/step\n",
            "Epoch 4372/5000\n",
            "\n",
            "Epoch 4372: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0939e-04 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8453 - 2s/epoch - 54ms/step\n",
            "Epoch 4373/5000\n",
            "\n",
            "Epoch 4373: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0179e-04 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4374/5000\n",
            "\n",
            "Epoch 4374: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1810e-04 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4375/5000\n",
            "\n",
            "Epoch 4375: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9274e-04 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4376/5000\n",
            "\n",
            "Epoch 4376: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3648e-04 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4377/5000\n",
            "\n",
            "Epoch 4377: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9556e-04 - accuracy: 1.0000 - val_loss: 0.6849 - val_accuracy: 0.8417 - 2s/epoch - 46ms/step\n",
            "Epoch 4378/5000\n",
            "\n",
            "Epoch 4378: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8314e-04 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8453 - 2s/epoch - 54ms/step\n",
            "Epoch 4379/5000\n",
            "\n",
            "Epoch 4379: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.8047e-04 - accuracy: 1.0000 - val_loss: 0.6833 - val_accuracy: 0.8453 - 3s/epoch - 79ms/step\n",
            "Epoch 4380/5000\n",
            "\n",
            "Epoch 4380: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0038e-04 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.8381 - 2s/epoch - 48ms/step\n",
            "Epoch 4381/5000\n",
            "\n",
            "Epoch 4381: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9332e-04 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4382/5000\n",
            "\n",
            "Epoch 4382: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7916e-04 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4383/5000\n",
            "\n",
            "Epoch 4383: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8929e-04 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4384/5000\n",
            "\n",
            "Epoch 4384: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2168e-04 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4385/5000\n",
            "\n",
            "Epoch 4385: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9428e-04 - accuracy: 1.0000 - val_loss: 0.6899 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4386/5000\n",
            "\n",
            "Epoch 4386: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9387e-04 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.8453 - 2s/epoch - 61ms/step\n",
            "Epoch 4387/5000\n",
            "\n",
            "Epoch 4387: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.8522e-04 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.8453 - 3s/epoch - 75ms/step\n",
            "Epoch 4388/5000\n",
            "\n",
            "Epoch 4388: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8491e-04 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4389/5000\n",
            "\n",
            "Epoch 4389: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2024e-04 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4390/5000\n",
            "\n",
            "Epoch 4390: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5253e-04 - accuracy: 1.0000 - val_loss: 0.6897 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4391/5000\n",
            "\n",
            "Epoch 4391: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8964e-04 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4392/5000\n",
            "\n",
            "Epoch 4392: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9723e-04 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4393/5000\n",
            "\n",
            "Epoch 4393: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9153e-04 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4394/5000\n",
            "\n",
            "Epoch 4394: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7630e-04 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.8489 - 2s/epoch - 69ms/step\n",
            "Epoch 4395/5000\n",
            "\n",
            "Epoch 4395: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8450e-04 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.8525 - 2s/epoch - 67ms/step\n",
            "Epoch 4396/5000\n",
            "\n",
            "Epoch 4396: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9525e-04 - accuracy: 1.0000 - val_loss: 0.6897 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4397/5000\n",
            "\n",
            "Epoch 4397: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9966e-04 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4398/5000\n",
            "\n",
            "Epoch 4398: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2912e-04 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4399/5000\n",
            "\n",
            "Epoch 4399: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.7101e-04 - accuracy: 1.0000 - val_loss: 0.6760 - val_accuracy: 0.8309 - 2s/epoch - 45ms/step\n",
            "Epoch 4400/5000\n",
            "\n",
            "Epoch 4400: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.7546 - val_accuracy: 0.8309 - 2s/epoch - 45ms/step\n",
            "Epoch 4401/5000\n",
            "\n",
            "Epoch 4401: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.8286e-04 - accuracy: 1.0000 - val_loss: 0.7489 - val_accuracy: 0.8345 - 2s/epoch - 45ms/step\n",
            "Epoch 4402/5000\n",
            "\n",
            "Epoch 4402: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 9.0325e-04 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.8381 - 3s/epoch - 77ms/step\n",
            "Epoch 4403/5000\n",
            "\n",
            "Epoch 4403: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2434e-04 - accuracy: 1.0000 - val_loss: 0.6894 - val_accuracy: 0.8345 - 2s/epoch - 59ms/step\n",
            "Epoch 4404/5000\n",
            "\n",
            "Epoch 4404: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6342e-04 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4405/5000\n",
            "\n",
            "Epoch 4405: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.1343e-04 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4406/5000\n",
            "\n",
            "Epoch 4406: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6990e-04 - accuracy: 1.0000 - val_loss: 0.7388 - val_accuracy: 0.8309 - 2s/epoch - 45ms/step\n",
            "Epoch 4407/5000\n",
            "\n",
            "Epoch 4407: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4339e-04 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.8345 - 2s/epoch - 45ms/step\n",
            "Epoch 4408/5000\n",
            "\n",
            "Epoch 4408: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1655e-04 - accuracy: 1.0000 - val_loss: 0.7171 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4409/5000\n",
            "\n",
            "Epoch 4409: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.2015e-04 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.8381 - 2s/epoch - 50ms/step\n",
            "Epoch 4410/5000\n",
            "\n",
            "Epoch 4410: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7582 - val_accuracy: 0.8309 - 3s/epoch - 80ms/step\n",
            "Epoch 4411/5000\n",
            "\n",
            "Epoch 4411: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.5680e-04 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.8381 - 2s/epoch - 52ms/step\n",
            "Epoch 4412/5000\n",
            "\n",
            "Epoch 4412: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9763e-04 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.8345 - 2s/epoch - 46ms/step\n",
            "Epoch 4413/5000\n",
            "\n",
            "Epoch 4413: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3981e-04 - accuracy: 1.0000 - val_loss: 0.6969 - val_accuracy: 0.8381 - 2s/epoch - 47ms/step\n",
            "Epoch 4414/5000\n",
            "\n",
            "Epoch 4414: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3200e-04 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4415/5000\n",
            "\n",
            "Epoch 4415: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1187e-04 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4416/5000\n",
            "\n",
            "Epoch 4416: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3396e-04 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4417/5000\n",
            "\n",
            "Epoch 4417: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1724e-04 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.8489 - 2s/epoch - 62ms/step\n",
            "Epoch 4418/5000\n",
            "\n",
            "Epoch 4418: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.6441e-04 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8453 - 3s/epoch - 76ms/step\n",
            "Epoch 4419/5000\n",
            "\n",
            "Epoch 4419: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1574e-04 - accuracy: 1.0000 - val_loss: 0.6768 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4420/5000\n",
            "\n",
            "Epoch 4420: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0721e-04 - accuracy: 1.0000 - val_loss: 0.6776 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4421/5000\n",
            "\n",
            "Epoch 4421: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2899e-04 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4422/5000\n",
            "\n",
            "Epoch 4422: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6141e-04 - accuracy: 1.0000 - val_loss: 0.6824 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4423/5000\n",
            "\n",
            "Epoch 4423: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0197e-04 - accuracy: 1.0000 - val_loss: 0.6745 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4424/5000\n",
            "\n",
            "Epoch 4424: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5494e-04 - accuracy: 1.0000 - val_loss: 0.7202 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4425/5000\n",
            "\n",
            "Epoch 4425: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1302e-04 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4426/5000\n",
            "\n",
            "Epoch 4426: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0686e-04 - accuracy: 1.0000 - val_loss: 0.6985 - val_accuracy: 0.8417 - 2s/epoch - 65ms/step\n",
            "Epoch 4427/5000\n",
            "\n",
            "Epoch 4427: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9353e-04 - accuracy: 1.0000 - val_loss: 0.6767 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4428/5000\n",
            "\n",
            "Epoch 4428: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0404e-04 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4429/5000\n",
            "\n",
            "Epoch 4429: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7910e-04 - accuracy: 1.0000 - val_loss: 0.6738 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4430/5000\n",
            "\n",
            "Epoch 4430: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9341e-04 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4431/5000\n",
            "\n",
            "Epoch 4431: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1216e-04 - accuracy: 1.0000 - val_loss: 0.6630 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4432/5000\n",
            "\n",
            "Epoch 4432: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9281e-04 - accuracy: 1.0000 - val_loss: 0.6630 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4433/5000\n",
            "\n",
            "Epoch 4433: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.8534e-04 - accuracy: 1.0000 - val_loss: 0.6635 - val_accuracy: 0.8489 - 3s/epoch - 77ms/step\n",
            "Epoch 4434/5000\n",
            "\n",
            "Epoch 4434: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7822e-04 - accuracy: 1.0000 - val_loss: 0.6625 - val_accuracy: 0.8489 - 2s/epoch - 59ms/step\n",
            "Epoch 4435/5000\n",
            "\n",
            "Epoch 4435: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6621e-04 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4436/5000\n",
            "\n",
            "Epoch 4436: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7253e-04 - accuracy: 1.0000 - val_loss: 0.6647 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4437/5000\n",
            "\n",
            "Epoch 4437: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1081e-04 - accuracy: 1.0000 - val_loss: 0.6667 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4438/5000\n",
            "\n",
            "Epoch 4438: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9430e-04 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4439/5000\n",
            "\n",
            "Epoch 4439: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6894e-04 - accuracy: 1.0000 - val_loss: 0.6701 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4440/5000\n",
            "\n",
            "Epoch 4440: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8784e-04 - accuracy: 1.0000 - val_loss: 0.6813 - val_accuracy: 0.8525 - 2s/epoch - 49ms/step\n",
            "Epoch 4441/5000\n",
            "\n",
            "Epoch 4441: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 8.1010e-04 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8345 - 3s/epoch - 79ms/step\n",
            "Epoch 4442/5000\n",
            "\n",
            "Epoch 4442: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.3953e-04 - accuracy: 1.0000 - val_loss: 0.6493 - val_accuracy: 0.8489 - 2s/epoch - 52ms/step\n",
            "Epoch 4443/5000\n",
            "\n",
            "Epoch 4443: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.9865e-04 - accuracy: 1.0000 - val_loss: 0.6342 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4444/5000\n",
            "\n",
            "Epoch 4444: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0016 - accuracy: 0.9991 - val_loss: 0.6701 - val_accuracy: 0.8597 - 2s/epoch - 44ms/step\n",
            "Epoch 4445/5000\n",
            "\n",
            "Epoch 4445: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.8410e-04 - accuracy: 1.0000 - val_loss: 0.6845 - val_accuracy: 0.8633 - 2s/epoch - 44ms/step\n",
            "Epoch 4446/5000\n",
            "\n",
            "Epoch 4446: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5476e-04 - accuracy: 1.0000 - val_loss: 0.6719 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4447/5000\n",
            "\n",
            "Epoch 4447: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0802e-04 - accuracy: 1.0000 - val_loss: 0.6659 - val_accuracy: 0.8561 - 2s/epoch - 45ms/step\n",
            "Epoch 4448/5000\n",
            "\n",
            "Epoch 4448: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1705e-04 - accuracy: 1.0000 - val_loss: 0.6618 - val_accuracy: 0.8597 - 2s/epoch - 55ms/step\n",
            "Epoch 4449/5000\n",
            "\n",
            "Epoch 4449: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.6097e-04 - accuracy: 1.0000 - val_loss: 0.6629 - val_accuracy: 0.8417 - 3s/epoch - 78ms/step\n",
            "Epoch 4450/5000\n",
            "\n",
            "Epoch 4450: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9818e-04 - accuracy: 1.0000 - val_loss: 0.6587 - val_accuracy: 0.8525 - 2s/epoch - 47ms/step\n",
            "Epoch 4451/5000\n",
            "\n",
            "Epoch 4451: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1738e-04 - accuracy: 1.0000 - val_loss: 0.6532 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4452/5000\n",
            "\n",
            "Epoch 4452: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3640e-04 - accuracy: 1.0000 - val_loss: 0.6525 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4453/5000\n",
            "\n",
            "Epoch 4453: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9987e-04 - accuracy: 1.0000 - val_loss: 0.6519 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4454/5000\n",
            "\n",
            "Epoch 4454: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7358e-04 - accuracy: 1.0000 - val_loss: 0.6604 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4455/5000\n",
            "\n",
            "Epoch 4455: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7951e-04 - accuracy: 1.0000 - val_loss: 0.6694 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4456/5000\n",
            "\n",
            "Epoch 4456: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3365e-04 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.8489 - 2s/epoch - 60ms/step\n",
            "Epoch 4457/5000\n",
            "\n",
            "Epoch 4457: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.0371e-04 - accuracy: 1.0000 - val_loss: 0.6722 - val_accuracy: 0.8525 - 3s/epoch - 75ms/step\n",
            "Epoch 4458/5000\n",
            "\n",
            "Epoch 4458: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3061e-04 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4459/5000\n",
            "\n",
            "Epoch 4459: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8613e-04 - accuracy: 1.0000 - val_loss: 0.6764 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4460/5000\n",
            "\n",
            "Epoch 4460: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7409e-04 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4461/5000\n",
            "\n",
            "Epoch 4461: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8258e-04 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4462/5000\n",
            "\n",
            "Epoch 4462: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8592e-04 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.8561 - 2s/epoch - 45ms/step\n",
            "Epoch 4463/5000\n",
            "\n",
            "Epoch 4463: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3781e-04 - accuracy: 1.0000 - val_loss: 0.6704 - val_accuracy: 0.8525 - 2s/epoch - 43ms/step\n",
            "Epoch 4464/5000\n",
            "\n",
            "Epoch 4464: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8518e-04 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.8525 - 2s/epoch - 67ms/step\n",
            "Epoch 4465/5000\n",
            "\n",
            "Epoch 4465: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0075e-04 - accuracy: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.8489 - 2s/epoch - 69ms/step\n",
            "Epoch 4466/5000\n",
            "\n",
            "Epoch 4466: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6061e-04 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4467/5000\n",
            "\n",
            "Epoch 4467: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9998e-04 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4468/5000\n",
            "\n",
            "Epoch 4468: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5589e-04 - accuracy: 1.0000 - val_loss: 0.6757 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4469/5000\n",
            "\n",
            "Epoch 4469: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8719e-04 - accuracy: 1.0000 - val_loss: 0.6690 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4470/5000\n",
            "\n",
            "Epoch 4470: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2859e-04 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4471/5000\n",
            "\n",
            "Epoch 4471: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2078e-04 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4472/5000\n",
            "\n",
            "Epoch 4472: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.2850e-04 - accuracy: 1.0000 - val_loss: 0.6659 - val_accuracy: 0.8561 - 3s/epoch - 75ms/step\n",
            "Epoch 4473/5000\n",
            "\n",
            "Epoch 4473: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8209e-04 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 0.8525 - 2s/epoch - 62ms/step\n",
            "Epoch 4474/5000\n",
            "\n",
            "Epoch 4474: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3415e-04 - accuracy: 1.0000 - val_loss: 0.6899 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4475/5000\n",
            "\n",
            "Epoch 4475: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9004e-04 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.8561 - 2s/epoch - 45ms/step\n",
            "Epoch 4476/5000\n",
            "\n",
            "Epoch 4476: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3201e-04 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4477/5000\n",
            "\n",
            "Epoch 4477: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9922e-04 - accuracy: 1.0000 - val_loss: 0.6848 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4478/5000\n",
            "\n",
            "Epoch 4478: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6721e-04 - accuracy: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4479/5000\n",
            "\n",
            "Epoch 4479: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1817e-04 - accuracy: 1.0000 - val_loss: 0.6686 - val_accuracy: 0.8525 - 2s/epoch - 48ms/step\n",
            "Epoch 4480/5000\n",
            "\n",
            "Epoch 4480: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.8158e-04 - accuracy: 1.0000 - val_loss: 0.6627 - val_accuracy: 0.8525 - 3s/epoch - 80ms/step\n",
            "Epoch 4481/5000\n",
            "\n",
            "Epoch 4481: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8488e-04 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.8561 - 2s/epoch - 55ms/step\n",
            "Epoch 4482/5000\n",
            "\n",
            "Epoch 4482: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1559e-04 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4483/5000\n",
            "\n",
            "Epoch 4483: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8887e-04 - accuracy: 1.0000 - val_loss: 0.6623 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4484/5000\n",
            "\n",
            "Epoch 4484: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6837e-04 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4485/5000\n",
            "\n",
            "Epoch 4485: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1269e-04 - accuracy: 1.0000 - val_loss: 0.6691 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4486/5000\n",
            "\n",
            "Epoch 4486: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8814e-04 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.8561 - 2s/epoch - 45ms/step\n",
            "Epoch 4487/5000\n",
            "\n",
            "Epoch 4487: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0171e-04 - accuracy: 1.0000 - val_loss: 0.6747 - val_accuracy: 0.8561 - 2s/epoch - 54ms/step\n",
            "Epoch 4488/5000\n",
            "\n",
            "Epoch 4488: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.5564e-04 - accuracy: 1.0000 - val_loss: 0.6765 - val_accuracy: 0.8525 - 3s/epoch - 79ms/step\n",
            "Epoch 4489/5000\n",
            "\n",
            "Epoch 4489: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1272e-04 - accuracy: 1.0000 - val_loss: 0.6732 - val_accuracy: 0.8525 - 2s/epoch - 48ms/step\n",
            "Epoch 4490/5000\n",
            "\n",
            "Epoch 4490: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9363e-04 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4491/5000\n",
            "\n",
            "Epoch 4491: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3268e-04 - accuracy: 1.0000 - val_loss: 0.6753 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4492/5000\n",
            "\n",
            "Epoch 4492: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8702e-04 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4493/5000\n",
            "\n",
            "Epoch 4493: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8279e-04 - accuracy: 1.0000 - val_loss: 0.6667 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4494/5000\n",
            "\n",
            "Epoch 4494: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8584e-04 - accuracy: 1.0000 - val_loss: 0.6715 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4495/5000\n",
            "\n",
            "Epoch 4495: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7779e-04 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.8525 - 2s/epoch - 62ms/step\n",
            "Epoch 4496/5000\n",
            "\n",
            "Epoch 4496: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.6589e-04 - accuracy: 1.0000 - val_loss: 0.6713 - val_accuracy: 0.8525 - 3s/epoch - 73ms/step\n",
            "Epoch 4497/5000\n",
            "\n",
            "Epoch 4497: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9022e-04 - accuracy: 1.0000 - val_loss: 0.6856 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4498/5000\n",
            "\n",
            "Epoch 4498: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 0.8345 - 2s/epoch - 45ms/step\n",
            "Epoch 4499/5000\n",
            "\n",
            "Epoch 4499: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.0856e-04 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4500/5000\n",
            "\n",
            "Epoch 4500: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7526 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4501/5000\n",
            "\n",
            "Epoch 4501: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8237e-04 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4502/5000\n",
            "\n",
            "Epoch 4502: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.5598e-04 - accuracy: 1.0000 - val_loss: 0.7059 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4503/5000\n",
            "\n",
            "Epoch 4503: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4562e-04 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.8309 - 2s/epoch - 70ms/step\n",
            "Epoch 4504/5000\n",
            "\n",
            "Epoch 4504: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.0130e-04 - accuracy: 1.0000 - val_loss: 0.6671 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4505/5000\n",
            "\n",
            "Epoch 4505: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.7819 - val_accuracy: 0.8237 - 2s/epoch - 44ms/step\n",
            "Epoch 4506/5000\n",
            "\n",
            "Epoch 4506: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.6128e-04 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.8273 - 2s/epoch - 45ms/step\n",
            "Epoch 4507/5000\n",
            "\n",
            "Epoch 4507: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4508/5000\n",
            "\n",
            "Epoch 4508: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3636e-04 - accuracy: 1.0000 - val_loss: 0.6981 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4509/5000\n",
            "\n",
            "Epoch 4509: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7451e-04 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4510/5000\n",
            "\n",
            "Epoch 4510: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5908e-04 - accuracy: 1.0000 - val_loss: 0.6973 - val_accuracy: 0.8453 - 2s/epoch - 43ms/step\n",
            "Epoch 4511/5000\n",
            "\n",
            "Epoch 4511: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.6775e-04 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.8381 - 3s/epoch - 76ms/step\n",
            "Epoch 4512/5000\n",
            "\n",
            "Epoch 4512: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6691e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8345 - 2s/epoch - 60ms/step\n",
            "Epoch 4513/5000\n",
            "\n",
            "Epoch 4513: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6313e-04 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4514/5000\n",
            "\n",
            "Epoch 4514: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4719e-04 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8309 - 2s/epoch - 44ms/step\n",
            "Epoch 4515/5000\n",
            "\n",
            "Epoch 4515: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2768e-04 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4516/5000\n",
            "\n",
            "Epoch 4516: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4674e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4517/5000\n",
            "\n",
            "Epoch 4517: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8437e-04 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4518/5000\n",
            "\n",
            "Epoch 4518: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3669e-04 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.8417 - 2s/epoch - 48ms/step\n",
            "Epoch 4519/5000\n",
            "\n",
            "Epoch 4519: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.8823e-04 - accuracy: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.8489 - 3s/epoch - 80ms/step\n",
            "Epoch 4520/5000\n",
            "\n",
            "Epoch 4520: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6559e-04 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.8453 - 2s/epoch - 52ms/step\n",
            "Epoch 4521/5000\n",
            "\n",
            "Epoch 4521: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3325e-04 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4522/5000\n",
            "\n",
            "Epoch 4522: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6345e-04 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4523/5000\n",
            "\n",
            "Epoch 4523: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4466e-04 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4524/5000\n",
            "\n",
            "Epoch 4524: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6706e-04 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4525/5000\n",
            "\n",
            "Epoch 4525: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4079e-04 - accuracy: 1.0000 - val_loss: 0.7169 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4526/5000\n",
            "\n",
            "Epoch 4526: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7237e-04 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.8489 - 2s/epoch - 55ms/step\n",
            "Epoch 4527/5000\n",
            "\n",
            "Epoch 4527: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.8290e-04 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 4528/5000\n",
            "\n",
            "Epoch 4528: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9860e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8489 - 2s/epoch - 47ms/step\n",
            "Epoch 4529/5000\n",
            "\n",
            "Epoch 4529: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9969e-04 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.8489 - 2s/epoch - 46ms/step\n",
            "Epoch 4530/5000\n",
            "\n",
            "Epoch 4530: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8973e-04 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4531/5000\n",
            "\n",
            "Epoch 4531: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9034e-04 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4532/5000\n",
            "\n",
            "Epoch 4532: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9223e-04 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4533/5000\n",
            "\n",
            "Epoch 4533: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3523e-04 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4534/5000\n",
            "\n",
            "Epoch 4534: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6911e-04 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.8489 - 2s/epoch - 61ms/step\n",
            "Epoch 4535/5000\n",
            "\n",
            "Epoch 4535: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.0327e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8453 - 3s/epoch - 73ms/step\n",
            "Epoch 4536/5000\n",
            "\n",
            "Epoch 4536: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8292e-04 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4537/5000\n",
            "\n",
            "Epoch 4537: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7403e-04 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4538/5000\n",
            "\n",
            "Epoch 4538: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6591e-04 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4539/5000\n",
            "\n",
            "Epoch 4539: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6656e-04 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4540/5000\n",
            "\n",
            "Epoch 4540: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7093e-04 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4541/5000\n",
            "\n",
            "Epoch 4541: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8865e-04 - accuracy: 1.0000 - val_loss: 0.6967 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4542/5000\n",
            "\n",
            "Epoch 4542: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6232e-04 - accuracy: 1.0000 - val_loss: 0.6944 - val_accuracy: 0.8417 - 2s/epoch - 66ms/step\n",
            "Epoch 4543/5000\n",
            "\n",
            "Epoch 4543: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9849e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4544/5000\n",
            "\n",
            "Epoch 4544: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9428e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4545/5000\n",
            "\n",
            "Epoch 4545: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2776e-04 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4546/5000\n",
            "\n",
            "Epoch 4546: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8444e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4547/5000\n",
            "\n",
            "Epoch 4547: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0640e-04 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4548/5000\n",
            "\n",
            "Epoch 4548: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3620e-04 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4549/5000\n",
            "\n",
            "Epoch 4549: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8532e-04 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4550/5000\n",
            "\n",
            "Epoch 4550: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.4417e-04 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8417 - 3s/epoch - 73ms/step\n",
            "Epoch 4551/5000\n",
            "\n",
            "Epoch 4551: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6747 - val_accuracy: 0.8597 - 2s/epoch - 63ms/step\n",
            "Epoch 4552/5000\n",
            "\n",
            "Epoch 4552: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4553/5000\n",
            "\n",
            "Epoch 4553: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4554/5000\n",
            "\n",
            "Epoch 4554: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.7391 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4555/5000\n",
            "\n",
            "Epoch 4555: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.8945e-04 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4556/5000\n",
            "\n",
            "Epoch 4556: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4557/5000\n",
            "\n",
            "Epoch 4557: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.2742e-04 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4558/5000\n",
            "\n",
            "Epoch 4558: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.3583e-04 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8489 - 3s/epoch - 77ms/step\n",
            "Epoch 4559/5000\n",
            "\n",
            "Epoch 4559: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8020e-04 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.8453 - 2s/epoch - 57ms/step\n",
            "Epoch 4560/5000\n",
            "\n",
            "Epoch 4560: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4514e-04 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4561/5000\n",
            "\n",
            "Epoch 4561: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4562/5000\n",
            "\n",
            "Epoch 4562: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7161 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4563/5000\n",
            "\n",
            "Epoch 4563: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4553e-04 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4564/5000\n",
            "\n",
            "Epoch 4564: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9908e-04 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4565/5000\n",
            "\n",
            "Epoch 4565: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.8417 - 2s/epoch - 50ms/step\n",
            "Epoch 4566/5000\n",
            "\n",
            "Epoch 4566: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 7.8206e-04 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.8381 - 3s/epoch - 79ms/step\n",
            "Epoch 4567/5000\n",
            "\n",
            "Epoch 4567: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7882e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8381 - 2s/epoch - 51ms/step\n",
            "Epoch 4568/5000\n",
            "\n",
            "Epoch 4568: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7791e-04 - accuracy: 1.0000 - val_loss: 0.6808 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4569/5000\n",
            "\n",
            "Epoch 4569: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0701e-04 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4570/5000\n",
            "\n",
            "Epoch 4570: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0318e-04 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4571/5000\n",
            "\n",
            "Epoch 4571: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5966e-04 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4572/5000\n",
            "\n",
            "Epoch 4572: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1636e-04 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4573/5000\n",
            "\n",
            "Epoch 4573: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2872e-04 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.8381 - 2s/epoch - 55ms/step\n",
            "Epoch 4574/5000\n",
            "\n",
            "Epoch 4574: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.1797e-04 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.8381 - 3s/epoch - 79ms/step\n",
            "Epoch 4575/5000\n",
            "\n",
            "Epoch 4575: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1279e-04 - accuracy: 1.0000 - val_loss: 0.6898 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4576/5000\n",
            "\n",
            "Epoch 4576: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0531e-04 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4577/5000\n",
            "\n",
            "Epoch 4577: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7592e-04 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4578/5000\n",
            "\n",
            "Epoch 4578: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7918e-04 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4579/5000\n",
            "\n",
            "Epoch 4579: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0667e-04 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4580/5000\n",
            "\n",
            "Epoch 4580: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9921e-04 - accuracy: 1.0000 - val_loss: 0.6900 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4581/5000\n",
            "\n",
            "Epoch 4581: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4802e-04 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.8489 - 2s/epoch - 61ms/step\n",
            "Epoch 4582/5000\n",
            "\n",
            "Epoch 4582: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.1335e-04 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 0.8453 - 3s/epoch - 73ms/step\n",
            "Epoch 4583/5000\n",
            "\n",
            "Epoch 4583: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6015e-04 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4584/5000\n",
            "\n",
            "Epoch 4584: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0858e-04 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4585/5000\n",
            "\n",
            "Epoch 4585: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6383e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8489 - 2s/epoch - 43ms/step\n",
            "Epoch 4586/5000\n",
            "\n",
            "Epoch 4586: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6012e-04 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4587/5000\n",
            "\n",
            "Epoch 4587: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9108e-04 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4588/5000\n",
            "\n",
            "Epoch 4588: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8449e-04 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4589/5000\n",
            "\n",
            "Epoch 4589: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3211e-04 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.8453 - 2s/epoch - 65ms/step\n",
            "Epoch 4590/5000\n",
            "\n",
            "Epoch 4590: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0646e-04 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.8453 - 2s/epoch - 68ms/step\n",
            "Epoch 4591/5000\n",
            "\n",
            "Epoch 4591: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8098e-04 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4592/5000\n",
            "\n",
            "Epoch 4592: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0107e-04 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4593/5000\n",
            "\n",
            "Epoch 4593: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8818e-04 - accuracy: 1.0000 - val_loss: 0.7524 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4594/5000\n",
            "\n",
            "Epoch 4594: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7400e-04 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4595/5000\n",
            "\n",
            "Epoch 4595: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7620e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4596/5000\n",
            "\n",
            "Epoch 4596: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5558e-04 - accuracy: 1.0000 - val_loss: 0.6852 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4597/5000\n",
            "\n",
            "Epoch 4597: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5092e-04 - accuracy: 1.0000 - val_loss: 0.6850 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4598/5000\n",
            "\n",
            "Epoch 4598: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1723e-04 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.8381 - 2s/epoch - 64ms/step\n",
            "Epoch 4599/5000\n",
            "\n",
            "Epoch 4599: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.4759e-04 - accuracy: 1.0000 - val_loss: 0.6812 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4600/5000\n",
            "\n",
            "Epoch 4600: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1985e-04 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4601/5000\n",
            "\n",
            "Epoch 4601: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5615e-04 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4602/5000\n",
            "\n",
            "Epoch 4602: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0602e-04 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4603/5000\n",
            "\n",
            "Epoch 4603: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1631e-04 - accuracy: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4604/5000\n",
            "\n",
            "Epoch 4604: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7235e-04 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4605/5000\n",
            "\n",
            "Epoch 4605: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.8450e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8417 - 3s/epoch - 77ms/step\n",
            "Epoch 4606/5000\n",
            "\n",
            "Epoch 4606: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0516e-04 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.8417 - 2s/epoch - 59ms/step\n",
            "Epoch 4607/5000\n",
            "\n",
            "Epoch 4607: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3881e-04 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4608/5000\n",
            "\n",
            "Epoch 4608: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6053e-04 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4609/5000\n",
            "\n",
            "Epoch 4609: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7266e-04 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4610/5000\n",
            "\n",
            "Epoch 4610: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9605e-04 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4611/5000\n",
            "\n",
            "Epoch 4611: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9282e-04 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4612/5000\n",
            "\n",
            "Epoch 4612: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3155e-04 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8417 - 2s/epoch - 48ms/step\n",
            "Epoch 4613/5000\n",
            "\n",
            "Epoch 4613: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.7396e-04 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.8417 - 3s/epoch - 79ms/step\n",
            "Epoch 4614/5000\n",
            "\n",
            "Epoch 4614: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0632e-04 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8417 - 2s/epoch - 55ms/step\n",
            "Epoch 4615/5000\n",
            "\n",
            "Epoch 4615: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7990e-04 - accuracy: 1.0000 - val_loss: 0.6863 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4616/5000\n",
            "\n",
            "Epoch 4616: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7843e-04 - accuracy: 1.0000 - val_loss: 0.6875 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4617/5000\n",
            "\n",
            "Epoch 4617: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.6761 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4618/5000\n",
            "\n",
            "Epoch 4618: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4619/5000\n",
            "\n",
            "Epoch 4619: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8021e-04 - accuracy: 1.0000 - val_loss: 0.7464 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4620/5000\n",
            "\n",
            "Epoch 4620: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8133 - val_accuracy: 0.8201 - 2s/epoch - 53ms/step\n",
            "Epoch 4621/5000\n",
            "\n",
            "Epoch 4621: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 9.7819e-04 - accuracy: 1.0000 - val_loss: 0.7199 - val_accuracy: 0.8453 - 3s/epoch - 79ms/step\n",
            "Epoch 4622/5000\n",
            "\n",
            "Epoch 4622: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2033e-04 - accuracy: 1.0000 - val_loss: 0.7289 - val_accuracy: 0.8597 - 2s/epoch - 49ms/step\n",
            "Epoch 4623/5000\n",
            "\n",
            "Epoch 4623: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4947e-04 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.8597 - 2s/epoch - 44ms/step\n",
            "Epoch 4624/5000\n",
            "\n",
            "Epoch 4624: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9170e-04 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4625/5000\n",
            "\n",
            "Epoch 4625: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4088e-04 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4626/5000\n",
            "\n",
            "Epoch 4626: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0255e-04 - accuracy: 1.0000 - val_loss: 0.7104 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4627/5000\n",
            "\n",
            "Epoch 4627: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2061e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4628/5000\n",
            "\n",
            "Epoch 4628: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4565e-04 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8525 - 2s/epoch - 58ms/step\n",
            "Epoch 4629/5000\n",
            "\n",
            "Epoch 4629: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 8.0051e-04 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.8525 - 3s/epoch - 77ms/step\n",
            "Epoch 4630/5000\n",
            "\n",
            "Epoch 4630: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2774e-04 - accuracy: 1.0000 - val_loss: 0.7544 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4631/5000\n",
            "\n",
            "Epoch 4631: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2358e-04 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4632/5000\n",
            "\n",
            "Epoch 4632: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0353e-04 - accuracy: 1.0000 - val_loss: 0.7309 - val_accuracy: 0.8489 - 2s/epoch - 43ms/step\n",
            "Epoch 4633/5000\n",
            "\n",
            "Epoch 4633: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3517e-04 - accuracy: 1.0000 - val_loss: 0.7200 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4634/5000\n",
            "\n",
            "Epoch 4634: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9784e-04 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4635/5000\n",
            "\n",
            "Epoch 4635: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2780e-04 - accuracy: 1.0000 - val_loss: 0.7170 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4636/5000\n",
            "\n",
            "Epoch 4636: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0305e-04 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8489 - 2s/epoch - 64ms/step\n",
            "Epoch 4637/5000\n",
            "\n",
            "Epoch 4637: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.0037e-04 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4638/5000\n",
            "\n",
            "Epoch 4638: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9353e-04 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4639/5000\n",
            "\n",
            "Epoch 4639: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0088e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4640/5000\n",
            "\n",
            "Epoch 4640: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7941e-04 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4641/5000\n",
            "\n",
            "Epoch 4641: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4604e-04 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4642/5000\n",
            "\n",
            "Epoch 4642: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8320e-04 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4643/5000\n",
            "\n",
            "Epoch 4643: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8002e-04 - accuracy: 1.0000 - val_loss: 0.7247 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4644/5000\n",
            "\n",
            "Epoch 4644: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.7853e-04 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.8525 - 3s/epoch - 72ms/step\n",
            "Epoch 4645/5000\n",
            "\n",
            "Epoch 4645: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3453e-04 - accuracy: 1.0000 - val_loss: 0.7576 - val_accuracy: 0.8345 - 2s/epoch - 64ms/step\n",
            "Epoch 4646/5000\n",
            "\n",
            "Epoch 4646: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6980 - val_accuracy: 0.8525 - 2s/epoch - 46ms/step\n",
            "Epoch 4647/5000\n",
            "\n",
            "Epoch 4647: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7330e-04 - accuracy: 1.0000 - val_loss: 0.6875 - val_accuracy: 0.8597 - 2s/epoch - 44ms/step\n",
            "Epoch 4648/5000\n",
            "\n",
            "Epoch 4648: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2057e-04 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.8597 - 2s/epoch - 45ms/step\n",
            "Epoch 4649/5000\n",
            "\n",
            "Epoch 4649: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8101e-04 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4650/5000\n",
            "\n",
            "Epoch 4650: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9867e-04 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4651/5000\n",
            "\n",
            "Epoch 4651: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6955e-04 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8525 - 2s/epoch - 47ms/step\n",
            "Epoch 4652/5000\n",
            "\n",
            "Epoch 4652: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.2538e-04 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 4653/5000\n",
            "\n",
            "Epoch 4653: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1508e-04 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.8489 - 2s/epoch - 55ms/step\n",
            "Epoch 4654/5000\n",
            "\n",
            "Epoch 4654: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9123e-04 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4655/5000\n",
            "\n",
            "Epoch 4655: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0148e-04 - accuracy: 1.0000 - val_loss: 0.6927 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4656/5000\n",
            "\n",
            "Epoch 4656: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8408e-04 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4657/5000\n",
            "\n",
            "Epoch 4657: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8896e-04 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4658/5000\n",
            "\n",
            "Epoch 4658: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6972e-04 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4659/5000\n",
            "\n",
            "Epoch 4659: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5503e-04 - accuracy: 1.0000 - val_loss: 0.6985 - val_accuracy: 0.8489 - 2s/epoch - 51ms/step\n",
            "Epoch 4660/5000\n",
            "\n",
            "Epoch 4660: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.7537e-04 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8453 - 3s/epoch - 78ms/step\n",
            "Epoch 4661/5000\n",
            "\n",
            "Epoch 4661: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8272e-04 - accuracy: 1.0000 - val_loss: 0.6944 - val_accuracy: 0.8417 - 2s/epoch - 50ms/step\n",
            "Epoch 4662/5000\n",
            "\n",
            "Epoch 4662: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9341e-04 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4663/5000\n",
            "\n",
            "Epoch 4663: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9276e-04 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4664/5000\n",
            "\n",
            "Epoch 4664: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9696e-04 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4665/5000\n",
            "\n",
            "Epoch 4665: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7522e-04 - accuracy: 1.0000 - val_loss: 0.6875 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4666/5000\n",
            "\n",
            "Epoch 4666: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3168e-04 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4667/5000\n",
            "\n",
            "Epoch 4667: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2432e-04 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8489 - 2s/epoch - 58ms/step\n",
            "Epoch 4668/5000\n",
            "\n",
            "Epoch 4668: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.1282e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8489 - 3s/epoch - 79ms/step\n",
            "Epoch 4669/5000\n",
            "\n",
            "Epoch 4669: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7948e-04 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4670/5000\n",
            "\n",
            "Epoch 4670: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7531e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4671/5000\n",
            "\n",
            "Epoch 4671: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6848e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4672/5000\n",
            "\n",
            "Epoch 4672: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4974e-04 - accuracy: 1.0000 - val_loss: 0.7031 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4673/5000\n",
            "\n",
            "Epoch 4673: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0462e-04 - accuracy: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4674/5000\n",
            "\n",
            "Epoch 4674: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7767e-04 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4675/5000\n",
            "\n",
            "Epoch 4675: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5462e-04 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.8381 - 2s/epoch - 65ms/step\n",
            "Epoch 4676/5000\n",
            "\n",
            "Epoch 4676: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.0135e-04 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4677/5000\n",
            "\n",
            "Epoch 4677: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0642e-04 - accuracy: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4678/5000\n",
            "\n",
            "Epoch 4678: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1997e-04 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4679/5000\n",
            "\n",
            "Epoch 4679: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0937e-04 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4680/5000\n",
            "\n",
            "Epoch 4680: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3284e-04 - accuracy: 1.0000 - val_loss: 0.6804 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4681/5000\n",
            "\n",
            "Epoch 4681: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9770e-04 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4682/5000\n",
            "\n",
            "Epoch 4682: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7611e-04 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4683/5000\n",
            "\n",
            "Epoch 4683: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.8263e-04 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.8453 - 3s/epoch - 75ms/step\n",
            "Epoch 4684/5000\n",
            "\n",
            "Epoch 4684: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5789e-04 - accuracy: 1.0000 - val_loss: 0.6967 - val_accuracy: 0.8453 - 2s/epoch - 63ms/step\n",
            "Epoch 4685/5000\n",
            "\n",
            "Epoch 4685: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8530e-04 - accuracy: 1.0000 - val_loss: 0.6927 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4686/5000\n",
            "\n",
            "Epoch 4686: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9664e-04 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4687/5000\n",
            "\n",
            "Epoch 4687: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2806e-04 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4688/5000\n",
            "\n",
            "Epoch 4688: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9768e-04 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4689/5000\n",
            "\n",
            "Epoch 4689: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8498e-04 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4690/5000\n",
            "\n",
            "Epoch 4690: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7929e-04 - accuracy: 1.0000 - val_loss: 0.6949 - val_accuracy: 0.8561 - 2s/epoch - 49ms/step\n",
            "Epoch 4691/5000\n",
            "\n",
            "Epoch 4691: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.7009e-04 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8489 - 3s/epoch - 80ms/step\n",
            "Epoch 4692/5000\n",
            "\n",
            "Epoch 4692: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2662e-04 - accuracy: 1.0000 - val_loss: 0.6992 - val_accuracy: 0.8489 - 2s/epoch - 53ms/step\n",
            "Epoch 4693/5000\n",
            "\n",
            "Epoch 4693: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7357e-04 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4694/5000\n",
            "\n",
            "Epoch 4694: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1856e-04 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4695/5000\n",
            "\n",
            "Epoch 4695: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1539e-04 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4696/5000\n",
            "\n",
            "Epoch 4696: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0707e-04 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4697/5000\n",
            "\n",
            "Epoch 4697: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0314e-04 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4698/5000\n",
            "\n",
            "Epoch 4698: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6565e-04 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.8561 - 2s/epoch - 54ms/step\n",
            "Epoch 4699/5000\n",
            "\n",
            "Epoch 4699: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.9267e-04 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.8561 - 3s/epoch - 79ms/step\n",
            "Epoch 4700/5000\n",
            "\n",
            "Epoch 4700: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7595e-04 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8633 - 2s/epoch - 45ms/step\n",
            "Epoch 4701/5000\n",
            "\n",
            "Epoch 4701: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5663e-04 - accuracy: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4702/5000\n",
            "\n",
            "Epoch 4702: val_accuracy did not improve from 0.86331\n",
            "35/35 - 1s - loss: 5.5635e-04 - accuracy: 1.0000 - val_loss: 0.6903 - val_accuracy: 0.8561 - 1s/epoch - 43ms/step\n",
            "Epoch 4703/5000\n",
            "\n",
            "Epoch 4703: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6537e-04 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.8561 - 2s/epoch - 43ms/step\n",
            "Epoch 4704/5000\n",
            "\n",
            "Epoch 4704: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6323e-04 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.8525 - 2s/epoch - 43ms/step\n",
            "Epoch 4705/5000\n",
            "\n",
            "Epoch 4705: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5496e-04 - accuracy: 1.0000 - val_loss: 0.6899 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4706/5000\n",
            "\n",
            "Epoch 4706: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4564e-04 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.8489 - 2s/epoch - 58ms/step\n",
            "Epoch 4707/5000\n",
            "\n",
            "Epoch 4707: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.9645e-04 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8489 - 3s/epoch - 77ms/step\n",
            "Epoch 4708/5000\n",
            "\n",
            "Epoch 4708: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5377e-04 - accuracy: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4709/5000\n",
            "\n",
            "Epoch 4709: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4986e-04 - accuracy: 1.0000 - val_loss: 0.6872 - val_accuracy: 0.8489 - 2s/epoch - 43ms/step\n",
            "Epoch 4710/5000\n",
            "\n",
            "Epoch 4710: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6840e-04 - accuracy: 1.0000 - val_loss: 0.6852 - val_accuracy: 0.8489 - 2s/epoch - 43ms/step\n",
            "Epoch 4711/5000\n",
            "\n",
            "Epoch 4711: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5365e-04 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.8489 - 2s/epoch - 43ms/step\n",
            "Epoch 4712/5000\n",
            "\n",
            "Epoch 4712: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3760e-04 - accuracy: 1.0000 - val_loss: 0.6811 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4713/5000\n",
            "\n",
            "Epoch 4713: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3071e-04 - accuracy: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4714/5000\n",
            "\n",
            "Epoch 4714: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5606e-04 - accuracy: 1.0000 - val_loss: 0.6830 - val_accuracy: 0.8453 - 2s/epoch - 60ms/step\n",
            "Epoch 4715/5000\n",
            "\n",
            "Epoch 4715: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.7518e-04 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8489 - 3s/epoch - 74ms/step\n",
            "Epoch 4716/5000\n",
            "\n",
            "Epoch 4716: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5135e-04 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8489 - 2s/epoch - 43ms/step\n",
            "Epoch 4717/5000\n",
            "\n",
            "Epoch 4717: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6917e-04 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4718/5000\n",
            "\n",
            "Epoch 4718: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1974e-04 - accuracy: 1.0000 - val_loss: 0.6901 - val_accuracy: 0.8453 - 2s/epoch - 43ms/step\n",
            "Epoch 4719/5000\n",
            "\n",
            "Epoch 4719: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0741e-04 - accuracy: 1.0000 - val_loss: 0.7213 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4720/5000\n",
            "\n",
            "Epoch 4720: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7107e-04 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4721/5000\n",
            "\n",
            "Epoch 4721: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.6676e-04 - accuracy: 1.0000 - val_loss: 0.7385 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4722/5000\n",
            "\n",
            "Epoch 4722: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2461e-04 - accuracy: 1.0000 - val_loss: 0.6919 - val_accuracy: 0.8525 - 2s/epoch - 64ms/step\n",
            "Epoch 4723/5000\n",
            "\n",
            "Epoch 4723: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3807e-04 - accuracy: 1.0000 - val_loss: 0.6703 - val_accuracy: 0.8561 - 2s/epoch - 70ms/step\n",
            "Epoch 4724/5000\n",
            "\n",
            "Epoch 4724: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.8381 - 2s/epoch - 43ms/step\n",
            "Epoch 4725/5000\n",
            "\n",
            "Epoch 4725: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0147e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8381 - 2s/epoch - 43ms/step\n",
            "Epoch 4726/5000\n",
            "\n",
            "Epoch 4726: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5215e-04 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.8309 - 2s/epoch - 44ms/step\n",
            "Epoch 4727/5000\n",
            "\n",
            "Epoch 4727: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5018e-04 - accuracy: 1.0000 - val_loss: 0.7212 - val_accuracy: 0.8309 - 2s/epoch - 44ms/step\n",
            "Epoch 4728/5000\n",
            "\n",
            "Epoch 4728: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6720e-04 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4729/5000\n",
            "\n",
            "Epoch 4729: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8527e-04 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4730/5000\n",
            "\n",
            "Epoch 4730: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4985e-04 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8417 - 2s/epoch - 67ms/step\n",
            "Epoch 4731/5000\n",
            "\n",
            "Epoch 4731: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0658e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.8417 - 2s/epoch - 66ms/step\n",
            "Epoch 4732/5000\n",
            "\n",
            "Epoch 4732: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.8345 - 2s/epoch - 43ms/step\n",
            "Epoch 4733/5000\n",
            "\n",
            "Epoch 4733: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.8454 - val_accuracy: 0.8058 - 2s/epoch - 44ms/step\n",
            "Epoch 4734/5000\n",
            "\n",
            "Epoch 4734: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7297 - val_accuracy: 0.8525 - 2s/epoch - 43ms/step\n",
            "Epoch 4735/5000\n",
            "\n",
            "Epoch 4735: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.3898e-04 - accuracy: 1.0000 - val_loss: 0.7464 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4736/5000\n",
            "\n",
            "Epoch 4736: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.1945e-04 - accuracy: 1.0000 - val_loss: 0.7364 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4737/5000\n",
            "\n",
            "Epoch 4737: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5814e-04 - accuracy: 1.0000 - val_loss: 0.7247 - val_accuracy: 0.8525 - 2s/epoch - 43ms/step\n",
            "Epoch 4738/5000\n",
            "\n",
            "Epoch 4738: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1610e-04 - accuracy: 1.0000 - val_loss: 0.7225 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4739/5000\n",
            "\n",
            "Epoch 4739: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1088e-04 - accuracy: 1.0000 - val_loss: 0.7238 - val_accuracy: 0.8489 - 2s/epoch - 65ms/step\n",
            "Epoch 4740/5000\n",
            "\n",
            "Epoch 4740: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6248e-04 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4741/5000\n",
            "\n",
            "Epoch 4741: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1693e-04 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4742/5000\n",
            "\n",
            "Epoch 4742: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9840e-04 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4743/5000\n",
            "\n",
            "Epoch 4743: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4005e-04 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4744/5000\n",
            "\n",
            "Epoch 4744: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0522e-04 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4745/5000\n",
            "\n",
            "Epoch 4745: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0352e-04 - accuracy: 1.0000 - val_loss: 0.7212 - val_accuracy: 0.8489 - 2s/epoch - 46ms/step\n",
            "Epoch 4746/5000\n",
            "\n",
            "Epoch 4746: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.6885e-04 - accuracy: 1.0000 - val_loss: 0.7381 - val_accuracy: 0.8525 - 3s/epoch - 76ms/step\n",
            "Epoch 4747/5000\n",
            "\n",
            "Epoch 4747: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6908e-04 - accuracy: 1.0000 - val_loss: 0.7374 - val_accuracy: 0.8525 - 2s/epoch - 57ms/step\n",
            "Epoch 4748/5000\n",
            "\n",
            "Epoch 4748: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7897e-04 - accuracy: 1.0000 - val_loss: 0.7358 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4749/5000\n",
            "\n",
            "Epoch 4749: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1068e-04 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.8345 - 2s/epoch - 45ms/step\n",
            "Epoch 4750/5000\n",
            "\n",
            "Epoch 4750: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8628e-04 - accuracy: 1.0000 - val_loss: 0.7205 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4751/5000\n",
            "\n",
            "Epoch 4751: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2367e-04 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4752/5000\n",
            "\n",
            "Epoch 4752: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1980e-04 - accuracy: 1.0000 - val_loss: 0.7176 - val_accuracy: 0.8381 - 2s/epoch - 43ms/step\n",
            "Epoch 4753/5000\n",
            "\n",
            "Epoch 4753: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8082e-04 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.8417 - 2s/epoch - 49ms/step\n",
            "Epoch 4754/5000\n",
            "\n",
            "Epoch 4754: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.7320e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8381 - 3s/epoch - 78ms/step\n",
            "Epoch 4755/5000\n",
            "\n",
            "Epoch 4755: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5798e-04 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.8381 - 2s/epoch - 52ms/step\n",
            "Epoch 4756/5000\n",
            "\n",
            "Epoch 4756: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7955e-04 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4757/5000\n",
            "\n",
            "Epoch 4757: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1052e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8453 - 2s/epoch - 43ms/step\n",
            "Epoch 4758/5000\n",
            "\n",
            "Epoch 4758: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7886e-04 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4759/5000\n",
            "\n",
            "Epoch 4759: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7249e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4760/5000\n",
            "\n",
            "Epoch 4760: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5783e-04 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4761/5000\n",
            "\n",
            "Epoch 4761: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4418e-04 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.8417 - 2s/epoch - 51ms/step\n",
            "Epoch 4762/5000\n",
            "\n",
            "Epoch 4762: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.3164e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8417 - 3s/epoch - 80ms/step\n",
            "Epoch 4763/5000\n",
            "\n",
            "Epoch 4763: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9253e-04 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.8345 - 2s/epoch - 49ms/step\n",
            "Epoch 4764/5000\n",
            "\n",
            "Epoch 4764: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6738e-04 - accuracy: 1.0000 - val_loss: 0.6985 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4765/5000\n",
            "\n",
            "Epoch 4765: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5987e-04 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8381 - 2s/epoch - 43ms/step\n",
            "Epoch 4766/5000\n",
            "\n",
            "Epoch 4766: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7428e-04 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4767/5000\n",
            "\n",
            "Epoch 4767: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5458e-04 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4768/5000\n",
            "\n",
            "Epoch 4768: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5754e-04 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4769/5000\n",
            "\n",
            "Epoch 4769: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.1794e-04 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.8417 - 2s/epoch - 55ms/step\n",
            "Epoch 4770/5000\n",
            "\n",
            "Epoch 4770: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.5137e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8417 - 3s/epoch - 78ms/step\n",
            "Epoch 4771/5000\n",
            "\n",
            "Epoch 4771: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7713e-04 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.8345 - 2s/epoch - 46ms/step\n",
            "Epoch 4772/5000\n",
            "\n",
            "Epoch 4772: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6468e-04 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4773/5000\n",
            "\n",
            "Epoch 4773: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8752e-04 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4774/5000\n",
            "\n",
            "Epoch 4774: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5982e-04 - accuracy: 1.0000 - val_loss: 0.6903 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4775/5000\n",
            "\n",
            "Epoch 4775: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8848e-04 - accuracy: 1.0000 - val_loss: 0.6951 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4776/5000\n",
            "\n",
            "Epoch 4776: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8852e-04 - accuracy: 1.0000 - val_loss: 0.6995 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4777/5000\n",
            "\n",
            "Epoch 4777: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6585e-04 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.8453 - 2s/epoch - 61ms/step\n",
            "Epoch 4778/5000\n",
            "\n",
            "Epoch 4778: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.0557e-04 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.8453 - 3s/epoch - 73ms/step\n",
            "Epoch 4779/5000\n",
            "\n",
            "Epoch 4779: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1975e-04 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4780/5000\n",
            "\n",
            "Epoch 4780: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4099e-04 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4781/5000\n",
            "\n",
            "Epoch 4781: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7129e-04 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.8489 - 2s/epoch - 43ms/step\n",
            "Epoch 4782/5000\n",
            "\n",
            "Epoch 4782: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0401e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4783/5000\n",
            "\n",
            "Epoch 4783: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7855e-04 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4784/5000\n",
            "\n",
            "Epoch 4784: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7152e-04 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4785/5000\n",
            "\n",
            "Epoch 4785: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5205e-04 - accuracy: 1.0000 - val_loss: 0.6969 - val_accuracy: 0.8453 - 2s/epoch - 66ms/step\n",
            "Epoch 4786/5000\n",
            "\n",
            "Epoch 4786: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6333e-04 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.8453 - 2s/epoch - 68ms/step\n",
            "Epoch 4787/5000\n",
            "\n",
            "Epoch 4787: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2438e-04 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4788/5000\n",
            "\n",
            "Epoch 4788: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3062e-04 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4789/5000\n",
            "\n",
            "Epoch 4789: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6088e-04 - accuracy: 1.0000 - val_loss: 0.6961 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4790/5000\n",
            "\n",
            "Epoch 4790: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4509e-04 - accuracy: 1.0000 - val_loss: 0.6980 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4791/5000\n",
            "\n",
            "Epoch 4791: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3881e-04 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4792/5000\n",
            "\n",
            "Epoch 4792: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8021e-04 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4793/5000\n",
            "\n",
            "Epoch 4793: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.3370e-04 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8417 - 3s/epoch - 73ms/step\n",
            "Epoch 4794/5000\n",
            "\n",
            "Epoch 4794: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3545e-04 - accuracy: 1.0000 - val_loss: 0.6845 - val_accuracy: 0.8453 - 2s/epoch - 63ms/step\n",
            "Epoch 4795/5000\n",
            "\n",
            "Epoch 4795: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1816e-04 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.8489 - 2s/epoch - 43ms/step\n",
            "Epoch 4796/5000\n",
            "\n",
            "Epoch 4796: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5288e-04 - accuracy: 1.0000 - val_loss: 0.6741 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4797/5000\n",
            "\n",
            "Epoch 4797: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6437e-04 - accuracy: 1.0000 - val_loss: 0.6792 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4798/5000\n",
            "\n",
            "Epoch 4798: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2877e-04 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4799/5000\n",
            "\n",
            "Epoch 4799: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6523e-04 - accuracy: 1.0000 - val_loss: 0.6778 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4800/5000\n",
            "\n",
            "Epoch 4800: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4194e-04 - accuracy: 1.0000 - val_loss: 0.6783 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4801/5000\n",
            "\n",
            "Epoch 4801: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.2895e-04 - accuracy: 1.0000 - val_loss: 0.6767 - val_accuracy: 0.8453 - 3s/epoch - 75ms/step\n",
            "Epoch 4802/5000\n",
            "\n",
            "Epoch 4802: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9818e-04 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.8453 - 2s/epoch - 58ms/step\n",
            "Epoch 4803/5000\n",
            "\n",
            "Epoch 4803: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5392e-04 - accuracy: 1.0000 - val_loss: 0.6788 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4804/5000\n",
            "\n",
            "Epoch 4804: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7094e-04 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4805/5000\n",
            "\n",
            "Epoch 4805: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9532e-04 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4806/5000\n",
            "\n",
            "Epoch 4806: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2786e-04 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4807/5000\n",
            "\n",
            "Epoch 4807: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5372e-04 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4808/5000\n",
            "\n",
            "Epoch 4808: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3769e-04 - accuracy: 1.0000 - val_loss: 0.6828 - val_accuracy: 0.8489 - 2s/epoch - 47ms/step\n",
            "Epoch 4809/5000\n",
            "\n",
            "Epoch 4809: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.2102e-04 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 4810/5000\n",
            "\n",
            "Epoch 4810: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9559e-04 - accuracy: 1.0000 - val_loss: 0.7066 - val_accuracy: 0.8309 - 2s/epoch - 55ms/step\n",
            "Epoch 4811/5000\n",
            "\n",
            "Epoch 4811: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9131e-04 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4812/5000\n",
            "\n",
            "Epoch 4812: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9361e-04 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4813/5000\n",
            "\n",
            "Epoch 4813: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6381e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4814/5000\n",
            "\n",
            "Epoch 4814: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.0527e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4815/5000\n",
            "\n",
            "Epoch 4815: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7226 - val_accuracy: 0.8309 - 2s/epoch - 44ms/step\n",
            "Epoch 4816/5000\n",
            "\n",
            "Epoch 4816: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.8381 - 2s/epoch - 51ms/step\n",
            "Epoch 4817/5000\n",
            "\n",
            "Epoch 4817: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 8.9989e-04 - accuracy: 1.0000 - val_loss: 0.7397 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 4818/5000\n",
            "\n",
            "Epoch 4818: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.7738 - val_accuracy: 0.8309 - 2s/epoch - 50ms/step\n",
            "Epoch 4819/5000\n",
            "\n",
            "Epoch 4819: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.5868e-04 - accuracy: 1.0000 - val_loss: 0.6572 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4820/5000\n",
            "\n",
            "Epoch 4820: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.3213e-04 - accuracy: 1.0000 - val_loss: 0.6407 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4821/5000\n",
            "\n",
            "Epoch 4821: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.5324e-04 - accuracy: 1.0000 - val_loss: 0.6633 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4822/5000\n",
            "\n",
            "Epoch 4822: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9044e-04 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 0.8453 - 2s/epoch - 46ms/step\n",
            "Epoch 4823/5000\n",
            "\n",
            "Epoch 4823: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.3504e-04 - accuracy: 1.0000 - val_loss: 0.6443 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4824/5000\n",
            "\n",
            "Epoch 4824: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8127e-04 - accuracy: 1.0000 - val_loss: 0.6463 - val_accuracy: 0.8417 - 2s/epoch - 59ms/step\n",
            "Epoch 4825/5000\n",
            "\n",
            "Epoch 4825: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.6381e-04 - accuracy: 1.0000 - val_loss: 0.6504 - val_accuracy: 0.8381 - 3s/epoch - 77ms/step\n",
            "Epoch 4826/5000\n",
            "\n",
            "Epoch 4826: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4492e-04 - accuracy: 1.0000 - val_loss: 0.6370 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4827/5000\n",
            "\n",
            "Epoch 4827: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0240e-04 - accuracy: 1.0000 - val_loss: 0.6408 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4828/5000\n",
            "\n",
            "Epoch 4828: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9010e-04 - accuracy: 1.0000 - val_loss: 0.6441 - val_accuracy: 0.8489 - 2s/epoch - 43ms/step\n",
            "Epoch 4829/5000\n",
            "\n",
            "Epoch 4829: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1887e-04 - accuracy: 1.0000 - val_loss: 0.6579 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4830/5000\n",
            "\n",
            "Epoch 4830: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0209e-04 - accuracy: 1.0000 - val_loss: 0.6674 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4831/5000\n",
            "\n",
            "Epoch 4831: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8767e-04 - accuracy: 1.0000 - val_loss: 0.6685 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4832/5000\n",
            "\n",
            "Epoch 4832: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6894e-04 - accuracy: 1.0000 - val_loss: 0.6685 - val_accuracy: 0.8453 - 2s/epoch - 62ms/step\n",
            "Epoch 4833/5000\n",
            "\n",
            "Epoch 4833: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.8750e-04 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8381 - 3s/epoch - 74ms/step\n",
            "Epoch 4834/5000\n",
            "\n",
            "Epoch 4834: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9222e-04 - accuracy: 1.0000 - val_loss: 0.6838 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4835/5000\n",
            "\n",
            "Epoch 4835: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1649e-04 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4836/5000\n",
            "\n",
            "Epoch 4836: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0236e-04 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4837/5000\n",
            "\n",
            "Epoch 4837: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7523e-04 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4838/5000\n",
            "\n",
            "Epoch 4838: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3894e-04 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4839/5000\n",
            "\n",
            "Epoch 4839: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7620e-04 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4840/5000\n",
            "\n",
            "Epoch 4840: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8459e-04 - accuracy: 1.0000 - val_loss: 0.6875 - val_accuracy: 0.8489 - 2s/epoch - 66ms/step\n",
            "Epoch 4841/5000\n",
            "\n",
            "Epoch 4841: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8650e-04 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8489 - 2s/epoch - 69ms/step\n",
            "Epoch 4842/5000\n",
            "\n",
            "Epoch 4842: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9258e-04 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4843/5000\n",
            "\n",
            "Epoch 4843: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4870e-04 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4844/5000\n",
            "\n",
            "Epoch 4844: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5044e-04 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.8597 - 2s/epoch - 44ms/step\n",
            "Epoch 4845/5000\n",
            "\n",
            "Epoch 4845: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5908e-04 - accuracy: 1.0000 - val_loss: 0.6803 - val_accuracy: 0.8561 - 2s/epoch - 45ms/step\n",
            "Epoch 4846/5000\n",
            "\n",
            "Epoch 4846: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0170e-04 - accuracy: 1.0000 - val_loss: 0.6798 - val_accuracy: 0.8597 - 2s/epoch - 44ms/step\n",
            "Epoch 4847/5000\n",
            "\n",
            "Epoch 4847: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6838e-04 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8597 - 2s/epoch - 44ms/step\n",
            "Epoch 4848/5000\n",
            "\n",
            "Epoch 4848: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1374e-04 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.8561 - 2s/epoch - 71ms/step\n",
            "Epoch 4849/5000\n",
            "\n",
            "Epoch 4849: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6290e-04 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8489 - 2s/epoch - 64ms/step\n",
            "Epoch 4850/5000\n",
            "\n",
            "Epoch 4850: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7134e-04 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4851/5000\n",
            "\n",
            "Epoch 4851: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6448e-04 - accuracy: 1.0000 - val_loss: 0.6930 - val_accuracy: 0.8525 - 2s/epoch - 46ms/step\n",
            "Epoch 4852/5000\n",
            "\n",
            "Epoch 4852: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5144e-04 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4853/5000\n",
            "\n",
            "Epoch 4853: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4393e-04 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4854/5000\n",
            "\n",
            "Epoch 4854: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0774e-04 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4855/5000\n",
            "\n",
            "Epoch 4855: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2671e-04 - accuracy: 1.0000 - val_loss: 0.6949 - val_accuracy: 0.8561 - 2s/epoch - 45ms/step\n",
            "Epoch 4856/5000\n",
            "\n",
            "Epoch 4856: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.4388e-04 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.8525 - 3s/epoch - 77ms/step\n",
            "Epoch 4857/5000\n",
            "\n",
            "Epoch 4857: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2567e-04 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.8489 - 2s/epoch - 58ms/step\n",
            "Epoch 4858/5000\n",
            "\n",
            "Epoch 4858: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5050e-04 - accuracy: 1.0000 - val_loss: 0.6792 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4859/5000\n",
            "\n",
            "Epoch 4859: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9144e-04 - accuracy: 1.0000 - val_loss: 0.6779 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4860/5000\n",
            "\n",
            "Epoch 4860: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6387e-04 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4861/5000\n",
            "\n",
            "Epoch 4861: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8628e-04 - accuracy: 1.0000 - val_loss: 0.6981 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4862/5000\n",
            "\n",
            "Epoch 4862: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2660e-04 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4863/5000\n",
            "\n",
            "Epoch 4863: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3041e-04 - accuracy: 1.0000 - val_loss: 0.7175 - val_accuracy: 0.8453 - 2s/epoch - 49ms/step\n",
            "Epoch 4864/5000\n",
            "\n",
            "Epoch 4864: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.5048e-04 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.8489 - 3s/epoch - 79ms/step\n",
            "Epoch 4865/5000\n",
            "\n",
            "Epoch 4865: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2254e-04 - accuracy: 1.0000 - val_loss: 0.7086 - val_accuracy: 0.8489 - 2s/epoch - 53ms/step\n",
            "Epoch 4866/5000\n",
            "\n",
            "Epoch 4866: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7504e-04 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4867/5000\n",
            "\n",
            "Epoch 4867: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7169e-04 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.8489 - 2s/epoch - 46ms/step\n",
            "Epoch 4868/5000\n",
            "\n",
            "Epoch 4868: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6198e-04 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4869/5000\n",
            "\n",
            "Epoch 4869: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5184e-04 - accuracy: 1.0000 - val_loss: 0.6928 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4870/5000\n",
            "\n",
            "Epoch 4870: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9276e-04 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4871/5000\n",
            "\n",
            "Epoch 4871: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4605e-04 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8453 - 2s/epoch - 58ms/step\n",
            "Epoch 4872/5000\n",
            "\n",
            "Epoch 4872: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.2530e-04 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.8453 - 3s/epoch - 77ms/step\n",
            "Epoch 4873/5000\n",
            "\n",
            "Epoch 4873: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8396e-04 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8453 - 2s/epoch - 46ms/step\n",
            "Epoch 4874/5000\n",
            "\n",
            "Epoch 4874: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8659e-04 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4875/5000\n",
            "\n",
            "Epoch 4875: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.2949e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4876/5000\n",
            "\n",
            "Epoch 4876: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6139e-04 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.8525 - 2s/epoch - 46ms/step\n",
            "Epoch 4877/5000\n",
            "\n",
            "Epoch 4877: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4815e-04 - accuracy: 1.0000 - val_loss: 0.6775 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4878/5000\n",
            "\n",
            "Epoch 4878: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6749e-04 - accuracy: 1.0000 - val_loss: 0.6819 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4879/5000\n",
            "\n",
            "Epoch 4879: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7659e-04 - accuracy: 1.0000 - val_loss: 0.6855 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4880/5000\n",
            "\n",
            "Epoch 4880: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6832e-04 - accuracy: 1.0000 - val_loss: 0.6860 - val_accuracy: 0.8525 - 2s/epoch - 68ms/step\n",
            "Epoch 4881/5000\n",
            "\n",
            "Epoch 4881: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4007e-04 - accuracy: 1.0000 - val_loss: 0.6834 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4882/5000\n",
            "\n",
            "Epoch 4882: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3214e-04 - accuracy: 1.0000 - val_loss: 0.6872 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4883/5000\n",
            "\n",
            "Epoch 4883: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8175e-04 - accuracy: 1.0000 - val_loss: 0.6722 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4884/5000\n",
            "\n",
            "Epoch 4884: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4711e-04 - accuracy: 1.0000 - val_loss: 0.6751 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4885/5000\n",
            "\n",
            "Epoch 4885: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2840e-04 - accuracy: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4886/5000\n",
            "\n",
            "Epoch 4886: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7601e-04 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4887/5000\n",
            "\n",
            "Epoch 4887: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.8664e-04 - accuracy: 1.0000 - val_loss: 0.6989 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 4888/5000\n",
            "\n",
            "Epoch 4888: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2936e-04 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8489 - 2s/epoch - 59ms/step\n",
            "Epoch 4889/5000\n",
            "\n",
            "Epoch 4889: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7803e-04 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4890/5000\n",
            "\n",
            "Epoch 4890: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3205e-04 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4891/5000\n",
            "\n",
            "Epoch 4891: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5978e-04 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4892/5000\n",
            "\n",
            "Epoch 4892: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4002e-04 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4893/5000\n",
            "\n",
            "Epoch 4893: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3424e-04 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4894/5000\n",
            "\n",
            "Epoch 4894: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.1499e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8489 - 2s/epoch - 52ms/step\n",
            "Epoch 4895/5000\n",
            "\n",
            "Epoch 4895: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.2388e-04 - accuracy: 1.0000 - val_loss: 0.6982 - val_accuracy: 0.8489 - 3s/epoch - 79ms/step\n",
            "Epoch 4896/5000\n",
            "\n",
            "Epoch 4896: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2437e-04 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.8525 - 2s/epoch - 49ms/step\n",
            "Epoch 4897/5000\n",
            "\n",
            "Epoch 4897: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4672e-04 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4898/5000\n",
            "\n",
            "Epoch 4898: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4032e-04 - accuracy: 1.0000 - val_loss: 0.6930 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4899/5000\n",
            "\n",
            "Epoch 4899: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3897e-04 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4900/5000\n",
            "\n",
            "Epoch 4900: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2333e-04 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4901/5000\n",
            "\n",
            "Epoch 4901: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7492e-04 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4902/5000\n",
            "\n",
            "Epoch 4902: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.1556e-04 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.8489 - 2s/epoch - 59ms/step\n",
            "Epoch 4903/5000\n",
            "\n",
            "Epoch 4903: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.1874e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 4904/5000\n",
            "\n",
            "Epoch 4904: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6547e-04 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4905/5000\n",
            "\n",
            "Epoch 4905: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.0488e-04 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4906/5000\n",
            "\n",
            "Epoch 4906: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.1671e-04 - accuracy: 1.0000 - val_loss: 0.6856 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4907/5000\n",
            "\n",
            "Epoch 4907: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 4.9742e-04 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4908/5000\n",
            "\n",
            "Epoch 4908: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6031e-04 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4909/5000\n",
            "\n",
            "Epoch 4909: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3129e-04 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.8561 - 2s/epoch - 44ms/step\n",
            "Epoch 4910/5000\n",
            "\n",
            "Epoch 4910: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.1101e-04 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.8561 - 2s/epoch - 66ms/step\n",
            "Epoch 4911/5000\n",
            "\n",
            "Epoch 4911: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6259e-04 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4912/5000\n",
            "\n",
            "Epoch 4912: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4012e-04 - accuracy: 1.0000 - val_loss: 0.6912 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4913/5000\n",
            "\n",
            "Epoch 4913: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2262e-04 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4914/5000\n",
            "\n",
            "Epoch 4914: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4309e-04 - accuracy: 1.0000 - val_loss: 0.6775 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4915/5000\n",
            "\n",
            "Epoch 4915: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.1414e-04 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.8525 - 2s/epoch - 44ms/step\n",
            "Epoch 4916/5000\n",
            "\n",
            "Epoch 4916: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3983e-04 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.8489 - 2s/epoch - 43ms/step\n",
            "Epoch 4917/5000\n",
            "\n",
            "Epoch 4917: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4975e-04 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4918/5000\n",
            "\n",
            "Epoch 4918: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.0450e-04 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4919/5000\n",
            "\n",
            "Epoch 4919: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3943e-04 - accuracy: 1.0000 - val_loss: 0.6763 - val_accuracy: 0.8453 - 2s/epoch - 65ms/step\n",
            "Epoch 4920/5000\n",
            "\n",
            "Epoch 4920: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2604e-04 - accuracy: 1.0000 - val_loss: 0.6767 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4921/5000\n",
            "\n",
            "Epoch 4921: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 4.9860e-04 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4922/5000\n",
            "\n",
            "Epoch 4922: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4673e-04 - accuracy: 1.0000 - val_loss: 0.6944 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4923/5000\n",
            "\n",
            "Epoch 4923: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.1017e-04 - accuracy: 1.0000 - val_loss: 0.6872 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4924/5000\n",
            "\n",
            "Epoch 4924: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0020 - accuracy: 0.9991 - val_loss: 0.7247 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4925/5000\n",
            "\n",
            "Epoch 4925: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.6859 - val_accuracy: 0.8453 - 2s/epoch - 46ms/step\n",
            "Epoch 4926/5000\n",
            "\n",
            "Epoch 4926: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.7746 - val_accuracy: 0.8381 - 3s/epoch - 76ms/step\n",
            "Epoch 4927/5000\n",
            "\n",
            "Epoch 4927: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7662 - val_accuracy: 0.8417 - 2s/epoch - 59ms/step\n",
            "Epoch 4928/5000\n",
            "\n",
            "Epoch 4928: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4929/5000\n",
            "\n",
            "Epoch 4929: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4930/5000\n",
            "\n",
            "Epoch 4930: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.2533e-04 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4931/5000\n",
            "\n",
            "Epoch 4931: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 8.0340e-04 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4932/5000\n",
            "\n",
            "Epoch 4932: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4711e-04 - accuracy: 1.0000 - val_loss: 0.7467 - val_accuracy: 0.8381 - 2s/epoch - 45ms/step\n",
            "Epoch 4933/5000\n",
            "\n",
            "Epoch 4933: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 7.8270e-04 - accuracy: 1.0000 - val_loss: 0.7238 - val_accuracy: 0.8345 - 2s/epoch - 48ms/step\n",
            "Epoch 4934/5000\n",
            "\n",
            "Epoch 4934: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.1022e-04 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8417 - 3s/epoch - 78ms/step\n",
            "Epoch 4935/5000\n",
            "\n",
            "Epoch 4935: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.9359e-04 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.8381 - 2s/epoch - 53ms/step\n",
            "Epoch 4936/5000\n",
            "\n",
            "Epoch 4936: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1325e-04 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4937/5000\n",
            "\n",
            "Epoch 4937: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3134e-04 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4938/5000\n",
            "\n",
            "Epoch 4938: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1713e-04 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.8489 - 2s/epoch - 45ms/step\n",
            "Epoch 4939/5000\n",
            "\n",
            "Epoch 4939: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0299e-04 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4940/5000\n",
            "\n",
            "Epoch 4940: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.0012e-04 - accuracy: 1.0000 - val_loss: 0.7151 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4941/5000\n",
            "\n",
            "Epoch 4941: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.8650e-04 - accuracy: 1.0000 - val_loss: 0.7227 - val_accuracy: 0.8525 - 2s/epoch - 54ms/step\n",
            "Epoch 4942/5000\n",
            "\n",
            "Epoch 4942: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 6.1261e-04 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 4943/5000\n",
            "\n",
            "Epoch 4943: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4908e-04 - accuracy: 1.0000 - val_loss: 0.7176 - val_accuracy: 0.8489 - 2s/epoch - 47ms/step\n",
            "Epoch 4944/5000\n",
            "\n",
            "Epoch 4944: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9119e-04 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8525 - 2s/epoch - 45ms/step\n",
            "Epoch 4945/5000\n",
            "\n",
            "Epoch 4945: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1843e-04 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4946/5000\n",
            "\n",
            "Epoch 4946: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3708e-04 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4947/5000\n",
            "\n",
            "Epoch 4947: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8502e-04 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4948/5000\n",
            "\n",
            "Epoch 4948: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.5553e-04 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.8453 - 2s/epoch - 46ms/step\n",
            "Epoch 4949/5000\n",
            "\n",
            "Epoch 4949: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4246e-04 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8453 - 2s/epoch - 63ms/step\n",
            "Epoch 4950/5000\n",
            "\n",
            "Epoch 4950: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.8558e-04 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.8453 - 3s/epoch - 74ms/step\n",
            "Epoch 4951/5000\n",
            "\n",
            "Epoch 4951: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9003e-04 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.8453 - 2s/epoch - 46ms/step\n",
            "Epoch 4952/5000\n",
            "\n",
            "Epoch 4952: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6086e-04 - accuracy: 1.0000 - val_loss: 0.7145 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4953/5000\n",
            "\n",
            "Epoch 4953: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8715e-04 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4954/5000\n",
            "\n",
            "Epoch 4954: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5197e-04 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4955/5000\n",
            "\n",
            "Epoch 4955: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.7771e-04 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4956/5000\n",
            "\n",
            "Epoch 4956: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6625e-04 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4957/5000\n",
            "\n",
            "Epoch 4957: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.1685e-04 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4958/5000\n",
            "\n",
            "Epoch 4958: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.7825e-04 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8525 - 2s/epoch - 64ms/step\n",
            "Epoch 4959/5000\n",
            "\n",
            "Epoch 4959: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8649e-04 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4960/5000\n",
            "\n",
            "Epoch 4960: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3970e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4961/5000\n",
            "\n",
            "Epoch 4961: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8878e-04 - accuracy: 1.0000 - val_loss: 0.7101 - val_accuracy: 0.8453 - 2s/epoch - 43ms/step\n",
            "Epoch 4962/5000\n",
            "\n",
            "Epoch 4962: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3731e-04 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 4963/5000\n",
            "\n",
            "Epoch 4963: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9169e-04 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4964/5000\n",
            "\n",
            "Epoch 4964: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3818e-04 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.8453 - 2s/epoch - 44ms/step\n",
            "Epoch 4965/5000\n",
            "\n",
            "Epoch 4965: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.6371e-04 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.8453 - 3s/epoch - 76ms/step\n",
            "Epoch 4966/5000\n",
            "\n",
            "Epoch 4966: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.6185e-04 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.8489 - 2s/epoch - 60ms/step\n",
            "Epoch 4967/5000\n",
            "\n",
            "Epoch 4967: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.1647e-04 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4968/5000\n",
            "\n",
            "Epoch 4968: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 9.3641e-04 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4969/5000\n",
            "\n",
            "Epoch 4969: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.5223e-04 - accuracy: 1.0000 - val_loss: 0.7461 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4970/5000\n",
            "\n",
            "Epoch 4970: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6522e-04 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4971/5000\n",
            "\n",
            "Epoch 4971: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.4839e-04 - accuracy: 1.0000 - val_loss: 0.7378 - val_accuracy: 0.8345 - 2s/epoch - 44ms/step\n",
            "Epoch 4972/5000\n",
            "\n",
            "Epoch 4972: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3560e-04 - accuracy: 1.0000 - val_loss: 0.7368 - val_accuracy: 0.8345 - 2s/epoch - 46ms/step\n",
            "Epoch 4973/5000\n",
            "\n",
            "Epoch 4973: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.3348e-04 - accuracy: 1.0000 - val_loss: 0.7359 - val_accuracy: 0.8345 - 3s/epoch - 78ms/step\n",
            "Epoch 4974/5000\n",
            "\n",
            "Epoch 4974: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.6841e-04 - accuracy: 1.0000 - val_loss: 0.7353 - val_accuracy: 0.8345 - 2s/epoch - 55ms/step\n",
            "Epoch 4975/5000\n",
            "\n",
            "Epoch 4975: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4302e-04 - accuracy: 1.0000 - val_loss: 0.7347 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4976/5000\n",
            "\n",
            "Epoch 4976: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4672e-04 - accuracy: 1.0000 - val_loss: 0.7348 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4977/5000\n",
            "\n",
            "Epoch 4977: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4576e-04 - accuracy: 1.0000 - val_loss: 0.7365 - val_accuracy: 0.8381 - 2s/epoch - 44ms/step\n",
            "Epoch 4978/5000\n",
            "\n",
            "Epoch 4978: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 6.3090e-04 - accuracy: 1.0000 - val_loss: 0.7309 - val_accuracy: 0.8381 - 2s/epoch - 43ms/step\n",
            "Epoch 4979/5000\n",
            "\n",
            "Epoch 4979: val_accuracy did not improve from 0.86331\n",
            "35/35 - 1s - loss: 6.1364e-04 - accuracy: 1.0000 - val_loss: 0.7331 - val_accuracy: 0.8381 - 1s/epoch - 43ms/step\n",
            "Epoch 4980/5000\n",
            "\n",
            "Epoch 4980: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4812e-04 - accuracy: 1.0000 - val_loss: 0.7350 - val_accuracy: 0.8417 - 2s/epoch - 49ms/step\n",
            "Epoch 4981/5000\n",
            "\n",
            "Epoch 4981: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.5994e-04 - accuracy: 1.0000 - val_loss: 0.7310 - val_accuracy: 0.8417 - 3s/epoch - 78ms/step\n",
            "Epoch 4982/5000\n",
            "\n",
            "Epoch 4982: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9265e-04 - accuracy: 1.0000 - val_loss: 0.7262 - val_accuracy: 0.8417 - 2s/epoch - 53ms/step\n",
            "Epoch 4983/5000\n",
            "\n",
            "Epoch 4983: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.4380e-04 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4984/5000\n",
            "\n",
            "Epoch 4984: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3457e-04 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4985/5000\n",
            "\n",
            "Epoch 4985: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3162e-04 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.8453 - 2s/epoch - 43ms/step\n",
            "Epoch 4986/5000\n",
            "\n",
            "Epoch 4986: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3739e-04 - accuracy: 1.0000 - val_loss: 0.7171 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4987/5000\n",
            "\n",
            "Epoch 4987: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.0788e-04 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4988/5000\n",
            "\n",
            "Epoch 4988: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3241e-04 - accuracy: 1.0000 - val_loss: 0.7171 - val_accuracy: 0.8417 - 2s/epoch - 50ms/step\n",
            "Epoch 4989/5000\n",
            "\n",
            "Epoch 4989: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.7780e-04 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.8417 - 3s/epoch - 79ms/step\n",
            "Epoch 4990/5000\n",
            "\n",
            "Epoch 4990: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3253e-04 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.8417 - 2s/epoch - 51ms/step\n",
            "Epoch 4991/5000\n",
            "\n",
            "Epoch 4991: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2925e-04 - accuracy: 1.0000 - val_loss: 0.7169 - val_accuracy: 0.8417 - 2s/epoch - 43ms/step\n",
            "Epoch 4992/5000\n",
            "\n",
            "Epoch 4992: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.3197e-04 - accuracy: 1.0000 - val_loss: 0.7135 - val_accuracy: 0.8417 - 2s/epoch - 44ms/step\n",
            "Epoch 4993/5000\n",
            "\n",
            "Epoch 4993: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.8137e-04 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4994/5000\n",
            "\n",
            "Epoch 4994: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.1314e-04 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4995/5000\n",
            "\n",
            "Epoch 4995: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.9782e-04 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8489 - 2s/epoch - 44ms/step\n",
            "Epoch 4996/5000\n",
            "\n",
            "Epoch 4996: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2219e-04 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.8453 - 2s/epoch - 55ms/step\n",
            "Epoch 4997/5000\n",
            "\n",
            "Epoch 4997: val_accuracy did not improve from 0.86331\n",
            "35/35 - 3s - loss: 5.1135e-04 - accuracy: 1.0000 - val_loss: 0.7171 - val_accuracy: 0.8453 - 3s/epoch - 77ms/step\n",
            "Epoch 4998/5000\n",
            "\n",
            "Epoch 4998: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2462e-04 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.8453 - 2s/epoch - 45ms/step\n",
            "Epoch 4999/5000\n",
            "\n",
            "Epoch 4999: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.2608e-04 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n",
            "Epoch 5000/5000\n",
            "\n",
            "Epoch 5000: val_accuracy did not improve from 0.86331\n",
            "35/35 - 2s - loss: 5.1650e-04 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.8417 - 2s/epoch - 45ms/step\n"
          ]
        }
      ],
      "source": [
        "model4.compile(optimizer=Adam(learning_rate = 0.00001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "history4 = model4.fit(X_train, y_train,batch_size = 32, epochs = 5000, validation_data= (X_test, y_test),callbacks=callbacks_list,verbose=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpm1dvfBCasR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87ee1a8-0376-4046-9fda-a25005fd4398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 9ms/step\n",
            "Test Accuracy 86.33093525179856 %\n",
            "35/35 [==============================] - 1s 9ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Train accuracy: 100.00%\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6142 - accuracy: 0.8633\n",
            "test accuracy: 86.33%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "modelp = keras.models.load_model(\"pccr_mean.best.hdf5\")\n",
        "y_pred = modelp.predict(X_test)\n",
        "y_pred=np.argmax(y_pred,axis=1)\n",
        "print(\"Test Accuracy\",accuracy_score(y_test, y_pred)*100,\"%\")\n",
        "\n",
        "scores = modelp.evaluate(X_train, y_train)\n",
        "print(\"Train %s: %.2f%%\" % (modelp.metrics_names[1], scores[1]*100))\n",
        "\n",
        "scores = modelp.evaluate(X_test, y_test)\n",
        "print(\"test %s: %.2f%%\" % (modelp.metrics_names[1], scores[1]*100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMJEOiBwCdqs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "6c613c62-a0f8-4ac4-e7d7-bb1a1ffd0a13"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "srt=\"Pearson - Mean Model\"\n",
        "plot_accuracy(history4, no_of_epoch,srt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGfDvZBVCgRq"
      },
      "outputs": [],
      "source": [
        "plot_loss(history4,no_of_epoch, srt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4H1nTUACmiC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "7fd1c44e-0391-4988-9267-eba104a5a966"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "title=\"Confusion Matrix of pccr-mean\"\n",
        "cm=confusion(y_pred,y_test)\n",
        "conf_mat2(cm,class_names,title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zudgD9wcCo6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb9703d-ba52-43e6-f215-82fb4d30f8c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.82      0.85        51\n",
            "           1       0.79      0.84      0.82        37\n",
            "           2       0.92      0.88      0.90        50\n",
            "           3       0.81      0.81      0.81        47\n",
            "           4       0.86      0.83      0.84        46\n",
            "           5       0.90      1.00      0.95        47\n",
            "\n",
            "    accuracy                           0.86       278\n",
            "   macro avg       0.86      0.86      0.86       278\n",
            "weighted avg       0.86      0.86      0.86       278\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-MB0-ifCpmr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b9d76b0e-38d5-446b-9703-db3fe4a86cf1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8201a803-f34e-4b43-9d99-f380d2a0b3ee\", \"pccr-mean.h5\", 3473352)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "modelp.save(\"pccr-mean.h5\")\n",
        "from google.colab import files\n",
        "files.download(\"pccr-mean.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pccr_xcorr_mi=[]"
      ],
      "metadata": {
        "id": "7ZNmhe_LaUue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### data test construction ############\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i in range(0,fall_number):\n",
        "  temp=[]\n",
        "\n",
        "  temp.append(pearson_corr[i])\n",
        "  temp.append(xcorr[i])\n",
        "  temp.append(mi_score[i])\n",
        "\n",
        "  pccr_xcorr_mi.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "  #walk_temp=np.stack((xcorr_walk[i],pearson_corr_walk[i],mi_score_walk[i],partial_mi_score_walk[i],mean_f_walk[i]),axis=0)\n",
        "for i in range(0,walk_number):\n",
        "  temp=[]\n",
        "\n",
        "\n",
        "  temp.append(pearson_corr_walk[i])\n",
        "  temp.append(xcorr_walk[i])\n",
        "  temp.append(mi_score_walk[i])\n",
        "\n",
        "  pccr_xcorr_mi.append(temp)\n",
        "\n",
        "\n",
        "for i in range(0,sit_number):\n",
        "  temp=[]\n",
        "\n",
        "\n",
        "  temp.append(pearson_corr_sit[i])\n",
        "  temp.append(xcorr_sit[i])\n",
        "  temp.append(mi_score_sit[i])\n",
        "\n",
        "  pccr_xcorr_mi.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,bsc_number):\n",
        "  temp=[]\n",
        "\n",
        "  temp.append(pearson_corr_bsc[i])\n",
        "  temp.append(xcorr_bsc[i])\n",
        "  temp.append(mi_score_bsc[i])\n",
        "\n",
        "  pccr_xcorr_mi.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,stand_number):\n",
        "  temp=[]\n",
        "\n",
        "  temp.append(pearson_corr_stand[i])\n",
        "  temp.append(xcorr_stand[i])\n",
        "  temp.append(mi_score_stand[i])\n",
        "\n",
        "  pccr_xcorr_mi.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,laying_number):\n",
        "  temp=[]\n",
        "\n",
        "  temp.append(pearson_corr_laying[i])\n",
        "  temp.append(xcorr_laying[i])\n",
        "  temp.append(mi_score_laying[i])\n",
        "\n",
        "  pccr_xcorr_mi.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#X_data=pd.DataFrame(data=X_data,columns=[['Xcorr','Pearson','MI','NMI','Mean']])\n",
        "#y_data=pd.DataFrame(data=y_data,columns=['Label'])\n"
      ],
      "metadata": {
        "id": "SB3XtP1RaEaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "def get_3d_2():\n",
        "  model1 = Sequential()\n",
        "  model1.add(Conv3D(16, (2, 7,7),kernel_initializer='normal', activation = 'relu', input_shape = (3,16,16,1)))\n",
        "\n",
        "\n",
        "  model1.add(Conv3D(128, (1, 7,7), activation='relu'))\n",
        "  model1.add(Dropout(0.25))\n",
        "\n",
        "  model1.add(Conv3D(128, (1, 3,3), activation='relu'))\n",
        "  model1.add(Dropout(0.25))\n",
        "\n",
        "  model1.add(MaxPool3D((1, 2,2)))\n",
        "  model1.add(BatchNormalization())\n",
        "\n",
        "  model1.add(Flatten())\n",
        "\n",
        "  model1.add(Dense(256, activation = 'relu'))\n",
        "  model1.add(Dropout(0.25))\n",
        "\n",
        "  model1.add(Dense(6, activation='softmax',kernel_regularizer=l2(0.01)))\n",
        "  return model1"
      ],
      "metadata": {
        "id": "EpUL6wh0aP-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pccr_xcorr_mi=np.array(pccr_xcorr_mi)\n",
        "print(pccr_xcorr_mi.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCJgPY9sbrxJ",
        "outputId": "c923de2e-d1e7-430d-cfa1-ef78d2c1becb"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1390, 3, 16, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"pccr_xcorr_mi.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "#es = EarlyStopping(monitor='val_loss', patience=100, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "lNmVyrMvbtGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_data=y_temp\n",
        "yenc = sklearn.preprocessing.LabelEncoder()\n",
        "y_data = yenc.fit_transform(y_data)\n",
        "X_train, X_test, y_train, y_test = train_test_split(pccr_xcorr_mi, y_data, test_size = 0.20, random_state = 42)\n",
        "\n",
        "#X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.10, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 3,16, 16,1)\n",
        "X_test = X_test.reshape(X_test.shape[0],3, 16,16,1)\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEX4cCNhby_i",
        "outputId": "52badffd-5850-4d0a-b25e-afc91a8c20b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1112, 3, 16, 16, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5=get_3d_2()\n",
        "model5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUyX6Dhgbf3f",
        "outputId": "cf2df7e5-1164-4038-fd64-2113f3d34ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 2, 10, 10, 16)     1584      \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 2, 4, 4, 128)      100480    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2, 4, 4, 128)      0         \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 2, 2, 2, 128)      147584    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2, 2, 2, 128)      0         \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 2, 1, 1, 128)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 2, 1, 1, 128)     512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 317,494\n",
            "Trainable params: 317,238\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.compile(optimizer=Adam(learning_rate = 0.00001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "history5 = model5.fit(X_train, y_train,batch_size = 32, epochs = no_of_epoch, validation_data= (X_test, y_test),callbacks=callbacks_list,verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EApZkBKNbnJY",
        "outputId": "ba3bcb31-2e06-4924-f216-5964a061c592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3751/5000\n",
            "\n",
            "Epoch 3751: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7567e-04 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 3752/5000\n",
            "\n",
            "Epoch 3752: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7470e-04 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 3753/5000\n",
            "\n",
            "Epoch 3753: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7453e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8201 - 3s/epoch - 93ms/step\n",
            "Epoch 3754/5000\n",
            "\n",
            "Epoch 3754: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.7386e-04 - accuracy: 1.0000 - val_loss: 0.6951 - val_accuracy: 0.8273 - 4s/epoch - 109ms/step\n",
            "Epoch 3755/5000\n",
            "\n",
            "Epoch 3755: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7985e-04 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 3756/5000\n",
            "\n",
            "Epoch 3756: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.8306e-04 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 3757/5000\n",
            "\n",
            "Epoch 3757: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6965e-04 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.8237 - 4s/epoch - 106ms/step\n",
            "Epoch 3758/5000\n",
            "\n",
            "Epoch 3758: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7150e-04 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.8273 - 3s/epoch - 96ms/step\n",
            "Epoch 3759/5000\n",
            "\n",
            "Epoch 3759: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7717e-04 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 3760/5000\n",
            "\n",
            "Epoch 3760: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7609e-04 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3761/5000\n",
            "\n",
            "Epoch 3761: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.7069e-04 - accuracy: 1.0000 - val_loss: 0.6900 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 3762/5000\n",
            "\n",
            "Epoch 3762: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7144e-04 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 3763/5000\n",
            "\n",
            "Epoch 3763: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7501e-04 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.8417 - 3s/epoch - 86ms/step\n",
            "Epoch 3764/5000\n",
            "\n",
            "Epoch 3764: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7578e-04 - accuracy: 1.0000 - val_loss: 0.6981 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 3765/5000\n",
            "\n",
            "Epoch 3765: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.8743e-04 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 3766/5000\n",
            "\n",
            "Epoch 3766: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.8485e-04 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 3767/5000\n",
            "\n",
            "Epoch 3767: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.8222e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8345 - 3s/epoch - 86ms/step\n",
            "Epoch 3768/5000\n",
            "\n",
            "Epoch 3768: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.8308e-04 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 3769/5000\n",
            "\n",
            "Epoch 3769: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.7704e-04 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 3770/5000\n",
            "\n",
            "Epoch 3770: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7080e-04 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 3771/5000\n",
            "\n",
            "Epoch 3771: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7566e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3772/5000\n",
            "\n",
            "Epoch 3772: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7790e-04 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.8309 - 3s/epoch - 91ms/step\n",
            "Epoch 3773/5000\n",
            "\n",
            "Epoch 3773: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6948e-04 - accuracy: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.8273 - 4s/epoch - 111ms/step\n",
            "Epoch 3774/5000\n",
            "\n",
            "Epoch 3774: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7135e-04 - accuracy: 1.0000 - val_loss: 0.6842 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 3775/5000\n",
            "\n",
            "Epoch 3775: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6937e-04 - accuracy: 1.0000 - val_loss: 0.6834 - val_accuracy: 0.8237 - 3s/epoch - 87ms/step\n",
            "Epoch 3776/5000\n",
            "\n",
            "Epoch 3776: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6799e-04 - accuracy: 1.0000 - val_loss: 0.6872 - val_accuracy: 0.8201 - 4s/epoch - 104ms/step\n",
            "Epoch 3777/5000\n",
            "\n",
            "Epoch 3777: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7121e-04 - accuracy: 1.0000 - val_loss: 0.6806 - val_accuracy: 0.8201 - 3s/epoch - 99ms/step\n",
            "Epoch 3778/5000\n",
            "\n",
            "Epoch 3778: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7707e-04 - accuracy: 1.0000 - val_loss: 0.7051 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 3779/5000\n",
            "\n",
            "Epoch 3779: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6877e-04 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 3780/5000\n",
            "\n",
            "Epoch 3780: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.8189e-04 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 3781/5000\n",
            "\n",
            "Epoch 3781: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7207e-04 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 3782/5000\n",
            "\n",
            "Epoch 3782: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7861e-04 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 3783/5000\n",
            "\n",
            "Epoch 3783: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7280e-04 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 3784/5000\n",
            "\n",
            "Epoch 3784: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.7040e-04 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 3785/5000\n",
            "\n",
            "Epoch 3785: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7127e-04 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3786/5000\n",
            "\n",
            "Epoch 3786: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7362e-04 - accuracy: 1.0000 - val_loss: 0.6995 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 3787/5000\n",
            "\n",
            "Epoch 3787: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7178e-04 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3788/5000\n",
            "\n",
            "Epoch 3788: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.7284e-04 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.8201 - 4s/epoch - 118ms/step\n",
            "Epoch 3789/5000\n",
            "\n",
            "Epoch 3789: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7061e-04 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.8201 - 3s/epoch - 87ms/step\n",
            "Epoch 3790/5000\n",
            "\n",
            "Epoch 3790: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7088e-04 - accuracy: 1.0000 - val_loss: 0.7047 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3791/5000\n",
            "\n",
            "Epoch 3791: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6580e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8237 - 3s/epoch - 94ms/step\n",
            "Epoch 3792/5000\n",
            "\n",
            "Epoch 3792: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.7015e-04 - accuracy: 1.0000 - val_loss: 0.7150 - val_accuracy: 0.8237 - 4s/epoch - 108ms/step\n",
            "Epoch 3793/5000\n",
            "\n",
            "Epoch 3793: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6650e-04 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3794/5000\n",
            "\n",
            "Epoch 3794: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6824e-04 - accuracy: 1.0000 - val_loss: 0.6910 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3795/5000\n",
            "\n",
            "Epoch 3795: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6482e-04 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8237 - 4s/epoch - 106ms/step\n",
            "Epoch 3796/5000\n",
            "\n",
            "Epoch 3796: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6922e-04 - accuracy: 1.0000 - val_loss: 0.6871 - val_accuracy: 0.8309 - 3s/epoch - 96ms/step\n",
            "Epoch 3797/5000\n",
            "\n",
            "Epoch 3797: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7277e-04 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8381 - 3s/epoch - 86ms/step\n",
            "Epoch 3798/5000\n",
            "\n",
            "Epoch 3798: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7338e-04 - accuracy: 1.0000 - val_loss: 0.6922 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 3799/5000\n",
            "\n",
            "Epoch 3799: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.8206e-04 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.8345 - 4s/epoch - 117ms/step\n",
            "Epoch 3800/5000\n",
            "\n",
            "Epoch 3800: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.8088e-04 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3801/5000\n",
            "\n",
            "Epoch 3801: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6600e-04 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3802/5000\n",
            "\n",
            "Epoch 3802: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7574e-04 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8345 - 3s/epoch - 86ms/step\n",
            "Epoch 3803/5000\n",
            "\n",
            "Epoch 3803: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.7256e-04 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.8237 - 4s/epoch - 116ms/step\n",
            "Epoch 3804/5000\n",
            "\n",
            "Epoch 3804: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6839e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3805/5000\n",
            "\n",
            "Epoch 3805: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6895e-04 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 3806/5000\n",
            "\n",
            "Epoch 3806: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6466e-04 - accuracy: 1.0000 - val_loss: 0.6969 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3807/5000\n",
            "\n",
            "Epoch 3807: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6475e-04 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.8201 - 4s/epoch - 116ms/step\n",
            "Epoch 3808/5000\n",
            "\n",
            "Epoch 3808: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6863e-04 - accuracy: 1.0000 - val_loss: 0.6969 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3809/5000\n",
            "\n",
            "Epoch 3809: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7406e-04 - accuracy: 1.0000 - val_loss: 0.6933 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3810/5000\n",
            "\n",
            "Epoch 3810: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7147e-04 - accuracy: 1.0000 - val_loss: 0.6974 - val_accuracy: 0.8201 - 3s/epoch - 89ms/step\n",
            "Epoch 3811/5000\n",
            "\n",
            "Epoch 3811: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6581e-04 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8273 - 4s/epoch - 112ms/step\n",
            "Epoch 3812/5000\n",
            "\n",
            "Epoch 3812: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6679e-04 - accuracy: 1.0000 - val_loss: 0.6989 - val_accuracy: 0.8345 - 3s/epoch - 86ms/step\n",
            "Epoch 3813/5000\n",
            "\n",
            "Epoch 3813: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6669e-04 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 3814/5000\n",
            "\n",
            "Epoch 3814: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6581e-04 - accuracy: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.8201 - 4s/epoch - 101ms/step\n",
            "Epoch 3815/5000\n",
            "\n",
            "Epoch 3815: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6778e-04 - accuracy: 1.0000 - val_loss: 0.7015 - val_accuracy: 0.8237 - 4s/epoch - 101ms/step\n",
            "Epoch 3816/5000\n",
            "\n",
            "Epoch 3816: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7106e-04 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 3817/5000\n",
            "\n",
            "Epoch 3817: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6300e-04 - accuracy: 1.0000 - val_loss: 0.7065 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 3818/5000\n",
            "\n",
            "Epoch 3818: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6778e-04 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.8309 - 4s/epoch - 114ms/step\n",
            "Epoch 3819/5000\n",
            "\n",
            "Epoch 3819: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6561e-04 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8201 - 3s/epoch - 87ms/step\n",
            "Epoch 3820/5000\n",
            "\n",
            "Epoch 3820: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7147e-04 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 3821/5000\n",
            "\n",
            "Epoch 3821: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6786e-04 - accuracy: 1.0000 - val_loss: 0.7076 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3822/5000\n",
            "\n",
            "Epoch 3822: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6616e-04 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.8129 - 4s/epoch - 116ms/step\n",
            "Epoch 3823/5000\n",
            "\n",
            "Epoch 3823: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6551e-04 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.8129 - 3s/epoch - 97ms/step\n",
            "Epoch 3824/5000\n",
            "\n",
            "Epoch 3824: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.8226e-04 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8237 - 3s/epoch - 96ms/step\n",
            "Epoch 3825/5000\n",
            "\n",
            "Epoch 3825: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6655e-04 - accuracy: 1.0000 - val_loss: 0.7073 - val_accuracy: 0.8345 - 3s/epoch - 92ms/step\n",
            "Epoch 3826/5000\n",
            "\n",
            "Epoch 3826: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6393e-04 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.8237 - 4s/epoch - 110ms/step\n",
            "Epoch 3827/5000\n",
            "\n",
            "Epoch 3827: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6322e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3828/5000\n",
            "\n",
            "Epoch 3828: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7000e-04 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3829/5000\n",
            "\n",
            "Epoch 3829: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6611e-04 - accuracy: 1.0000 - val_loss: 0.7002 - val_accuracy: 0.8237 - 4s/epoch - 104ms/step\n",
            "Epoch 3830/5000\n",
            "\n",
            "Epoch 3830: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6445e-04 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.8201 - 3s/epoch - 99ms/step\n",
            "Epoch 3831/5000\n",
            "\n",
            "Epoch 3831: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6963e-04 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 3832/5000\n",
            "\n",
            "Epoch 3832: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6286e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 3833/5000\n",
            "\n",
            "Epoch 3833: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6122e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 3834/5000\n",
            "\n",
            "Epoch 3834: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6358e-04 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 3835/5000\n",
            "\n",
            "Epoch 3835: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6300e-04 - accuracy: 1.0000 - val_loss: 0.7051 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 3836/5000\n",
            "\n",
            "Epoch 3836: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6309e-04 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 0.8345 - 3s/epoch - 86ms/step\n",
            "Epoch 3837/5000\n",
            "\n",
            "Epoch 3837: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5999e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 3838/5000\n",
            "\n",
            "Epoch 3838: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6409e-04 - accuracy: 1.0000 - val_loss: 0.7101 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3839/5000\n",
            "\n",
            "Epoch 3839: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6653e-04 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 3840/5000\n",
            "\n",
            "Epoch 3840: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6684e-04 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3841/5000\n",
            "\n",
            "Epoch 3841: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6552e-04 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8237 - 4s/epoch - 118ms/step\n",
            "Epoch 3842/5000\n",
            "\n",
            "Epoch 3842: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6505e-04 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.8453 - 3s/epoch - 85ms/step\n",
            "Epoch 3843/5000\n",
            "\n",
            "Epoch 3843: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6836e-04 - accuracy: 1.0000 - val_loss: 0.6944 - val_accuracy: 0.8381 - 3s/epoch - 86ms/step\n",
            "Epoch 3844/5000\n",
            "\n",
            "Epoch 3844: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6532e-04 - accuracy: 1.0000 - val_loss: 0.6974 - val_accuracy: 0.8237 - 3s/epoch - 91ms/step\n",
            "Epoch 3845/5000\n",
            "\n",
            "Epoch 3845: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6223e-04 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8237 - 4s/epoch - 111ms/step\n",
            "Epoch 3846/5000\n",
            "\n",
            "Epoch 3846: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5742e-04 - accuracy: 1.0000 - val_loss: 0.6974 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3847/5000\n",
            "\n",
            "Epoch 3847: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6697e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 3848/5000\n",
            "\n",
            "Epoch 3848: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5891e-04 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.8273 - 4s/epoch - 103ms/step\n",
            "Epoch 3849/5000\n",
            "\n",
            "Epoch 3849: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6643e-04 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8201 - 3s/epoch - 99ms/step\n",
            "Epoch 3850/5000\n",
            "\n",
            "Epoch 3850: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6452e-04 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 3851/5000\n",
            "\n",
            "Epoch 3851: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6384e-04 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3852/5000\n",
            "\n",
            "Epoch 3852: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6301e-04 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.8165 - 4s/epoch - 116ms/step\n",
            "Epoch 3853/5000\n",
            "\n",
            "Epoch 3853: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7253e-04 - accuracy: 1.0000 - val_loss: 0.7150 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3854/5000\n",
            "\n",
            "Epoch 3854: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7418e-04 - accuracy: 1.0000 - val_loss: 0.7302 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3855/5000\n",
            "\n",
            "Epoch 3855: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 2.1114e-04 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3856/5000\n",
            "\n",
            "Epoch 3856: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.8307e-04 - accuracy: 1.0000 - val_loss: 0.7191 - val_accuracy: 0.8201 - 4s/epoch - 116ms/step\n",
            "Epoch 3857/5000\n",
            "\n",
            "Epoch 3857: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6445e-04 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3858/5000\n",
            "\n",
            "Epoch 3858: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7855e-04 - accuracy: 1.0000 - val_loss: 0.7179 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 3859/5000\n",
            "\n",
            "Epoch 3859: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6886e-04 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 3860/5000\n",
            "\n",
            "Epoch 3860: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6529e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8381 - 4s/epoch - 117ms/step\n",
            "Epoch 3861/5000\n",
            "\n",
            "Epoch 3861: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6289e-04 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.8273 - 3s/epoch - 93ms/step\n",
            "Epoch 3862/5000\n",
            "\n",
            "Epoch 3862: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6028e-04 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 3863/5000\n",
            "\n",
            "Epoch 3863: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.7114e-04 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8201 - 3s/epoch - 88ms/step\n",
            "Epoch 3864/5000\n",
            "\n",
            "Epoch 3864: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5951e-04 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8165 - 4s/epoch - 112ms/step\n",
            "Epoch 3865/5000\n",
            "\n",
            "Epoch 3865: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6516e-04 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3866/5000\n",
            "\n",
            "Epoch 3866: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5979e-04 - accuracy: 1.0000 - val_loss: 0.7031 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3867/5000\n",
            "\n",
            "Epoch 3867: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6467e-04 - accuracy: 1.0000 - val_loss: 0.7031 - val_accuracy: 0.8201 - 4s/epoch - 102ms/step\n",
            "Epoch 3868/5000\n",
            "\n",
            "Epoch 3868: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5550e-04 - accuracy: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.8237 - 3s/epoch - 100ms/step\n",
            "Epoch 3869/5000\n",
            "\n",
            "Epoch 3869: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5633e-04 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3870/5000\n",
            "\n",
            "Epoch 3870: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6539e-04 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3871/5000\n",
            "\n",
            "Epoch 3871: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5915e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8237 - 4s/epoch - 116ms/step\n",
            "Epoch 3872/5000\n",
            "\n",
            "Epoch 3872: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6243e-04 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3873/5000\n",
            "\n",
            "Epoch 3873: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6205e-04 - accuracy: 1.0000 - val_loss: 0.6979 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3874/5000\n",
            "\n",
            "Epoch 3874: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5841e-04 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8381 - 3s/epoch - 86ms/step\n",
            "Epoch 3875/5000\n",
            "\n",
            "Epoch 3875: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5848e-04 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8381 - 4s/epoch - 117ms/step\n",
            "Epoch 3876/5000\n",
            "\n",
            "Epoch 3876: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6227e-04 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8381 - 3s/epoch - 86ms/step\n",
            "Epoch 3877/5000\n",
            "\n",
            "Epoch 3877: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5956e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 3878/5000\n",
            "\n",
            "Epoch 3878: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5345e-04 - accuracy: 1.0000 - val_loss: 0.6982 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3879/5000\n",
            "\n",
            "Epoch 3879: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6473e-04 - accuracy: 1.0000 - val_loss: 0.7065 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 3880/5000\n",
            "\n",
            "Epoch 3880: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6223e-04 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3881/5000\n",
            "\n",
            "Epoch 3881: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5410e-04 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3882/5000\n",
            "\n",
            "Epoch 3882: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6075e-04 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.8201 - 3s/epoch - 92ms/step\n",
            "Epoch 3883/5000\n",
            "\n",
            "Epoch 3883: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6323e-04 - accuracy: 1.0000 - val_loss: 0.6944 - val_accuracy: 0.8201 - 4s/epoch - 111ms/step\n",
            "Epoch 3884/5000\n",
            "\n",
            "Epoch 3884: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5717e-04 - accuracy: 1.0000 - val_loss: 0.6949 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3885/5000\n",
            "\n",
            "Epoch 3885: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5430e-04 - accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3886/5000\n",
            "\n",
            "Epoch 3886: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5657e-04 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.8201 - 4s/epoch - 102ms/step\n",
            "Epoch 3887/5000\n",
            "\n",
            "Epoch 3887: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5786e-04 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8237 - 3s/epoch - 99ms/step\n",
            "Epoch 3888/5000\n",
            "\n",
            "Epoch 3888: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5559e-04 - accuracy: 1.0000 - val_loss: 0.6995 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3889/5000\n",
            "\n",
            "Epoch 3889: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5519e-04 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3890/5000\n",
            "\n",
            "Epoch 3890: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6542e-04 - accuracy: 1.0000 - val_loss: 0.7179 - val_accuracy: 0.8237 - 4s/epoch - 115ms/step\n",
            "Epoch 3891/5000\n",
            "\n",
            "Epoch 3891: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5679e-04 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3892/5000\n",
            "\n",
            "Epoch 3892: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5950e-04 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3893/5000\n",
            "\n",
            "Epoch 3893: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5877e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 3894/5000\n",
            "\n",
            "Epoch 3894: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5857e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 3895/5000\n",
            "\n",
            "Epoch 3895: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5295e-04 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3896/5000\n",
            "\n",
            "Epoch 3896: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5738e-04 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 3897/5000\n",
            "\n",
            "Epoch 3897: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5035e-04 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3898/5000\n",
            "\n",
            "Epoch 3898: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5672e-04 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8201 - 4s/epoch - 116ms/step\n",
            "Epoch 3899/5000\n",
            "\n",
            "Epoch 3899: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6041e-04 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3900/5000\n",
            "\n",
            "Epoch 3900: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6030e-04 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3901/5000\n",
            "\n",
            "Epoch 3901: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5223e-04 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3902/5000\n",
            "\n",
            "Epoch 3902: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5341e-04 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.8237 - 4s/epoch - 116ms/step\n",
            "Epoch 3903/5000\n",
            "\n",
            "Epoch 3903: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5361e-04 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3904/5000\n",
            "\n",
            "Epoch 3904: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5286e-04 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3905/5000\n",
            "\n",
            "Epoch 3905: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5982e-04 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8273 - 3s/epoch - 99ms/step\n",
            "Epoch 3906/5000\n",
            "\n",
            "Epoch 3906: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5871e-04 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.8273 - 4s/epoch - 103ms/step\n",
            "Epoch 3907/5000\n",
            "\n",
            "Epoch 3907: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5704e-04 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.8237 - 3s/epoch - 87ms/step\n",
            "Epoch 3908/5000\n",
            "\n",
            "Epoch 3908: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5399e-04 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3909/5000\n",
            "\n",
            "Epoch 3909: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5145e-04 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8165 - 4s/epoch - 115ms/step\n",
            "Epoch 3910/5000\n",
            "\n",
            "Epoch 3910: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5030e-04 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.8273 - 3s/epoch - 88ms/step\n",
            "Epoch 3911/5000\n",
            "\n",
            "Epoch 3911: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5228e-04 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3912/5000\n",
            "\n",
            "Epoch 3912: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5719e-04 - accuracy: 1.0000 - val_loss: 0.6897 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3913/5000\n",
            "\n",
            "Epoch 3913: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5370e-04 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 3914/5000\n",
            "\n",
            "Epoch 3914: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5848e-04 - accuracy: 1.0000 - val_loss: 0.6985 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3915/5000\n",
            "\n",
            "Epoch 3915: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4937e-04 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3916/5000\n",
            "\n",
            "Epoch 3916: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6451e-04 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3917/5000\n",
            "\n",
            "Epoch 3917: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6150e-04 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8309 - 4s/epoch - 117ms/step\n",
            "Epoch 3918/5000\n",
            "\n",
            "Epoch 3918: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5331e-04 - accuracy: 1.0000 - val_loss: 0.6954 - val_accuracy: 0.8453 - 3s/epoch - 86ms/step\n",
            "Epoch 3919/5000\n",
            "\n",
            "Epoch 3919: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5547e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3920/5000\n",
            "\n",
            "Epoch 3920: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5709e-04 - accuracy: 1.0000 - val_loss: 0.7015 - val_accuracy: 0.8273 - 3s/epoch - 88ms/step\n",
            "Epoch 3921/5000\n",
            "\n",
            "Epoch 3921: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5607e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8345 - 4s/epoch - 114ms/step\n",
            "Epoch 3922/5000\n",
            "\n",
            "Epoch 3922: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5453e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 3923/5000\n",
            "\n",
            "Epoch 3923: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5384e-04 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3924/5000\n",
            "\n",
            "Epoch 3924: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5442e-04 - accuracy: 1.0000 - val_loss: 0.7048 - val_accuracy: 0.8237 - 3s/epoch - 99ms/step\n",
            "Epoch 3925/5000\n",
            "\n",
            "Epoch 3925: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5105e-04 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.8273 - 4s/epoch - 103ms/step\n",
            "Epoch 3926/5000\n",
            "\n",
            "Epoch 3926: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5209e-04 - accuracy: 1.0000 - val_loss: 0.7015 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3927/5000\n",
            "\n",
            "Epoch 3927: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4817e-04 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3928/5000\n",
            "\n",
            "Epoch 3928: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6027e-04 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8273 - 4s/epoch - 114ms/step\n",
            "Epoch 3929/5000\n",
            "\n",
            "Epoch 3929: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5127e-04 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8273 - 3s/epoch - 88ms/step\n",
            "Epoch 3930/5000\n",
            "\n",
            "Epoch 3930: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5344e-04 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3931/5000\n",
            "\n",
            "Epoch 3931: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4733e-04 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3932/5000\n",
            "\n",
            "Epoch 3932: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4781e-04 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.8273 - 4s/epoch - 118ms/step\n",
            "Epoch 3933/5000\n",
            "\n",
            "Epoch 3933: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5641e-04 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3934/5000\n",
            "\n",
            "Epoch 3934: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5318e-04 - accuracy: 1.0000 - val_loss: 0.6981 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 3935/5000\n",
            "\n",
            "Epoch 3935: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4913e-04 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3936/5000\n",
            "\n",
            "Epoch 3936: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.7603e-04 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 3937/5000\n",
            "\n",
            "Epoch 3937: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6715e-04 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3938/5000\n",
            "\n",
            "Epoch 3938: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5639e-04 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 3939/5000\n",
            "\n",
            "Epoch 3939: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5177e-04 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 3940/5000\n",
            "\n",
            "Epoch 3940: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.6453e-04 - accuracy: 1.0000 - val_loss: 0.7076 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 3941/5000\n",
            "\n",
            "Epoch 3941: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5687e-04 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 3942/5000\n",
            "\n",
            "Epoch 3942: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5715e-04 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3943/5000\n",
            "\n",
            "Epoch 3943: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5103e-04 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.8201 - 3s/epoch - 98ms/step\n",
            "Epoch 3944/5000\n",
            "\n",
            "Epoch 3944: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5107e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8381 - 4s/epoch - 104ms/step\n",
            "Epoch 3945/5000\n",
            "\n",
            "Epoch 3945: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4860e-04 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 3946/5000\n",
            "\n",
            "Epoch 3946: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5609e-04 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 3947/5000\n",
            "\n",
            "Epoch 3947: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5428e-04 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.8237 - 4s/epoch - 111ms/step\n",
            "Epoch 3948/5000\n",
            "\n",
            "Epoch 3948: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5127e-04 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.8237 - 3s/epoch - 92ms/step\n",
            "Epoch 3949/5000\n",
            "\n",
            "Epoch 3949: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5419e-04 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3950/5000\n",
            "\n",
            "Epoch 3950: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5091e-04 - accuracy: 1.0000 - val_loss: 0.6985 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3951/5000\n",
            "\n",
            "Epoch 3951: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5009e-04 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.8237 - 4s/epoch - 116ms/step\n",
            "Epoch 3952/5000\n",
            "\n",
            "Epoch 3952: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4691e-04 - accuracy: 1.0000 - val_loss: 0.7031 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3953/5000\n",
            "\n",
            "Epoch 3953: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4530e-04 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 3954/5000\n",
            "\n",
            "Epoch 3954: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4947e-04 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3955/5000\n",
            "\n",
            "Epoch 3955: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5004e-04 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.8309 - 4s/epoch - 117ms/step\n",
            "Epoch 3956/5000\n",
            "\n",
            "Epoch 3956: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5112e-04 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 3957/5000\n",
            "\n",
            "Epoch 3957: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5093e-04 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3958/5000\n",
            "\n",
            "Epoch 3958: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4804e-04 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 3959/5000\n",
            "\n",
            "Epoch 3959: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5082e-04 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.8201 - 4s/epoch - 118ms/step\n",
            "Epoch 3960/5000\n",
            "\n",
            "Epoch 3960: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4616e-04 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 3961/5000\n",
            "\n",
            "Epoch 3961: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4527e-04 - accuracy: 1.0000 - val_loss: 0.6954 - val_accuracy: 0.8273 - 3s/epoch - 87ms/step\n",
            "Epoch 3962/5000\n",
            "\n",
            "Epoch 3962: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4979e-04 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.8309 - 3s/epoch - 96ms/step\n",
            "Epoch 3963/5000\n",
            "\n",
            "Epoch 3963: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4839e-04 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.8201 - 4s/epoch - 106ms/step\n",
            "Epoch 3964/5000\n",
            "\n",
            "Epoch 3964: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4812e-04 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 3965/5000\n",
            "\n",
            "Epoch 3965: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4745e-04 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 3966/5000\n",
            "\n",
            "Epoch 3966: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4609e-04 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8237 - 4s/epoch - 107ms/step\n",
            "Epoch 3967/5000\n",
            "\n",
            "Epoch 3967: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4828e-04 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8201 - 3s/epoch - 96ms/step\n",
            "Epoch 3968/5000\n",
            "\n",
            "Epoch 3968: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5286e-04 - accuracy: 1.0000 - val_loss: 0.6940 - val_accuracy: 0.8309 - 3s/epoch - 87ms/step\n",
            "Epoch 3969/5000\n",
            "\n",
            "Epoch 3969: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4543e-04 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3970/5000\n",
            "\n",
            "Epoch 3970: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4679e-04 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.8237 - 4s/epoch - 118ms/step\n",
            "Epoch 3971/5000\n",
            "\n",
            "Epoch 3971: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4992e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3972/5000\n",
            "\n",
            "Epoch 3972: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4854e-04 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 3973/5000\n",
            "\n",
            "Epoch 3973: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4619e-04 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3974/5000\n",
            "\n",
            "Epoch 3974: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4530e-04 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.8273 - 4s/epoch - 118ms/step\n",
            "Epoch 3975/5000\n",
            "\n",
            "Epoch 3975: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4729e-04 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8345 - 3s/epoch - 86ms/step\n",
            "Epoch 3976/5000\n",
            "\n",
            "Epoch 3976: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4823e-04 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.8345 - 3s/epoch - 86ms/step\n",
            "Epoch 3977/5000\n",
            "\n",
            "Epoch 3977: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5037e-04 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3978/5000\n",
            "\n",
            "Epoch 3978: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4289e-04 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 3979/5000\n",
            "\n",
            "Epoch 3979: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4309e-04 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 3980/5000\n",
            "\n",
            "Epoch 3980: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5322e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3981/5000\n",
            "\n",
            "Epoch 3981: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4407e-04 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.8165 - 3s/epoch - 97ms/step\n",
            "Epoch 3982/5000\n",
            "\n",
            "Epoch 3982: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5171e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8309 - 4s/epoch - 104ms/step\n",
            "Epoch 3983/5000\n",
            "\n",
            "Epoch 3983: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4300e-04 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 3984/5000\n",
            "\n",
            "Epoch 3984: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4632e-04 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.8345 - 3s/epoch - 86ms/step\n",
            "Epoch 3985/5000\n",
            "\n",
            "Epoch 3985: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4408e-04 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8201 - 4s/epoch - 110ms/step\n",
            "Epoch 3986/5000\n",
            "\n",
            "Epoch 3986: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5236e-04 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.8237 - 3s/epoch - 92ms/step\n",
            "Epoch 3987/5000\n",
            "\n",
            "Epoch 3987: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4749e-04 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3988/5000\n",
            "\n",
            "Epoch 3988: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4729e-04 - accuracy: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 3989/5000\n",
            "\n",
            "Epoch 3989: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4868e-04 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.8129 - 4s/epoch - 117ms/step\n",
            "Epoch 3990/5000\n",
            "\n",
            "Epoch 3990: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4267e-04 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3991/5000\n",
            "\n",
            "Epoch 3991: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4697e-04 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3992/5000\n",
            "\n",
            "Epoch 3992: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4873e-04 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 3993/5000\n",
            "\n",
            "Epoch 3993: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4390e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8165 - 4s/epoch - 116ms/step\n",
            "Epoch 3994/5000\n",
            "\n",
            "Epoch 3994: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4287e-04 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 3995/5000\n",
            "\n",
            "Epoch 3995: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4229e-04 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 3996/5000\n",
            "\n",
            "Epoch 3996: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4280e-04 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 3997/5000\n",
            "\n",
            "Epoch 3997: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4258e-04 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8237 - 4s/epoch - 116ms/step\n",
            "Epoch 3998/5000\n",
            "\n",
            "Epoch 3998: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4159e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 3999/5000\n",
            "\n",
            "Epoch 3999: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4235e-04 - accuracy: 1.0000 - val_loss: 0.6952 - val_accuracy: 0.8237 - 3s/epoch - 84ms/step\n",
            "Epoch 4000/5000\n",
            "\n",
            "Epoch 4000: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5311e-04 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 0.8237 - 3s/epoch - 94ms/step\n",
            "Epoch 4001/5000\n",
            "\n",
            "Epoch 4001: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4962e-04 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.8165 - 4s/epoch - 107ms/step\n",
            "Epoch 4002/5000\n",
            "\n",
            "Epoch 4002: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4453e-04 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4003/5000\n",
            "\n",
            "Epoch 4003: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4382e-04 - accuracy: 1.0000 - val_loss: 0.7073 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4004/5000\n",
            "\n",
            "Epoch 4004: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4335e-04 - accuracy: 1.0000 - val_loss: 0.7032 - val_accuracy: 0.8165 - 4s/epoch - 108ms/step\n",
            "Epoch 4005/5000\n",
            "\n",
            "Epoch 4005: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4335e-04 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.8201 - 3s/epoch - 92ms/step\n",
            "Epoch 4006/5000\n",
            "\n",
            "Epoch 4006: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4164e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4007/5000\n",
            "\n",
            "Epoch 4007: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4207e-04 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4008/5000\n",
            "\n",
            "Epoch 4008: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.5218e-04 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.8165 - 4s/epoch - 116ms/step\n",
            "Epoch 4009/5000\n",
            "\n",
            "Epoch 4009: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4044e-04 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4010/5000\n",
            "\n",
            "Epoch 4010: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4144e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4011/5000\n",
            "\n",
            "Epoch 4011: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3999e-04 - accuracy: 1.0000 - val_loss: 0.7073 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4012/5000\n",
            "\n",
            "Epoch 4012: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3802e-04 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 4013/5000\n",
            "\n",
            "Epoch 4013: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4036e-04 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 4014/5000\n",
            "\n",
            "Epoch 4014: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3851e-04 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4015/5000\n",
            "\n",
            "Epoch 4015: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4165e-04 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4016/5000\n",
            "\n",
            "Epoch 4016: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4114e-04 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4017/5000\n",
            "\n",
            "Epoch 4017: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4017e-04 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4018/5000\n",
            "\n",
            "Epoch 4018: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4963e-04 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4019/5000\n",
            "\n",
            "Epoch 4019: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5342e-04 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.8417 - 3s/epoch - 93ms/step\n",
            "Epoch 4020/5000\n",
            "\n",
            "Epoch 4020: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4144e-04 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8309 - 4s/epoch - 109ms/step\n",
            "Epoch 4021/5000\n",
            "\n",
            "Epoch 4021: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4057e-04 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4022/5000\n",
            "\n",
            "Epoch 4022: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3762e-04 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4023/5000\n",
            "\n",
            "Epoch 4023: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4285e-04 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.8273 - 4s/epoch - 106ms/step\n",
            "Epoch 4024/5000\n",
            "\n",
            "Epoch 4024: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4044e-04 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.8345 - 3s/epoch - 97ms/step\n",
            "Epoch 4025/5000\n",
            "\n",
            "Epoch 4025: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4153e-04 - accuracy: 1.0000 - val_loss: 0.7232 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4026/5000\n",
            "\n",
            "Epoch 4026: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4049e-04 - accuracy: 1.0000 - val_loss: 0.7214 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4027/5000\n",
            "\n",
            "Epoch 4027: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4267e-04 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4028/5000\n",
            "\n",
            "Epoch 4028: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4076e-04 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4029/5000\n",
            "\n",
            "Epoch 4029: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3850e-04 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4030/5000\n",
            "\n",
            "Epoch 4030: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4192e-04 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4031/5000\n",
            "\n",
            "Epoch 4031: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3907e-04 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.8309 - 4s/epoch - 116ms/step\n",
            "Epoch 4032/5000\n",
            "\n",
            "Epoch 4032: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4101e-04 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4033/5000\n",
            "\n",
            "Epoch 4033: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4059e-04 - accuracy: 1.0000 - val_loss: 0.7060 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4034/5000\n",
            "\n",
            "Epoch 4034: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4150e-04 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4035/5000\n",
            "\n",
            "Epoch 4035: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3839e-04 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8237 - 4s/epoch - 118ms/step\n",
            "Epoch 4036/5000\n",
            "\n",
            "Epoch 4036: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4073e-04 - accuracy: 1.0000 - val_loss: 0.7066 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4037/5000\n",
            "\n",
            "Epoch 4037: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3856e-04 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4038/5000\n",
            "\n",
            "Epoch 4038: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3953e-04 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.8201 - 3s/epoch - 90ms/step\n",
            "Epoch 4039/5000\n",
            "\n",
            "Epoch 4039: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3609e-04 - accuracy: 1.0000 - val_loss: 0.7150 - val_accuracy: 0.8165 - 4s/epoch - 111ms/step\n",
            "Epoch 4040/5000\n",
            "\n",
            "Epoch 4040: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4070e-04 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4041/5000\n",
            "\n",
            "Epoch 4041: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4187e-04 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4042/5000\n",
            "\n",
            "Epoch 4042: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3799e-04 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.8129 - 4s/epoch - 102ms/step\n",
            "Epoch 4043/5000\n",
            "\n",
            "Epoch 4043: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3878e-04 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8237 - 3s/epoch - 99ms/step\n",
            "Epoch 4044/5000\n",
            "\n",
            "Epoch 4044: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3896e-04 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4045/5000\n",
            "\n",
            "Epoch 4045: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3592e-04 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4046/5000\n",
            "\n",
            "Epoch 4046: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3767e-04 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.8201 - 4s/epoch - 110ms/step\n",
            "Epoch 4047/5000\n",
            "\n",
            "Epoch 4047: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3583e-04 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8165 - 3s/epoch - 91ms/step\n",
            "Epoch 4048/5000\n",
            "\n",
            "Epoch 4048: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3830e-04 - accuracy: 1.0000 - val_loss: 0.7169 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4049/5000\n",
            "\n",
            "Epoch 4049: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4061e-04 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8381 - 3s/epoch - 86ms/step\n",
            "Epoch 4050/5000\n",
            "\n",
            "Epoch 4050: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4583e-04 - accuracy: 1.0000 - val_loss: 0.7143 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4051/5000\n",
            "\n",
            "Epoch 4051: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4614e-04 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4052/5000\n",
            "\n",
            "Epoch 4052: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4280e-04 - accuracy: 1.0000 - val_loss: 0.7214 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4053/5000\n",
            "\n",
            "Epoch 4053: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4236e-04 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4054/5000\n",
            "\n",
            "Epoch 4054: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4312e-04 - accuracy: 1.0000 - val_loss: 0.7351 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 4055/5000\n",
            "\n",
            "Epoch 4055: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4342e-04 - accuracy: 1.0000 - val_loss: 0.7385 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4056/5000\n",
            "\n",
            "Epoch 4056: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3785e-04 - accuracy: 1.0000 - val_loss: 0.7288 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4057/5000\n",
            "\n",
            "Epoch 4057: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3667e-04 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.8237 - 3s/epoch - 87ms/step\n",
            "Epoch 4058/5000\n",
            "\n",
            "Epoch 4058: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3668e-04 - accuracy: 1.0000 - val_loss: 0.7201 - val_accuracy: 0.8237 - 4s/epoch - 114ms/step\n",
            "Epoch 4059/5000\n",
            "\n",
            "Epoch 4059: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3702e-04 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4060/5000\n",
            "\n",
            "Epoch 4060: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4116e-04 - accuracy: 1.0000 - val_loss: 0.7313 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4061/5000\n",
            "\n",
            "Epoch 4061: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4380e-04 - accuracy: 1.0000 - val_loss: 0.7332 - val_accuracy: 0.8201 - 3s/epoch - 96ms/step\n",
            "Epoch 4062/5000\n",
            "\n",
            "Epoch 4062: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3422e-04 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.8201 - 4s/epoch - 105ms/step\n",
            "Epoch 4063/5000\n",
            "\n",
            "Epoch 4063: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3816e-04 - accuracy: 1.0000 - val_loss: 0.7223 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4064/5000\n",
            "\n",
            "Epoch 4064: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3639e-04 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4065/5000\n",
            "\n",
            "Epoch 4065: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3730e-04 - accuracy: 1.0000 - val_loss: 0.7208 - val_accuracy: 0.8201 - 4s/epoch - 108ms/step\n",
            "Epoch 4066/5000\n",
            "\n",
            "Epoch 4066: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3768e-04 - accuracy: 1.0000 - val_loss: 0.7245 - val_accuracy: 0.8273 - 3s/epoch - 93ms/step\n",
            "Epoch 4067/5000\n",
            "\n",
            "Epoch 4067: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3592e-04 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4068/5000\n",
            "\n",
            "Epoch 4068: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3824e-04 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4069/5000\n",
            "\n",
            "Epoch 4069: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.4128e-04 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.8237 - 4s/epoch - 118ms/step\n",
            "Epoch 4070/5000\n",
            "\n",
            "Epoch 4070: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3743e-04 - accuracy: 1.0000 - val_loss: 0.7206 - val_accuracy: 0.8201 - 3s/epoch - 87ms/step\n",
            "Epoch 4071/5000\n",
            "\n",
            "Epoch 4071: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3567e-04 - accuracy: 1.0000 - val_loss: 0.7145 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4072/5000\n",
            "\n",
            "Epoch 4072: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3939e-04 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4073/5000\n",
            "\n",
            "Epoch 4073: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3585e-04 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4074/5000\n",
            "\n",
            "Epoch 4074: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3692e-04 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4075/5000\n",
            "\n",
            "Epoch 4075: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3640e-04 - accuracy: 1.0000 - val_loss: 0.7170 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4076/5000\n",
            "\n",
            "Epoch 4076: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4365e-04 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4077/5000\n",
            "\n",
            "Epoch 4077: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3485e-04 - accuracy: 1.0000 - val_loss: 0.7175 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4078/5000\n",
            "\n",
            "Epoch 4078: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3722e-04 - accuracy: 1.0000 - val_loss: 0.7143 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4079/5000\n",
            "\n",
            "Epoch 4079: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3586e-04 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8309 - 3s/epoch - 88ms/step\n",
            "Epoch 4080/5000\n",
            "\n",
            "Epoch 4080: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3493e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8309 - 3s/epoch - 93ms/step\n",
            "Epoch 4081/5000\n",
            "\n",
            "Epoch 4081: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3839e-04 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.8201 - 4s/epoch - 109ms/step\n",
            "Epoch 4082/5000\n",
            "\n",
            "Epoch 4082: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3560e-04 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4083/5000\n",
            "\n",
            "Epoch 4083: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3397e-04 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4084/5000\n",
            "\n",
            "Epoch 4084: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3231e-04 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8273 - 4s/epoch - 106ms/step\n",
            "Epoch 4085/5000\n",
            "\n",
            "Epoch 4085: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3250e-04 - accuracy: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.8201 - 3s/epoch - 97ms/step\n",
            "Epoch 4086/5000\n",
            "\n",
            "Epoch 4086: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3239e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4087/5000\n",
            "\n",
            "Epoch 4087: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3823e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4088/5000\n",
            "\n",
            "Epoch 4088: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3320e-04 - accuracy: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.8309 - 4s/epoch - 117ms/step\n",
            "Epoch 4089/5000\n",
            "\n",
            "Epoch 4089: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3274e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4090/5000\n",
            "\n",
            "Epoch 4090: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3004e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8201 - 3s/epoch - 88ms/step\n",
            "Epoch 4091/5000\n",
            "\n",
            "Epoch 4091: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3357e-04 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4092/5000\n",
            "\n",
            "Epoch 4092: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3438e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 4093/5000\n",
            "\n",
            "Epoch 4093: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2955e-04 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4094/5000\n",
            "\n",
            "Epoch 4094: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3262e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4095/5000\n",
            "\n",
            "Epoch 4095: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.4087e-04 - accuracy: 1.0000 - val_loss: 0.7343 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4096/5000\n",
            "\n",
            "Epoch 4096: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3597e-04 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4097/5000\n",
            "\n",
            "Epoch 4097: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.5200e-04 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4098/5000\n",
            "\n",
            "Epoch 4098: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3491e-04 - accuracy: 1.0000 - val_loss: 0.7208 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4099/5000\n",
            "\n",
            "Epoch 4099: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3861e-04 - accuracy: 1.0000 - val_loss: 0.7221 - val_accuracy: 0.8309 - 3s/epoch - 91ms/step\n",
            "Epoch 4100/5000\n",
            "\n",
            "Epoch 4100: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3799e-04 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.8201 - 4s/epoch - 110ms/step\n",
            "Epoch 4101/5000\n",
            "\n",
            "Epoch 4101: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3680e-04 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4102/5000\n",
            "\n",
            "Epoch 4102: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3127e-04 - accuracy: 1.0000 - val_loss: 0.7232 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4103/5000\n",
            "\n",
            "Epoch 4103: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3125e-04 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.8201 - 4s/epoch - 103ms/step\n",
            "Epoch 4104/5000\n",
            "\n",
            "Epoch 4104: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3155e-04 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8237 - 3s/epoch - 98ms/step\n",
            "Epoch 4105/5000\n",
            "\n",
            "Epoch 4105: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2899e-04 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4106/5000\n",
            "\n",
            "Epoch 4106: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2978e-04 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4107/5000\n",
            "\n",
            "Epoch 4107: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3186e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8094 - 4s/epoch - 117ms/step\n",
            "Epoch 4108/5000\n",
            "\n",
            "Epoch 4108: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3485e-04 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4109/5000\n",
            "\n",
            "Epoch 4109: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2879e-04 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4110/5000\n",
            "\n",
            "Epoch 4110: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2910e-04 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4111/5000\n",
            "\n",
            "Epoch 4111: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2969e-04 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4112/5000\n",
            "\n",
            "Epoch 4112: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3272e-04 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4113/5000\n",
            "\n",
            "Epoch 4113: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3372e-04 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4114/5000\n",
            "\n",
            "Epoch 4114: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2840e-04 - accuracy: 1.0000 - val_loss: 0.7065 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4115/5000\n",
            "\n",
            "Epoch 4115: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2878e-04 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.8129 - 4s/epoch - 118ms/step\n",
            "Epoch 4116/5000\n",
            "\n",
            "Epoch 4116: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3164e-04 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4117/5000\n",
            "\n",
            "Epoch 4117: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3084e-04 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4118/5000\n",
            "\n",
            "Epoch 4118: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3165e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8201 - 3s/epoch - 89ms/step\n",
            "Epoch 4119/5000\n",
            "\n",
            "Epoch 4119: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3033e-04 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.8129 - 4s/epoch - 112ms/step\n",
            "Epoch 4120/5000\n",
            "\n",
            "Epoch 4120: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2977e-04 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4121/5000\n",
            "\n",
            "Epoch 4121: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2768e-04 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4122/5000\n",
            "\n",
            "Epoch 4122: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3159e-04 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.8129 - 4s/epoch - 101ms/step\n",
            "Epoch 4123/5000\n",
            "\n",
            "Epoch 4123: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2847e-04 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.8129 - 4s/epoch - 102ms/step\n",
            "Epoch 4124/5000\n",
            "\n",
            "Epoch 4124: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3101e-04 - accuracy: 1.0000 - val_loss: 0.7135 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4125/5000\n",
            "\n",
            "Epoch 4125: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3152e-04 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4126/5000\n",
            "\n",
            "Epoch 4126: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2969e-04 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.8129 - 4s/epoch - 116ms/step\n",
            "Epoch 4127/5000\n",
            "\n",
            "Epoch 4127: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2675e-04 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4128/5000\n",
            "\n",
            "Epoch 4128: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2551e-04 - accuracy: 1.0000 - val_loss: 0.7043 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4129/5000\n",
            "\n",
            "Epoch 4129: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2802e-04 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4130/5000\n",
            "\n",
            "Epoch 4130: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2886e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4131/5000\n",
            "\n",
            "Epoch 4131: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2570e-04 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8201 - 3s/epoch - 87ms/step\n",
            "Epoch 4132/5000\n",
            "\n",
            "Epoch 4132: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2939e-04 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.8165 - 3s/epoch - 87ms/step\n",
            "Epoch 4133/5000\n",
            "\n",
            "Epoch 4133: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2874e-04 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4134/5000\n",
            "\n",
            "Epoch 4134: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2521e-04 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4135/5000\n",
            "\n",
            "Epoch 4135: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2629e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4136/5000\n",
            "\n",
            "Epoch 4136: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2537e-04 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4137/5000\n",
            "\n",
            "Epoch 4137: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2720e-04 - accuracy: 1.0000 - val_loss: 0.7086 - val_accuracy: 0.8165 - 3s/epoch - 89ms/step\n",
            "Epoch 4138/5000\n",
            "\n",
            "Epoch 4138: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2556e-04 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.8165 - 4s/epoch - 112ms/step\n",
            "Epoch 4139/5000\n",
            "\n",
            "Epoch 4139: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2568e-04 - accuracy: 1.0000 - val_loss: 0.7043 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4140/5000\n",
            "\n",
            "Epoch 4140: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2805e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8345 - 3s/epoch - 86ms/step\n",
            "Epoch 4141/5000\n",
            "\n",
            "Epoch 4141: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2730e-04 - accuracy: 1.0000 - val_loss: 0.7055 - val_accuracy: 0.8273 - 4s/epoch - 103ms/step\n",
            "Epoch 4142/5000\n",
            "\n",
            "Epoch 4142: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3147e-04 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.8201 - 3s/epoch - 100ms/step\n",
            "Epoch 4143/5000\n",
            "\n",
            "Epoch 4143: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2707e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4144/5000\n",
            "\n",
            "Epoch 4144: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2711e-04 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.8237 - 3s/epoch - 87ms/step\n",
            "Epoch 4145/5000\n",
            "\n",
            "Epoch 4145: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2723e-04 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4146/5000\n",
            "\n",
            "Epoch 4146: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3162e-04 - accuracy: 1.0000 - val_loss: 0.7239 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4147/5000\n",
            "\n",
            "Epoch 4147: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2848e-04 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4148/5000\n",
            "\n",
            "Epoch 4148: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2832e-04 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.8165 - 3s/epoch - 87ms/step\n",
            "Epoch 4149/5000\n",
            "\n",
            "Epoch 4149: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3040e-04 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4150/5000\n",
            "\n",
            "Epoch 4150: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2797e-04 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4151/5000\n",
            "\n",
            "Epoch 4151: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2735e-04 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4152/5000\n",
            "\n",
            "Epoch 4152: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2687e-04 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4153/5000\n",
            "\n",
            "Epoch 4153: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2251e-04 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4154/5000\n",
            "\n",
            "Epoch 4154: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2563e-04 - accuracy: 1.0000 - val_loss: 0.7170 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4155/5000\n",
            "\n",
            "Epoch 4155: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2396e-04 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4156/5000\n",
            "\n",
            "Epoch 4156: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3103e-04 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.8201 - 3s/epoch - 94ms/step\n",
            "Epoch 4157/5000\n",
            "\n",
            "Epoch 4157: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3192e-04 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.8201 - 4s/epoch - 108ms/step\n",
            "Epoch 4158/5000\n",
            "\n",
            "Epoch 4158: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3169e-04 - accuracy: 1.0000 - val_loss: 0.7273 - val_accuracy: 0.8273 - 3s/epoch - 84ms/step\n",
            "Epoch 4159/5000\n",
            "\n",
            "Epoch 4159: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2623e-04 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4160/5000\n",
            "\n",
            "Epoch 4160: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3083e-04 - accuracy: 1.0000 - val_loss: 0.7230 - val_accuracy: 0.8237 - 4s/epoch - 105ms/step\n",
            "Epoch 4161/5000\n",
            "\n",
            "Epoch 4161: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2589e-04 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.8273 - 3s/epoch - 96ms/step\n",
            "Epoch 4162/5000\n",
            "\n",
            "Epoch 4162: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2790e-04 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.8381 - 3s/epoch - 86ms/step\n",
            "Epoch 4163/5000\n",
            "\n",
            "Epoch 4163: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2446e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8309 - 3s/epoch - 87ms/step\n",
            "Epoch 4164/5000\n",
            "\n",
            "Epoch 4164: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2443e-04 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 4165/5000\n",
            "\n",
            "Epoch 4165: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2578e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4166/5000\n",
            "\n",
            "Epoch 4166: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2384e-04 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4167/5000\n",
            "\n",
            "Epoch 4167: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2744e-04 - accuracy: 1.0000 - val_loss: 0.7202 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4168/5000\n",
            "\n",
            "Epoch 4168: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2530e-04 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.8273 - 4s/epoch - 118ms/step\n",
            "Epoch 4169/5000\n",
            "\n",
            "Epoch 4169: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3065e-04 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4170/5000\n",
            "\n",
            "Epoch 4170: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2393e-04 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4171/5000\n",
            "\n",
            "Epoch 4171: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2618e-04 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4172/5000\n",
            "\n",
            "Epoch 4172: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2282e-04 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4173/5000\n",
            "\n",
            "Epoch 4173: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2622e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4174/5000\n",
            "\n",
            "Epoch 4174: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2411e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4175/5000\n",
            "\n",
            "Epoch 4175: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2372e-04 - accuracy: 1.0000 - val_loss: 0.6903 - val_accuracy: 0.8273 - 3s/epoch - 91ms/step\n",
            "Epoch 4176/5000\n",
            "\n",
            "Epoch 4176: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2499e-04 - accuracy: 1.0000 - val_loss: 0.6944 - val_accuracy: 0.8309 - 4s/epoch - 111ms/step\n",
            "Epoch 4177/5000\n",
            "\n",
            "Epoch 4177: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2155e-04 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4178/5000\n",
            "\n",
            "Epoch 4178: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2421e-04 - accuracy: 1.0000 - val_loss: 0.7031 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4179/5000\n",
            "\n",
            "Epoch 4179: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2595e-04 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.8273 - 4s/epoch - 106ms/step\n",
            "Epoch 4180/5000\n",
            "\n",
            "Epoch 4180: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2033e-04 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.8201 - 3s/epoch - 98ms/step\n",
            "Epoch 4181/5000\n",
            "\n",
            "Epoch 4181: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2279e-04 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4182/5000\n",
            "\n",
            "Epoch 4182: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3424e-04 - accuracy: 1.0000 - val_loss: 0.7277 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4183/5000\n",
            "\n",
            "Epoch 4183: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2429e-04 - accuracy: 1.0000 - val_loss: 0.7143 - val_accuracy: 0.8201 - 4s/epoch - 115ms/step\n",
            "Epoch 4184/5000\n",
            "\n",
            "Epoch 4184: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2179e-04 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4185/5000\n",
            "\n",
            "Epoch 4185: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2271e-04 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4186/5000\n",
            "\n",
            "Epoch 4186: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2535e-04 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.8345 - 3s/epoch - 87ms/step\n",
            "Epoch 4187/5000\n",
            "\n",
            "Epoch 4187: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2408e-04 - accuracy: 1.0000 - val_loss: 0.7205 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4188/5000\n",
            "\n",
            "Epoch 4188: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2665e-04 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4189/5000\n",
            "\n",
            "Epoch 4189: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3665e-04 - accuracy: 1.0000 - val_loss: 0.7238 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4190/5000\n",
            "\n",
            "Epoch 4190: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2259e-04 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4191/5000\n",
            "\n",
            "Epoch 4191: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2205e-04 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4192/5000\n",
            "\n",
            "Epoch 4192: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2702e-04 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4193/5000\n",
            "\n",
            "Epoch 4193: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2047e-04 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4194/5000\n",
            "\n",
            "Epoch 4194: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3192e-04 - accuracy: 1.0000 - val_loss: 0.7221 - val_accuracy: 0.8129 - 3s/epoch - 87ms/step\n",
            "Epoch 4195/5000\n",
            "\n",
            "Epoch 4195: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2349e-04 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.8237 - 4s/epoch - 115ms/step\n",
            "Epoch 4196/5000\n",
            "\n",
            "Epoch 4196: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2490e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 4197/5000\n",
            "\n",
            "Epoch 4197: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2568e-04 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4198/5000\n",
            "\n",
            "Epoch 4198: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2758e-04 - accuracy: 1.0000 - val_loss: 0.7203 - val_accuracy: 0.8273 - 3s/epoch - 99ms/step\n",
            "Epoch 4199/5000\n",
            "\n",
            "Epoch 4199: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2350e-04 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.8129 - 4s/epoch - 103ms/step\n",
            "Epoch 4200/5000\n",
            "\n",
            "Epoch 4200: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2265e-04 - accuracy: 1.0000 - val_loss: 0.7145 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4201/5000\n",
            "\n",
            "Epoch 4201: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2825e-04 - accuracy: 1.0000 - val_loss: 0.7243 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4202/5000\n",
            "\n",
            "Epoch 4202: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2072e-04 - accuracy: 1.0000 - val_loss: 0.7170 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 4203/5000\n",
            "\n",
            "Epoch 4203: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2028e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8237 - 3s/epoch - 87ms/step\n",
            "Epoch 4204/5000\n",
            "\n",
            "Epoch 4204: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2364e-04 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8165 - 3s/epoch - 87ms/step\n",
            "Epoch 4205/5000\n",
            "\n",
            "Epoch 4205: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2297e-04 - accuracy: 1.0000 - val_loss: 0.7171 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4206/5000\n",
            "\n",
            "Epoch 4206: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2042e-04 - accuracy: 1.0000 - val_loss: 0.7152 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4207/5000\n",
            "\n",
            "Epoch 4207: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2584e-04 - accuracy: 1.0000 - val_loss: 0.7161 - val_accuracy: 0.8201 - 3s/epoch - 88ms/step\n",
            "Epoch 4208/5000\n",
            "\n",
            "Epoch 4208: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2383e-04 - accuracy: 1.0000 - val_loss: 0.7169 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4209/5000\n",
            "\n",
            "Epoch 4209: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2946e-04 - accuracy: 1.0000 - val_loss: 0.7289 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4210/5000\n",
            "\n",
            "Epoch 4210: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2108e-04 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4211/5000\n",
            "\n",
            "Epoch 4211: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2320e-04 - accuracy: 1.0000 - val_loss: 0.7314 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4212/5000\n",
            "\n",
            "Epoch 4212: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2314e-04 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4213/5000\n",
            "\n",
            "Epoch 4213: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2402e-04 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.8237 - 3s/epoch - 88ms/step\n",
            "Epoch 4214/5000\n",
            "\n",
            "Epoch 4214: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2194e-04 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.8273 - 4s/epoch - 112ms/step\n",
            "Epoch 4215/5000\n",
            "\n",
            "Epoch 4215: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1688e-04 - accuracy: 1.0000 - val_loss: 0.7002 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4216/5000\n",
            "\n",
            "Epoch 4216: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2502e-04 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4217/5000\n",
            "\n",
            "Epoch 4217: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2102e-04 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.8165 - 4s/epoch - 101ms/step\n",
            "Epoch 4218/5000\n",
            "\n",
            "Epoch 4218: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.3027e-04 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.8273 - 4s/epoch - 101ms/step\n",
            "Epoch 4219/5000\n",
            "\n",
            "Epoch 4219: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2849e-04 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4220/5000\n",
            "\n",
            "Epoch 4220: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2345e-04 - accuracy: 1.0000 - val_loss: 0.7059 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4221/5000\n",
            "\n",
            "Epoch 4221: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2474e-04 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.8381 - 4s/epoch - 115ms/step\n",
            "Epoch 4222/5000\n",
            "\n",
            "Epoch 4222: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2165e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8309 - 3s/epoch - 87ms/step\n",
            "Epoch 4223/5000\n",
            "\n",
            "Epoch 4223: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1669e-04 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4224/5000\n",
            "\n",
            "Epoch 4224: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2036e-04 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4225/5000\n",
            "\n",
            "Epoch 4225: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1799e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8309 - 4s/epoch - 117ms/step\n",
            "Epoch 4226/5000\n",
            "\n",
            "Epoch 4226: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1869e-04 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4227/5000\n",
            "\n",
            "Epoch 4227: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1804e-04 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4228/5000\n",
            "\n",
            "Epoch 4228: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1891e-04 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4229/5000\n",
            "\n",
            "Epoch 4229: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2008e-04 - accuracy: 1.0000 - val_loss: 0.6993 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4230/5000\n",
            "\n",
            "Epoch 4230: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1995e-04 - accuracy: 1.0000 - val_loss: 0.7059 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4231/5000\n",
            "\n",
            "Epoch 4231: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1897e-04 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4232/5000\n",
            "\n",
            "Epoch 4232: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2095e-04 - accuracy: 1.0000 - val_loss: 0.7002 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4233/5000\n",
            "\n",
            "Epoch 4233: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1708e-04 - accuracy: 1.0000 - val_loss: 0.7015 - val_accuracy: 0.8201 - 4s/epoch - 118ms/step\n",
            "Epoch 4234/5000\n",
            "\n",
            "Epoch 4234: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2014e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4235/5000\n",
            "\n",
            "Epoch 4235: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2414e-04 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4236/5000\n",
            "\n",
            "Epoch 4236: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1945e-04 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.8273 - 3s/epoch - 98ms/step\n",
            "Epoch 4237/5000\n",
            "\n",
            "Epoch 4237: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1753e-04 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.8273 - 4s/epoch - 104ms/step\n",
            "Epoch 4238/5000\n",
            "\n",
            "Epoch 4238: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1975e-04 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4239/5000\n",
            "\n",
            "Epoch 4239: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1957e-04 - accuracy: 1.0000 - val_loss: 0.6979 - val_accuracy: 0.8273 - 3s/epoch - 88ms/step\n",
            "Epoch 4240/5000\n",
            "\n",
            "Epoch 4240: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2062e-04 - accuracy: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.8345 - 4s/epoch - 112ms/step\n",
            "Epoch 4241/5000\n",
            "\n",
            "Epoch 4241: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1749e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8345 - 3s/epoch - 90ms/step\n",
            "Epoch 4242/5000\n",
            "\n",
            "Epoch 4242: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1576e-04 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4243/5000\n",
            "\n",
            "Epoch 4243: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2093e-04 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4244/5000\n",
            "\n",
            "Epoch 4244: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1946e-04 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4245/5000\n",
            "\n",
            "Epoch 4245: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2583e-04 - accuracy: 1.0000 - val_loss: 0.7151 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4246/5000\n",
            "\n",
            "Epoch 4246: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2315e-04 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4247/5000\n",
            "\n",
            "Epoch 4247: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3276e-04 - accuracy: 1.0000 - val_loss: 0.7440 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4248/5000\n",
            "\n",
            "Epoch 4248: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2514e-04 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4249/5000\n",
            "\n",
            "Epoch 4249: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1981e-04 - accuracy: 1.0000 - val_loss: 0.7140 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4250/5000\n",
            "\n",
            "Epoch 4250: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2014e-04 - accuracy: 1.0000 - val_loss: 0.7204 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4251/5000\n",
            "\n",
            "Epoch 4251: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2032e-04 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8201 - 3s/epoch - 87ms/step\n",
            "Epoch 4252/5000\n",
            "\n",
            "Epoch 4252: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1776e-04 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.8309 - 4s/epoch - 115ms/step\n",
            "Epoch 4253/5000\n",
            "\n",
            "Epoch 4253: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1635e-04 - accuracy: 1.0000 - val_loss: 0.7143 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4254/5000\n",
            "\n",
            "Epoch 4254: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1566e-04 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4255/5000\n",
            "\n",
            "Epoch 4255: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1692e-04 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.8201 - 3s/epoch - 98ms/step\n",
            "Epoch 4256/5000\n",
            "\n",
            "Epoch 4256: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1734e-04 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.8237 - 4s/epoch - 105ms/step\n",
            "Epoch 4257/5000\n",
            "\n",
            "Epoch 4257: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1709e-04 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4258/5000\n",
            "\n",
            "Epoch 4258: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2175e-04 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4259/5000\n",
            "\n",
            "Epoch 4259: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2283e-04 - accuracy: 1.0000 - val_loss: 0.6930 - val_accuracy: 0.8201 - 4s/epoch - 112ms/step\n",
            "Epoch 4260/5000\n",
            "\n",
            "Epoch 4260: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1725e-04 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8273 - 3s/epoch - 90ms/step\n",
            "Epoch 4261/5000\n",
            "\n",
            "Epoch 4261: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1943e-04 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4262/5000\n",
            "\n",
            "Epoch 4262: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1796e-04 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4263/5000\n",
            "\n",
            "Epoch 4263: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1795e-04 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4264/5000\n",
            "\n",
            "Epoch 4264: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1873e-04 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4265/5000\n",
            "\n",
            "Epoch 4265: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1840e-04 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4266/5000\n",
            "\n",
            "Epoch 4266: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2212e-04 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4267/5000\n",
            "\n",
            "Epoch 4267: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1565e-04 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4268/5000\n",
            "\n",
            "Epoch 4268: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1892e-04 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4269/5000\n",
            "\n",
            "Epoch 4269: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2217e-04 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4270/5000\n",
            "\n",
            "Epoch 4270: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1667e-04 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.8237 - 3s/epoch - 88ms/step\n",
            "Epoch 4271/5000\n",
            "\n",
            "Epoch 4271: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1665e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8237 - 4s/epoch - 115ms/step\n",
            "Epoch 4272/5000\n",
            "\n",
            "Epoch 4272: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1809e-04 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4273/5000\n",
            "\n",
            "Epoch 4273: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1542e-04 - accuracy: 1.0000 - val_loss: 0.7047 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4274/5000\n",
            "\n",
            "Epoch 4274: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1257e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8237 - 4s/epoch - 101ms/step\n",
            "Epoch 4275/5000\n",
            "\n",
            "Epoch 4275: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2060e-04 - accuracy: 1.0000 - val_loss: 0.7101 - val_accuracy: 0.8237 - 4s/epoch - 100ms/step\n",
            "Epoch 4276/5000\n",
            "\n",
            "Epoch 4276: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1527e-04 - accuracy: 1.0000 - val_loss: 0.7086 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4277/5000\n",
            "\n",
            "Epoch 4277: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1738e-04 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4278/5000\n",
            "\n",
            "Epoch 4278: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1866e-04 - accuracy: 1.0000 - val_loss: 0.7150 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 4279/5000\n",
            "\n",
            "Epoch 4279: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1548e-04 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4280/5000\n",
            "\n",
            "Epoch 4280: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1597e-04 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4281/5000\n",
            "\n",
            "Epoch 4281: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1678e-04 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4282/5000\n",
            "\n",
            "Epoch 4282: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1411e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4283/5000\n",
            "\n",
            "Epoch 4283: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1474e-04 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4284/5000\n",
            "\n",
            "Epoch 4284: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1267e-04 - accuracy: 1.0000 - val_loss: 0.6996 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4285/5000\n",
            "\n",
            "Epoch 4285: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1298e-04 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4286/5000\n",
            "\n",
            "Epoch 4286: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1334e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4287/5000\n",
            "\n",
            "Epoch 4287: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1193e-04 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4288/5000\n",
            "\n",
            "Epoch 4288: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1358e-04 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4289/5000\n",
            "\n",
            "Epoch 4289: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1053e-04 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8273 - 3s/epoch - 88ms/step\n",
            "Epoch 4290/5000\n",
            "\n",
            "Epoch 4290: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1247e-04 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.8237 - 4s/epoch - 114ms/step\n",
            "Epoch 4291/5000\n",
            "\n",
            "Epoch 4291: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1293e-04 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4292/5000\n",
            "\n",
            "Epoch 4292: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1728e-04 - accuracy: 1.0000 - val_loss: 0.7066 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4293/5000\n",
            "\n",
            "Epoch 4293: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1964e-04 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.8237 - 4s/epoch - 101ms/step\n",
            "Epoch 4294/5000\n",
            "\n",
            "Epoch 4294: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1245e-04 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.8273 - 4s/epoch - 101ms/step\n",
            "Epoch 4295/5000\n",
            "\n",
            "Epoch 4295: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1643e-04 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4296/5000\n",
            "\n",
            "Epoch 4296: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2293e-04 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4297/5000\n",
            "\n",
            "Epoch 4297: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1741e-04 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.8309 - 4s/epoch - 115ms/step\n",
            "Epoch 4298/5000\n",
            "\n",
            "Epoch 4298: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1271e-04 - accuracy: 1.0000 - val_loss: 0.7271 - val_accuracy: 0.8381 - 3s/epoch - 87ms/step\n",
            "Epoch 4299/5000\n",
            "\n",
            "Epoch 4299: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1401e-04 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 4300/5000\n",
            "\n",
            "Epoch 4300: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2736e-04 - accuracy: 1.0000 - val_loss: 0.7578 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4301/5000\n",
            "\n",
            "Epoch 4301: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2187e-04 - accuracy: 1.0000 - val_loss: 0.7369 - val_accuracy: 0.8309 - 4s/epoch - 118ms/step\n",
            "Epoch 4302/5000\n",
            "\n",
            "Epoch 4302: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1945e-04 - accuracy: 1.0000 - val_loss: 0.7282 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4303/5000\n",
            "\n",
            "Epoch 4303: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1498e-04 - accuracy: 1.0000 - val_loss: 0.7358 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4304/5000\n",
            "\n",
            "Epoch 4304: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1263e-04 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4305/5000\n",
            "\n",
            "Epoch 4305: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1253e-04 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.8309 - 4s/epoch - 117ms/step\n",
            "Epoch 4306/5000\n",
            "\n",
            "Epoch 4306: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2045e-04 - accuracy: 1.0000 - val_loss: 0.7554 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4307/5000\n",
            "\n",
            "Epoch 4307: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2473e-04 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4308/5000\n",
            "\n",
            "Epoch 4308: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1743e-04 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8273 - 3s/epoch - 88ms/step\n",
            "Epoch 4309/5000\n",
            "\n",
            "Epoch 4309: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.2318e-04 - accuracy: 1.0000 - val_loss: 0.7546 - val_accuracy: 0.8094 - 4s/epoch - 114ms/step\n",
            "Epoch 4310/5000\n",
            "\n",
            "Epoch 4310: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1578e-04 - accuracy: 1.0000 - val_loss: 0.7466 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4311/5000\n",
            "\n",
            "Epoch 4311: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1329e-04 - accuracy: 1.0000 - val_loss: 0.7409 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4312/5000\n",
            "\n",
            "Epoch 4312: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1236e-04 - accuracy: 1.0000 - val_loss: 0.7325 - val_accuracy: 0.8201 - 4s/epoch - 101ms/step\n",
            "Epoch 4313/5000\n",
            "\n",
            "Epoch 4313: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1628e-04 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.8309 - 4s/epoch - 102ms/step\n",
            "Epoch 4314/5000\n",
            "\n",
            "Epoch 4314: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1289e-04 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4315/5000\n",
            "\n",
            "Epoch 4315: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1483e-04 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4316/5000\n",
            "\n",
            "Epoch 4316: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1155e-04 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.8237 - 4s/epoch - 115ms/step\n",
            "Epoch 4317/5000\n",
            "\n",
            "Epoch 4317: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1514e-04 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.8237 - 3s/epoch - 87ms/step\n",
            "Epoch 4318/5000\n",
            "\n",
            "Epoch 4318: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1323e-04 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4319/5000\n",
            "\n",
            "Epoch 4319: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1052e-04 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4320/5000\n",
            "\n",
            "Epoch 4320: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1297e-04 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8237 - 4s/epoch - 116ms/step\n",
            "Epoch 4321/5000\n",
            "\n",
            "Epoch 4321: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1200e-04 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4322/5000\n",
            "\n",
            "Epoch 4322: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1076e-04 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.8345 - 3s/epoch - 86ms/step\n",
            "Epoch 4323/5000\n",
            "\n",
            "Epoch 4323: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0975e-04 - accuracy: 1.0000 - val_loss: 0.7032 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 4324/5000\n",
            "\n",
            "Epoch 4324: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1264e-04 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4325/5000\n",
            "\n",
            "Epoch 4325: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0858e-04 - accuracy: 1.0000 - val_loss: 0.7101 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4326/5000\n",
            "\n",
            "Epoch 4326: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1201e-04 - accuracy: 1.0000 - val_loss: 0.7056 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4327/5000\n",
            "\n",
            "Epoch 4327: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1163e-04 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.8165 - 3s/epoch - 89ms/step\n",
            "Epoch 4328/5000\n",
            "\n",
            "Epoch 4328: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0849e-04 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.8165 - 4s/epoch - 114ms/step\n",
            "Epoch 4329/5000\n",
            "\n",
            "Epoch 4329: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1226e-04 - accuracy: 1.0000 - val_loss: 0.7104 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4330/5000\n",
            "\n",
            "Epoch 4330: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1209e-04 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4331/5000\n",
            "\n",
            "Epoch 4331: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1255e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8309 - 4s/epoch - 101ms/step\n",
            "Epoch 4332/5000\n",
            "\n",
            "Epoch 4332: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1631e-04 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.8273 - 4s/epoch - 100ms/step\n",
            "Epoch 4333/5000\n",
            "\n",
            "Epoch 4333: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1398e-04 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4334/5000\n",
            "\n",
            "Epoch 4334: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2145e-04 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4335/5000\n",
            "\n",
            "Epoch 4335: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1304e-04 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.8201 - 4s/epoch - 116ms/step\n",
            "Epoch 4336/5000\n",
            "\n",
            "Epoch 4336: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1108e-04 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.8165 - 3s/epoch - 87ms/step\n",
            "Epoch 4337/5000\n",
            "\n",
            "Epoch 4337: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1219e-04 - accuracy: 1.0000 - val_loss: 0.7152 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4338/5000\n",
            "\n",
            "Epoch 4338: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0866e-04 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4339/5000\n",
            "\n",
            "Epoch 4339: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0988e-04 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.8201 - 4s/epoch - 116ms/step\n",
            "Epoch 4340/5000\n",
            "\n",
            "Epoch 4340: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1113e-04 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4341/5000\n",
            "\n",
            "Epoch 4341: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1534e-04 - accuracy: 1.0000 - val_loss: 0.7238 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4342/5000\n",
            "\n",
            "Epoch 4342: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0925e-04 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4343/5000\n",
            "\n",
            "Epoch 4343: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1073e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8309 - 4s/epoch - 118ms/step\n",
            "Epoch 4344/5000\n",
            "\n",
            "Epoch 4344: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1119e-04 - accuracy: 1.0000 - val_loss: 0.6951 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4345/5000\n",
            "\n",
            "Epoch 4345: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1185e-04 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4346/5000\n",
            "\n",
            "Epoch 4346: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1073e-04 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.8237 - 3s/epoch - 88ms/step\n",
            "Epoch 4347/5000\n",
            "\n",
            "Epoch 4347: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1057e-04 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.8201 - 4s/epoch - 113ms/step\n",
            "Epoch 4348/5000\n",
            "\n",
            "Epoch 4348: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1143e-04 - accuracy: 1.0000 - val_loss: 0.7104 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4349/5000\n",
            "\n",
            "Epoch 4349: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0962e-04 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4350/5000\n",
            "\n",
            "Epoch 4350: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0921e-04 - accuracy: 1.0000 - val_loss: 0.7056 - val_accuracy: 0.8165 - 4s/epoch - 104ms/step\n",
            "Epoch 4351/5000\n",
            "\n",
            "Epoch 4351: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0847e-04 - accuracy: 1.0000 - val_loss: 0.7043 - val_accuracy: 0.8165 - 3s/epoch - 98ms/step\n",
            "Epoch 4352/5000\n",
            "\n",
            "Epoch 4352: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0921e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4353/5000\n",
            "\n",
            "Epoch 4353: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1889e-04 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4354/5000\n",
            "\n",
            "Epoch 4354: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1254e-04 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.8129 - 4s/epoch - 117ms/step\n",
            "Epoch 4355/5000\n",
            "\n",
            "Epoch 4355: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1088e-04 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4356/5000\n",
            "\n",
            "Epoch 4356: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0909e-04 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4357/5000\n",
            "\n",
            "Epoch 4357: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0885e-04 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4358/5000\n",
            "\n",
            "Epoch 4358: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1323e-04 - accuracy: 1.0000 - val_loss: 0.7066 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4359/5000\n",
            "\n",
            "Epoch 4359: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0947e-04 - accuracy: 1.0000 - val_loss: 0.7113 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4360/5000\n",
            "\n",
            "Epoch 4360: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0910e-04 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4361/5000\n",
            "\n",
            "Epoch 4361: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1002e-04 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.8237 - 3s/epoch - 87ms/step\n",
            "Epoch 4362/5000\n",
            "\n",
            "Epoch 4362: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0547e-04 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4363/5000\n",
            "\n",
            "Epoch 4363: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0799e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8309 - 3s/epoch - 87ms/step\n",
            "Epoch 4364/5000\n",
            "\n",
            "Epoch 4364: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1099e-04 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4365/5000\n",
            "\n",
            "Epoch 4365: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0710e-04 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8237 - 3s/epoch - 91ms/step\n",
            "Epoch 4366/5000\n",
            "\n",
            "Epoch 4366: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0666e-04 - accuracy: 1.0000 - val_loss: 0.7038 - val_accuracy: 0.8237 - 4s/epoch - 111ms/step\n",
            "Epoch 4367/5000\n",
            "\n",
            "Epoch 4367: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0784e-04 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4368/5000\n",
            "\n",
            "Epoch 4368: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0724e-04 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4369/5000\n",
            "\n",
            "Epoch 4369: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0557e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8201 - 4s/epoch - 105ms/step\n",
            "Epoch 4370/5000\n",
            "\n",
            "Epoch 4370: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0783e-04 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.8237 - 3s/epoch - 97ms/step\n",
            "Epoch 4371/5000\n",
            "\n",
            "Epoch 4371: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1005e-04 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4372/5000\n",
            "\n",
            "Epoch 4372: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0727e-04 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4373/5000\n",
            "\n",
            "Epoch 4373: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1069e-04 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.8237 - 4s/epoch - 118ms/step\n",
            "Epoch 4374/5000\n",
            "\n",
            "Epoch 4374: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0883e-04 - accuracy: 1.0000 - val_loss: 0.7135 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4375/5000\n",
            "\n",
            "Epoch 4375: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0687e-04 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4376/5000\n",
            "\n",
            "Epoch 4376: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0974e-04 - accuracy: 1.0000 - val_loss: 0.7266 - val_accuracy: 0.8094 - 3s/epoch - 85ms/step\n",
            "Epoch 4377/5000\n",
            "\n",
            "Epoch 4377: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0915e-04 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4378/5000\n",
            "\n",
            "Epoch 4378: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0607e-04 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4379/5000\n",
            "\n",
            "Epoch 4379: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0877e-04 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4380/5000\n",
            "\n",
            "Epoch 4380: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1714e-04 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4381/5000\n",
            "\n",
            "Epoch 4381: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0944e-04 - accuracy: 1.0000 - val_loss: 0.7032 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4382/5000\n",
            "\n",
            "Epoch 4382: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0991e-04 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4383/5000\n",
            "\n",
            "Epoch 4383: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1016e-04 - accuracy: 1.0000 - val_loss: 0.7175 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4384/5000\n",
            "\n",
            "Epoch 4384: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0789e-04 - accuracy: 1.0000 - val_loss: 0.7055 - val_accuracy: 0.8201 - 3s/epoch - 90ms/step\n",
            "Epoch 4385/5000\n",
            "\n",
            "Epoch 4385: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0778e-04 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.8129 - 4s/epoch - 111ms/step\n",
            "Epoch 4386/5000\n",
            "\n",
            "Epoch 4386: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0904e-04 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4387/5000\n",
            "\n",
            "Epoch 4387: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0824e-04 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4388/5000\n",
            "\n",
            "Epoch 4388: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0545e-04 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.8201 - 4s/epoch - 102ms/step\n",
            "Epoch 4389/5000\n",
            "\n",
            "Epoch 4389: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0388e-04 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.8345 - 3s/epoch - 99ms/step\n",
            "Epoch 4390/5000\n",
            "\n",
            "Epoch 4390: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0817e-04 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4391/5000\n",
            "\n",
            "Epoch 4391: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0681e-04 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4392/5000\n",
            "\n",
            "Epoch 4392: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0329e-04 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8237 - 4s/epoch - 112ms/step\n",
            "Epoch 4393/5000\n",
            "\n",
            "Epoch 4393: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0361e-04 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8201 - 3s/epoch - 88ms/step\n",
            "Epoch 4394/5000\n",
            "\n",
            "Epoch 4394: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0414e-04 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4395/5000\n",
            "\n",
            "Epoch 4395: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0470e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4396/5000\n",
            "\n",
            "Epoch 4396: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0711e-04 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.8309 - 4s/epoch - 116ms/step\n",
            "Epoch 4397/5000\n",
            "\n",
            "Epoch 4397: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0581e-04 - accuracy: 1.0000 - val_loss: 0.7101 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 4398/5000\n",
            "\n",
            "Epoch 4398: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0922e-04 - accuracy: 1.0000 - val_loss: 0.7056 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4399/5000\n",
            "\n",
            "Epoch 4399: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0809e-04 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4400/5000\n",
            "\n",
            "Epoch 4400: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0714e-04 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4401/5000\n",
            "\n",
            "Epoch 4401: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0373e-04 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4402/5000\n",
            "\n",
            "Epoch 4402: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1242e-04 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4403/5000\n",
            "\n",
            "Epoch 4403: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1148e-04 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4404/5000\n",
            "\n",
            "Epoch 4404: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0731e-04 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.8345 - 4s/epoch - 117ms/step\n",
            "Epoch 4405/5000\n",
            "\n",
            "Epoch 4405: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0560e-04 - accuracy: 1.0000 - val_loss: 0.7043 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4406/5000\n",
            "\n",
            "Epoch 4406: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0296e-04 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4407/5000\n",
            "\n",
            "Epoch 4407: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0690e-04 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.8237 - 3s/epoch - 94ms/step\n",
            "Epoch 4408/5000\n",
            "\n",
            "Epoch 4408: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0801e-04 - accuracy: 1.0000 - val_loss: 0.7252 - val_accuracy: 0.8237 - 4s/epoch - 107ms/step\n",
            "Epoch 4409/5000\n",
            "\n",
            "Epoch 4409: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0516e-04 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4410/5000\n",
            "\n",
            "Epoch 4410: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0323e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4411/5000\n",
            "\n",
            "Epoch 4411: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0579e-04 - accuracy: 1.0000 - val_loss: 0.7259 - val_accuracy: 0.8129 - 4s/epoch - 105ms/step\n",
            "Epoch 4412/5000\n",
            "\n",
            "Epoch 4412: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0677e-04 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.8237 - 3s/epoch - 96ms/step\n",
            "Epoch 4413/5000\n",
            "\n",
            "Epoch 4413: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0665e-04 - accuracy: 1.0000 - val_loss: 0.7033 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4414/5000\n",
            "\n",
            "Epoch 4414: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0440e-04 - accuracy: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4415/5000\n",
            "\n",
            "Epoch 4415: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0530e-04 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4416/5000\n",
            "\n",
            "Epoch 4416: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0402e-04 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4417/5000\n",
            "\n",
            "Epoch 4417: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0426e-04 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4418/5000\n",
            "\n",
            "Epoch 4418: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0252e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4419/5000\n",
            "\n",
            "Epoch 4419: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0457e-04 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.8237 - 4s/epoch - 118ms/step\n",
            "Epoch 4420/5000\n",
            "\n",
            "Epoch 4420: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0384e-04 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4421/5000\n",
            "\n",
            "Epoch 4421: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0402e-04 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4422/5000\n",
            "\n",
            "Epoch 4422: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0354e-04 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4423/5000\n",
            "\n",
            "Epoch 4423: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0425e-04 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4424/5000\n",
            "\n",
            "Epoch 4424: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0320e-04 - accuracy: 1.0000 - val_loss: 0.7150 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4425/5000\n",
            "\n",
            "Epoch 4425: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0167e-04 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4426/5000\n",
            "\n",
            "Epoch 4426: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0572e-04 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.8345 - 3s/epoch - 91ms/step\n",
            "Epoch 4427/5000\n",
            "\n",
            "Epoch 4427: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0101e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8201 - 4s/epoch - 110ms/step\n",
            "Epoch 4428/5000\n",
            "\n",
            "Epoch 4428: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0287e-04 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4429/5000\n",
            "\n",
            "Epoch 4429: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0239e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4430/5000\n",
            "\n",
            "Epoch 4430: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0489e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8129 - 4s/epoch - 105ms/step\n",
            "Epoch 4431/5000\n",
            "\n",
            "Epoch 4431: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0107e-04 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8201 - 3s/epoch - 96ms/step\n",
            "Epoch 4432/5000\n",
            "\n",
            "Epoch 4432: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0060e-04 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4433/5000\n",
            "\n",
            "Epoch 4433: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0122e-04 - accuracy: 1.0000 - val_loss: 0.7086 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4434/5000\n",
            "\n",
            "Epoch 4434: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0139e-04 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4435/5000\n",
            "\n",
            "Epoch 4435: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0276e-04 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4436/5000\n",
            "\n",
            "Epoch 4436: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0095e-04 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4437/5000\n",
            "\n",
            "Epoch 4437: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0437e-04 - accuracy: 1.0000 - val_loss: 0.7252 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4438/5000\n",
            "\n",
            "Epoch 4438: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0280e-04 - accuracy: 1.0000 - val_loss: 0.7288 - val_accuracy: 0.8237 - 4s/epoch - 118ms/step\n",
            "Epoch 4439/5000\n",
            "\n",
            "Epoch 4439: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0807e-04 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4440/5000\n",
            "\n",
            "Epoch 4440: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0853e-04 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4441/5000\n",
            "\n",
            "Epoch 4441: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0336e-04 - accuracy: 1.0000 - val_loss: 0.7271 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4442/5000\n",
            "\n",
            "Epoch 4442: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0391e-04 - accuracy: 1.0000 - val_loss: 0.7269 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4443/5000\n",
            "\n",
            "Epoch 4443: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0098e-04 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4444/5000\n",
            "\n",
            "Epoch 4444: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0527e-04 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4445/5000\n",
            "\n",
            "Epoch 4445: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0272e-04 - accuracy: 1.0000 - val_loss: 0.7109 - val_accuracy: 0.8237 - 3s/epoch - 93ms/step\n",
            "Epoch 4446/5000\n",
            "\n",
            "Epoch 4446: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0318e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8201 - 4s/epoch - 108ms/step\n",
            "Epoch 4447/5000\n",
            "\n",
            "Epoch 4447: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.6152e-04 - accuracy: 1.0000 - val_loss: 0.7356 - val_accuracy: 0.8273 - 3s/epoch - 87ms/step\n",
            "Epoch 4448/5000\n",
            "\n",
            "Epoch 4448: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.3450e-04 - accuracy: 1.0000 - val_loss: 0.7397 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4449/5000\n",
            "\n",
            "Epoch 4449: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0587e-04 - accuracy: 1.0000 - val_loss: 0.7372 - val_accuracy: 0.8165 - 4s/epoch - 108ms/step\n",
            "Epoch 4450/5000\n",
            "\n",
            "Epoch 4450: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0764e-04 - accuracy: 1.0000 - val_loss: 0.7409 - val_accuracy: 0.8129 - 3s/epoch - 94ms/step\n",
            "Epoch 4451/5000\n",
            "\n",
            "Epoch 4451: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0543e-04 - accuracy: 1.0000 - val_loss: 0.7374 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4452/5000\n",
            "\n",
            "Epoch 4452: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0342e-04 - accuracy: 1.0000 - val_loss: 0.7364 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4453/5000\n",
            "\n",
            "Epoch 4453: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0379e-04 - accuracy: 1.0000 - val_loss: 0.7289 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4454/5000\n",
            "\n",
            "Epoch 4454: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0809e-04 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4455/5000\n",
            "\n",
            "Epoch 4455: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0503e-04 - accuracy: 1.0000 - val_loss: 0.7282 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4456/5000\n",
            "\n",
            "Epoch 4456: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0383e-04 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4457/5000\n",
            "\n",
            "Epoch 4457: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0122e-04 - accuracy: 1.0000 - val_loss: 0.7259 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4458/5000\n",
            "\n",
            "Epoch 4458: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0292e-04 - accuracy: 1.0000 - val_loss: 0.7269 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4459/5000\n",
            "\n",
            "Epoch 4459: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0956e-04 - accuracy: 1.0000 - val_loss: 0.7135 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4460/5000\n",
            "\n",
            "Epoch 4460: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0483e-04 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4461/5000\n",
            "\n",
            "Epoch 4461: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0331e-04 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4462/5000\n",
            "\n",
            "Epoch 4462: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0169e-04 - accuracy: 1.0000 - val_loss: 0.7170 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4463/5000\n",
            "\n",
            "Epoch 4463: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0494e-04 - accuracy: 1.0000 - val_loss: 0.7204 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4464/5000\n",
            "\n",
            "Epoch 4464: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0389e-04 - accuracy: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.8165 - 3s/epoch - 94ms/step\n",
            "Epoch 4465/5000\n",
            "\n",
            "Epoch 4465: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0701e-04 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.8165 - 4s/epoch - 109ms/step\n",
            "Epoch 4466/5000\n",
            "\n",
            "Epoch 4466: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0080e-04 - accuracy: 1.0000 - val_loss: 0.7201 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4467/5000\n",
            "\n",
            "Epoch 4467: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0266e-04 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4468/5000\n",
            "\n",
            "Epoch 4468: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0099e-04 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.8201 - 4s/epoch - 107ms/step\n",
            "Epoch 4469/5000\n",
            "\n",
            "Epoch 4469: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0374e-04 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.8237 - 3s/epoch - 96ms/step\n",
            "Epoch 4470/5000\n",
            "\n",
            "Epoch 4470: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0585e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4471/5000\n",
            "\n",
            "Epoch 4471: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0425e-04 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4472/5000\n",
            "\n",
            "Epoch 4472: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0191e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8129 - 4s/epoch - 117ms/step\n",
            "Epoch 4473/5000\n",
            "\n",
            "Epoch 4473: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0152e-04 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4474/5000\n",
            "\n",
            "Epoch 4474: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.9149e-05 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4475/5000\n",
            "\n",
            "Epoch 4475: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.9580e-05 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4476/5000\n",
            "\n",
            "Epoch 4476: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0466e-04 - accuracy: 1.0000 - val_loss: 0.7203 - val_accuracy: 0.8165 - 4s/epoch - 116ms/step\n",
            "Epoch 4477/5000\n",
            "\n",
            "Epoch 4477: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.9339e-05 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4478/5000\n",
            "\n",
            "Epoch 4478: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.9591e-05 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4479/5000\n",
            "\n",
            "Epoch 4479: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0626e-04 - accuracy: 1.0000 - val_loss: 0.7223 - val_accuracy: 0.8201 - 3s/epoch - 87ms/step\n",
            "Epoch 4480/5000\n",
            "\n",
            "Epoch 4480: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0145e-04 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4481/5000\n",
            "\n",
            "Epoch 4481: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0021e-04 - accuracy: 1.0000 - val_loss: 0.7261 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4482/5000\n",
            "\n",
            "Epoch 4482: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7371e-05 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4483/5000\n",
            "\n",
            "Epoch 4483: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0196e-04 - accuracy: 1.0000 - val_loss: 0.7199 - val_accuracy: 0.8237 - 3s/epoch - 98ms/step\n",
            "Epoch 4484/5000\n",
            "\n",
            "Epoch 4484: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.7766e-05 - accuracy: 1.0000 - val_loss: 0.7150 - val_accuracy: 0.8273 - 4s/epoch - 103ms/step\n",
            "Epoch 4485/5000\n",
            "\n",
            "Epoch 4485: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.9035e-05 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4486/5000\n",
            "\n",
            "Epoch 4486: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1037e-04 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4487/5000\n",
            "\n",
            "Epoch 4487: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.9866e-05 - accuracy: 1.0000 - val_loss: 0.7199 - val_accuracy: 0.8309 - 4s/epoch - 111ms/step\n",
            "Epoch 4488/5000\n",
            "\n",
            "Epoch 4488: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0046e-04 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.8237 - 3s/epoch - 92ms/step\n",
            "Epoch 4489/5000\n",
            "\n",
            "Epoch 4489: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.9324e-05 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4490/5000\n",
            "\n",
            "Epoch 4490: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.8914e-05 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4491/5000\n",
            "\n",
            "Epoch 4491: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.8358e-05 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4492/5000\n",
            "\n",
            "Epoch 4492: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0123e-04 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.8201 - 3s/epoch - 87ms/step\n",
            "Epoch 4493/5000\n",
            "\n",
            "Epoch 4493: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0258e-04 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4494/5000\n",
            "\n",
            "Epoch 4494: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7758e-05 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4495/5000\n",
            "\n",
            "Epoch 4495: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0146e-04 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4496/5000\n",
            "\n",
            "Epoch 4496: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.9319e-05 - accuracy: 1.0000 - val_loss: 0.7151 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4497/5000\n",
            "\n",
            "Epoch 4497: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0032e-04 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4498/5000\n",
            "\n",
            "Epoch 4498: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0110e-04 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.8201 - 3s/epoch - 87ms/step\n",
            "Epoch 4499/5000\n",
            "\n",
            "Epoch 4499: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.9775e-05 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8237 - 4s/epoch - 115ms/step\n",
            "Epoch 4500/5000\n",
            "\n",
            "Epoch 4500: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.9216e-05 - accuracy: 1.0000 - val_loss: 0.7238 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4501/5000\n",
            "\n",
            "Epoch 4501: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.8007e-05 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4502/5000\n",
            "\n",
            "Epoch 4502: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0150e-04 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.8201 - 3s/epoch - 97ms/step\n",
            "Epoch 4503/5000\n",
            "\n",
            "Epoch 4503: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1398e-04 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.8165 - 4s/epoch - 104ms/step\n",
            "Epoch 4504/5000\n",
            "\n",
            "Epoch 4504: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0074e-04 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4505/5000\n",
            "\n",
            "Epoch 4505: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0444e-04 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 4506/5000\n",
            "\n",
            "Epoch 4506: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0370e-04 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.8237 - 4s/epoch - 110ms/step\n",
            "Epoch 4507/5000\n",
            "\n",
            "Epoch 4507: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.8808e-05 - accuracy: 1.0000 - val_loss: 0.7135 - val_accuracy: 0.8201 - 3s/epoch - 91ms/step\n",
            "Epoch 4508/5000\n",
            "\n",
            "Epoch 4508: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0659e-04 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4509/5000\n",
            "\n",
            "Epoch 4509: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0047e-04 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4510/5000\n",
            "\n",
            "Epoch 4510: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0299e-04 - accuracy: 1.0000 - val_loss: 0.7378 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4511/5000\n",
            "\n",
            "Epoch 4511: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0242e-04 - accuracy: 1.0000 - val_loss: 0.7292 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4512/5000\n",
            "\n",
            "Epoch 4512: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0143e-04 - accuracy: 1.0000 - val_loss: 0.7257 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4513/5000\n",
            "\n",
            "Epoch 4513: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.9981e-05 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4514/5000\n",
            "\n",
            "Epoch 4514: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.9123e-05 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4515/5000\n",
            "\n",
            "Epoch 4515: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.8795e-05 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4516/5000\n",
            "\n",
            "Epoch 4516: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6965e-05 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4517/5000\n",
            "\n",
            "Epoch 4517: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7631e-05 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4518/5000\n",
            "\n",
            "Epoch 4518: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.8146e-05 - accuracy: 1.0000 - val_loss: 0.7227 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4519/5000\n",
            "\n",
            "Epoch 4519: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.8226e-05 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4520/5000\n",
            "\n",
            "Epoch 4520: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6603e-05 - accuracy: 1.0000 - val_loss: 0.7101 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4521/5000\n",
            "\n",
            "Epoch 4521: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0199e-04 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8273 - 3s/epoch - 97ms/step\n",
            "Epoch 4522/5000\n",
            "\n",
            "Epoch 4522: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.5282e-05 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8165 - 4s/epoch - 105ms/step\n",
            "Epoch 4523/5000\n",
            "\n",
            "Epoch 4523: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7776e-05 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4524/5000\n",
            "\n",
            "Epoch 4524: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.9235e-05 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4525/5000\n",
            "\n",
            "Epoch 4525: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.7359e-05 - accuracy: 1.0000 - val_loss: 0.7152 - val_accuracy: 0.8237 - 4s/epoch - 114ms/step\n",
            "Epoch 4526/5000\n",
            "\n",
            "Epoch 4526: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0171e-04 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.8201 - 3s/epoch - 89ms/step\n",
            "Epoch 4527/5000\n",
            "\n",
            "Epoch 4527: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.5673e-05 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4528/5000\n",
            "\n",
            "Epoch 4528: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.8531e-05 - accuracy: 1.0000 - val_loss: 0.7113 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4529/5000\n",
            "\n",
            "Epoch 4529: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0040e-04 - accuracy: 1.0000 - val_loss: 0.7240 - val_accuracy: 0.8129 - 4s/epoch - 117ms/step\n",
            "Epoch 4530/5000\n",
            "\n",
            "Epoch 4530: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7027e-05 - accuracy: 1.0000 - val_loss: 0.7227 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4531/5000\n",
            "\n",
            "Epoch 4531: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.8958e-05 - accuracy: 1.0000 - val_loss: 0.7203 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4532/5000\n",
            "\n",
            "Epoch 4532: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.9191e-05 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4533/5000\n",
            "\n",
            "Epoch 4533: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0045e-04 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.8237 - 4s/epoch - 116ms/step\n",
            "Epoch 4534/5000\n",
            "\n",
            "Epoch 4534: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.8823e-05 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4535/5000\n",
            "\n",
            "Epoch 4535: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7858e-05 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4536/5000\n",
            "\n",
            "Epoch 4536: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6002e-05 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.8237 - 3s/epoch - 89ms/step\n",
            "Epoch 4537/5000\n",
            "\n",
            "Epoch 4537: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.6664e-05 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.8273 - 4s/epoch - 113ms/step\n",
            "Epoch 4538/5000\n",
            "\n",
            "Epoch 4538: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7766e-05 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4539/5000\n",
            "\n",
            "Epoch 4539: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7085e-05 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4540/5000\n",
            "\n",
            "Epoch 4540: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.7001e-05 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.8201 - 4s/epoch - 103ms/step\n",
            "Epoch 4541/5000\n",
            "\n",
            "Epoch 4541: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.9166e-05 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.8165 - 3s/epoch - 99ms/step\n",
            "Epoch 4542/5000\n",
            "\n",
            "Epoch 4542: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6592e-05 - accuracy: 1.0000 - val_loss: 0.7175 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4543/5000\n",
            "\n",
            "Epoch 4543: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6331e-05 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4544/5000\n",
            "\n",
            "Epoch 4544: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.7989e-05 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.8129 - 4s/epoch - 117ms/step\n",
            "Epoch 4545/5000\n",
            "\n",
            "Epoch 4545: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.8713e-05 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4546/5000\n",
            "\n",
            "Epoch 4546: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7388e-05 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4547/5000\n",
            "\n",
            "Epoch 4547: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7189e-05 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4548/5000\n",
            "\n",
            "Epoch 4548: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.4277e-05 - accuracy: 1.0000 - val_loss: 0.7101 - val_accuracy: 0.8165 - 4s/epoch - 116ms/step\n",
            "Epoch 4549/5000\n",
            "\n",
            "Epoch 4549: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0010e-04 - accuracy: 1.0000 - val_loss: 0.7059 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4550/5000\n",
            "\n",
            "Epoch 4550: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4540e-05 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4551/5000\n",
            "\n",
            "Epoch 4551: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4831e-05 - accuracy: 1.0000 - val_loss: 0.7073 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4552/5000\n",
            "\n",
            "Epoch 4552: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.4866e-05 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4553/5000\n",
            "\n",
            "Epoch 4553: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.5508e-05 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.8165 - 3s/epoch - 87ms/step\n",
            "Epoch 4554/5000\n",
            "\n",
            "Epoch 4554: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7508e-05 - accuracy: 1.0000 - val_loss: 0.7391 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4555/5000\n",
            "\n",
            "Epoch 4555: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.5018e-05 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.8165 - 3s/epoch - 88ms/step\n",
            "Epoch 4556/5000\n",
            "\n",
            "Epoch 4556: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.4347e-05 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.8165 - 4s/epoch - 114ms/step\n",
            "Epoch 4557/5000\n",
            "\n",
            "Epoch 4557: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.5795e-05 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4558/5000\n",
            "\n",
            "Epoch 4558: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.3597e-05 - accuracy: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4559/5000\n",
            "\n",
            "Epoch 4559: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.7481e-05 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.8129 - 4s/epoch - 103ms/step\n",
            "Epoch 4560/5000\n",
            "\n",
            "Epoch 4560: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.5387e-05 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.8129 - 4s/epoch - 101ms/step\n",
            "Epoch 4561/5000\n",
            "\n",
            "Epoch 4561: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7067e-05 - accuracy: 1.0000 - val_loss: 0.7243 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4562/5000\n",
            "\n",
            "Epoch 4562: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6741e-05 - accuracy: 1.0000 - val_loss: 0.7262 - val_accuracy: 0.8201 - 3s/epoch - 87ms/step\n",
            "Epoch 4563/5000\n",
            "\n",
            "Epoch 4563: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.3243e-05 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8165 - 4s/epoch - 116ms/step\n",
            "Epoch 4564/5000\n",
            "\n",
            "Epoch 4564: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.5692e-05 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4565/5000\n",
            "\n",
            "Epoch 4565: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.5267e-05 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4566/5000\n",
            "\n",
            "Epoch 4566: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.5894e-05 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4567/5000\n",
            "\n",
            "Epoch 4567: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.7614e-05 - accuracy: 1.0000 - val_loss: 0.7201 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4568/5000\n",
            "\n",
            "Epoch 4568: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0028e-04 - accuracy: 1.0000 - val_loss: 0.7217 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4569/5000\n",
            "\n",
            "Epoch 4569: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6170e-05 - accuracy: 1.0000 - val_loss: 0.7294 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4570/5000\n",
            "\n",
            "Epoch 4570: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.2822e-04 - accuracy: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4571/5000\n",
            "\n",
            "Epoch 4571: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.1016e-04 - accuracy: 1.0000 - val_loss: 0.7393 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4572/5000\n",
            "\n",
            "Epoch 4572: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0057e-04 - accuracy: 1.0000 - val_loss: 0.7295 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4573/5000\n",
            "\n",
            "Epoch 4573: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.9898e-05 - accuracy: 1.0000 - val_loss: 0.7283 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4574/5000\n",
            "\n",
            "Epoch 4574: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6512e-05 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.8273 - 3s/epoch - 89ms/step\n",
            "Epoch 4575/5000\n",
            "\n",
            "Epoch 4575: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0110e-04 - accuracy: 1.0000 - val_loss: 0.7284 - val_accuracy: 0.8201 - 4s/epoch - 112ms/step\n",
            "Epoch 4576/5000\n",
            "\n",
            "Epoch 4576: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7605e-05 - accuracy: 1.0000 - val_loss: 0.7265 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4577/5000\n",
            "\n",
            "Epoch 4577: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6986e-05 - accuracy: 1.0000 - val_loss: 0.7264 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4578/5000\n",
            "\n",
            "Epoch 4578: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.7045e-05 - accuracy: 1.0000 - val_loss: 0.7257 - val_accuracy: 0.8165 - 4s/epoch - 101ms/step\n",
            "Epoch 4579/5000\n",
            "\n",
            "Epoch 4579: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0029e-04 - accuracy: 1.0000 - val_loss: 0.7355 - val_accuracy: 0.8237 - 4s/epoch - 101ms/step\n",
            "Epoch 4580/5000\n",
            "\n",
            "Epoch 4580: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6267e-05 - accuracy: 1.0000 - val_loss: 0.7328 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4581/5000\n",
            "\n",
            "Epoch 4581: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.5112e-05 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4582/5000\n",
            "\n",
            "Epoch 4582: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.4620e-05 - accuracy: 1.0000 - val_loss: 0.7283 - val_accuracy: 0.8129 - 4s/epoch - 115ms/step\n",
            "Epoch 4583/5000\n",
            "\n",
            "Epoch 4583: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6122e-05 - accuracy: 1.0000 - val_loss: 0.7205 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4584/5000\n",
            "\n",
            "Epoch 4584: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6518e-05 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4585/5000\n",
            "\n",
            "Epoch 4585: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4873e-05 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4586/5000\n",
            "\n",
            "Epoch 4586: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.8103e-05 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4587/5000\n",
            "\n",
            "Epoch 4587: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0320e-04 - accuracy: 1.0000 - val_loss: 0.7161 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4588/5000\n",
            "\n",
            "Epoch 4588: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6727e-05 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4589/5000\n",
            "\n",
            "Epoch 4589: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7911e-05 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.8273 - 3s/epoch - 87ms/step\n",
            "Epoch 4590/5000\n",
            "\n",
            "Epoch 4590: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.8540e-05 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.8309 - 4s/epoch - 116ms/step\n",
            "Epoch 4591/5000\n",
            "\n",
            "Epoch 4591: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0015e-04 - accuracy: 1.0000 - val_loss: 0.7245 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 4592/5000\n",
            "\n",
            "Epoch 4592: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.3727e-05 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4593/5000\n",
            "\n",
            "Epoch 4593: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4308e-05 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.8237 - 3s/epoch - 87ms/step\n",
            "Epoch 4594/5000\n",
            "\n",
            "Epoch 4594: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.4852e-05 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.8237 - 4s/epoch - 114ms/step\n",
            "Epoch 4595/5000\n",
            "\n",
            "Epoch 4595: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.2889e-05 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4596/5000\n",
            "\n",
            "Epoch 4596: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6369e-05 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.8201 - 3s/epoch - 87ms/step\n",
            "Epoch 4597/5000\n",
            "\n",
            "Epoch 4597: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.4736e-05 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.8237 - 4s/epoch - 103ms/step\n",
            "Epoch 4598/5000\n",
            "\n",
            "Epoch 4598: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.4568e-05 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.8201 - 4s/epoch - 100ms/step\n",
            "Epoch 4599/5000\n",
            "\n",
            "Epoch 4599: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.3760e-05 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4600/5000\n",
            "\n",
            "Epoch 4600: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.8291e-05 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4601/5000\n",
            "\n",
            "Epoch 4601: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.3104e-05 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4602/5000\n",
            "\n",
            "Epoch 4602: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6891e-05 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4603/5000\n",
            "\n",
            "Epoch 4603: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4949e-05 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4604/5000\n",
            "\n",
            "Epoch 4604: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7596e-05 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4605/5000\n",
            "\n",
            "Epoch 4605: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.5202e-05 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4606/5000\n",
            "\n",
            "Epoch 4606: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4676e-05 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4607/5000\n",
            "\n",
            "Epoch 4607: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6656e-05 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.8237 - 3s/epoch - 87ms/step\n",
            "Epoch 4608/5000\n",
            "\n",
            "Epoch 4608: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.3529e-05 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.8273 - 3s/epoch - 87ms/step\n",
            "Epoch 4609/5000\n",
            "\n",
            "Epoch 4609: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 1.0112e-04 - accuracy: 1.0000 - val_loss: 0.7240 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4610/5000\n",
            "\n",
            "Epoch 4610: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.3208e-05 - accuracy: 1.0000 - val_loss: 0.7171 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4611/5000\n",
            "\n",
            "Epoch 4611: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.5719e-05 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.8273 - 3s/epoch - 88ms/step\n",
            "Epoch 4612/5000\n",
            "\n",
            "Epoch 4612: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4043e-05 - accuracy: 1.0000 - val_loss: 0.7093 - val_accuracy: 0.8273 - 3s/epoch - 95ms/step\n",
            "Epoch 4613/5000\n",
            "\n",
            "Epoch 4613: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.6182e-05 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.8273 - 4s/epoch - 107ms/step\n",
            "Epoch 4614/5000\n",
            "\n",
            "Epoch 4614: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6199e-05 - accuracy: 1.0000 - val_loss: 0.7275 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4615/5000\n",
            "\n",
            "Epoch 4615: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7066e-05 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4616/5000\n",
            "\n",
            "Epoch 4616: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.2838e-05 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.8273 - 4s/epoch - 111ms/step\n",
            "Epoch 4617/5000\n",
            "\n",
            "Epoch 4617: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.3148e-05 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.8201 - 3s/epoch - 91ms/step\n",
            "Epoch 4618/5000\n",
            "\n",
            "Epoch 4618: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.0867e-05 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4619/5000\n",
            "\n",
            "Epoch 4619: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.5230e-05 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4620/5000\n",
            "\n",
            "Epoch 4620: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.3008e-05 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.8237 - 4s/epoch - 116ms/step\n",
            "Epoch 4621/5000\n",
            "\n",
            "Epoch 4621: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.1101e-05 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4622/5000\n",
            "\n",
            "Epoch 4622: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.3597e-05 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4623/5000\n",
            "\n",
            "Epoch 4623: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7575e-05 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4624/5000\n",
            "\n",
            "Epoch 4624: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.1482e-05 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4625/5000\n",
            "\n",
            "Epoch 4625: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.2564e-05 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4626/5000\n",
            "\n",
            "Epoch 4626: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0011e-04 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.8201 - 3s/epoch - 88ms/step\n",
            "Epoch 4627/5000\n",
            "\n",
            "Epoch 4627: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4734e-05 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4628/5000\n",
            "\n",
            "Epoch 4628: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.4407e-05 - accuracy: 1.0000 - val_loss: 0.7264 - val_accuracy: 0.8381 - 4s/epoch - 118ms/step\n",
            "Epoch 4629/5000\n",
            "\n",
            "Epoch 4629: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.1863e-05 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4630/5000\n",
            "\n",
            "Epoch 4630: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.2996e-05 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4631/5000\n",
            "\n",
            "Epoch 4631: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.5359e-05 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.8201 - 3s/epoch - 99ms/step\n",
            "Epoch 4632/5000\n",
            "\n",
            "Epoch 4632: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.2551e-05 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.8273 - 4s/epoch - 103ms/step\n",
            "Epoch 4633/5000\n",
            "\n",
            "Epoch 4633: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.5273e-05 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4634/5000\n",
            "\n",
            "Epoch 4634: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.0964e-05 - accuracy: 1.0000 - val_loss: 0.7254 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4635/5000\n",
            "\n",
            "Epoch 4635: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.5894e-05 - accuracy: 1.0000 - val_loss: 0.7308 - val_accuracy: 0.8237 - 4s/epoch - 112ms/step\n",
            "Epoch 4636/5000\n",
            "\n",
            "Epoch 4636: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.7001e-05 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.8201 - 3s/epoch - 89ms/step\n",
            "Epoch 4637/5000\n",
            "\n",
            "Epoch 4637: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4148e-05 - accuracy: 1.0000 - val_loss: 0.7299 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4638/5000\n",
            "\n",
            "Epoch 4638: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4620e-05 - accuracy: 1.0000 - val_loss: 0.7324 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4639/5000\n",
            "\n",
            "Epoch 4639: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.3935e-05 - accuracy: 1.0000 - val_loss: 0.7273 - val_accuracy: 0.8129 - 4s/epoch - 116ms/step\n",
            "Epoch 4640/5000\n",
            "\n",
            "Epoch 4640: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.2122e-05 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4641/5000\n",
            "\n",
            "Epoch 4641: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.1831e-05 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4642/5000\n",
            "\n",
            "Epoch 4642: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0422e-04 - accuracy: 1.0000 - val_loss: 0.7224 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4643/5000\n",
            "\n",
            "Epoch 4643: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.3651e-05 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.8309 - 4s/epoch - 118ms/step\n",
            "Epoch 4644/5000\n",
            "\n",
            "Epoch 4644: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.3543e-05 - accuracy: 1.0000 - val_loss: 0.7289 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4645/5000\n",
            "\n",
            "Epoch 4645: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4341e-05 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4646/5000\n",
            "\n",
            "Epoch 4646: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.6501e-05 - accuracy: 1.0000 - val_loss: 0.7317 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4647/5000\n",
            "\n",
            "Epoch 4647: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.3260e-05 - accuracy: 1.0000 - val_loss: 0.7301 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4648/5000\n",
            "\n",
            "Epoch 4648: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.2592e-05 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4649/5000\n",
            "\n",
            "Epoch 4649: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.0808e-05 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4650/5000\n",
            "\n",
            "Epoch 4650: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.1926e-05 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.8201 - 3s/epoch - 93ms/step\n",
            "Epoch 4651/5000\n",
            "\n",
            "Epoch 4651: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.9570e-05 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.8309 - 4s/epoch - 110ms/step\n",
            "Epoch 4652/5000\n",
            "\n",
            "Epoch 4652: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.2505e-05 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4653/5000\n",
            "\n",
            "Epoch 4653: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.2785e-05 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4654/5000\n",
            "\n",
            "Epoch 4654: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.9661e-05 - accuracy: 1.0000 - val_loss: 0.7284 - val_accuracy: 0.8273 - 4s/epoch - 105ms/step\n",
            "Epoch 4655/5000\n",
            "\n",
            "Epoch 4655: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.0231e-05 - accuracy: 1.0000 - val_loss: 0.7242 - val_accuracy: 0.8309 - 3s/epoch - 97ms/step\n",
            "Epoch 4656/5000\n",
            "\n",
            "Epoch 4656: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.0955e-05 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4657/5000\n",
            "\n",
            "Epoch 4657: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9922e-05 - accuracy: 1.0000 - val_loss: 0.7223 - val_accuracy: 0.8309 - 3s/epoch - 87ms/step\n",
            "Epoch 4658/5000\n",
            "\n",
            "Epoch 4658: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.2771e-05 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8273 - 4s/epoch - 118ms/step\n",
            "Epoch 4659/5000\n",
            "\n",
            "Epoch 4659: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.0682e-05 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4660/5000\n",
            "\n",
            "Epoch 4660: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9838e-05 - accuracy: 1.0000 - val_loss: 0.7140 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4661/5000\n",
            "\n",
            "Epoch 4661: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.1135e-05 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4662/5000\n",
            "\n",
            "Epoch 4662: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.0693e-05 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4663/5000\n",
            "\n",
            "Epoch 4663: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4227e-05 - accuracy: 1.0000 - val_loss: 0.7256 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4664/5000\n",
            "\n",
            "Epoch 4664: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4832e-05 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4665/5000\n",
            "\n",
            "Epoch 4665: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.0858e-05 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4666/5000\n",
            "\n",
            "Epoch 4666: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.0329e-05 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4667/5000\n",
            "\n",
            "Epoch 4667: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.0379e-05 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4668/5000\n",
            "\n",
            "Epoch 4668: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.0112e-05 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4669/5000\n",
            "\n",
            "Epoch 4669: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.1543e-05 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8345 - 3s/epoch - 90ms/step\n",
            "Epoch 4670/5000\n",
            "\n",
            "Epoch 4670: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.0754e-05 - accuracy: 1.0000 - val_loss: 0.7048 - val_accuracy: 0.8237 - 4s/epoch - 113ms/step\n",
            "Epoch 4671/5000\n",
            "\n",
            "Epoch 4671: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.3144e-05 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4672/5000\n",
            "\n",
            "Epoch 4672: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.2439e-05 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4673/5000\n",
            "\n",
            "Epoch 4673: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.1786e-05 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.8165 - 4s/epoch - 103ms/step\n",
            "Epoch 4674/5000\n",
            "\n",
            "Epoch 4674: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9090e-05 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8201 - 3s/epoch - 99ms/step\n",
            "Epoch 4675/5000\n",
            "\n",
            "Epoch 4675: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8795e-05 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4676/5000\n",
            "\n",
            "Epoch 4676: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9672e-05 - accuracy: 1.0000 - val_loss: 0.7161 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4677/5000\n",
            "\n",
            "Epoch 4677: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.0700e-05 - accuracy: 1.0000 - val_loss: 0.7214 - val_accuracy: 0.8201 - 4s/epoch - 116ms/step\n",
            "Epoch 4678/5000\n",
            "\n",
            "Epoch 4678: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8468e-05 - accuracy: 1.0000 - val_loss: 0.7170 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4679/5000\n",
            "\n",
            "Epoch 4679: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.0099e-05 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4680/5000\n",
            "\n",
            "Epoch 4680: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4726e-05 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4681/5000\n",
            "\n",
            "Epoch 4681: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.9362e-05 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4682/5000\n",
            "\n",
            "Epoch 4682: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.1186e-05 - accuracy: 1.0000 - val_loss: 0.7208 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4683/5000\n",
            "\n",
            "Epoch 4683: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.5189e-05 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4684/5000\n",
            "\n",
            "Epoch 4684: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.2351e-05 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4685/5000\n",
            "\n",
            "Epoch 4685: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.4323e-05 - accuracy: 1.0000 - val_loss: 0.7586 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4686/5000\n",
            "\n",
            "Epoch 4686: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0034e-04 - accuracy: 1.0000 - val_loss: 0.7323 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4687/5000\n",
            "\n",
            "Epoch 4687: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9254e-05 - accuracy: 1.0000 - val_loss: 0.7309 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4688/5000\n",
            "\n",
            "Epoch 4688: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9621e-05 - accuracy: 1.0000 - val_loss: 0.7327 - val_accuracy: 0.8237 - 3s/epoch - 89ms/step\n",
            "Epoch 4689/5000\n",
            "\n",
            "Epoch 4689: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.0424e-05 - accuracy: 1.0000 - val_loss: 0.7289 - val_accuracy: 0.8273 - 4s/epoch - 113ms/step\n",
            "Epoch 4690/5000\n",
            "\n",
            "Epoch 4690: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.2618e-05 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4691/5000\n",
            "\n",
            "Epoch 4691: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.1143e-05 - accuracy: 1.0000 - val_loss: 0.7208 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4692/5000\n",
            "\n",
            "Epoch 4692: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.0527e-05 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.8309 - 4s/epoch - 100ms/step\n",
            "Epoch 4693/5000\n",
            "\n",
            "Epoch 4693: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.0268e-05 - accuracy: 1.0000 - val_loss: 0.7266 - val_accuracy: 0.8201 - 4s/epoch - 100ms/step\n",
            "Epoch 4694/5000\n",
            "\n",
            "Epoch 4694: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9267e-05 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4695/5000\n",
            "\n",
            "Epoch 4695: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9382e-05 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4696/5000\n",
            "\n",
            "Epoch 4696: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.7950e-05 - accuracy: 1.0000 - val_loss: 0.7227 - val_accuracy: 0.8309 - 4s/epoch - 113ms/step\n",
            "Epoch 4697/5000\n",
            "\n",
            "Epoch 4697: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8259e-05 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.8237 - 3s/epoch - 89ms/step\n",
            "Epoch 4698/5000\n",
            "\n",
            "Epoch 4698: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.3584e-05 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4699/5000\n",
            "\n",
            "Epoch 4699: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8110e-05 - accuracy: 1.0000 - val_loss: 0.7203 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4700/5000\n",
            "\n",
            "Epoch 4700: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.7412e-05 - accuracy: 1.0000 - val_loss: 0.7175 - val_accuracy: 0.8201 - 4s/epoch - 116ms/step\n",
            "Epoch 4701/5000\n",
            "\n",
            "Epoch 4701: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.1253e-05 - accuracy: 1.0000 - val_loss: 0.7195 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4702/5000\n",
            "\n",
            "Epoch 4702: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8471e-05 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4703/5000\n",
            "\n",
            "Epoch 4703: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8967e-05 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4704/5000\n",
            "\n",
            "Epoch 4704: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.7623e-05 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.8201 - 4s/epoch - 116ms/step\n",
            "Epoch 4705/5000\n",
            "\n",
            "Epoch 4705: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.0660e-05 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4706/5000\n",
            "\n",
            "Epoch 4706: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9819e-05 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4707/5000\n",
            "\n",
            "Epoch 4707: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7162e-05 - accuracy: 1.0000 - val_loss: 0.7224 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4708/5000\n",
            "\n",
            "Epoch 4708: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.6112e-05 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4709/5000\n",
            "\n",
            "Epoch 4709: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7328e-05 - accuracy: 1.0000 - val_loss: 0.7205 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4710/5000\n",
            "\n",
            "Epoch 4710: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7900e-05 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4711/5000\n",
            "\n",
            "Epoch 4711: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7805e-05 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.8309 - 3s/epoch - 96ms/step\n",
            "Epoch 4712/5000\n",
            "\n",
            "Epoch 4712: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.9200e-05 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8345 - 4s/epoch - 105ms/step\n",
            "Epoch 4713/5000\n",
            "\n",
            "Epoch 4713: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7591e-05 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4714/5000\n",
            "\n",
            "Epoch 4714: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9065e-05 - accuracy: 1.0000 - val_loss: 0.7202 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4715/5000\n",
            "\n",
            "Epoch 4715: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.6346e-05 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.8237 - 4s/epoch - 110ms/step\n",
            "Epoch 4716/5000\n",
            "\n",
            "Epoch 4716: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8365e-05 - accuracy: 1.0000 - val_loss: 0.7218 - val_accuracy: 0.8237 - 3s/epoch - 93ms/step\n",
            "Epoch 4717/5000\n",
            "\n",
            "Epoch 4717: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.0622e-05 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4718/5000\n",
            "\n",
            "Epoch 4718: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8812e-05 - accuracy: 1.0000 - val_loss: 0.7316 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4719/5000\n",
            "\n",
            "Epoch 4719: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.8893e-05 - accuracy: 1.0000 - val_loss: 0.7323 - val_accuracy: 0.8165 - 4s/epoch - 116ms/step\n",
            "Epoch 4720/5000\n",
            "\n",
            "Epoch 4720: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.6436e-05 - accuracy: 1.0000 - val_loss: 0.7304 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4721/5000\n",
            "\n",
            "Epoch 4721: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9103e-05 - accuracy: 1.0000 - val_loss: 0.7259 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4722/5000\n",
            "\n",
            "Epoch 4722: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8253e-05 - accuracy: 1.0000 - val_loss: 0.7364 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4723/5000\n",
            "\n",
            "Epoch 4723: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.5052e-05 - accuracy: 1.0000 - val_loss: 0.7298 - val_accuracy: 0.8165 - 4s/epoch - 116ms/step\n",
            "Epoch 4724/5000\n",
            "\n",
            "Epoch 4724: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7012e-05 - accuracy: 1.0000 - val_loss: 0.7234 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4725/5000\n",
            "\n",
            "Epoch 4725: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9990e-05 - accuracy: 1.0000 - val_loss: 0.7410 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4726/5000\n",
            "\n",
            "Epoch 4726: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7934e-05 - accuracy: 1.0000 - val_loss: 0.7380 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4727/5000\n",
            "\n",
            "Epoch 4727: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.9748e-05 - accuracy: 1.0000 - val_loss: 0.7305 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 4728/5000\n",
            "\n",
            "Epoch 4728: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8244e-05 - accuracy: 1.0000 - val_loss: 0.7225 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4729/5000\n",
            "\n",
            "Epoch 4729: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9935e-05 - accuracy: 1.0000 - val_loss: 0.7329 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4730/5000\n",
            "\n",
            "Epoch 4730: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8478e-05 - accuracy: 1.0000 - val_loss: 0.7316 - val_accuracy: 0.8273 - 3s/epoch - 97ms/step\n",
            "Epoch 4731/5000\n",
            "\n",
            "Epoch 4731: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.8050e-05 - accuracy: 1.0000 - val_loss: 0.7421 - val_accuracy: 0.8201 - 4s/epoch - 104ms/step\n",
            "Epoch 4732/5000\n",
            "\n",
            "Epoch 4732: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7434e-05 - accuracy: 1.0000 - val_loss: 0.7304 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4733/5000\n",
            "\n",
            "Epoch 4733: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7203e-05 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4734/5000\n",
            "\n",
            "Epoch 4734: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.5891e-05 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.8237 - 4s/epoch - 109ms/step\n",
            "Epoch 4735/5000\n",
            "\n",
            "Epoch 4735: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.6899e-05 - accuracy: 1.0000 - val_loss: 0.7264 - val_accuracy: 0.8237 - 3s/epoch - 91ms/step\n",
            "Epoch 4736/5000\n",
            "\n",
            "Epoch 4736: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5307e-05 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4737/5000\n",
            "\n",
            "Epoch 4737: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7019e-05 - accuracy: 1.0000 - val_loss: 0.7283 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4738/5000\n",
            "\n",
            "Epoch 4738: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.5290e-05 - accuracy: 1.0000 - val_loss: 0.7243 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4739/5000\n",
            "\n",
            "Epoch 4739: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9166e-05 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4740/5000\n",
            "\n",
            "Epoch 4740: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5590e-05 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4741/5000\n",
            "\n",
            "Epoch 4741: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4186e-05 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4742/5000\n",
            "\n",
            "Epoch 4742: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.5906e-05 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.8201 - 4s/epoch - 118ms/step\n",
            "Epoch 4743/5000\n",
            "\n",
            "Epoch 4743: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4717e-05 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4744/5000\n",
            "\n",
            "Epoch 4744: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.9522e-04 - accuracy: 1.0000 - val_loss: 0.7387 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4745/5000\n",
            "\n",
            "Epoch 4745: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.1117e-04 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 4746/5000\n",
            "\n",
            "Epoch 4746: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.5864e-05 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.8345 - 4s/epoch - 117ms/step\n",
            "Epoch 4747/5000\n",
            "\n",
            "Epoch 4747: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.2148e-05 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4748/5000\n",
            "\n",
            "Epoch 4748: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.4113e-05 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4749/5000\n",
            "\n",
            "Epoch 4749: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.1826e-05 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.8273 - 3s/epoch - 94ms/step\n",
            "Epoch 4750/5000\n",
            "\n",
            "Epoch 4750: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.0609e-05 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8273 - 4s/epoch - 107ms/step\n",
            "Epoch 4751/5000\n",
            "\n",
            "Epoch 4751: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9832e-05 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4752/5000\n",
            "\n",
            "Epoch 4752: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.1323e-05 - accuracy: 1.0000 - val_loss: 0.7264 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4753/5000\n",
            "\n",
            "Epoch 4753: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.7648e-05 - accuracy: 1.0000 - val_loss: 0.7269 - val_accuracy: 0.8309 - 4s/epoch - 108ms/step\n",
            "Epoch 4754/5000\n",
            "\n",
            "Epoch 4754: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8850e-05 - accuracy: 1.0000 - val_loss: 0.7203 - val_accuracy: 0.8273 - 3s/epoch - 94ms/step\n",
            "Epoch 4755/5000\n",
            "\n",
            "Epoch 4755: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.1008e-05 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4756/5000\n",
            "\n",
            "Epoch 4756: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8174e-05 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.8201 - 3s/epoch - 87ms/step\n",
            "Epoch 4757/5000\n",
            "\n",
            "Epoch 4757: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.9072e-05 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4758/5000\n",
            "\n",
            "Epoch 4758: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.2155e-05 - accuracy: 1.0000 - val_loss: 0.7421 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4759/5000\n",
            "\n",
            "Epoch 4759: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8562e-05 - accuracy: 1.0000 - val_loss: 0.7308 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4760/5000\n",
            "\n",
            "Epoch 4760: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8805e-05 - accuracy: 1.0000 - val_loss: 0.7298 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4761/5000\n",
            "\n",
            "Epoch 4761: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.8003e-05 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4762/5000\n",
            "\n",
            "Epoch 4762: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9090e-05 - accuracy: 1.0000 - val_loss: 0.7397 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4763/5000\n",
            "\n",
            "Epoch 4763: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7515e-05 - accuracy: 1.0000 - val_loss: 0.7378 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4764/5000\n",
            "\n",
            "Epoch 4764: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7716e-05 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4765/5000\n",
            "\n",
            "Epoch 4765: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.6233e-05 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4766/5000\n",
            "\n",
            "Epoch 4766: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5990e-05 - accuracy: 1.0000 - val_loss: 0.7242 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4767/5000\n",
            "\n",
            "Epoch 4767: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5594e-05 - accuracy: 1.0000 - val_loss: 0.7226 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4768/5000\n",
            "\n",
            "Epoch 4768: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.6270e-05 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.8201 - 3s/epoch - 92ms/step\n",
            "Epoch 4769/5000\n",
            "\n",
            "Epoch 4769: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.9640e-05 - accuracy: 1.0000 - val_loss: 0.7288 - val_accuracy: 0.8129 - 4s/epoch - 109ms/step\n",
            "Epoch 4770/5000\n",
            "\n",
            "Epoch 4770: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.6140e-05 - accuracy: 1.0000 - val_loss: 0.7266 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4771/5000\n",
            "\n",
            "Epoch 4771: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8162e-05 - accuracy: 1.0000 - val_loss: 0.7226 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4772/5000\n",
            "\n",
            "Epoch 4772: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.6610e-05 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.8237 - 4s/epoch - 104ms/step\n",
            "Epoch 4773/5000\n",
            "\n",
            "Epoch 4773: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5734e-05 - accuracy: 1.0000 - val_loss: 0.7269 - val_accuracy: 0.8201 - 3s/epoch - 98ms/step\n",
            "Epoch 4774/5000\n",
            "\n",
            "Epoch 4774: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.6178e-05 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4775/5000\n",
            "\n",
            "Epoch 4775: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.6101e-05 - accuracy: 1.0000 - val_loss: 0.7290 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4776/5000\n",
            "\n",
            "Epoch 4776: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.9373e-05 - accuracy: 1.0000 - val_loss: 0.7302 - val_accuracy: 0.8165 - 4s/epoch - 115ms/step\n",
            "Epoch 4777/5000\n",
            "\n",
            "Epoch 4777: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5970e-05 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4778/5000\n",
            "\n",
            "Epoch 4778: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8747e-05 - accuracy: 1.0000 - val_loss: 0.7235 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4779/5000\n",
            "\n",
            "Epoch 4779: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5602e-05 - accuracy: 1.0000 - val_loss: 0.7241 - val_accuracy: 0.8165 - 3s/epoch - 87ms/step\n",
            "Epoch 4780/5000\n",
            "\n",
            "Epoch 4780: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.6414e-05 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.8309 - 4s/epoch - 117ms/step\n",
            "Epoch 4781/5000\n",
            "\n",
            "Epoch 4781: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.6457e-05 - accuracy: 1.0000 - val_loss: 0.7243 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4782/5000\n",
            "\n",
            "Epoch 4782: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5963e-05 - accuracy: 1.0000 - val_loss: 0.7271 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4783/5000\n",
            "\n",
            "Epoch 4783: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4501e-05 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4784/5000\n",
            "\n",
            "Epoch 4784: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.7746e-05 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4785/5000\n",
            "\n",
            "Epoch 4785: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.6164e-05 - accuracy: 1.0000 - val_loss: 0.7303 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4786/5000\n",
            "\n",
            "Epoch 4786: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 1.0742e-04 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4787/5000\n",
            "\n",
            "Epoch 4787: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.1724e-05 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.8273 - 3s/epoch - 88ms/step\n",
            "Epoch 4788/5000\n",
            "\n",
            "Epoch 4788: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.8883e-05 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8273 - 4s/epoch - 115ms/step\n",
            "Epoch 4789/5000\n",
            "\n",
            "Epoch 4789: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9403e-05 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4790/5000\n",
            "\n",
            "Epoch 4790: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7158e-05 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4791/5000\n",
            "\n",
            "Epoch 4791: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5686e-05 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.8273 - 3s/epoch - 98ms/step\n",
            "Epoch 4792/5000\n",
            "\n",
            "Epoch 4792: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.5180e-05 - accuracy: 1.0000 - val_loss: 0.7056 - val_accuracy: 0.8237 - 4s/epoch - 102ms/step\n",
            "Epoch 4793/5000\n",
            "\n",
            "Epoch 4793: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5604e-05 - accuracy: 1.0000 - val_loss: 0.7065 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4794/5000\n",
            "\n",
            "Epoch 4794: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5167e-05 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4795/5000\n",
            "\n",
            "Epoch 4795: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.7278e-05 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.8201 - 4s/epoch - 109ms/step\n",
            "Epoch 4796/5000\n",
            "\n",
            "Epoch 4796: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7285e-05 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.8201 - 3s/epoch - 91ms/step\n",
            "Epoch 4797/5000\n",
            "\n",
            "Epoch 4797: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5550e-05 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4798/5000\n",
            "\n",
            "Epoch 4798: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3694e-05 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4799/5000\n",
            "\n",
            "Epoch 4799: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.5048e-05 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4800/5000\n",
            "\n",
            "Epoch 4800: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4038e-05 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4801/5000\n",
            "\n",
            "Epoch 4801: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3868e-05 - accuracy: 1.0000 - val_loss: 0.7086 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4802/5000\n",
            "\n",
            "Epoch 4802: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7263e-05 - accuracy: 1.0000 - val_loss: 0.7204 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4803/5000\n",
            "\n",
            "Epoch 4803: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.5203e-05 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 4804/5000\n",
            "\n",
            "Epoch 4804: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4665e-05 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4805/5000\n",
            "\n",
            "Epoch 4805: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7600e-05 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4806/5000\n",
            "\n",
            "Epoch 4806: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5315e-05 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4807/5000\n",
            "\n",
            "Epoch 4807: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.5579e-05 - accuracy: 1.0000 - val_loss: 0.7152 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4808/5000\n",
            "\n",
            "Epoch 4808: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.6029e-05 - accuracy: 1.0000 - val_loss: 0.7202 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4809/5000\n",
            "\n",
            "Epoch 4809: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4018e-05 - accuracy: 1.0000 - val_loss: 0.7199 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4810/5000\n",
            "\n",
            "Epoch 4810: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4643e-05 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.8237 - 3s/epoch - 92ms/step\n",
            "Epoch 4811/5000\n",
            "\n",
            "Epoch 4811: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.2655e-05 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.8237 - 4s/epoch - 109ms/step\n",
            "Epoch 4812/5000\n",
            "\n",
            "Epoch 4812: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4889e-05 - accuracy: 1.0000 - val_loss: 0.7135 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4813/5000\n",
            "\n",
            "Epoch 4813: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5159e-05 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4814/5000\n",
            "\n",
            "Epoch 4814: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.6601e-05 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.8237 - 4s/epoch - 106ms/step\n",
            "Epoch 4815/5000\n",
            "\n",
            "Epoch 4815: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7742e-05 - accuracy: 1.0000 - val_loss: 0.7358 - val_accuracy: 0.8201 - 3s/epoch - 95ms/step\n",
            "Epoch 4816/5000\n",
            "\n",
            "Epoch 4816: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7412e-05 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4817/5000\n",
            "\n",
            "Epoch 4817: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5399e-05 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4818/5000\n",
            "\n",
            "Epoch 4818: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.3139e-05 - accuracy: 1.0000 - val_loss: 0.7204 - val_accuracy: 0.8309 - 4s/epoch - 117ms/step\n",
            "Epoch 4819/5000\n",
            "\n",
            "Epoch 4819: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7291e-05 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4820/5000\n",
            "\n",
            "Epoch 4820: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7143e-05 - accuracy: 1.0000 - val_loss: 0.7191 - val_accuracy: 0.8309 - 3s/epoch - 87ms/step\n",
            "Epoch 4821/5000\n",
            "\n",
            "Epoch 4821: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4268e-05 - accuracy: 1.0000 - val_loss: 0.7217 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4822/5000\n",
            "\n",
            "Epoch 4822: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.4279e-05 - accuracy: 1.0000 - val_loss: 0.7201 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4823/5000\n",
            "\n",
            "Epoch 4823: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4172e-05 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4824/5000\n",
            "\n",
            "Epoch 4824: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4163e-05 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4825/5000\n",
            "\n",
            "Epoch 4825: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3747e-05 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4826/5000\n",
            "\n",
            "Epoch 4826: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.3970e-05 - accuracy: 1.0000 - val_loss: 0.7221 - val_accuracy: 0.8237 - 4s/epoch - 118ms/step\n",
            "Epoch 4827/5000\n",
            "\n",
            "Epoch 4827: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5267e-05 - accuracy: 1.0000 - val_loss: 0.7212 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4828/5000\n",
            "\n",
            "Epoch 4828: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2821e-05 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4829/5000\n",
            "\n",
            "Epoch 4829: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3040e-05 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.8237 - 3s/epoch - 92ms/step\n",
            "Epoch 4830/5000\n",
            "\n",
            "Epoch 4830: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.2746e-05 - accuracy: 1.0000 - val_loss: 0.7169 - val_accuracy: 0.8237 - 4s/epoch - 108ms/step\n",
            "Epoch 4831/5000\n",
            "\n",
            "Epoch 4831: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.6040e-05 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4832/5000\n",
            "\n",
            "Epoch 4832: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5865e-05 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4833/5000\n",
            "\n",
            "Epoch 4833: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.5944e-05 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.8237 - 4s/epoch - 107ms/step\n",
            "Epoch 4834/5000\n",
            "\n",
            "Epoch 4834: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4551e-05 - accuracy: 1.0000 - val_loss: 0.7225 - val_accuracy: 0.8237 - 3s/epoch - 94ms/step\n",
            "Epoch 4835/5000\n",
            "\n",
            "Epoch 4835: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3100e-05 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.8237 - 3s/epoch - 87ms/step\n",
            "Epoch 4836/5000\n",
            "\n",
            "Epoch 4836: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.0319e-05 - accuracy: 1.0000 - val_loss: 0.7293 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4837/5000\n",
            "\n",
            "Epoch 4837: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.7056e-05 - accuracy: 1.0000 - val_loss: 0.7327 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 4838/5000\n",
            "\n",
            "Epoch 4838: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3390e-05 - accuracy: 1.0000 - val_loss: 0.7326 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4839/5000\n",
            "\n",
            "Epoch 4839: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4905e-05 - accuracy: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4840/5000\n",
            "\n",
            "Epoch 4840: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2864e-05 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4841/5000\n",
            "\n",
            "Epoch 4841: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.5754e-05 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.8237 - 4s/epoch - 119ms/step\n",
            "Epoch 4842/5000\n",
            "\n",
            "Epoch 4842: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3094e-05 - accuracy: 1.0000 - val_loss: 0.7113 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4843/5000\n",
            "\n",
            "Epoch 4843: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3588e-05 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4844/5000\n",
            "\n",
            "Epoch 4844: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3405e-05 - accuracy: 1.0000 - val_loss: 0.7056 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4845/5000\n",
            "\n",
            "Epoch 4845: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.4872e-05 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4846/5000\n",
            "\n",
            "Epoch 4846: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4494e-05 - accuracy: 1.0000 - val_loss: 0.7212 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4847/5000\n",
            "\n",
            "Epoch 4847: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4164e-05 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4848/5000\n",
            "\n",
            "Epoch 4848: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3072e-05 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8309 - 3s/epoch - 94ms/step\n",
            "Epoch 4849/5000\n",
            "\n",
            "Epoch 4849: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.5886e-05 - accuracy: 1.0000 - val_loss: 0.7367 - val_accuracy: 0.8165 - 4s/epoch - 107ms/step\n",
            "Epoch 4850/5000\n",
            "\n",
            "Epoch 4850: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4447e-05 - accuracy: 1.0000 - val_loss: 0.7392 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4851/5000\n",
            "\n",
            "Epoch 4851: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2947e-05 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4852/5000\n",
            "\n",
            "Epoch 4852: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.3214e-05 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.8201 - 4s/epoch - 107ms/step\n",
            "Epoch 4853/5000\n",
            "\n",
            "Epoch 4853: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4069e-05 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.8201 - 3s/epoch - 95ms/step\n",
            "Epoch 4854/5000\n",
            "\n",
            "Epoch 4854: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3331e-05 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.8129 - 3s/epoch - 87ms/step\n",
            "Epoch 4855/5000\n",
            "\n",
            "Epoch 4855: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3345e-05 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4856/5000\n",
            "\n",
            "Epoch 4856: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.4314e-05 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8237 - 4s/epoch - 118ms/step\n",
            "Epoch 4857/5000\n",
            "\n",
            "Epoch 4857: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.1660e-05 - accuracy: 1.0000 - val_loss: 0.7179 - val_accuracy: 0.8201 - 3s/epoch - 87ms/step\n",
            "Epoch 4858/5000\n",
            "\n",
            "Epoch 4858: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4312e-05 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4859/5000\n",
            "\n",
            "Epoch 4859: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3066e-05 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4860/5000\n",
            "\n",
            "Epoch 4860: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.2288e-05 - accuracy: 1.0000 - val_loss: 0.7113 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4861/5000\n",
            "\n",
            "Epoch 4861: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2472e-05 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4862/5000\n",
            "\n",
            "Epoch 4862: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4211e-05 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4863/5000\n",
            "\n",
            "Epoch 4863: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 9.2200e-05 - accuracy: 1.0000 - val_loss: 0.7264 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4864/5000\n",
            "\n",
            "Epoch 4864: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.6887e-05 - accuracy: 1.0000 - val_loss: 0.7317 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4865/5000\n",
            "\n",
            "Epoch 4865: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4828e-05 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4866/5000\n",
            "\n",
            "Epoch 4866: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4431e-05 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4867/5000\n",
            "\n",
            "Epoch 4867: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.1659e-05 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.8201 - 3s/epoch - 95ms/step\n",
            "Epoch 4868/5000\n",
            "\n",
            "Epoch 4868: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.5728e-05 - accuracy: 1.0000 - val_loss: 0.7305 - val_accuracy: 0.8201 - 4s/epoch - 107ms/step\n",
            "Epoch 4869/5000\n",
            "\n",
            "Epoch 4869: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2866e-05 - accuracy: 1.0000 - val_loss: 0.7291 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4870/5000\n",
            "\n",
            "Epoch 4870: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2767e-05 - accuracy: 1.0000 - val_loss: 0.7212 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4871/5000\n",
            "\n",
            "Epoch 4871: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.4279e-05 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.8237 - 4s/epoch - 107ms/step\n",
            "Epoch 4872/5000\n",
            "\n",
            "Epoch 4872: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.8358e-05 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.8201 - 3s/epoch - 95ms/step\n",
            "Epoch 4873/5000\n",
            "\n",
            "Epoch 4873: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2779e-05 - accuracy: 1.0000 - val_loss: 0.7101 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4874/5000\n",
            "\n",
            "Epoch 4874: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3494e-05 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4875/5000\n",
            "\n",
            "Epoch 4875: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.3912e-05 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.8165 - 4s/epoch - 116ms/step\n",
            "Epoch 4876/5000\n",
            "\n",
            "Epoch 4876: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2754e-05 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4877/5000\n",
            "\n",
            "Epoch 4877: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.0124e-05 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4878/5000\n",
            "\n",
            "Epoch 4878: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2678e-05 - accuracy: 1.0000 - val_loss: 0.7169 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4879/5000\n",
            "\n",
            "Epoch 4879: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.3983e-05 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.8201 - 4s/epoch - 116ms/step\n",
            "Epoch 4880/5000\n",
            "\n",
            "Epoch 4880: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3465e-05 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4881/5000\n",
            "\n",
            "Epoch 4881: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.1957e-05 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4882/5000\n",
            "\n",
            "Epoch 4882: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.9167e-05 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4883/5000\n",
            "\n",
            "Epoch 4883: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.1322e-05 - accuracy: 1.0000 - val_loss: 0.7113 - val_accuracy: 0.8237 - 4s/epoch - 117ms/step\n",
            "Epoch 4884/5000\n",
            "\n",
            "Epoch 4884: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.5307e-05 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4885/5000\n",
            "\n",
            "Epoch 4885: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.1748e-05 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4886/5000\n",
            "\n",
            "Epoch 4886: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2756e-05 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.8237 - 3s/epoch - 90ms/step\n",
            "Epoch 4887/5000\n",
            "\n",
            "Epoch 4887: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.9348e-05 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8201 - 4s/epoch - 111ms/step\n",
            "Epoch 4888/5000\n",
            "\n",
            "Epoch 4888: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2543e-05 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8129 - 3s/epoch - 85ms/step\n",
            "Epoch 4889/5000\n",
            "\n",
            "Epoch 4889: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3000e-05 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4890/5000\n",
            "\n",
            "Epoch 4890: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.1808e-05 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.8165 - 4s/epoch - 105ms/step\n",
            "Epoch 4891/5000\n",
            "\n",
            "Epoch 4891: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2128e-05 - accuracy: 1.0000 - val_loss: 0.7230 - val_accuracy: 0.8165 - 3s/epoch - 98ms/step\n",
            "Epoch 4892/5000\n",
            "\n",
            "Epoch 4892: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.0729e-05 - accuracy: 1.0000 - val_loss: 0.7171 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4893/5000\n",
            "\n",
            "Epoch 4893: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.0667e-05 - accuracy: 1.0000 - val_loss: 0.7212 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4894/5000\n",
            "\n",
            "Epoch 4894: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 9.2111e-05 - accuracy: 1.0000 - val_loss: 0.7372 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4895/5000\n",
            "\n",
            "Epoch 4895: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4650e-05 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4896/5000\n",
            "\n",
            "Epoch 4896: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2450e-05 - accuracy: 1.0000 - val_loss: 0.7226 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4897/5000\n",
            "\n",
            "Epoch 4897: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.1462e-05 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4898/5000\n",
            "\n",
            "Epoch 4898: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.0942e-05 - accuracy: 1.0000 - val_loss: 0.7235 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4899/5000\n",
            "\n",
            "Epoch 4899: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3172e-05 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4900/5000\n",
            "\n",
            "Epoch 4900: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2764e-05 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4901/5000\n",
            "\n",
            "Epoch 4901: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3273e-05 - accuracy: 1.0000 - val_loss: 0.7326 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4902/5000\n",
            "\n",
            "Epoch 4902: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.2289e-05 - accuracy: 1.0000 - val_loss: 0.7326 - val_accuracy: 0.8237 - 4s/epoch - 116ms/step\n",
            "Epoch 4903/5000\n",
            "\n",
            "Epoch 4903: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2208e-05 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4904/5000\n",
            "\n",
            "Epoch 4904: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.1607e-05 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4905/5000\n",
            "\n",
            "Epoch 4905: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2038e-05 - accuracy: 1.0000 - val_loss: 0.7289 - val_accuracy: 0.8165 - 3s/epoch - 90ms/step\n",
            "Epoch 4906/5000\n",
            "\n",
            "Epoch 4906: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.0308e-05 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.8165 - 4s/epoch - 112ms/step\n",
            "Epoch 4907/5000\n",
            "\n",
            "Epoch 4907: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9597e-05 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4908/5000\n",
            "\n",
            "Epoch 4908: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9693e-05 - accuracy: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4909/5000\n",
            "\n",
            "Epoch 4909: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.9412e-05 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.8129 - 4s/epoch - 107ms/step\n",
            "Epoch 4910/5000\n",
            "\n",
            "Epoch 4910: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.0452e-05 - accuracy: 1.0000 - val_loss: 0.7263 - val_accuracy: 0.8129 - 3s/epoch - 95ms/step\n",
            "Epoch 4911/5000\n",
            "\n",
            "Epoch 4911: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.1349e-05 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4912/5000\n",
            "\n",
            "Epoch 4912: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2255e-05 - accuracy: 1.0000 - val_loss: 0.7230 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4913/5000\n",
            "\n",
            "Epoch 4913: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.1606e-05 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.8165 - 4s/epoch - 117ms/step\n",
            "Epoch 4914/5000\n",
            "\n",
            "Epoch 4914: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.0851e-05 - accuracy: 1.0000 - val_loss: 0.7290 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4915/5000\n",
            "\n",
            "Epoch 4915: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9104e-05 - accuracy: 1.0000 - val_loss: 0.7275 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4916/5000\n",
            "\n",
            "Epoch 4916: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.8916e-05 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4917/5000\n",
            "\n",
            "Epoch 4917: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.8241e-05 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.8201 - 4s/epoch - 116ms/step\n",
            "Epoch 4918/5000\n",
            "\n",
            "Epoch 4918: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.1600e-05 - accuracy: 1.0000 - val_loss: 0.7299 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4919/5000\n",
            "\n",
            "Epoch 4919: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.4833e-05 - accuracy: 1.0000 - val_loss: 0.7314 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4920/5000\n",
            "\n",
            "Epoch 4920: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.7872e-05 - accuracy: 1.0000 - val_loss: 0.7354 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4921/5000\n",
            "\n",
            "Epoch 4921: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.2853e-05 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4922/5000\n",
            "\n",
            "Epoch 4922: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.3842e-05 - accuracy: 1.0000 - val_loss: 0.7274 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4923/5000\n",
            "\n",
            "Epoch 4923: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2148e-05 - accuracy: 1.0000 - val_loss: 0.7332 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4924/5000\n",
            "\n",
            "Epoch 4924: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2596e-05 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.8237 - 3s/epoch - 89ms/step\n",
            "Epoch 4925/5000\n",
            "\n",
            "Epoch 4925: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.1010e-05 - accuracy: 1.0000 - val_loss: 0.7334 - val_accuracy: 0.8237 - 4s/epoch - 113ms/step\n",
            "Epoch 4926/5000\n",
            "\n",
            "Epoch 4926: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.1907e-05 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4927/5000\n",
            "\n",
            "Epoch 4927: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9788e-05 - accuracy: 1.0000 - val_loss: 0.7338 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4928/5000\n",
            "\n",
            "Epoch 4928: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.0494e-05 - accuracy: 1.0000 - val_loss: 0.7340 - val_accuracy: 0.8237 - 3s/epoch - 100ms/step\n",
            "Epoch 4929/5000\n",
            "\n",
            "Epoch 4929: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.2058e-05 - accuracy: 1.0000 - val_loss: 0.7262 - val_accuracy: 0.8237 - 4s/epoch - 102ms/step\n",
            "Epoch 4930/5000\n",
            "\n",
            "Epoch 4930: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9568e-05 - accuracy: 1.0000 - val_loss: 0.7257 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4931/5000\n",
            "\n",
            "Epoch 4931: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2499e-05 - accuracy: 1.0000 - val_loss: 0.7330 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4932/5000\n",
            "\n",
            "Epoch 4932: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.0533e-05 - accuracy: 1.0000 - val_loss: 0.7307 - val_accuracy: 0.8201 - 4s/epoch - 112ms/step\n",
            "Epoch 4933/5000\n",
            "\n",
            "Epoch 4933: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9701e-05 - accuracy: 1.0000 - val_loss: 0.7284 - val_accuracy: 0.8201 - 3s/epoch - 89ms/step\n",
            "Epoch 4934/5000\n",
            "\n",
            "Epoch 4934: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9945e-05 - accuracy: 1.0000 - val_loss: 0.7335 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4935/5000\n",
            "\n",
            "Epoch 4935: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.0019e-05 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4936/5000\n",
            "\n",
            "Epoch 4936: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.9952e-05 - accuracy: 1.0000 - val_loss: 0.7236 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4937/5000\n",
            "\n",
            "Epoch 4937: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.0543e-05 - accuracy: 1.0000 - val_loss: 0.7316 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4938/5000\n",
            "\n",
            "Epoch 4938: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.8242e-05 - accuracy: 1.0000 - val_loss: 0.7294 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4939/5000\n",
            "\n",
            "Epoch 4939: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.1446e-05 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4940/5000\n",
            "\n",
            "Epoch 4940: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.0228e-05 - accuracy: 1.0000 - val_loss: 0.7221 - val_accuracy: 0.8201 - 4s/epoch - 116ms/step\n",
            "Epoch 4941/5000\n",
            "\n",
            "Epoch 4941: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.8486e-05 - accuracy: 1.0000 - val_loss: 0.7285 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4942/5000\n",
            "\n",
            "Epoch 4942: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9447e-05 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4943/5000\n",
            "\n",
            "Epoch 4943: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2382e-05 - accuracy: 1.0000 - val_loss: 0.7223 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4944/5000\n",
            "\n",
            "Epoch 4944: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.9807e-05 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.8129 - 4s/epoch - 116ms/step\n",
            "Epoch 4945/5000\n",
            "\n",
            "Epoch 4945: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.1966e-05 - accuracy: 1.0000 - val_loss: 0.7303 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4946/5000\n",
            "\n",
            "Epoch 4946: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.0237e-05 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4947/5000\n",
            "\n",
            "Epoch 4947: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.8923e-05 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.8201 - 3s/epoch - 97ms/step\n",
            "Epoch 4948/5000\n",
            "\n",
            "Epoch 4948: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.0131e-05 - accuracy: 1.0000 - val_loss: 0.7362 - val_accuracy: 0.8237 - 4s/epoch - 105ms/step\n",
            "Epoch 4949/5000\n",
            "\n",
            "Epoch 4949: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9589e-05 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4950/5000\n",
            "\n",
            "Epoch 4950: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9775e-05 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4951/5000\n",
            "\n",
            "Epoch 4951: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.6902e-05 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.8129 - 4s/epoch - 113ms/step\n",
            "Epoch 4952/5000\n",
            "\n",
            "Epoch 4952: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2021e-05 - accuracy: 1.0000 - val_loss: 0.7109 - val_accuracy: 0.8201 - 3s/epoch - 90ms/step\n",
            "Epoch 4953/5000\n",
            "\n",
            "Epoch 4953: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9622e-05 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4954/5000\n",
            "\n",
            "Epoch 4954: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9489e-05 - accuracy: 1.0000 - val_loss: 0.7202 - val_accuracy: 0.8309 - 3s/epoch - 87ms/step\n",
            "Epoch 4955/5000\n",
            "\n",
            "Epoch 4955: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.8615e-05 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8309 - 4s/epoch - 117ms/step\n",
            "Epoch 4956/5000\n",
            "\n",
            "Epoch 4956: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.6961e-05 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4957/5000\n",
            "\n",
            "Epoch 4957: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.8492e-05 - accuracy: 1.0000 - val_loss: 0.7038 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4958/5000\n",
            "\n",
            "Epoch 4958: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9821e-05 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4959/5000\n",
            "\n",
            "Epoch 4959: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.8381e-05 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.8201 - 4s/epoch - 116ms/step\n",
            "Epoch 4960/5000\n",
            "\n",
            "Epoch 4960: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.7437e-05 - accuracy: 1.0000 - val_loss: 0.7140 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4961/5000\n",
            "\n",
            "Epoch 4961: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9476e-05 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4962/5000\n",
            "\n",
            "Epoch 4962: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9890e-05 - accuracy: 1.0000 - val_loss: 0.7240 - val_accuracy: 0.8165 - 3s/epoch - 87ms/step\n",
            "Epoch 4963/5000\n",
            "\n",
            "Epoch 4963: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.8432e-05 - accuracy: 1.0000 - val_loss: 0.7113 - val_accuracy: 0.8237 - 4s/epoch - 116ms/step\n",
            "Epoch 4964/5000\n",
            "\n",
            "Epoch 4964: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.0022e-05 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4965/5000\n",
            "\n",
            "Epoch 4965: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.1020e-05 - accuracy: 1.0000 - val_loss: 0.7201 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4966/5000\n",
            "\n",
            "Epoch 4966: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.8828e-05 - accuracy: 1.0000 - val_loss: 0.7170 - val_accuracy: 0.8201 - 4s/epoch - 100ms/step\n",
            "Epoch 4967/5000\n",
            "\n",
            "Epoch 4967: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.8504e-05 - accuracy: 1.0000 - val_loss: 0.7059 - val_accuracy: 0.8273 - 4s/epoch - 101ms/step\n",
            "Epoch 4968/5000\n",
            "\n",
            "Epoch 4968: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.7567e-05 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4969/5000\n",
            "\n",
            "Epoch 4969: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.6137e-05 - accuracy: 1.0000 - val_loss: 0.7093 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4970/5000\n",
            "\n",
            "Epoch 4970: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.6757e-05 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.8201 - 4s/epoch - 113ms/step\n",
            "Epoch 4971/5000\n",
            "\n",
            "Epoch 4971: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.0992e-05 - accuracy: 1.0000 - val_loss: 0.7473 - val_accuracy: 0.8165 - 3s/epoch - 88ms/step\n",
            "Epoch 4972/5000\n",
            "\n",
            "Epoch 4972: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.8915e-05 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4973/5000\n",
            "\n",
            "Epoch 4973: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.0342e-05 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 4974/5000\n",
            "\n",
            "Epoch 4974: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.0817e-05 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4975/5000\n",
            "\n",
            "Epoch 4975: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.8352e-05 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4976/5000\n",
            "\n",
            "Epoch 4976: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.8233e-05 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4977/5000\n",
            "\n",
            "Epoch 4977: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9017e-05 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4978/5000\n",
            "\n",
            "Epoch 4978: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.9682e-05 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.8201 - 4s/epoch - 117ms/step\n",
            "Epoch 4979/5000\n",
            "\n",
            "Epoch 4979: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.7983e-05 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8237 - 3s/epoch - 85ms/step\n",
            "Epoch 4980/5000\n",
            "\n",
            "Epoch 4980: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.7800e-05 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4981/5000\n",
            "\n",
            "Epoch 4981: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 8.2771e-05 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.8058 - 3s/epoch - 86ms/step\n",
            "Epoch 4982/5000\n",
            "\n",
            "Epoch 4982: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.5664e-05 - accuracy: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.8165 - 4s/epoch - 118ms/step\n",
            "Epoch 4983/5000\n",
            "\n",
            "Epoch 4983: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.9797e-05 - accuracy: 1.0000 - val_loss: 0.7238 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 4984/5000\n",
            "\n",
            "Epoch 4984: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.8933e-05 - accuracy: 1.0000 - val_loss: 0.7289 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4985/5000\n",
            "\n",
            "Epoch 4985: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.7649e-05 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8165 - 3s/epoch - 96ms/step\n",
            "Epoch 4986/5000\n",
            "\n",
            "Epoch 4986: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.6056e-05 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8165 - 4s/epoch - 106ms/step\n",
            "Epoch 4987/5000\n",
            "\n",
            "Epoch 4987: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.7934e-05 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.8129 - 3s/epoch - 86ms/step\n",
            "Epoch 4988/5000\n",
            "\n",
            "Epoch 4988: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.7708e-05 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8237 - 3s/epoch - 87ms/step\n",
            "Epoch 4989/5000\n",
            "\n",
            "Epoch 4989: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 8.0021e-05 - accuracy: 1.0000 - val_loss: 0.7171 - val_accuracy: 0.8201 - 4s/epoch - 110ms/step\n",
            "Epoch 4990/5000\n",
            "\n",
            "Epoch 4990: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.6829e-05 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.8237 - 3s/epoch - 92ms/step\n",
            "Epoch 4991/5000\n",
            "\n",
            "Epoch 4991: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.7585e-05 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n",
            "Epoch 4992/5000\n",
            "\n",
            "Epoch 4992: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.6337e-05 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4993/5000\n",
            "\n",
            "Epoch 4993: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.5389e-05 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8273 - 4s/epoch - 117ms/step\n",
            "Epoch 4994/5000\n",
            "\n",
            "Epoch 4994: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.6988e-05 - accuracy: 1.0000 - val_loss: 0.7140 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4995/5000\n",
            "\n",
            "Epoch 4995: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.8895e-05 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4996/5000\n",
            "\n",
            "Epoch 4996: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.6862e-05 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4997/5000\n",
            "\n",
            "Epoch 4997: val_accuracy did not improve from 0.85252\n",
            "35/35 - 4s - loss: 7.5974e-05 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.8273 - 4s/epoch - 116ms/step\n",
            "Epoch 4998/5000\n",
            "\n",
            "Epoch 4998: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.6699e-05 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.8165 - 3s/epoch - 85ms/step\n",
            "Epoch 4999/5000\n",
            "\n",
            "Epoch 4999: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.6165e-05 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.8165 - 3s/epoch - 86ms/step\n",
            "Epoch 5000/5000\n",
            "\n",
            "Epoch 5000: val_accuracy did not improve from 0.85252\n",
            "35/35 - 3s - loss: 7.8059e-05 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8201 - 3s/epoch - 85ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "modelp = keras.models.load_model(\"pccr_xcorr_mi.best.hdf5\")\n",
        "y_pred = modelp.predict(X_test)\n",
        "y_pred=np.argmax(y_pred,axis=1)\n",
        "print(\"Test Accuracy\",accuracy_score(y_test, y_pred)*100,\"%\")\n",
        "\n",
        "scores = modelp.evaluate(X_train, y_train)\n",
        "print(\"Train %s: %.2f%%\" % (modelp.metrics_names[1], scores[1]*100))\n",
        "\n",
        "scores = modelp.evaluate(X_test, y_test)\n",
        "print(\"test %s: %.2f%%\" % (modelp.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpINBLo8b6Li",
        "outputId": "64c94a60-3cf5-4aa0-b746-0c3bba7c6324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 9ms/step\n",
            "Test Accuracy 85.25179856115108 %\n",
            "35/35 [==============================] - 1s 9ms/step - loss: 4.9293e-04 - accuracy: 1.0000\n",
            "Train accuracy: 100.00%\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.6582 - accuracy: 0.8525\n",
            "test accuracy: 85.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "srt=\"pccr_xcorr_mi Model\"\n",
        "plot_accuracy(history5, no_of_epoch,srt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "AjLR_l5hc4KB",
        "outputId": "4494dfe3-9bd2-4e4f-ef71-0f131b893561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history5,no_of_epoch, srt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "l36y241Xc6b0",
        "outputId": "16b92617-1ce3-4fbe-fe00-b90fc7082ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title=\"Confusion Matrix of pccr_xcorr_mi\"\n",
        "cm=confusion(y_pred,y_test)\n",
        "conf_mat2(cm,class_names,title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "buJo46YSc8Sx",
        "outputId": "b8df5d93-02b3-4e5b-a5bf-25e45f4cab0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m26saFEZc-m6",
        "outputId": "c95cf268-b905-4809-d18e-96095139fc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.80      0.80        51\n",
            "           1       0.77      0.81      0.79        37\n",
            "           2       0.96      0.94      0.95        50\n",
            "           3       0.87      0.85      0.86        47\n",
            "           4       0.80      0.72      0.76        46\n",
            "           5       0.90      0.98      0.94        47\n",
            "\n",
            "    accuracy                           0.85       278\n",
            "   macro avg       0.85      0.85      0.85       278\n",
            "weighted avg       0.85      0.85      0.85       278\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelp.save(\"pccr_xcorr_mi.h5\")\n",
        "from google.colab import files\n",
        "files.download(\"pccr_xcorr_mi.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-6IoQBc4dA5R",
        "outputId": "fc3c1dcf-7bae-4748-a726-e4f285becddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_59ebd74f-94a4-4f43-b34d-eacbb40c5ce6\", \"pccr_xcorr_mi.h5\", 3866568)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pccr_xcorr_nmi=[]"
      ],
      "metadata": {
        "id": "3_XxCC9t6cS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### data test construction ############\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i in range(0,fall_number):\n",
        "  temp=[]\n",
        "\n",
        "  temp.append(pearson_corr[i])\n",
        "  temp.append(xcorr[i])\n",
        "  temp.append(partial_mi_score[i])\n",
        "\n",
        "  pccr_xcorr_nmi.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "  #walk_temp=np.stack((xcorr_walk[i],pearson_corr_walk[i],mi_score_walk[i],partial_mi_score_walk[i],mean_f_walk[i]),axis=0)\n",
        "for i in range(0,walk_number):\n",
        "  temp=[]\n",
        "\n",
        "\n",
        "  temp.append(pearson_corr_walk[i])\n",
        "  temp.append(xcorr_walk[i])\n",
        "  temp.append(partial_mi_score_walk[i])\n",
        "\n",
        "  pccr_xcorr_nmi.append(temp)\n",
        "\n",
        "\n",
        "for i in range(0,sit_number):\n",
        "  temp=[]\n",
        "\n",
        "\n",
        "  temp.append(pearson_corr_sit[i])\n",
        "  temp.append(xcorr_sit[i])\n",
        "  temp.append(partial_mi_score_sit[i])\n",
        "\n",
        "  pccr_xcorr_nmi.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,bsc_number):\n",
        "  temp=[]\n",
        "\n",
        "  temp.append(pearson_corr_bsc[i])\n",
        "  temp.append(xcorr_bsc[i])\n",
        "  temp.append(partial_mi_score_bsc[i])\n",
        "\n",
        "  pccr_xcorr_nmi.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,stand_number):\n",
        "  temp=[]\n",
        "\n",
        "  temp.append(pearson_corr_stand[i])\n",
        "  temp.append(xcorr_stand[i])\n",
        "  temp.append(partial_mi_score_stand[i])\n",
        "\n",
        "  pccr_xcorr_nmi.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,laying_number):\n",
        "  temp=[]\n",
        "\n",
        "  temp.append(pearson_corr_laying[i])\n",
        "  temp.append(xcorr_laying[i])\n",
        "  temp.append(partial_mi_score_laying[i])\n",
        "\n",
        "  pccr_xcorr_nmi.append(temp)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wMQDe0jX6KKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pccr_xcorr_nmi=np.array(pccr_xcorr_nmi)\n",
        "print(pccr_xcorr_nmi.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glRAjomn63ho",
        "outputId": "d51cbefb-a90c-4b2e-d856-c1e33d2cc7ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1390, 3, 16, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UnYkkH-67eFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"pccr_xcorr_nmi.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "#es = EarlyStopping(monitor='val_loss', patience=100, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "Y69BNAPi7GAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_data=y_temp\n",
        "yenc = sklearn.preprocessing.LabelEncoder()\n",
        "y_data = yenc.fit_transform(y_data)\n",
        "X_train, X_test, y_train, y_test = train_test_split(pccr_xcorr_nmi, y_data, test_size = 0.20, random_state = 42)\n",
        "\n",
        "#X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.10, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 3,16, 16,1)\n",
        "X_test = X_test.reshape(X_test.shape[0],3, 16,16,1)\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE7cr8bn7PTk",
        "outputId": "e02f7d52-d1f4-462b-bb2d-39f62e6785df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1112, 3, 16, 16, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6=get_3d_2()\n",
        "model6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsSnteoC7QD6",
        "outputId": "0f178ab0-359c-45f2-95d1-27587cb16cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 2, 10, 10, 16)     1584      \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 2, 4, 4, 128)      100480    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2, 4, 4, 128)      0         \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 2, 2, 2, 128)      147584    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2, 2, 2, 128)      0         \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 2, 1, 1, 128)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 2, 1, 1, 128)     512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 317,494\n",
            "Trainable params: 317,238\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.compile(optimizer=Adam(learning_rate = 0.00001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "history6 = model6.fit(X_train, y_train,batch_size = 32, epochs = no_of_epoch, validation_data= (X_test, y_test),callbacks=callbacks_list,verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBoDEMFJ7fpU",
        "outputId": "be8ac1d7-7095-43cb-a692-36acf79a101c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3749/5000\n",
            "\n",
            "Epoch 3749: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.1067e-04 - accuracy: 1.0000 - val_loss: 0.7535 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3750/5000\n",
            "\n",
            "Epoch 3750: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0892e-04 - accuracy: 1.0000 - val_loss: 0.7546 - val_accuracy: 0.8417 - 3s/epoch - 73ms/step\n",
            "Epoch 3751/5000\n",
            "\n",
            "Epoch 3751: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.1426e-04 - accuracy: 1.0000 - val_loss: 0.7462 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 3752/5000\n",
            "\n",
            "Epoch 3752: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 2.1147e-04 - accuracy: 1.0000 - val_loss: 0.7526 - val_accuracy: 0.8381 - 4s/epoch - 120ms/step\n",
            "Epoch 3753/5000\n",
            "\n",
            "Epoch 3753: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0582e-04 - accuracy: 1.0000 - val_loss: 0.7501 - val_accuracy: 0.8417 - 3s/epoch - 77ms/step\n",
            "Epoch 3754/5000\n",
            "\n",
            "Epoch 3754: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0337e-04 - accuracy: 1.0000 - val_loss: 0.7430 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3755/5000\n",
            "\n",
            "Epoch 3755: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0516e-04 - accuracy: 1.0000 - val_loss: 0.7573 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 3756/5000\n",
            "\n",
            "Epoch 3756: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.1272e-04 - accuracy: 1.0000 - val_loss: 0.7441 - val_accuracy: 0.8381 - 3s/epoch - 79ms/step\n",
            "Epoch 3757/5000\n",
            "\n",
            "Epoch 3757: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 2.0435e-04 - accuracy: 1.0000 - val_loss: 0.7348 - val_accuracy: 0.8453 - 4s/epoch - 110ms/step\n",
            "Epoch 3758/5000\n",
            "\n",
            "Epoch 3758: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0682e-04 - accuracy: 1.0000 - val_loss: 0.7487 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 3759/5000\n",
            "\n",
            "Epoch 3759: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.1855e-04 - accuracy: 1.0000 - val_loss: 0.7419 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3760/5000\n",
            "\n",
            "Epoch 3760: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0395e-04 - accuracy: 1.0000 - val_loss: 0.7458 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3761/5000\n",
            "\n",
            "Epoch 3761: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.1289e-04 - accuracy: 1.0000 - val_loss: 0.7453 - val_accuracy: 0.8345 - 3s/epoch - 89ms/step\n",
            "Epoch 3762/5000\n",
            "\n",
            "Epoch 3762: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 2.0603e-04 - accuracy: 1.0000 - val_loss: 0.7533 - val_accuracy: 0.8453 - 4s/epoch - 100ms/step\n",
            "Epoch 3763/5000\n",
            "\n",
            "Epoch 3763: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0781e-04 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3764/5000\n",
            "\n",
            "Epoch 3764: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0923e-04 - accuracy: 1.0000 - val_loss: 0.7615 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3765/5000\n",
            "\n",
            "Epoch 3765: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0617e-04 - accuracy: 1.0000 - val_loss: 0.7576 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3766/5000\n",
            "\n",
            "Epoch 3766: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 2.0941e-04 - accuracy: 1.0000 - val_loss: 0.7416 - val_accuracy: 0.8453 - 4s/epoch - 101ms/step\n",
            "Epoch 3767/5000\n",
            "\n",
            "Epoch 3767: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0532e-04 - accuracy: 1.0000 - val_loss: 0.7481 - val_accuracy: 0.8417 - 3s/epoch - 90ms/step\n",
            "Epoch 3768/5000\n",
            "\n",
            "Epoch 3768: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0058e-04 - accuracy: 1.0000 - val_loss: 0.7490 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3769/5000\n",
            "\n",
            "Epoch 3769: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0404e-04 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3770/5000\n",
            "\n",
            "Epoch 3770: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0714e-04 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 3771/5000\n",
            "\n",
            "Epoch 3771: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 2.0504e-04 - accuracy: 1.0000 - val_loss: 0.7481 - val_accuracy: 0.8453 - 4s/epoch - 109ms/step\n",
            "Epoch 3772/5000\n",
            "\n",
            "Epoch 3772: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0120e-04 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.8417 - 3s/epoch - 81ms/step\n",
            "Epoch 3773/5000\n",
            "\n",
            "Epoch 3773: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.1549e-04 - accuracy: 1.0000 - val_loss: 0.7982 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3774/5000\n",
            "\n",
            "Epoch 3774: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.2357e-04 - accuracy: 1.0000 - val_loss: 0.7574 - val_accuracy: 0.8309 - 2s/epoch - 71ms/step\n",
            "Epoch 3775/5000\n",
            "\n",
            "Epoch 3775: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.1741e-04 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.8345 - 3s/epoch - 72ms/step\n",
            "Epoch 3776/5000\n",
            "\n",
            "Epoch 3776: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 2.1823e-04 - accuracy: 1.0000 - val_loss: 0.7291 - val_accuracy: 0.8453 - 4s/epoch - 119ms/step\n",
            "Epoch 3777/5000\n",
            "\n",
            "Epoch 3777: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0657e-04 - accuracy: 1.0000 - val_loss: 0.7413 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 3778/5000\n",
            "\n",
            "Epoch 3778: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.1266e-04 - accuracy: 1.0000 - val_loss: 0.7414 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 3779/5000\n",
            "\n",
            "Epoch 3779: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0245e-04 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3780/5000\n",
            "\n",
            "Epoch 3780: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0555e-04 - accuracy: 1.0000 - val_loss: 0.7580 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 3781/5000\n",
            "\n",
            "Epoch 3781: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 2.0946e-04 - accuracy: 1.0000 - val_loss: 0.7581 - val_accuracy: 0.8417 - 4s/epoch - 120ms/step\n",
            "Epoch 3782/5000\n",
            "\n",
            "Epoch 3782: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0804e-04 - accuracy: 1.0000 - val_loss: 0.7716 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 3783/5000\n",
            "\n",
            "Epoch 3783: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0208e-04 - accuracy: 1.0000 - val_loss: 0.7626 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3784/5000\n",
            "\n",
            "Epoch 3784: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0383e-04 - accuracy: 1.0000 - val_loss: 0.7544 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3785/5000\n",
            "\n",
            "Epoch 3785: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0514e-04 - accuracy: 1.0000 - val_loss: 0.7590 - val_accuracy: 0.8417 - 3s/epoch - 80ms/step\n",
            "Epoch 3786/5000\n",
            "\n",
            "Epoch 3786: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 2.0902e-04 - accuracy: 1.0000 - val_loss: 0.7633 - val_accuracy: 0.8381 - 4s/epoch - 110ms/step\n",
            "Epoch 3787/5000\n",
            "\n",
            "Epoch 3787: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0832e-04 - accuracy: 1.0000 - val_loss: 0.7578 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3788/5000\n",
            "\n",
            "Epoch 3788: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9979e-04 - accuracy: 1.0000 - val_loss: 0.7539 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 3789/5000\n",
            "\n",
            "Epoch 3789: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0211e-04 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3790/5000\n",
            "\n",
            "Epoch 3790: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0582e-04 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.8453 - 3s/epoch - 92ms/step\n",
            "Epoch 3791/5000\n",
            "\n",
            "Epoch 3791: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 2.0200e-04 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.8417 - 4s/epoch - 101ms/step\n",
            "Epoch 3792/5000\n",
            "\n",
            "Epoch 3792: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9746e-04 - accuracy: 1.0000 - val_loss: 0.7537 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3793/5000\n",
            "\n",
            "Epoch 3793: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9696e-04 - accuracy: 1.0000 - val_loss: 0.7492 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3794/5000\n",
            "\n",
            "Epoch 3794: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0172e-04 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3795/5000\n",
            "\n",
            "Epoch 3795: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.9267e-04 - accuracy: 1.0000 - val_loss: 0.7508 - val_accuracy: 0.8417 - 4s/epoch - 104ms/step\n",
            "Epoch 3796/5000\n",
            "\n",
            "Epoch 3796: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9566e-04 - accuracy: 1.0000 - val_loss: 0.7520 - val_accuracy: 0.8453 - 3s/epoch - 89ms/step\n",
            "Epoch 3797/5000\n",
            "\n",
            "Epoch 3797: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9861e-04 - accuracy: 1.0000 - val_loss: 0.7489 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 3798/5000\n",
            "\n",
            "Epoch 3798: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0070e-04 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3799/5000\n",
            "\n",
            "Epoch 3799: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9794e-04 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3800/5000\n",
            "\n",
            "Epoch 3800: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.9565e-04 - accuracy: 1.0000 - val_loss: 0.7584 - val_accuracy: 0.8381 - 4s/epoch - 111ms/step\n",
            "Epoch 3801/5000\n",
            "\n",
            "Epoch 3801: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9889e-04 - accuracy: 1.0000 - val_loss: 0.7686 - val_accuracy: 0.8381 - 3s/epoch - 79ms/step\n",
            "Epoch 3802/5000\n",
            "\n",
            "Epoch 3802: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9380e-04 - accuracy: 1.0000 - val_loss: 0.7619 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3803/5000\n",
            "\n",
            "Epoch 3803: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0015e-04 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 3804/5000\n",
            "\n",
            "Epoch 3804: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9563e-04 - accuracy: 1.0000 - val_loss: 0.7532 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3805/5000\n",
            "\n",
            "Epoch 3805: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 2.0172e-04 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.8381 - 4s/epoch - 119ms/step\n",
            "Epoch 3806/5000\n",
            "\n",
            "Epoch 3806: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9173e-04 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.8345 - 3s/epoch - 73ms/step\n",
            "Epoch 3807/5000\n",
            "\n",
            "Epoch 3807: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9384e-04 - accuracy: 1.0000 - val_loss: 0.7379 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 3808/5000\n",
            "\n",
            "Epoch 3808: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9455e-04 - accuracy: 1.0000 - val_loss: 0.7423 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 3809/5000\n",
            "\n",
            "Epoch 3809: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9706e-04 - accuracy: 1.0000 - val_loss: 0.7410 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3810/5000\n",
            "\n",
            "Epoch 3810: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.9869e-04 - accuracy: 1.0000 - val_loss: 0.7406 - val_accuracy: 0.8381 - 4s/epoch - 120ms/step\n",
            "Epoch 3811/5000\n",
            "\n",
            "Epoch 3811: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9351e-04 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3812/5000\n",
            "\n",
            "Epoch 3812: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0660e-04 - accuracy: 1.0000 - val_loss: 0.7572 - val_accuracy: 0.8345 - 3s/epoch - 71ms/step\n",
            "Epoch 3813/5000\n",
            "\n",
            "Epoch 3813: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0100e-04 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3814/5000\n",
            "\n",
            "Epoch 3814: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.1383e-04 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.8453 - 3s/epoch - 76ms/step\n",
            "Epoch 3815/5000\n",
            "\n",
            "Epoch 3815: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.9522e-04 - accuracy: 1.0000 - val_loss: 0.7388 - val_accuracy: 0.8417 - 4s/epoch - 114ms/step\n",
            "Epoch 3816/5000\n",
            "\n",
            "Epoch 3816: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9874e-04 - accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 3817/5000\n",
            "\n",
            "Epoch 3817: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9800e-04 - accuracy: 1.0000 - val_loss: 0.7616 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3818/5000\n",
            "\n",
            "Epoch 3818: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9651e-04 - accuracy: 1.0000 - val_loss: 0.7518 - val_accuracy: 0.8417 - 3s/epoch - 73ms/step\n",
            "Epoch 3819/5000\n",
            "\n",
            "Epoch 3819: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9421e-04 - accuracy: 1.0000 - val_loss: 0.7655 - val_accuracy: 0.8417 - 3s/epoch - 90ms/step\n",
            "Epoch 3820/5000\n",
            "\n",
            "Epoch 3820: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.9946e-04 - accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.8309 - 4s/epoch - 101ms/step\n",
            "Epoch 3821/5000\n",
            "\n",
            "Epoch 3821: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9348e-04 - accuracy: 1.0000 - val_loss: 0.7597 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3822/5000\n",
            "\n",
            "Epoch 3822: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8957e-04 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3823/5000\n",
            "\n",
            "Epoch 3823: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9188e-04 - accuracy: 1.0000 - val_loss: 0.7417 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3824/5000\n",
            "\n",
            "Epoch 3824: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.9191e-04 - accuracy: 1.0000 - val_loss: 0.7508 - val_accuracy: 0.8417 - 4s/epoch - 100ms/step\n",
            "Epoch 3825/5000\n",
            "\n",
            "Epoch 3825: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0213e-04 - accuracy: 1.0000 - val_loss: 0.7373 - val_accuracy: 0.8453 - 3s/epoch - 90ms/step\n",
            "Epoch 3826/5000\n",
            "\n",
            "Epoch 3826: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9791e-04 - accuracy: 1.0000 - val_loss: 0.7508 - val_accuracy: 0.8345 - 3s/epoch - 72ms/step\n",
            "Epoch 3827/5000\n",
            "\n",
            "Epoch 3827: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9705e-04 - accuracy: 1.0000 - val_loss: 0.7605 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 3828/5000\n",
            "\n",
            "Epoch 3828: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9577e-04 - accuracy: 1.0000 - val_loss: 0.7616 - val_accuracy: 0.8309 - 3s/epoch - 72ms/step\n",
            "Epoch 3829/5000\n",
            "\n",
            "Epoch 3829: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.9968e-04 - accuracy: 1.0000 - val_loss: 0.7418 - val_accuracy: 0.8417 - 4s/epoch - 109ms/step\n",
            "Epoch 3830/5000\n",
            "\n",
            "Epoch 3830: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.8231e-04 - accuracy: 1.0000 - val_loss: 0.7631 - val_accuracy: 0.8525 - 3s/epoch - 81ms/step\n",
            "Epoch 3831/5000\n",
            "\n",
            "Epoch 3831: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.3781e-04 - accuracy: 1.0000 - val_loss: 0.7451 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3832/5000\n",
            "\n",
            "Epoch 3832: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0602e-04 - accuracy: 1.0000 - val_loss: 0.7525 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3833/5000\n",
            "\n",
            "Epoch 3833: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0971e-04 - accuracy: 1.0000 - val_loss: 0.7643 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3834/5000\n",
            "\n",
            "Epoch 3834: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 2.0280e-04 - accuracy: 1.0000 - val_loss: 0.7770 - val_accuracy: 0.8417 - 4s/epoch - 119ms/step\n",
            "Epoch 3835/5000\n",
            "\n",
            "Epoch 3835: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.2042e-04 - accuracy: 1.0000 - val_loss: 0.7630 - val_accuracy: 0.8525 - 3s/epoch - 73ms/step\n",
            "Epoch 3836/5000\n",
            "\n",
            "Epoch 3836: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0894e-04 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 3837/5000\n",
            "\n",
            "Epoch 3837: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.0398e-04 - accuracy: 1.0000 - val_loss: 0.7632 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3838/5000\n",
            "\n",
            "Epoch 3838: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0188e-04 - accuracy: 1.0000 - val_loss: 0.7630 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 3839/5000\n",
            "\n",
            "Epoch 3839: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 2.0028e-04 - accuracy: 1.0000 - val_loss: 0.7729 - val_accuracy: 0.8453 - 4s/epoch - 120ms/step\n",
            "Epoch 3840/5000\n",
            "\n",
            "Epoch 3840: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9311e-04 - accuracy: 1.0000 - val_loss: 0.7674 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3841/5000\n",
            "\n",
            "Epoch 3841: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9704e-04 - accuracy: 1.0000 - val_loss: 0.7732 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3842/5000\n",
            "\n",
            "Epoch 3842: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0048e-04 - accuracy: 1.0000 - val_loss: 0.7709 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3843/5000\n",
            "\n",
            "Epoch 3843: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.0927e-04 - accuracy: 1.0000 - val_loss: 0.7697 - val_accuracy: 0.8345 - 3s/epoch - 79ms/step\n",
            "Epoch 3844/5000\n",
            "\n",
            "Epoch 3844: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.9714e-04 - accuracy: 1.0000 - val_loss: 0.7695 - val_accuracy: 0.8309 - 4s/epoch - 112ms/step\n",
            "Epoch 3845/5000\n",
            "\n",
            "Epoch 3845: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.1763e-04 - accuracy: 1.0000 - val_loss: 0.7753 - val_accuracy: 0.8237 - 3s/epoch - 72ms/step\n",
            "Epoch 3846/5000\n",
            "\n",
            "Epoch 3846: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9558e-04 - accuracy: 1.0000 - val_loss: 0.7686 - val_accuracy: 0.8309 - 2s/epoch - 71ms/step\n",
            "Epoch 3847/5000\n",
            "\n",
            "Epoch 3847: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9356e-04 - accuracy: 1.0000 - val_loss: 0.7647 - val_accuracy: 0.8309 - 2s/epoch - 71ms/step\n",
            "Epoch 3848/5000\n",
            "\n",
            "Epoch 3848: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9593e-04 - accuracy: 1.0000 - val_loss: 0.7677 - val_accuracy: 0.8345 - 3s/epoch - 89ms/step\n",
            "Epoch 3849/5000\n",
            "\n",
            "Epoch 3849: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.9855e-04 - accuracy: 1.0000 - val_loss: 0.7642 - val_accuracy: 0.8381 - 4s/epoch - 104ms/step\n",
            "Epoch 3850/5000\n",
            "\n",
            "Epoch 3850: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9357e-04 - accuracy: 1.0000 - val_loss: 0.7694 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3851/5000\n",
            "\n",
            "Epoch 3851: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9607e-04 - accuracy: 1.0000 - val_loss: 0.7672 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3852/5000\n",
            "\n",
            "Epoch 3852: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9573e-04 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3853/5000\n",
            "\n",
            "Epoch 3853: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9463e-04 - accuracy: 1.0000 - val_loss: 0.7758 - val_accuracy: 0.8309 - 3s/epoch - 94ms/step\n",
            "Epoch 3854/5000\n",
            "\n",
            "Epoch 3854: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9115e-04 - accuracy: 1.0000 - val_loss: 0.7632 - val_accuracy: 0.8381 - 3s/epoch - 97ms/step\n",
            "Epoch 3855/5000\n",
            "\n",
            "Epoch 3855: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8760e-04 - accuracy: 1.0000 - val_loss: 0.7590 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 3856/5000\n",
            "\n",
            "Epoch 3856: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9069e-04 - accuracy: 1.0000 - val_loss: 0.7614 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3857/5000\n",
            "\n",
            "Epoch 3857: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9052e-04 - accuracy: 1.0000 - val_loss: 0.7566 - val_accuracy: 0.8381 - 3s/epoch - 71ms/step\n",
            "Epoch 3858/5000\n",
            "\n",
            "Epoch 3858: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.9008e-04 - accuracy: 1.0000 - val_loss: 0.7591 - val_accuracy: 0.8381 - 4s/epoch - 106ms/step\n",
            "Epoch 3859/5000\n",
            "\n",
            "Epoch 3859: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8951e-04 - accuracy: 1.0000 - val_loss: 0.7626 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 3860/5000\n",
            "\n",
            "Epoch 3860: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8354e-04 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.8345 - 3s/epoch - 71ms/step\n",
            "Epoch 3861/5000\n",
            "\n",
            "Epoch 3861: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8889e-04 - accuracy: 1.0000 - val_loss: 0.7551 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 3862/5000\n",
            "\n",
            "Epoch 3862: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8837e-04 - accuracy: 1.0000 - val_loss: 0.7529 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 3863/5000\n",
            "\n",
            "Epoch 3863: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.9128e-04 - accuracy: 1.0000 - val_loss: 0.7565 - val_accuracy: 0.8381 - 4s/epoch - 117ms/step\n",
            "Epoch 3864/5000\n",
            "\n",
            "Epoch 3864: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9614e-04 - accuracy: 1.0000 - val_loss: 0.7497 - val_accuracy: 0.8345 - 3s/epoch - 74ms/step\n",
            "Epoch 3865/5000\n",
            "\n",
            "Epoch 3865: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9346e-04 - accuracy: 1.0000 - val_loss: 0.7556 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 3866/5000\n",
            "\n",
            "Epoch 3866: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8815e-04 - accuracy: 1.0000 - val_loss: 0.7674 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3867/5000\n",
            "\n",
            "Epoch 3867: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9194e-04 - accuracy: 1.0000 - val_loss: 0.7620 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3868/5000\n",
            "\n",
            "Epoch 3868: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.8512e-04 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.8381 - 4s/epoch - 120ms/step\n",
            "Epoch 3869/5000\n",
            "\n",
            "Epoch 3869: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9050e-04 - accuracy: 1.0000 - val_loss: 0.7443 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3870/5000\n",
            "\n",
            "Epoch 3870: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8806e-04 - accuracy: 1.0000 - val_loss: 0.7412 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 3871/5000\n",
            "\n",
            "Epoch 3871: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9109e-04 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3872/5000\n",
            "\n",
            "Epoch 3872: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8322e-04 - accuracy: 1.0000 - val_loss: 0.7497 - val_accuracy: 0.8417 - 3s/epoch - 79ms/step\n",
            "Epoch 3873/5000\n",
            "\n",
            "Epoch 3873: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.8846e-04 - accuracy: 1.0000 - val_loss: 0.7450 - val_accuracy: 0.8417 - 4s/epoch - 113ms/step\n",
            "Epoch 3874/5000\n",
            "\n",
            "Epoch 3874: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8963e-04 - accuracy: 1.0000 - val_loss: 0.7443 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 3875/5000\n",
            "\n",
            "Epoch 3875: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8963e-04 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3876/5000\n",
            "\n",
            "Epoch 3876: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8662e-04 - accuracy: 1.0000 - val_loss: 0.7472 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 3877/5000\n",
            "\n",
            "Epoch 3877: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8409e-04 - accuracy: 1.0000 - val_loss: 0.7475 - val_accuracy: 0.8381 - 3s/epoch - 86ms/step\n",
            "Epoch 3878/5000\n",
            "\n",
            "Epoch 3878: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.9096e-04 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.8417 - 4s/epoch - 104ms/step\n",
            "Epoch 3879/5000\n",
            "\n",
            "Epoch 3879: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8682e-04 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.8345 - 3s/epoch - 72ms/step\n",
            "Epoch 3880/5000\n",
            "\n",
            "Epoch 3880: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9193e-04 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 3881/5000\n",
            "\n",
            "Epoch 3881: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9058e-04 - accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 3882/5000\n",
            "\n",
            "Epoch 3882: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8487e-04 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.8381 - 3s/epoch - 91ms/step\n",
            "Epoch 3883/5000\n",
            "\n",
            "Epoch 3883: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9342e-04 - accuracy: 1.0000 - val_loss: 0.7536 - val_accuracy: 0.8417 - 3s/epoch - 97ms/step\n",
            "Epoch 3884/5000\n",
            "\n",
            "Epoch 3884: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8484e-04 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3885/5000\n",
            "\n",
            "Epoch 3885: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9086e-04 - accuracy: 1.0000 - val_loss: 0.7609 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3886/5000\n",
            "\n",
            "Epoch 3886: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8550e-04 - accuracy: 1.0000 - val_loss: 0.7568 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3887/5000\n",
            "\n",
            "Epoch 3887: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.8687e-04 - accuracy: 1.0000 - val_loss: 0.7521 - val_accuracy: 0.8381 - 4s/epoch - 101ms/step\n",
            "Epoch 3888/5000\n",
            "\n",
            "Epoch 3888: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8943e-04 - accuracy: 1.0000 - val_loss: 0.7466 - val_accuracy: 0.8345 - 3s/epoch - 90ms/step\n",
            "Epoch 3889/5000\n",
            "\n",
            "Epoch 3889: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9048e-04 - accuracy: 1.0000 - val_loss: 0.7492 - val_accuracy: 0.8309 - 3s/epoch - 71ms/step\n",
            "Epoch 3890/5000\n",
            "\n",
            "Epoch 3890: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8691e-04 - accuracy: 1.0000 - val_loss: 0.7596 - val_accuracy: 0.8309 - 2s/epoch - 71ms/step\n",
            "Epoch 3891/5000\n",
            "\n",
            "Epoch 3891: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8902e-04 - accuracy: 1.0000 - val_loss: 0.7642 - val_accuracy: 0.8345 - 3s/epoch - 72ms/step\n",
            "Epoch 3892/5000\n",
            "\n",
            "Epoch 3892: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.8770e-04 - accuracy: 1.0000 - val_loss: 0.7607 - val_accuracy: 0.8381 - 4s/epoch - 108ms/step\n",
            "Epoch 3893/5000\n",
            "\n",
            "Epoch 3893: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8547e-04 - accuracy: 1.0000 - val_loss: 0.7748 - val_accuracy: 0.8309 - 3s/epoch - 81ms/step\n",
            "Epoch 3894/5000\n",
            "\n",
            "Epoch 3894: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8670e-04 - accuracy: 1.0000 - val_loss: 0.7568 - val_accuracy: 0.8273 - 2s/epoch - 71ms/step\n",
            "Epoch 3895/5000\n",
            "\n",
            "Epoch 3895: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8322e-04 - accuracy: 1.0000 - val_loss: 0.7566 - val_accuracy: 0.8309 - 2s/epoch - 71ms/step\n",
            "Epoch 3896/5000\n",
            "\n",
            "Epoch 3896: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8487e-04 - accuracy: 1.0000 - val_loss: 0.7645 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 3897/5000\n",
            "\n",
            "Epoch 3897: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.8756e-04 - accuracy: 1.0000 - val_loss: 0.7529 - val_accuracy: 0.8417 - 4s/epoch - 119ms/step\n",
            "Epoch 3898/5000\n",
            "\n",
            "Epoch 3898: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8303e-04 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.8381 - 3s/epoch - 73ms/step\n",
            "Epoch 3899/5000\n",
            "\n",
            "Epoch 3899: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8487e-04 - accuracy: 1.0000 - val_loss: 0.7519 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3900/5000\n",
            "\n",
            "Epoch 3900: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8650e-04 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 3901/5000\n",
            "\n",
            "Epoch 3901: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7973e-04 - accuracy: 1.0000 - val_loss: 0.7508 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3902/5000\n",
            "\n",
            "Epoch 3902: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.8528e-04 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.8417 - 4s/epoch - 120ms/step\n",
            "Epoch 3903/5000\n",
            "\n",
            "Epoch 3903: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8624e-04 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8417 - 3s/epoch - 77ms/step\n",
            "Epoch 3904/5000\n",
            "\n",
            "Epoch 3904: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8302e-04 - accuracy: 1.0000 - val_loss: 0.7445 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3905/5000\n",
            "\n",
            "Epoch 3905: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8514e-04 - accuracy: 1.0000 - val_loss: 0.7431 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 3906/5000\n",
            "\n",
            "Epoch 3906: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8311e-04 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.8381 - 3s/epoch - 80ms/step\n",
            "Epoch 3907/5000\n",
            "\n",
            "Epoch 3907: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.8377e-04 - accuracy: 1.0000 - val_loss: 0.7818 - val_accuracy: 0.8417 - 4s/epoch - 110ms/step\n",
            "Epoch 3908/5000\n",
            "\n",
            "Epoch 3908: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8768e-04 - accuracy: 1.0000 - val_loss: 0.7433 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3909/5000\n",
            "\n",
            "Epoch 3909: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8155e-04 - accuracy: 1.0000 - val_loss: 0.7347 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 3910/5000\n",
            "\n",
            "Epoch 3910: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7818e-04 - accuracy: 1.0000 - val_loss: 0.7361 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 3911/5000\n",
            "\n",
            "Epoch 3911: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8394e-04 - accuracy: 1.0000 - val_loss: 0.7446 - val_accuracy: 0.8525 - 3s/epoch - 90ms/step\n",
            "Epoch 3912/5000\n",
            "\n",
            "Epoch 3912: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7926e-04 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.8453 - 4s/epoch - 101ms/step\n",
            "Epoch 3913/5000\n",
            "\n",
            "Epoch 3913: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8453e-04 - accuracy: 1.0000 - val_loss: 0.7441 - val_accuracy: 0.8453 - 3s/epoch - 73ms/step\n",
            "Epoch 3914/5000\n",
            "\n",
            "Epoch 3914: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7928e-04 - accuracy: 1.0000 - val_loss: 0.7461 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3915/5000\n",
            "\n",
            "Epoch 3915: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8037e-04 - accuracy: 1.0000 - val_loss: 0.7546 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3916/5000\n",
            "\n",
            "Epoch 3916: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8083e-04 - accuracy: 1.0000 - val_loss: 0.7585 - val_accuracy: 0.8417 - 3s/epoch - 96ms/step\n",
            "Epoch 3917/5000\n",
            "\n",
            "Epoch 3917: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8089e-04 - accuracy: 1.0000 - val_loss: 0.7469 - val_accuracy: 0.8417 - 3s/epoch - 94ms/step\n",
            "Epoch 3918/5000\n",
            "\n",
            "Epoch 3918: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8648e-04 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 3919/5000\n",
            "\n",
            "Epoch 3919: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7981e-04 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3920/5000\n",
            "\n",
            "Epoch 3920: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8023e-04 - accuracy: 1.0000 - val_loss: 0.7457 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 3921/5000\n",
            "\n",
            "Epoch 3921: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.8096e-04 - accuracy: 1.0000 - val_loss: 0.7443 - val_accuracy: 0.8381 - 4s/epoch - 106ms/step\n",
            "Epoch 3922/5000\n",
            "\n",
            "Epoch 3922: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7959e-04 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.8381 - 3s/epoch - 85ms/step\n",
            "Epoch 3923/5000\n",
            "\n",
            "Epoch 3923: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7830e-04 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3924/5000\n",
            "\n",
            "Epoch 3924: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7316e-04 - accuracy: 1.0000 - val_loss: 0.7421 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3925/5000\n",
            "\n",
            "Epoch 3925: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7732e-04 - accuracy: 1.0000 - val_loss: 0.7414 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3926/5000\n",
            "\n",
            "Epoch 3926: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.8201e-04 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.8417 - 4s/epoch - 113ms/step\n",
            "Epoch 3927/5000\n",
            "\n",
            "Epoch 3927: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8053e-04 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.8453 - 3s/epoch - 77ms/step\n",
            "Epoch 3928/5000\n",
            "\n",
            "Epoch 3928: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7792e-04 - accuracy: 1.0000 - val_loss: 0.7487 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3929/5000\n",
            "\n",
            "Epoch 3929: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8195e-04 - accuracy: 1.0000 - val_loss: 0.7482 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 3930/5000\n",
            "\n",
            "Epoch 3930: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8692e-04 - accuracy: 1.0000 - val_loss: 0.7465 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3931/5000\n",
            "\n",
            "Epoch 3931: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.8135e-04 - accuracy: 1.0000 - val_loss: 0.7472 - val_accuracy: 0.8417 - 4s/epoch - 118ms/step\n",
            "Epoch 3932/5000\n",
            "\n",
            "Epoch 3932: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7532e-04 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 3933/5000\n",
            "\n",
            "Epoch 3933: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7919e-04 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3934/5000\n",
            "\n",
            "Epoch 3934: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7633e-04 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 3935/5000\n",
            "\n",
            "Epoch 3935: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7536e-04 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3936/5000\n",
            "\n",
            "Epoch 3936: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7798e-04 - accuracy: 1.0000 - val_loss: 0.7433 - val_accuracy: 0.8417 - 4s/epoch - 127ms/step\n",
            "Epoch 3937/5000\n",
            "\n",
            "Epoch 3937: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7536e-04 - accuracy: 1.0000 - val_loss: 0.7449 - val_accuracy: 0.8417 - 3s/epoch - 75ms/step\n",
            "Epoch 3938/5000\n",
            "\n",
            "Epoch 3938: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7628e-04 - accuracy: 1.0000 - val_loss: 0.7336 - val_accuracy: 0.8453 - 3s/epoch - 86ms/step\n",
            "Epoch 3939/5000\n",
            "\n",
            "Epoch 3939: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7433e-04 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3940/5000\n",
            "\n",
            "Epoch 3940: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7919e-04 - accuracy: 1.0000 - val_loss: 0.7417 - val_accuracy: 0.8417 - 4s/epoch - 102ms/step\n",
            "Epoch 3941/5000\n",
            "\n",
            "Epoch 3941: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7948e-04 - accuracy: 1.0000 - val_loss: 0.7580 - val_accuracy: 0.8381 - 3s/epoch - 89ms/step\n",
            "Epoch 3942/5000\n",
            "\n",
            "Epoch 3942: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8016e-04 - accuracy: 1.0000 - val_loss: 0.7519 - val_accuracy: 0.8309 - 2s/epoch - 71ms/step\n",
            "Epoch 3943/5000\n",
            "\n",
            "Epoch 3943: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7571e-04 - accuracy: 1.0000 - val_loss: 0.7382 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 3944/5000\n",
            "\n",
            "Epoch 3944: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7895e-04 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.8381 - 3s/epoch - 71ms/step\n",
            "Epoch 3945/5000\n",
            "\n",
            "Epoch 3945: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.8057e-04 - accuracy: 1.0000 - val_loss: 0.7383 - val_accuracy: 0.8381 - 4s/epoch - 109ms/step\n",
            "Epoch 3946/5000\n",
            "\n",
            "Epoch 3946: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 2.1339e-04 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.8381 - 3s/epoch - 82ms/step\n",
            "Epoch 3947/5000\n",
            "\n",
            "Epoch 3947: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8346e-04 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.8489 - 3s/epoch - 71ms/step\n",
            "Epoch 3948/5000\n",
            "\n",
            "Epoch 3948: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.9155e-04 - accuracy: 1.0000 - val_loss: 0.7620 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3949/5000\n",
            "\n",
            "Epoch 3949: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8338e-04 - accuracy: 1.0000 - val_loss: 0.7545 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 3950/5000\n",
            "\n",
            "Epoch 3950: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.8032e-04 - accuracy: 1.0000 - val_loss: 0.7614 - val_accuracy: 0.8453 - 4s/epoch - 117ms/step\n",
            "Epoch 3951/5000\n",
            "\n",
            "Epoch 3951: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8225e-04 - accuracy: 1.0000 - val_loss: 0.7792 - val_accuracy: 0.8417 - 3s/epoch - 74ms/step\n",
            "Epoch 3952/5000\n",
            "\n",
            "Epoch 3952: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8951e-04 - accuracy: 1.0000 - val_loss: 0.7845 - val_accuracy: 0.8309 - 2s/epoch - 71ms/step\n",
            "Epoch 3953/5000\n",
            "\n",
            "Epoch 3953: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7784e-04 - accuracy: 1.0000 - val_loss: 0.7810 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 3954/5000\n",
            "\n",
            "Epoch 3954: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7760e-04 - accuracy: 1.0000 - val_loss: 0.7665 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 3955/5000\n",
            "\n",
            "Epoch 3955: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7805e-04 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.8417 - 4s/epoch - 118ms/step\n",
            "Epoch 3956/5000\n",
            "\n",
            "Epoch 3956: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7628e-04 - accuracy: 1.0000 - val_loss: 0.7445 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3957/5000\n",
            "\n",
            "Epoch 3957: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7635e-04 - accuracy: 1.0000 - val_loss: 0.7460 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3958/5000\n",
            "\n",
            "Epoch 3958: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7254e-04 - accuracy: 1.0000 - val_loss: 0.7411 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3959/5000\n",
            "\n",
            "Epoch 3959: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7612e-04 - accuracy: 1.0000 - val_loss: 0.7353 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 3960/5000\n",
            "\n",
            "Epoch 3960: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7579e-04 - accuracy: 1.0000 - val_loss: 0.7466 - val_accuracy: 0.8417 - 4s/epoch - 115ms/step\n",
            "Epoch 3961/5000\n",
            "\n",
            "Epoch 3961: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7910e-04 - accuracy: 1.0000 - val_loss: 0.7778 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3962/5000\n",
            "\n",
            "Epoch 3962: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7879e-04 - accuracy: 1.0000 - val_loss: 0.7611 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3963/5000\n",
            "\n",
            "Epoch 3963: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.8511e-04 - accuracy: 1.0000 - val_loss: 0.7441 - val_accuracy: 0.8345 - 3s/epoch - 72ms/step\n",
            "Epoch 3964/5000\n",
            "\n",
            "Epoch 3964: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7778e-04 - accuracy: 1.0000 - val_loss: 0.7363 - val_accuracy: 0.8417 - 3s/epoch - 85ms/step\n",
            "Epoch 3965/5000\n",
            "\n",
            "Epoch 3965: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7310e-04 - accuracy: 1.0000 - val_loss: 0.7338 - val_accuracy: 0.8381 - 4s/epoch - 106ms/step\n",
            "Epoch 3966/5000\n",
            "\n",
            "Epoch 3966: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7152e-04 - accuracy: 1.0000 - val_loss: 0.7326 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3967/5000\n",
            "\n",
            "Epoch 3967: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7924e-04 - accuracy: 1.0000 - val_loss: 0.7465 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3968/5000\n",
            "\n",
            "Epoch 3968: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8012e-04 - accuracy: 1.0000 - val_loss: 0.7532 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 3969/5000\n",
            "\n",
            "Epoch 3969: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7682e-04 - accuracy: 1.0000 - val_loss: 0.7461 - val_accuracy: 0.8381 - 3s/epoch - 90ms/step\n",
            "Epoch 3970/5000\n",
            "\n",
            "Epoch 3970: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7305e-04 - accuracy: 1.0000 - val_loss: 0.7338 - val_accuracy: 0.8453 - 3s/epoch - 99ms/step\n",
            "Epoch 3971/5000\n",
            "\n",
            "Epoch 3971: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7280e-04 - accuracy: 1.0000 - val_loss: 0.7356 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 3972/5000\n",
            "\n",
            "Epoch 3972: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7330e-04 - accuracy: 1.0000 - val_loss: 0.7654 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 3973/5000\n",
            "\n",
            "Epoch 3973: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7183e-04 - accuracy: 1.0000 - val_loss: 0.7569 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 3974/5000\n",
            "\n",
            "Epoch 3974: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7559e-04 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.8309 - 3s/epoch - 100ms/step\n",
            "Epoch 3975/5000\n",
            "\n",
            "Epoch 3975: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7830e-04 - accuracy: 1.0000 - val_loss: 0.7437 - val_accuracy: 0.8453 - 3s/epoch - 96ms/step\n",
            "Epoch 3976/5000\n",
            "\n",
            "Epoch 3976: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7069e-04 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3977/5000\n",
            "\n",
            "Epoch 3977: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7014e-04 - accuracy: 1.0000 - val_loss: 0.7554 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3978/5000\n",
            "\n",
            "Epoch 3978: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7455e-04 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3979/5000\n",
            "\n",
            "Epoch 3979: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7452e-04 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.8453 - 4s/epoch - 114ms/step\n",
            "Epoch 3980/5000\n",
            "\n",
            "Epoch 3980: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9396e-04 - accuracy: 1.0000 - val_loss: 0.7350 - val_accuracy: 0.8417 - 3s/epoch - 86ms/step\n",
            "Epoch 3981/5000\n",
            "\n",
            "Epoch 3981: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7924e-04 - accuracy: 1.0000 - val_loss: 0.7543 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3982/5000\n",
            "\n",
            "Epoch 3982: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7357e-04 - accuracy: 1.0000 - val_loss: 0.7573 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 3983/5000\n",
            "\n",
            "Epoch 3983: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7995e-04 - accuracy: 1.0000 - val_loss: 0.7426 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 3984/5000\n",
            "\n",
            "Epoch 3984: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.9517e-04 - accuracy: 1.0000 - val_loss: 0.8037 - val_accuracy: 0.8453 - 4s/epoch - 118ms/step\n",
            "Epoch 3985/5000\n",
            "\n",
            "Epoch 3985: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8164e-04 - accuracy: 1.0000 - val_loss: 0.7374 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 3986/5000\n",
            "\n",
            "Epoch 3986: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7578e-04 - accuracy: 1.0000 - val_loss: 0.7361 - val_accuracy: 0.8561 - 3s/epoch - 72ms/step\n",
            "Epoch 3987/5000\n",
            "\n",
            "Epoch 3987: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7527e-04 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.8525 - 3s/epoch - 73ms/step\n",
            "Epoch 3988/5000\n",
            "\n",
            "Epoch 3988: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7634e-04 - accuracy: 1.0000 - val_loss: 0.7546 - val_accuracy: 0.8453 - 3s/epoch - 79ms/step\n",
            "Epoch 3989/5000\n",
            "\n",
            "Epoch 3989: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7446e-04 - accuracy: 1.0000 - val_loss: 0.7441 - val_accuracy: 0.8525 - 4s/epoch - 111ms/step\n",
            "Epoch 3990/5000\n",
            "\n",
            "Epoch 3990: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6832e-04 - accuracy: 1.0000 - val_loss: 0.7450 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 3991/5000\n",
            "\n",
            "Epoch 3991: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.9245e-04 - accuracy: 1.0000 - val_loss: 0.7405 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 3992/5000\n",
            "\n",
            "Epoch 3992: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.8345e-04 - accuracy: 1.0000 - val_loss: 0.7439 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 3993/5000\n",
            "\n",
            "Epoch 3993: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7987e-04 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.8489 - 3s/epoch - 88ms/step\n",
            "Epoch 3994/5000\n",
            "\n",
            "Epoch 3994: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7123e-04 - accuracy: 1.0000 - val_loss: 0.7484 - val_accuracy: 0.8525 - 4s/epoch - 102ms/step\n",
            "Epoch 3995/5000\n",
            "\n",
            "Epoch 3995: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7405e-04 - accuracy: 1.0000 - val_loss: 0.7479 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 3996/5000\n",
            "\n",
            "Epoch 3996: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6982e-04 - accuracy: 1.0000 - val_loss: 0.7498 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 3997/5000\n",
            "\n",
            "Epoch 3997: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7298e-04 - accuracy: 1.0000 - val_loss: 0.7579 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 3998/5000\n",
            "\n",
            "Epoch 3998: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6985e-04 - accuracy: 1.0000 - val_loss: 0.7598 - val_accuracy: 0.8417 - 3s/epoch - 96ms/step\n",
            "Epoch 3999/5000\n",
            "\n",
            "Epoch 3999: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6779e-04 - accuracy: 1.0000 - val_loss: 0.7518 - val_accuracy: 0.8417 - 3s/epoch - 93ms/step\n",
            "Epoch 4000/5000\n",
            "\n",
            "Epoch 4000: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7530e-04 - accuracy: 1.0000 - val_loss: 0.7345 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4001/5000\n",
            "\n",
            "Epoch 4001: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7232e-04 - accuracy: 1.0000 - val_loss: 0.7491 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4002/5000\n",
            "\n",
            "Epoch 4002: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6870e-04 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 0.8561 - 2s/epoch - 71ms/step\n",
            "Epoch 4003/5000\n",
            "\n",
            "Epoch 4003: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7290e-04 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.8489 - 4s/epoch - 103ms/step\n",
            "Epoch 4004/5000\n",
            "\n",
            "Epoch 4004: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6597e-04 - accuracy: 1.0000 - val_loss: 0.7489 - val_accuracy: 0.8489 - 3s/epoch - 87ms/step\n",
            "Epoch 4005/5000\n",
            "\n",
            "Epoch 4005: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6563e-04 - accuracy: 1.0000 - val_loss: 0.7454 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4006/5000\n",
            "\n",
            "Epoch 4006: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6446e-04 - accuracy: 1.0000 - val_loss: 0.7398 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4007/5000\n",
            "\n",
            "Epoch 4007: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6962e-04 - accuracy: 1.0000 - val_loss: 0.7422 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4008/5000\n",
            "\n",
            "Epoch 4008: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.6672e-04 - accuracy: 1.0000 - val_loss: 0.7466 - val_accuracy: 0.8453 - 4s/epoch - 114ms/step\n",
            "Epoch 4009/5000\n",
            "\n",
            "Epoch 4009: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7142e-04 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.8417 - 3s/epoch - 76ms/step\n",
            "Epoch 4010/5000\n",
            "\n",
            "Epoch 4010: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6881e-04 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4011/5000\n",
            "\n",
            "Epoch 4011: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7112e-04 - accuracy: 1.0000 - val_loss: 0.7568 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4012/5000\n",
            "\n",
            "Epoch 4012: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6800e-04 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4013/5000\n",
            "\n",
            "Epoch 4013: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.6773e-04 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.8525 - 4s/epoch - 119ms/step\n",
            "Epoch 4014/5000\n",
            "\n",
            "Epoch 4014: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6457e-04 - accuracy: 1.0000 - val_loss: 0.7454 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4015/5000\n",
            "\n",
            "Epoch 4015: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6983e-04 - accuracy: 1.0000 - val_loss: 0.7383 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4016/5000\n",
            "\n",
            "Epoch 4016: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6433e-04 - accuracy: 1.0000 - val_loss: 0.7396 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4017/5000\n",
            "\n",
            "Epoch 4017: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6696e-04 - accuracy: 1.0000 - val_loss: 0.7401 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4018/5000\n",
            "\n",
            "Epoch 4018: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7198e-04 - accuracy: 1.0000 - val_loss: 0.7359 - val_accuracy: 0.8453 - 4s/epoch - 119ms/step\n",
            "Epoch 4019/5000\n",
            "\n",
            "Epoch 4019: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6926e-04 - accuracy: 1.0000 - val_loss: 0.7502 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4020/5000\n",
            "\n",
            "Epoch 4020: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7205e-04 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4021/5000\n",
            "\n",
            "Epoch 4021: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7497e-04 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4022/5000\n",
            "\n",
            "Epoch 4022: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6659e-04 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.8489 - 3s/epoch - 73ms/step\n",
            "Epoch 4023/5000\n",
            "\n",
            "Epoch 4023: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.6685e-04 - accuracy: 1.0000 - val_loss: 0.7420 - val_accuracy: 0.8417 - 4s/epoch - 115ms/step\n",
            "Epoch 4024/5000\n",
            "\n",
            "Epoch 4024: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6698e-04 - accuracy: 1.0000 - val_loss: 0.7403 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4025/5000\n",
            "\n",
            "Epoch 4025: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6554e-04 - accuracy: 1.0000 - val_loss: 0.7400 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4026/5000\n",
            "\n",
            "Epoch 4026: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6846e-04 - accuracy: 1.0000 - val_loss: 0.7401 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4027/5000\n",
            "\n",
            "Epoch 4027: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6378e-04 - accuracy: 1.0000 - val_loss: 0.7482 - val_accuracy: 0.8381 - 3s/epoch - 77ms/step\n",
            "Epoch 4028/5000\n",
            "\n",
            "Epoch 4028: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.6548e-04 - accuracy: 1.0000 - val_loss: 0.7444 - val_accuracy: 0.8417 - 4s/epoch - 112ms/step\n",
            "Epoch 4029/5000\n",
            "\n",
            "Epoch 4029: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6562e-04 - accuracy: 1.0000 - val_loss: 0.7452 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4030/5000\n",
            "\n",
            "Epoch 4030: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6711e-04 - accuracy: 1.0000 - val_loss: 0.7467 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 4031/5000\n",
            "\n",
            "Epoch 4031: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6337e-04 - accuracy: 1.0000 - val_loss: 0.7369 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4032/5000\n",
            "\n",
            "Epoch 4032: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7567e-04 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.8453 - 3s/epoch - 86ms/step\n",
            "Epoch 4033/5000\n",
            "\n",
            "Epoch 4033: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.6888e-04 - accuracy: 1.0000 - val_loss: 0.7481 - val_accuracy: 0.8453 - 4s/epoch - 103ms/step\n",
            "Epoch 4034/5000\n",
            "\n",
            "Epoch 4034: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7215e-04 - accuracy: 1.0000 - val_loss: 0.7451 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4035/5000\n",
            "\n",
            "Epoch 4035: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6945e-04 - accuracy: 1.0000 - val_loss: 0.7426 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4036/5000\n",
            "\n",
            "Epoch 4036: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6477e-04 - accuracy: 1.0000 - val_loss: 0.7469 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4037/5000\n",
            "\n",
            "Epoch 4037: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6703e-04 - accuracy: 1.0000 - val_loss: 0.7533 - val_accuracy: 0.8417 - 3s/epoch - 95ms/step\n",
            "Epoch 4038/5000\n",
            "\n",
            "Epoch 4038: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6424e-04 - accuracy: 1.0000 - val_loss: 0.7533 - val_accuracy: 0.8453 - 3s/epoch - 94ms/step\n",
            "Epoch 4039/5000\n",
            "\n",
            "Epoch 4039: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7434e-04 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4040/5000\n",
            "\n",
            "Epoch 4040: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.5574e-04 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.8309 - 2s/epoch - 71ms/step\n",
            "Epoch 4041/5000\n",
            "\n",
            "Epoch 4041: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 2.1038e-04 - accuracy: 1.0000 - val_loss: 0.7771 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4042/5000\n",
            "\n",
            "Epoch 4042: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7206e-04 - accuracy: 1.0000 - val_loss: 0.7643 - val_accuracy: 0.8417 - 4s/epoch - 100ms/step\n",
            "Epoch 4043/5000\n",
            "\n",
            "Epoch 4043: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.7023e-04 - accuracy: 1.0000 - val_loss: 0.7631 - val_accuracy: 0.8417 - 3s/epoch - 88ms/step\n",
            "Epoch 4044/5000\n",
            "\n",
            "Epoch 4044: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6869e-04 - accuracy: 1.0000 - val_loss: 0.7622 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4045/5000\n",
            "\n",
            "Epoch 4045: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6963e-04 - accuracy: 1.0000 - val_loss: 0.7551 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4046/5000\n",
            "\n",
            "Epoch 4046: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7254e-04 - accuracy: 1.0000 - val_loss: 0.7647 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4047/5000\n",
            "\n",
            "Epoch 4047: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7138e-04 - accuracy: 1.0000 - val_loss: 0.7698 - val_accuracy: 0.8381 - 4s/epoch - 109ms/step\n",
            "Epoch 4048/5000\n",
            "\n",
            "Epoch 4050: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6050e-04 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 4051/5000\n",
            "\n",
            "Epoch 4051: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7017e-04 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.8345 - 2s/epoch - 70ms/step\n",
            "Epoch 4052/5000\n",
            "\n",
            "Epoch 4052: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.6685e-04 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.8417 - 4s/epoch - 113ms/step\n",
            "Epoch 4053/5000\n",
            "\n",
            "Epoch 4053: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6701e-04 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.8453 - 3s/epoch - 74ms/step\n",
            "Epoch 4054/5000\n",
            "\n",
            "Epoch 4054: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6507e-04 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4055/5000\n",
            "\n",
            "Epoch 4055: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6603e-04 - accuracy: 1.0000 - val_loss: 0.7535 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4056/5000\n",
            "\n",
            "Epoch 4056: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6287e-04 - accuracy: 1.0000 - val_loss: 0.7547 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4057/5000\n",
            "\n",
            "Epoch 4057: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.6234e-04 - accuracy: 1.0000 - val_loss: 0.7520 - val_accuracy: 0.8417 - 4s/epoch - 116ms/step\n",
            "Epoch 4058/5000\n",
            "\n",
            "Epoch 4058: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6429e-04 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4059/5000\n",
            "\n",
            "Epoch 4059: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6059e-04 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4060/5000\n",
            "\n",
            "Epoch 4060: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6579e-04 - accuracy: 1.0000 - val_loss: 0.7424 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4061/5000\n",
            "\n",
            "Epoch 4061: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6522e-04 - accuracy: 1.0000 - val_loss: 0.7446 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4062/5000\n",
            "\n",
            "Epoch 4062: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.6798e-04 - accuracy: 1.0000 - val_loss: 0.7547 - val_accuracy: 0.8345 - 4s/epoch - 118ms/step\n",
            "Epoch 4063/5000\n",
            "\n",
            "Epoch 4063: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6499e-04 - accuracy: 1.0000 - val_loss: 0.7514 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4064/5000\n",
            "\n",
            "Epoch 4064: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5955e-04 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4065/5000\n",
            "\n",
            "Epoch 4065: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6981e-04 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4066/5000\n",
            "\n",
            "Epoch 4066: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6281e-04 - accuracy: 1.0000 - val_loss: 0.7482 - val_accuracy: 0.8453 - 3s/epoch - 76ms/step\n",
            "Epoch 4067/5000\n",
            "\n",
            "Epoch 4067: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.6551e-04 - accuracy: 1.0000 - val_loss: 0.7514 - val_accuracy: 0.8453 - 4s/epoch - 112ms/step\n",
            "Epoch 4068/5000\n",
            "\n",
            "Epoch 4068: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6050e-04 - accuracy: 1.0000 - val_loss: 0.7388 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4069/5000\n",
            "\n",
            "Epoch 4069: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.7130e-04 - accuracy: 1.0000 - val_loss: 0.7467 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4070/5000\n",
            "\n",
            "Epoch 4070: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6273e-04 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4071/5000\n",
            "\n",
            "Epoch 4071: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5875e-04 - accuracy: 1.0000 - val_loss: 0.7510 - val_accuracy: 0.8453 - 3s/epoch - 80ms/step\n",
            "Epoch 4072/5000\n",
            "\n",
            "Epoch 4072: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.6498e-04 - accuracy: 1.0000 - val_loss: 0.7328 - val_accuracy: 0.8489 - 4s/epoch - 109ms/step\n",
            "Epoch 4073/5000\n",
            "\n",
            "Epoch 4073: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6420e-04 - accuracy: 1.0000 - val_loss: 0.7339 - val_accuracy: 0.8489 - 3s/epoch - 71ms/step\n",
            "Epoch 4074/5000\n",
            "\n",
            "Epoch 4074: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6150e-04 - accuracy: 1.0000 - val_loss: 0.7409 - val_accuracy: 0.8453 - 2s/epoch - 69ms/step\n",
            "Epoch 4075/5000\n",
            "\n",
            "Epoch 4075: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6000e-04 - accuracy: 1.0000 - val_loss: 0.7458 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4076/5000\n",
            "\n",
            "Epoch 4076: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6027e-04 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.8417 - 3s/epoch - 85ms/step\n",
            "Epoch 4077/5000\n",
            "\n",
            "Epoch 4077: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.6428e-04 - accuracy: 1.0000 - val_loss: 0.7510 - val_accuracy: 0.8417 - 4s/epoch - 104ms/step\n",
            "Epoch 4078/5000\n",
            "\n",
            "Epoch 4078: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6354e-04 - accuracy: 1.0000 - val_loss: 0.7432 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4079/5000\n",
            "\n",
            "Epoch 4079: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6181e-04 - accuracy: 1.0000 - val_loss: 0.7458 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4080/5000\n",
            "\n",
            "Epoch 4080: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5860e-04 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4081/5000\n",
            "\n",
            "Epoch 4081: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5792e-04 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 0.8417 - 3s/epoch - 92ms/step\n",
            "Epoch 4082/5000\n",
            "\n",
            "Epoch 4082: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6107e-04 - accuracy: 1.0000 - val_loss: 0.7463 - val_accuracy: 0.8453 - 3s/epoch - 97ms/step\n",
            "Epoch 4083/5000\n",
            "\n",
            "Epoch 4083: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6323e-04 - accuracy: 1.0000 - val_loss: 0.7401 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4084/5000\n",
            "\n",
            "Epoch 4084: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6314e-04 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4085/5000\n",
            "\n",
            "Epoch 4085: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6018e-04 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4086/5000\n",
            "\n",
            "Epoch 4086: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6484e-04 - accuracy: 1.0000 - val_loss: 0.7485 - val_accuracy: 0.8417 - 3s/epoch - 97ms/step\n",
            "Epoch 4087/5000\n",
            "\n",
            "Epoch 4087: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6145e-04 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.8381 - 3s/epoch - 92ms/step\n",
            "Epoch 4088/5000\n",
            "\n",
            "Epoch 4088: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5789e-04 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4089/5000\n",
            "\n",
            "Epoch 4089: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6137e-04 - accuracy: 1.0000 - val_loss: 0.7532 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4090/5000\n",
            "\n",
            "Epoch 4090: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5580e-04 - accuracy: 1.0000 - val_loss: 0.7451 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4091/5000\n",
            "\n",
            "Epoch 4091: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5709e-04 - accuracy: 1.0000 - val_loss: 0.7428 - val_accuracy: 0.8489 - 4s/epoch - 106ms/step\n",
            "Epoch 4092/5000\n",
            "\n",
            "Epoch 4092: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5909e-04 - accuracy: 1.0000 - val_loss: 0.7466 - val_accuracy: 0.8417 - 3s/epoch - 83ms/step\n",
            "Epoch 4093/5000\n",
            "\n",
            "Epoch 4093: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5813e-04 - accuracy: 1.0000 - val_loss: 0.7501 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4094/5000\n",
            "\n",
            "Epoch 4094: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5792e-04 - accuracy: 1.0000 - val_loss: 0.7514 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4095/5000\n",
            "\n",
            "Epoch 4095: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6146e-04 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4096/5000\n",
            "\n",
            "Epoch 4096: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5821e-04 - accuracy: 1.0000 - val_loss: 0.7492 - val_accuracy: 0.8489 - 4s/epoch - 109ms/step\n",
            "Epoch 4097/5000\n",
            "\n",
            "Epoch 4097: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5547e-04 - accuracy: 1.0000 - val_loss: 0.7468 - val_accuracy: 0.8453 - 3s/epoch - 80ms/step\n",
            "Epoch 4098/5000\n",
            "\n",
            "Epoch 4098: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6112e-04 - accuracy: 1.0000 - val_loss: 0.7364 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4099/5000\n",
            "\n",
            "Epoch 4099: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6072e-04 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.8345 - 2s/epoch - 70ms/step\n",
            "Epoch 4100/5000\n",
            "\n",
            "Epoch 4100: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5831e-04 - accuracy: 1.0000 - val_loss: 0.7494 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4101/5000\n",
            "\n",
            "Epoch 4101: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5340e-04 - accuracy: 1.0000 - val_loss: 0.7453 - val_accuracy: 0.8453 - 4s/epoch - 116ms/step\n",
            "Epoch 4102/5000\n",
            "\n",
            "Epoch 4102: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5979e-04 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.8489 - 3s/epoch - 73ms/step\n",
            "Epoch 4103/5000\n",
            "\n",
            "Epoch 4103: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6021e-04 - accuracy: 1.0000 - val_loss: 0.7458 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4104/5000\n",
            "\n",
            "Epoch 4104: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5641e-04 - accuracy: 1.0000 - val_loss: 0.7431 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4105/5000\n",
            "\n",
            "Epoch 4105: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5629e-04 - accuracy: 1.0000 - val_loss: 0.7441 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4106/5000\n",
            "\n",
            "Epoch 4106: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7309e-04 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.8453 - 4s/epoch - 119ms/step\n",
            "Epoch 4107/5000\n",
            "\n",
            "Epoch 4107: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6798e-04 - accuracy: 1.0000 - val_loss: 0.7930 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4108/5000\n",
            "\n",
            "Epoch 4108: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5913e-04 - accuracy: 1.0000 - val_loss: 0.7522 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4109/5000\n",
            "\n",
            "Epoch 4109: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5769e-04 - accuracy: 1.0000 - val_loss: 0.7527 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4110/5000\n",
            "\n",
            "Epoch 4110: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5865e-04 - accuracy: 1.0000 - val_loss: 0.7449 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 4111/5000\n",
            "\n",
            "Epoch 4111: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5547e-04 - accuracy: 1.0000 - val_loss: 0.7444 - val_accuracy: 0.8453 - 4s/epoch - 115ms/step\n",
            "Epoch 4112/5000\n",
            "\n",
            "Epoch 4112: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5120e-04 - accuracy: 1.0000 - val_loss: 0.7431 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4113/5000\n",
            "\n",
            "Epoch 4113: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5549e-04 - accuracy: 1.0000 - val_loss: 0.7458 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4114/5000\n",
            "\n",
            "Epoch 4114: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5800e-04 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4115/5000\n",
            "\n",
            "Epoch 4115: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5827e-04 - accuracy: 1.0000 - val_loss: 0.7537 - val_accuracy: 0.8417 - 3s/epoch - 82ms/step\n",
            "Epoch 4116/5000\n",
            "\n",
            "Epoch 4116: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.6054e-04 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8417 - 4s/epoch - 108ms/step\n",
            "Epoch 4117/5000\n",
            "\n",
            "Epoch 4117: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5206e-04 - accuracy: 1.0000 - val_loss: 0.7556 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4118/5000\n",
            "\n",
            "Epoch 4118: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5301e-04 - accuracy: 1.0000 - val_loss: 0.7479 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4119/5000\n",
            "\n",
            "Epoch 4119: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6219e-04 - accuracy: 1.0000 - val_loss: 0.7274 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4120/5000\n",
            "\n",
            "Epoch 4120: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5489e-04 - accuracy: 1.0000 - val_loss: 0.7314 - val_accuracy: 0.8453 - 3s/epoch - 87ms/step\n",
            "Epoch 4121/5000\n",
            "\n",
            "Epoch 4121: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5920e-04 - accuracy: 1.0000 - val_loss: 0.7432 - val_accuracy: 0.8453 - 4s/epoch - 101ms/step\n",
            "Epoch 4122/5000\n",
            "\n",
            "Epoch 4122: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5873e-04 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4123/5000\n",
            "\n",
            "Epoch 4123: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5578e-04 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4124/5000\n",
            "\n",
            "Epoch 4124: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5467e-04 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4125/5000\n",
            "\n",
            "Epoch 4125: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5159e-04 - accuracy: 1.0000 - val_loss: 0.7423 - val_accuracy: 0.8453 - 3s/epoch - 95ms/step\n",
            "Epoch 4126/5000\n",
            "\n",
            "Epoch 4126: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5854e-04 - accuracy: 1.0000 - val_loss: 0.7376 - val_accuracy: 0.8453 - 3s/epoch - 95ms/step\n",
            "Epoch 4127/5000\n",
            "\n",
            "Epoch 4127: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5477e-04 - accuracy: 1.0000 - val_loss: 0.7390 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4128/5000\n",
            "\n",
            "Epoch 4128: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4941e-04 - accuracy: 1.0000 - val_loss: 0.7448 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4129/5000\n",
            "\n",
            "Epoch 4129: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5678e-04 - accuracy: 1.0000 - val_loss: 0.7386 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4130/5000\n",
            "\n",
            "Epoch 4130: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5664e-04 - accuracy: 1.0000 - val_loss: 0.7285 - val_accuracy: 0.8525 - 4s/epoch - 100ms/step\n",
            "Epoch 4131/5000\n",
            "\n",
            "Epoch 4131: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6276e-04 - accuracy: 1.0000 - val_loss: 0.7370 - val_accuracy: 0.8453 - 3s/epoch - 90ms/step\n",
            "Epoch 4132/5000\n",
            "\n",
            "Epoch 4132: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5537e-04 - accuracy: 1.0000 - val_loss: 0.7498 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4133/5000\n",
            "\n",
            "Epoch 4133: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5536e-04 - accuracy: 1.0000 - val_loss: 0.7443 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4134/5000\n",
            "\n",
            "Epoch 4134: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5469e-04 - accuracy: 1.0000 - val_loss: 0.7401 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 4135/5000\n",
            "\n",
            "Epoch 4135: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5380e-04 - accuracy: 1.0000 - val_loss: 0.7373 - val_accuracy: 0.8489 - 4s/epoch - 108ms/step\n",
            "Epoch 4136/5000\n",
            "\n",
            "Epoch 4136: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5888e-04 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.8453 - 3s/epoch - 83ms/step\n",
            "Epoch 4137/5000\n",
            "\n",
            "Epoch 4137: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5712e-04 - accuracy: 1.0000 - val_loss: 0.7295 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4138/5000\n",
            "\n",
            "Epoch 4138: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5470e-04 - accuracy: 1.0000 - val_loss: 0.7382 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4139/5000\n",
            "\n",
            "Epoch 4139: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5881e-04 - accuracy: 1.0000 - val_loss: 0.7399 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4140/5000\n",
            "\n",
            "Epoch 4140: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5536e-04 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.8417 - 4s/epoch - 115ms/step\n",
            "Epoch 4141/5000\n",
            "\n",
            "Epoch 4141: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5581e-04 - accuracy: 1.0000 - val_loss: 0.7661 - val_accuracy: 0.8273 - 3s/epoch - 74ms/step\n",
            "Epoch 4142/5000\n",
            "\n",
            "Epoch 4142: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.6536e-04 - accuracy: 1.0000 - val_loss: 0.7872 - val_accuracy: 0.8345 - 2s/epoch - 70ms/step\n",
            "Epoch 4143/5000\n",
            "\n",
            "Epoch 4143: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5826e-04 - accuracy: 1.0000 - val_loss: 0.7360 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4144/5000\n",
            "\n",
            "Epoch 4144: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5360e-04 - accuracy: 1.0000 - val_loss: 0.7426 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4145/5000\n",
            "\n",
            "Epoch 4145: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5853e-04 - accuracy: 1.0000 - val_loss: 0.7759 - val_accuracy: 0.8381 - 4s/epoch - 118ms/step\n",
            "Epoch 4146/5000\n",
            "\n",
            "Epoch 4146: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5786e-04 - accuracy: 1.0000 - val_loss: 0.7640 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 4147/5000\n",
            "\n",
            "Epoch 4147: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5882e-04 - accuracy: 1.0000 - val_loss: 0.7547 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4148/5000\n",
            "\n",
            "Epoch 4148: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5050e-04 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4149/5000\n",
            "\n",
            "Epoch 4149: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5302e-04 - accuracy: 1.0000 - val_loss: 0.7428 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4150/5000\n",
            "\n",
            "Epoch 4150: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5486e-04 - accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.8417 - 4s/epoch - 118ms/step\n",
            "Epoch 4151/5000\n",
            "\n",
            "Epoch 4151: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5277e-04 - accuracy: 1.0000 - val_loss: 0.7484 - val_accuracy: 0.8489 - 3s/epoch - 71ms/step\n",
            "Epoch 4152/5000\n",
            "\n",
            "Epoch 4152: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5647e-04 - accuracy: 1.0000 - val_loss: 0.7529 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4153/5000\n",
            "\n",
            "Epoch 4153: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5383e-04 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4154/5000\n",
            "\n",
            "Epoch 4154: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4948e-04 - accuracy: 1.0000 - val_loss: 0.7527 - val_accuracy: 0.8453 - 3s/epoch - 79ms/step\n",
            "Epoch 4155/5000\n",
            "\n",
            "Epoch 4155: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4989e-04 - accuracy: 1.0000 - val_loss: 0.7628 - val_accuracy: 0.8453 - 4s/epoch - 110ms/step\n",
            "Epoch 4156/5000\n",
            "\n",
            "Epoch 4156: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4554e-04 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4157/5000\n",
            "\n",
            "Epoch 4157: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5217e-04 - accuracy: 1.0000 - val_loss: 0.7526 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4158/5000\n",
            "\n",
            "Epoch 4158: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5021e-04 - accuracy: 1.0000 - val_loss: 0.7491 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4159/5000\n",
            "\n",
            "Epoch 4159: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4907e-04 - accuracy: 1.0000 - val_loss: 0.7628 - val_accuracy: 0.8453 - 3s/epoch - 88ms/step\n",
            "Epoch 4160/5000\n",
            "\n",
            "Epoch 4160: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5539e-04 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.8381 - 4s/epoch - 102ms/step\n",
            "Epoch 4161/5000\n",
            "\n",
            "Epoch 4161: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5576e-04 - accuracy: 1.0000 - val_loss: 0.7485 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4162/5000\n",
            "\n",
            "Epoch 4162: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4987e-04 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4163/5000\n",
            "\n",
            "Epoch 4163: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4951e-04 - accuracy: 1.0000 - val_loss: 0.7585 - val_accuracy: 0.8345 - 2s/epoch - 70ms/step\n",
            "Epoch 4164/5000\n",
            "\n",
            "Epoch 4164: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5039e-04 - accuracy: 1.0000 - val_loss: 0.7464 - val_accuracy: 0.8345 - 3s/epoch - 91ms/step\n",
            "Epoch 4165/5000\n",
            "\n",
            "Epoch 4165: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5360e-04 - accuracy: 1.0000 - val_loss: 0.7463 - val_accuracy: 0.8381 - 3s/epoch - 97ms/step\n",
            "Epoch 4166/5000\n",
            "\n",
            "Epoch 4166: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5161e-04 - accuracy: 1.0000 - val_loss: 0.7554 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4167/5000\n",
            "\n",
            "Epoch 4167: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5064e-04 - accuracy: 1.0000 - val_loss: 0.7436 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4168/5000\n",
            "\n",
            "Epoch 4168: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5227e-04 - accuracy: 1.0000 - val_loss: 0.7424 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4169/5000\n",
            "\n",
            "Epoch 4169: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4925e-04 - accuracy: 1.0000 - val_loss: 0.7460 - val_accuracy: 0.8489 - 4s/epoch - 103ms/step\n",
            "Epoch 4170/5000\n",
            "\n",
            "Epoch 4170: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4893e-04 - accuracy: 1.0000 - val_loss: 0.7498 - val_accuracy: 0.8489 - 3s/epoch - 88ms/step\n",
            "Epoch 4171/5000\n",
            "\n",
            "Epoch 4171: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5353e-04 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4172/5000\n",
            "\n",
            "Epoch 4172: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4556e-04 - accuracy: 1.0000 - val_loss: 0.7478 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4173/5000\n",
            "\n",
            "Epoch 4173: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4878e-04 - accuracy: 1.0000 - val_loss: 0.7371 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4174/5000\n",
            "\n",
            "Epoch 4174: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5092e-04 - accuracy: 1.0000 - val_loss: 0.7664 - val_accuracy: 0.8381 - 4s/epoch - 108ms/step\n",
            "Epoch 4175/5000\n",
            "\n",
            "Epoch 4175: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4748e-04 - accuracy: 1.0000 - val_loss: 0.7598 - val_accuracy: 0.8345 - 3s/epoch - 83ms/step\n",
            "Epoch 4176/5000\n",
            "\n",
            "Epoch 4176: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4616e-04 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4177/5000\n",
            "\n",
            "Epoch 4177: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4644e-04 - accuracy: 1.0000 - val_loss: 0.7462 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4178/5000\n",
            "\n",
            "Epoch 4178: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4985e-04 - accuracy: 1.0000 - val_loss: 0.7376 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4179/5000\n",
            "\n",
            "Epoch 4179: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4729e-04 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.8381 - 4s/epoch - 118ms/step\n",
            "Epoch 4180/5000\n",
            "\n",
            "Epoch 4180: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4922e-04 - accuracy: 1.0000 - val_loss: 0.7434 - val_accuracy: 0.8417 - 3s/epoch - 73ms/step\n",
            "Epoch 4181/5000\n",
            "\n",
            "Epoch 4181: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4982e-04 - accuracy: 1.0000 - val_loss: 0.7489 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4182/5000\n",
            "\n",
            "Epoch 4182: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5322e-04 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4183/5000\n",
            "\n",
            "Epoch 4183: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4899e-04 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4184/5000\n",
            "\n",
            "Epoch 4184: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4797e-04 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.8453 - 4s/epoch - 120ms/step\n",
            "Epoch 4185/5000\n",
            "\n",
            "Epoch 4185: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4958e-04 - accuracy: 1.0000 - val_loss: 0.7411 - val_accuracy: 0.8525 - 3s/epoch - 72ms/step\n",
            "Epoch 4186/5000\n",
            "\n",
            "Epoch 4186: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4950e-04 - accuracy: 1.0000 - val_loss: 0.7396 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4187/5000\n",
            "\n",
            "Epoch 4187: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4373e-04 - accuracy: 1.0000 - val_loss: 0.7430 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4188/5000\n",
            "\n",
            "Epoch 4188: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4347e-04 - accuracy: 1.0000 - val_loss: 0.7478 - val_accuracy: 0.8417 - 3s/epoch - 79ms/step\n",
            "Epoch 4189/5000\n",
            "\n",
            "Epoch 4189: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4319e-04 - accuracy: 1.0000 - val_loss: 0.7426 - val_accuracy: 0.8525 - 4s/epoch - 113ms/step\n",
            "Epoch 4190/5000\n",
            "\n",
            "Epoch 4190: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4408e-04 - accuracy: 1.0000 - val_loss: 0.7408 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4191/5000\n",
            "\n",
            "Epoch 4191: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4621e-04 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4192/5000\n",
            "\n",
            "Epoch 4192: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4665e-04 - accuracy: 1.0000 - val_loss: 0.7544 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4193/5000\n",
            "\n",
            "Epoch 4193: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5393e-04 - accuracy: 1.0000 - val_loss: 0.7545 - val_accuracy: 0.8417 - 3s/epoch - 87ms/step\n",
            "Epoch 4194/5000\n",
            "\n",
            "Epoch 4194: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4797e-04 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.8417 - 4s/epoch - 104ms/step\n",
            "Epoch 4195/5000\n",
            "\n",
            "Epoch 4195: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4562e-04 - accuracy: 1.0000 - val_loss: 0.7524 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4196/5000\n",
            "\n",
            "Epoch 4196: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4692e-04 - accuracy: 1.0000 - val_loss: 0.7468 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4197/5000\n",
            "\n",
            "Epoch 4197: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4667e-04 - accuracy: 1.0000 - val_loss: 0.7521 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4198/5000\n",
            "\n",
            "Epoch 4198: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4406e-04 - accuracy: 1.0000 - val_loss: 0.7547 - val_accuracy: 0.8489 - 3s/epoch - 97ms/step\n",
            "Epoch 4199/5000\n",
            "\n",
            "Epoch 4199: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4339e-04 - accuracy: 1.0000 - val_loss: 0.7527 - val_accuracy: 0.8453 - 3s/epoch - 95ms/step\n",
            "Epoch 4200/5000\n",
            "\n",
            "Epoch 4200: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4672e-04 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 4201/5000\n",
            "\n",
            "Epoch 4201: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4301e-04 - accuracy: 1.0000 - val_loss: 0.7394 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4202/5000\n",
            "\n",
            "Epoch 4202: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4759e-04 - accuracy: 1.0000 - val_loss: 0.7460 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4203/5000\n",
            "\n",
            "Epoch 4203: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4397e-04 - accuracy: 1.0000 - val_loss: 0.7384 - val_accuracy: 0.8525 - 4s/epoch - 104ms/step\n",
            "Epoch 4204/5000\n",
            "\n",
            "Epoch 4204: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4679e-04 - accuracy: 1.0000 - val_loss: 0.7400 - val_accuracy: 0.8489 - 3s/epoch - 87ms/step\n",
            "Epoch 4205/5000\n",
            "\n",
            "Epoch 4205: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4762e-04 - accuracy: 1.0000 - val_loss: 0.7582 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4206/5000\n",
            "\n",
            "Epoch 4206: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4651e-04 - accuracy: 1.0000 - val_loss: 0.7490 - val_accuracy: 0.8489 - 3s/epoch - 71ms/step\n",
            "Epoch 4207/5000\n",
            "\n",
            "Epoch 4207: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4843e-04 - accuracy: 1.0000 - val_loss: 0.7467 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4208/5000\n",
            "\n",
            "Epoch 4208: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4783e-04 - accuracy: 1.0000 - val_loss: 0.7487 - val_accuracy: 0.8453 - 4s/epoch - 116ms/step\n",
            "Epoch 4209/5000\n",
            "\n",
            "Epoch 4209: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3990e-04 - accuracy: 1.0000 - val_loss: 0.7421 - val_accuracy: 0.8417 - 3s/epoch - 77ms/step\n",
            "Epoch 4210/5000\n",
            "\n",
            "Epoch 4210: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.6150e-04 - accuracy: 1.0000 - val_loss: 0.7487 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 4211/5000\n",
            "\n",
            "Epoch 4211: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4969e-04 - accuracy: 1.0000 - val_loss: 0.7265 - val_accuracy: 0.8489 - 3s/epoch - 73ms/step\n",
            "Epoch 4212/5000\n",
            "\n",
            "Epoch 4212: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4618e-04 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4213/5000\n",
            "\n",
            "Epoch 4213: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5130e-04 - accuracy: 1.0000 - val_loss: 0.7903 - val_accuracy: 0.8417 - 4s/epoch - 120ms/step\n",
            "Epoch 4214/5000\n",
            "\n",
            "Epoch 4214: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5251e-04 - accuracy: 1.0000 - val_loss: 0.7450 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4215/5000\n",
            "\n",
            "Epoch 4215: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4083e-04 - accuracy: 1.0000 - val_loss: 0.7433 - val_accuracy: 0.8525 - 3s/epoch - 72ms/step\n",
            "Epoch 4216/5000\n",
            "\n",
            "Epoch 4216: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4188e-04 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.8525 - 3s/epoch - 72ms/step\n",
            "Epoch 4217/5000\n",
            "\n",
            "Epoch 4217: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4854e-04 - accuracy: 1.0000 - val_loss: 0.7669 - val_accuracy: 0.8489 - 3s/epoch - 81ms/step\n",
            "Epoch 4218/5000\n",
            "\n",
            "Epoch 4218: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4242e-04 - accuracy: 1.0000 - val_loss: 0.7705 - val_accuracy: 0.8489 - 4s/epoch - 112ms/step\n",
            "Epoch 4219/5000\n",
            "\n",
            "Epoch 4219: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4498e-04 - accuracy: 1.0000 - val_loss: 0.7543 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4220/5000\n",
            "\n",
            "Epoch 4220: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4457e-04 - accuracy: 1.0000 - val_loss: 0.7509 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4221/5000\n",
            "\n",
            "Epoch 4221: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4096e-04 - accuracy: 1.0000 - val_loss: 0.7569 - val_accuracy: 0.8525 - 3s/epoch - 72ms/step\n",
            "Epoch 4222/5000\n",
            "\n",
            "Epoch 4222: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4218e-04 - accuracy: 1.0000 - val_loss: 0.7510 - val_accuracy: 0.8489 - 3s/epoch - 91ms/step\n",
            "Epoch 4223/5000\n",
            "\n",
            "Epoch 4223: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4271e-04 - accuracy: 1.0000 - val_loss: 0.7573 - val_accuracy: 0.8525 - 4s/epoch - 100ms/step\n",
            "Epoch 4224/5000\n",
            "\n",
            "Epoch 4224: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4407e-04 - accuracy: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4225/5000\n",
            "\n",
            "Epoch 4225: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4441e-04 - accuracy: 1.0000 - val_loss: 0.7591 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4226/5000\n",
            "\n",
            "Epoch 4226: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4215e-04 - accuracy: 1.0000 - val_loss: 0.7461 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 4227/5000\n",
            "\n",
            "Epoch 4227: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4287e-04 - accuracy: 1.0000 - val_loss: 0.7482 - val_accuracy: 0.8489 - 3s/epoch - 98ms/step\n",
            "Epoch 4228/5000\n",
            "\n",
            "Epoch 4228: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3929e-04 - accuracy: 1.0000 - val_loss: 0.7453 - val_accuracy: 0.8489 - 3s/epoch - 93ms/step\n",
            "Epoch 4229/5000\n",
            "\n",
            "Epoch 4229: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4036e-04 - accuracy: 1.0000 - val_loss: 0.7390 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4230/5000\n",
            "\n",
            "Epoch 4230: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4447e-04 - accuracy: 1.0000 - val_loss: 0.7575 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4231/5000\n",
            "\n",
            "Epoch 4231: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4453e-04 - accuracy: 1.0000 - val_loss: 0.7519 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4232/5000\n",
            "\n",
            "Epoch 4232: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4289e-04 - accuracy: 1.0000 - val_loss: 0.7572 - val_accuracy: 0.8417 - 4s/epoch - 108ms/step\n",
            "Epoch 4233/5000\n",
            "\n",
            "Epoch 4233: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4372e-04 - accuracy: 1.0000 - val_loss: 0.7576 - val_accuracy: 0.8453 - 3s/epoch - 83ms/step\n",
            "Epoch 4234/5000\n",
            "\n",
            "Epoch 4234: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4370e-04 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4235/5000\n",
            "\n",
            "Epoch 4235: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4105e-04 - accuracy: 1.0000 - val_loss: 0.7461 - val_accuracy: 0.8453 - 3s/epoch - 73ms/step\n",
            "Epoch 4236/5000\n",
            "\n",
            "Epoch 4236: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4081e-04 - accuracy: 1.0000 - val_loss: 0.7441 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 4237/5000\n",
            "\n",
            "Epoch 4237: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4934e-04 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.8489 - 4s/epoch - 120ms/step\n",
            "Epoch 4238/5000\n",
            "\n",
            "Epoch 4238: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4486e-04 - accuracy: 1.0000 - val_loss: 0.7544 - val_accuracy: 0.8489 - 3s/epoch - 73ms/step\n",
            "Epoch 4239/5000\n",
            "\n",
            "Epoch 4239: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4119e-04 - accuracy: 1.0000 - val_loss: 0.7464 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4240/5000\n",
            "\n",
            "Epoch 4240: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3970e-04 - accuracy: 1.0000 - val_loss: 0.7460 - val_accuracy: 0.8489 - 3s/epoch - 71ms/step\n",
            "Epoch 4241/5000\n",
            "\n",
            "Epoch 4241: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3565e-04 - accuracy: 1.0000 - val_loss: 0.7424 - val_accuracy: 0.8453 - 3s/epoch - 77ms/step\n",
            "Epoch 4242/5000\n",
            "\n",
            "Epoch 4242: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4172e-04 - accuracy: 1.0000 - val_loss: 0.7348 - val_accuracy: 0.8489 - 4s/epoch - 117ms/step\n",
            "Epoch 4243/5000\n",
            "\n",
            "Epoch 4243: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3670e-04 - accuracy: 1.0000 - val_loss: 0.7320 - val_accuracy: 0.8525 - 3s/epoch - 72ms/step\n",
            "Epoch 4244/5000\n",
            "\n",
            "Epoch 4244: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4664e-04 - accuracy: 1.0000 - val_loss: 0.7830 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 4245/5000\n",
            "\n",
            "Epoch 4245: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3937e-04 - accuracy: 1.0000 - val_loss: 0.7602 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 4246/5000\n",
            "\n",
            "Epoch 4246: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3913e-04 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.8381 - 3s/epoch - 85ms/step\n",
            "Epoch 4247/5000\n",
            "\n",
            "Epoch 4247: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3975e-04 - accuracy: 1.0000 - val_loss: 0.7494 - val_accuracy: 0.8381 - 4s/epoch - 106ms/step\n",
            "Epoch 4248/5000\n",
            "\n",
            "Epoch 4248: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3985e-04 - accuracy: 1.0000 - val_loss: 0.7453 - val_accuracy: 0.8381 - 3s/epoch - 73ms/step\n",
            "Epoch 4249/5000\n",
            "\n",
            "Epoch 4249: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4229e-04 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4250/5000\n",
            "\n",
            "Epoch 4250: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3652e-04 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4251/5000\n",
            "\n",
            "Epoch 4251: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4059e-04 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.8381 - 3s/epoch - 95ms/step\n",
            "Epoch 4252/5000\n",
            "\n",
            "Epoch 4252: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4091e-04 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.8489 - 3s/epoch - 96ms/step\n",
            "Epoch 4253/5000\n",
            "\n",
            "Epoch 4253: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3818e-04 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4254/5000\n",
            "\n",
            "Epoch 4254: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3638e-04 - accuracy: 1.0000 - val_loss: 0.7472 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4255/5000\n",
            "\n",
            "Epoch 4255: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4031e-04 - accuracy: 1.0000 - val_loss: 0.7605 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4256/5000\n",
            "\n",
            "Epoch 4256: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3874e-04 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.8525 - 4s/epoch - 104ms/step\n",
            "Epoch 4257/5000\n",
            "\n",
            "Epoch 4257: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3881e-04 - accuracy: 1.0000 - val_loss: 0.7693 - val_accuracy: 0.8453 - 3s/epoch - 86ms/step\n",
            "Epoch 4258/5000\n",
            "\n",
            "Epoch 4258: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4070e-04 - accuracy: 1.0000 - val_loss: 0.7714 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4259/5000\n",
            "\n",
            "Epoch 4259: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3570e-04 - accuracy: 1.0000 - val_loss: 0.7564 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4260/5000\n",
            "\n",
            "Epoch 4260: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4245e-04 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4261/5000\n",
            "\n",
            "Epoch 4261: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3736e-04 - accuracy: 1.0000 - val_loss: 0.7454 - val_accuracy: 0.8489 - 4s/epoch - 114ms/step\n",
            "Epoch 4262/5000\n",
            "\n",
            "Epoch 4262: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3824e-04 - accuracy: 1.0000 - val_loss: 0.7509 - val_accuracy: 0.8309 - 3s/epoch - 75ms/step\n",
            "Epoch 4263/5000\n",
            "\n",
            "Epoch 4263: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3805e-04 - accuracy: 1.0000 - val_loss: 0.7655 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4264/5000\n",
            "\n",
            "Epoch 4264: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3814e-04 - accuracy: 1.0000 - val_loss: 0.7470 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4265/5000\n",
            "\n",
            "Epoch 4265: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3796e-04 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4266/5000\n",
            "\n",
            "Epoch 4266: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3922e-04 - accuracy: 1.0000 - val_loss: 0.7475 - val_accuracy: 0.8453 - 4s/epoch - 118ms/step\n",
            "Epoch 4267/5000\n",
            "\n",
            "Epoch 4267: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3824e-04 - accuracy: 1.0000 - val_loss: 0.7411 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4268/5000\n",
            "\n",
            "Epoch 4268: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3734e-04 - accuracy: 1.0000 - val_loss: 0.7431 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4269/5000\n",
            "\n",
            "Epoch 4269: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3934e-04 - accuracy: 1.0000 - val_loss: 0.7478 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4270/5000\n",
            "\n",
            "Epoch 4270: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3918e-04 - accuracy: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4271/5000\n",
            "\n",
            "Epoch 4271: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3645e-04 - accuracy: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.8381 - 4s/epoch - 118ms/step\n",
            "Epoch 4272/5000\n",
            "\n",
            "Epoch 4272: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3466e-04 - accuracy: 1.0000 - val_loss: 0.7566 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4273/5000\n",
            "\n",
            "Epoch 4273: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3823e-04 - accuracy: 1.0000 - val_loss: 0.7551 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4274/5000\n",
            "\n",
            "Epoch 4274: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3661e-04 - accuracy: 1.0000 - val_loss: 0.7503 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4275/5000\n",
            "\n",
            "Epoch 4275: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3270e-04 - accuracy: 1.0000 - val_loss: 0.7512 - val_accuracy: 0.8417 - 3s/epoch - 79ms/step\n",
            "Epoch 4276/5000\n",
            "\n",
            "Epoch 4276: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3449e-04 - accuracy: 1.0000 - val_loss: 0.7510 - val_accuracy: 0.8345 - 4s/epoch - 111ms/step\n",
            "Epoch 4277/5000\n",
            "\n",
            "Epoch 4277: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3593e-04 - accuracy: 1.0000 - val_loss: 0.7494 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4278/5000\n",
            "\n",
            "Epoch 4278: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4174e-04 - accuracy: 1.0000 - val_loss: 0.7384 - val_accuracy: 0.8525 - 3s/epoch - 72ms/step\n",
            "Epoch 4279/5000\n",
            "\n",
            "Epoch 4279: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3715e-04 - accuracy: 1.0000 - val_loss: 0.7383 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4280/5000\n",
            "\n",
            "Epoch 4280: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3543e-04 - accuracy: 1.0000 - val_loss: 0.7424 - val_accuracy: 0.8453 - 3s/epoch - 88ms/step\n",
            "Epoch 4281/5000\n",
            "\n",
            "Epoch 4281: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3597e-04 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.8453 - 4s/epoch - 101ms/step\n",
            "Epoch 4282/5000\n",
            "\n",
            "Epoch 4282: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3677e-04 - accuracy: 1.0000 - val_loss: 0.7765 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4283/5000\n",
            "\n",
            "Epoch 4283: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3437e-04 - accuracy: 1.0000 - val_loss: 0.7780 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4284/5000\n",
            "\n",
            "Epoch 4284: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3436e-04 - accuracy: 1.0000 - val_loss: 0.7689 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4285/5000\n",
            "\n",
            "Epoch 4285: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3276e-04 - accuracy: 1.0000 - val_loss: 0.7481 - val_accuracy: 0.8381 - 3s/epoch - 95ms/step\n",
            "Epoch 4286/5000\n",
            "\n",
            "Epoch 4286: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3613e-04 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.8453 - 3s/epoch - 94ms/step\n",
            "Epoch 4287/5000\n",
            "\n",
            "Epoch 4287: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3371e-04 - accuracy: 1.0000 - val_loss: 0.7494 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 4288/5000\n",
            "\n",
            "Epoch 4288: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3751e-04 - accuracy: 1.0000 - val_loss: 0.7764 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4289/5000\n",
            "\n",
            "Epoch 4289: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3810e-04 - accuracy: 1.0000 - val_loss: 0.7725 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4290/5000\n",
            "\n",
            "Epoch 4290: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3387e-04 - accuracy: 1.0000 - val_loss: 0.7627 - val_accuracy: 0.8453 - 4s/epoch - 100ms/step\n",
            "Epoch 4291/5000\n",
            "\n",
            "Epoch 4291: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3239e-04 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.8453 - 3s/epoch - 89ms/step\n",
            "Epoch 4292/5000\n",
            "\n",
            "Epoch 4292: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3367e-04 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4293/5000\n",
            "\n",
            "Epoch 4293: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3725e-04 - accuracy: 1.0000 - val_loss: 0.7828 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4294/5000\n",
            "\n",
            "Epoch 4294: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3638e-04 - accuracy: 1.0000 - val_loss: 0.7454 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4295/5000\n",
            "\n",
            "Epoch 4295: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3323e-04 - accuracy: 1.0000 - val_loss: 0.7576 - val_accuracy: 0.8417 - 4s/epoch - 109ms/step\n",
            "Epoch 4296/5000\n",
            "\n",
            "Epoch 4296: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3822e-04 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.8489 - 3s/epoch - 82ms/step\n",
            "Epoch 4297/5000\n",
            "\n",
            "Epoch 4297: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3876e-04 - accuracy: 1.0000 - val_loss: 0.7715 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 4298/5000\n",
            "\n",
            "Epoch 4298: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3406e-04 - accuracy: 1.0000 - val_loss: 0.7638 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4299/5000\n",
            "\n",
            "Epoch 4299: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3296e-04 - accuracy: 1.0000 - val_loss: 0.7600 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4300/5000\n",
            "\n",
            "Epoch 4300: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.4076e-04 - accuracy: 1.0000 - val_loss: 0.7729 - val_accuracy: 0.8345 - 4s/epoch - 116ms/step\n",
            "Epoch 4301/5000\n",
            "\n",
            "Epoch 4301: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3155e-04 - accuracy: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.8417 - 3s/epoch - 75ms/step\n",
            "Epoch 4302/5000\n",
            "\n",
            "Epoch 4302: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3191e-04 - accuracy: 1.0000 - val_loss: 0.7618 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4303/5000\n",
            "\n",
            "Epoch 4303: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3377e-04 - accuracy: 1.0000 - val_loss: 0.7716 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4304/5000\n",
            "\n",
            "Epoch 4304: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3605e-04 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4305/5000\n",
            "\n",
            "Epoch 4305: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3286e-04 - accuracy: 1.0000 - val_loss: 0.7617 - val_accuracy: 0.8453 - 4s/epoch - 119ms/step\n",
            "Epoch 4306/5000\n",
            "\n",
            "Epoch 4306: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3140e-04 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4307/5000\n",
            "\n",
            "Epoch 4307: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3212e-04 - accuracy: 1.0000 - val_loss: 0.7600 - val_accuracy: 0.8453 - 3s/epoch - 71ms/step\n",
            "Epoch 4308/5000\n",
            "\n",
            "Epoch 4308: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3077e-04 - accuracy: 1.0000 - val_loss: 0.7444 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4309/5000\n",
            "\n",
            "Epoch 4309: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3087e-04 - accuracy: 1.0000 - val_loss: 0.7573 - val_accuracy: 0.8489 - 3s/epoch - 80ms/step\n",
            "Epoch 4310/5000\n",
            "\n",
            "Epoch 4310: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3273e-04 - accuracy: 1.0000 - val_loss: 0.7645 - val_accuracy: 0.8453 - 4s/epoch - 109ms/step\n",
            "Epoch 4311/5000\n",
            "\n",
            "Epoch 4311: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3704e-04 - accuracy: 1.0000 - val_loss: 0.7746 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4312/5000\n",
            "\n",
            "Epoch 4312: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3196e-04 - accuracy: 1.0000 - val_loss: 0.7711 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4313/5000\n",
            "\n",
            "Epoch 4313: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3495e-04 - accuracy: 1.0000 - val_loss: 0.7474 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4314/5000\n",
            "\n",
            "Epoch 4314: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2997e-04 - accuracy: 1.0000 - val_loss: 0.7539 - val_accuracy: 0.8453 - 3s/epoch - 88ms/step\n",
            "Epoch 4315/5000\n",
            "\n",
            "Epoch 4315: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2894e-04 - accuracy: 1.0000 - val_loss: 0.7626 - val_accuracy: 0.8453 - 4s/epoch - 102ms/step\n",
            "Epoch 4316/5000\n",
            "\n",
            "Epoch 4316: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3135e-04 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4317/5000\n",
            "\n",
            "Epoch 4317: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3025e-04 - accuracy: 1.0000 - val_loss: 0.7716 - val_accuracy: 0.8525 - 3s/epoch - 72ms/step\n",
            "Epoch 4318/5000\n",
            "\n",
            "Epoch 4318: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3625e-04 - accuracy: 1.0000 - val_loss: 0.7764 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4319/5000\n",
            "\n",
            "Epoch 4319: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3349e-04 - accuracy: 1.0000 - val_loss: 0.7493 - val_accuracy: 0.8453 - 3s/epoch - 96ms/step\n",
            "Epoch 4320/5000\n",
            "\n",
            "Epoch 4320: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2962e-04 - accuracy: 1.0000 - val_loss: 0.7626 - val_accuracy: 0.8381 - 3s/epoch - 94ms/step\n",
            "Epoch 4321/5000\n",
            "\n",
            "Epoch 4321: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2702e-04 - accuracy: 1.0000 - val_loss: 0.7433 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4322/5000\n",
            "\n",
            "Epoch 4322: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3100e-04 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4323/5000\n",
            "\n",
            "Epoch 4323: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3344e-04 - accuracy: 1.0000 - val_loss: 0.7526 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4324/5000\n",
            "\n",
            "Epoch 4324: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3470e-04 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.8489 - 4s/epoch - 105ms/step\n",
            "Epoch 4325/5000\n",
            "\n",
            "Epoch 4325: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3004e-04 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.8453 - 3s/epoch - 85ms/step\n",
            "Epoch 4326/5000\n",
            "\n",
            "Epoch 4326: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2898e-04 - accuracy: 1.0000 - val_loss: 0.7569 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4327/5000\n",
            "\n",
            "Epoch 4327: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3154e-04 - accuracy: 1.0000 - val_loss: 0.7555 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4328/5000\n",
            "\n",
            "Epoch 4328: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3388e-04 - accuracy: 1.0000 - val_loss: 0.7518 - val_accuracy: 0.8489 - 3s/epoch - 74ms/step\n",
            "Epoch 4329/5000\n",
            "\n",
            "Epoch 4329: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3306e-04 - accuracy: 1.0000 - val_loss: 0.7747 - val_accuracy: 0.8381 - 4s/epoch - 119ms/step\n",
            "Epoch 4330/5000\n",
            "\n",
            "Epoch 4330: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3306e-04 - accuracy: 1.0000 - val_loss: 0.7445 - val_accuracy: 0.8381 - 3s/epoch - 73ms/step\n",
            "Epoch 4331/5000\n",
            "\n",
            "Epoch 4331: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3434e-04 - accuracy: 1.0000 - val_loss: 0.7651 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4332/5000\n",
            "\n",
            "Epoch 4332: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3265e-04 - accuracy: 1.0000 - val_loss: 0.7739 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4333/5000\n",
            "\n",
            "Epoch 4333: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2984e-04 - accuracy: 1.0000 - val_loss: 0.7696 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4334/5000\n",
            "\n",
            "Epoch 4334: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3401e-04 - accuracy: 1.0000 - val_loss: 0.7669 - val_accuracy: 0.8417 - 4s/epoch - 118ms/step\n",
            "Epoch 4335/5000\n",
            "\n",
            "Epoch 4335: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3206e-04 - accuracy: 1.0000 - val_loss: 0.7719 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4336/5000\n",
            "\n",
            "Epoch 4336: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3045e-04 - accuracy: 1.0000 - val_loss: 0.7642 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4337/5000\n",
            "\n",
            "Epoch 4337: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2845e-04 - accuracy: 1.0000 - val_loss: 0.7584 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4338/5000\n",
            "\n",
            "Epoch 4338: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2871e-04 - accuracy: 1.0000 - val_loss: 0.7472 - val_accuracy: 0.8489 - 3s/epoch - 76ms/step\n",
            "Epoch 4339/5000\n",
            "\n",
            "Epoch 4339: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3013e-04 - accuracy: 1.0000 - val_loss: 0.7481 - val_accuracy: 0.8381 - 4s/epoch - 116ms/step\n",
            "Epoch 4340/5000\n",
            "\n",
            "Epoch 4340: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2985e-04 - accuracy: 1.0000 - val_loss: 0.7474 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 4341/5000\n",
            "\n",
            "Epoch 4341: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2970e-04 - accuracy: 1.0000 - val_loss: 0.7458 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4342/5000\n",
            "\n",
            "Epoch 4342: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2674e-04 - accuracy: 1.0000 - val_loss: 0.7490 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4343/5000\n",
            "\n",
            "Epoch 4343: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2792e-04 - accuracy: 1.0000 - val_loss: 0.7423 - val_accuracy: 0.8453 - 3s/epoch - 85ms/step\n",
            "Epoch 4344/5000\n",
            "\n",
            "Epoch 4344: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.5115e-04 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.8381 - 4s/epoch - 106ms/step\n",
            "Epoch 4345/5000\n",
            "\n",
            "Epoch 4345: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3469e-04 - accuracy: 1.0000 - val_loss: 0.7406 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 4346/5000\n",
            "\n",
            "Epoch 4346: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.4017e-04 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 4347/5000\n",
            "\n",
            "Epoch 4347: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3212e-04 - accuracy: 1.0000 - val_loss: 0.7421 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4348/5000\n",
            "\n",
            "Epoch 4348: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3216e-04 - accuracy: 1.0000 - val_loss: 0.7708 - val_accuracy: 0.8345 - 3s/epoch - 95ms/step\n",
            "Epoch 4349/5000\n",
            "\n",
            "Epoch 4349: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3418e-04 - accuracy: 1.0000 - val_loss: 0.7452 - val_accuracy: 0.8381 - 3s/epoch - 96ms/step\n",
            "Epoch 4350/5000\n",
            "\n",
            "Epoch 4350: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2930e-04 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.8345 - 3s/epoch - 72ms/step\n",
            "Epoch 4351/5000\n",
            "\n",
            "Epoch 4351: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2861e-04 - accuracy: 1.0000 - val_loss: 0.7440 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4352/5000\n",
            "\n",
            "Epoch 4352: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2964e-04 - accuracy: 1.0000 - val_loss: 0.7526 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4353/5000\n",
            "\n",
            "Epoch 4353: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2673e-04 - accuracy: 1.0000 - val_loss: 0.7625 - val_accuracy: 0.8417 - 3s/epoch - 98ms/step\n",
            "Epoch 4354/5000\n",
            "\n",
            "Epoch 4354: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3010e-04 - accuracy: 1.0000 - val_loss: 0.7388 - val_accuracy: 0.8489 - 3s/epoch - 91ms/step\n",
            "Epoch 4355/5000\n",
            "\n",
            "Epoch 4355: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2625e-04 - accuracy: 1.0000 - val_loss: 0.7381 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4356/5000\n",
            "\n",
            "Epoch 4356: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3139e-04 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4357/5000\n",
            "\n",
            "Epoch 4357: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2777e-04 - accuracy: 1.0000 - val_loss: 0.7502 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4358/5000\n",
            "\n",
            "Epoch 4358: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2694e-04 - accuracy: 1.0000 - val_loss: 0.7509 - val_accuracy: 0.8489 - 4s/epoch - 104ms/step\n",
            "Epoch 4359/5000\n",
            "\n",
            "Epoch 4359: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2864e-04 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.8489 - 3s/epoch - 85ms/step\n",
            "Epoch 4360/5000\n",
            "\n",
            "Epoch 4360: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3248e-04 - accuracy: 1.0000 - val_loss: 0.7554 - val_accuracy: 0.8345 - 3s/epoch - 72ms/step\n",
            "Epoch 4361/5000\n",
            "\n",
            "Epoch 4361: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3698e-04 - accuracy: 1.0000 - val_loss: 0.7503 - val_accuracy: 0.8561 - 2s/epoch - 70ms/step\n",
            "Epoch 4362/5000\n",
            "\n",
            "Epoch 4362: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3408e-04 - accuracy: 1.0000 - val_loss: 0.7305 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4363/5000\n",
            "\n",
            "Epoch 4363: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3450e-04 - accuracy: 1.0000 - val_loss: 0.7602 - val_accuracy: 0.8453 - 4s/epoch - 111ms/step\n",
            "Epoch 4364/5000\n",
            "\n",
            "Epoch 4364: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3412e-04 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.8525 - 3s/epoch - 79ms/step\n",
            "Epoch 4365/5000\n",
            "\n",
            "Epoch 4365: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2644e-04 - accuracy: 1.0000 - val_loss: 0.7551 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4366/5000\n",
            "\n",
            "Epoch 4366: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2872e-04 - accuracy: 1.0000 - val_loss: 0.7650 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4367/5000\n",
            "\n",
            "Epoch 4367: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2772e-04 - accuracy: 1.0000 - val_loss: 0.7472 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4368/5000\n",
            "\n",
            "Epoch 4368: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2862e-04 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.8453 - 4s/epoch - 119ms/step\n",
            "Epoch 4369/5000\n",
            "\n",
            "Epoch 4369: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3043e-04 - accuracy: 1.0000 - val_loss: 0.7522 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4370/5000\n",
            "\n",
            "Epoch 4370: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2727e-04 - accuracy: 1.0000 - val_loss: 0.7600 - val_accuracy: 0.8453 - 3s/epoch - 73ms/step\n",
            "Epoch 4371/5000\n",
            "\n",
            "Epoch 4371: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2870e-04 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4372/5000\n",
            "\n",
            "Epoch 4372: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2526e-04 - accuracy: 1.0000 - val_loss: 0.7494 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4373/5000\n",
            "\n",
            "Epoch 4373: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2508e-04 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.8489 - 4s/epoch - 119ms/step\n",
            "Epoch 4374/5000\n",
            "\n",
            "Epoch 4374: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2507e-04 - accuracy: 1.0000 - val_loss: 0.7490 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4375/5000\n",
            "\n",
            "Epoch 4375: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2503e-04 - accuracy: 1.0000 - val_loss: 0.7851 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4376/5000\n",
            "\n",
            "Epoch 4376: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2760e-04 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4377/5000\n",
            "\n",
            "Epoch 4377: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2522e-04 - accuracy: 1.0000 - val_loss: 0.7521 - val_accuracy: 0.8489 - 3s/epoch - 76ms/step\n",
            "Epoch 4378/5000\n",
            "\n",
            "Epoch 4378: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2535e-04 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.8525 - 4s/epoch - 112ms/step\n",
            "Epoch 4379/5000\n",
            "\n",
            "Epoch 4379: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2481e-04 - accuracy: 1.0000 - val_loss: 0.7487 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4380/5000\n",
            "\n",
            "Epoch 4380: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2520e-04 - accuracy: 1.0000 - val_loss: 0.7515 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4381/5000\n",
            "\n",
            "Epoch 4381: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2409e-04 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4382/5000\n",
            "\n",
            "Epoch 4382: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2781e-04 - accuracy: 1.0000 - val_loss: 0.7353 - val_accuracy: 0.8417 - 3s/epoch - 82ms/step\n",
            "Epoch 4383/5000\n",
            "\n",
            "Epoch 4383: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2840e-04 - accuracy: 1.0000 - val_loss: 0.7422 - val_accuracy: 0.8381 - 4s/epoch - 106ms/step\n",
            "Epoch 4384/5000\n",
            "\n",
            "Epoch 4384: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2761e-04 - accuracy: 1.0000 - val_loss: 0.7477 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4385/5000\n",
            "\n",
            "Epoch 4385: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2315e-04 - accuracy: 1.0000 - val_loss: 0.7402 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4386/5000\n",
            "\n",
            "Epoch 4386: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2393e-04 - accuracy: 1.0000 - val_loss: 0.7358 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4387/5000\n",
            "\n",
            "Epoch 4387: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2575e-04 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.8453 - 3s/epoch - 91ms/step\n",
            "Epoch 4388/5000\n",
            "\n",
            "Epoch 4388: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2636e-04 - accuracy: 1.0000 - val_loss: 0.7615 - val_accuracy: 0.8453 - 3s/epoch - 99ms/step\n",
            "Epoch 4389/5000\n",
            "\n",
            "Epoch 4389: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2372e-04 - accuracy: 1.0000 - val_loss: 0.7502 - val_accuracy: 0.8453 - 2s/epoch - 69ms/step\n",
            "Epoch 4390/5000\n",
            "\n",
            "Epoch 4390: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2017e-04 - accuracy: 1.0000 - val_loss: 0.7463 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4391/5000\n",
            "\n",
            "Epoch 4391: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2415e-04 - accuracy: 1.0000 - val_loss: 0.7360 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4392/5000\n",
            "\n",
            "Epoch 4392: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.3218e-04 - accuracy: 1.0000 - val_loss: 0.7351 - val_accuracy: 0.8417 - 3s/epoch - 95ms/step\n",
            "Epoch 4393/5000\n",
            "\n",
            "Epoch 4393: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2818e-04 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.8489 - 3s/epoch - 95ms/step\n",
            "Epoch 4394/5000\n",
            "\n",
            "Epoch 4394: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2283e-04 - accuracy: 1.0000 - val_loss: 0.7380 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4395/5000\n",
            "\n",
            "Epoch 4395: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4480e-04 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4396/5000\n",
            "\n",
            "Epoch 4396: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2634e-04 - accuracy: 1.0000 - val_loss: 0.7763 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4397/5000\n",
            "\n",
            "Epoch 4397: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2591e-04 - accuracy: 1.0000 - val_loss: 0.7484 - val_accuracy: 0.8489 - 3s/epoch - 98ms/step\n",
            "Epoch 4398/5000\n",
            "\n",
            "Epoch 4398: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2605e-04 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.8381 - 3s/epoch - 89ms/step\n",
            "Epoch 4399/5000\n",
            "\n",
            "Epoch 4399: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3048e-04 - accuracy: 1.0000 - val_loss: 0.7707 - val_accuracy: 0.8345 - 2s/epoch - 70ms/step\n",
            "Epoch 4400/5000\n",
            "\n",
            "Epoch 4400: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2700e-04 - accuracy: 1.0000 - val_loss: 0.7643 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4401/5000\n",
            "\n",
            "Epoch 4401: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2292e-04 - accuracy: 1.0000 - val_loss: 0.7529 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4402/5000\n",
            "\n",
            "Epoch 4402: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2376e-04 - accuracy: 1.0000 - val_loss: 0.7493 - val_accuracy: 0.8417 - 4s/epoch - 105ms/step\n",
            "Epoch 4403/5000\n",
            "\n",
            "Epoch 4403: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2290e-04 - accuracy: 1.0000 - val_loss: 0.7481 - val_accuracy: 0.8345 - 3s/epoch - 83ms/step\n",
            "Epoch 4404/5000\n",
            "\n",
            "Epoch 4404: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2429e-04 - accuracy: 1.0000 - val_loss: 0.7522 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4405/5000\n",
            "\n",
            "Epoch 4405: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2301e-04 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4406/5000\n",
            "\n",
            "Epoch 4406: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2496e-04 - accuracy: 1.0000 - val_loss: 0.7498 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4407/5000\n",
            "\n",
            "Epoch 4407: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2422e-04 - accuracy: 1.0000 - val_loss: 0.7517 - val_accuracy: 0.8453 - 4s/epoch - 108ms/step\n",
            "Epoch 4408/5000\n",
            "\n",
            "Epoch 4408: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2399e-04 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.8417 - 3s/epoch - 79ms/step\n",
            "Epoch 4409/5000\n",
            "\n",
            "Epoch 4409: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2431e-04 - accuracy: 1.0000 - val_loss: 0.7418 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4410/5000\n",
            "\n",
            "Epoch 4410: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2860e-04 - accuracy: 1.0000 - val_loss: 0.7862 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4411/5000\n",
            "\n",
            "Epoch 4411: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2704e-04 - accuracy: 1.0000 - val_loss: 0.7755 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4412/5000\n",
            "\n",
            "Epoch 4412: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2442e-04 - accuracy: 1.0000 - val_loss: 0.7695 - val_accuracy: 0.8453 - 4s/epoch - 115ms/step\n",
            "Epoch 4413/5000\n",
            "\n",
            "Epoch 4413: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2419e-04 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.8453 - 3s/epoch - 75ms/step\n",
            "Epoch 4414/5000\n",
            "\n",
            "Epoch 4414: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2392e-04 - accuracy: 1.0000 - val_loss: 0.7507 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4415/5000\n",
            "\n",
            "Epoch 4415: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2129e-04 - accuracy: 1.0000 - val_loss: 0.7490 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4416/5000\n",
            "\n",
            "Epoch 4416: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1813e-04 - accuracy: 1.0000 - val_loss: 0.7330 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4417/5000\n",
            "\n",
            "Epoch 4417: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.3083e-04 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8381 - 4s/epoch - 116ms/step\n",
            "Epoch 4418/5000\n",
            "\n",
            "Epoch 4418: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2493e-04 - accuracy: 1.0000 - val_loss: 0.7381 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4419/5000\n",
            "\n",
            "Epoch 4419: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2173e-04 - accuracy: 1.0000 - val_loss: 0.7445 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4420/5000\n",
            "\n",
            "Epoch 4420: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2186e-04 - accuracy: 1.0000 - val_loss: 0.7448 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4421/5000\n",
            "\n",
            "Epoch 4421: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2492e-04 - accuracy: 1.0000 - val_loss: 0.7463 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4422/5000\n",
            "\n",
            "Epoch 4422: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2295e-04 - accuracy: 1.0000 - val_loss: 0.7436 - val_accuracy: 0.8417 - 4s/epoch - 118ms/step\n",
            "Epoch 4423/5000\n",
            "\n",
            "Epoch 4423: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2020e-04 - accuracy: 1.0000 - val_loss: 0.7474 - val_accuracy: 0.8453 - 2s/epoch - 69ms/step\n",
            "Epoch 4424/5000\n",
            "\n",
            "Epoch 4424: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2104e-04 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4425/5000\n",
            "\n",
            "Epoch 4425: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2258e-04 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4426/5000\n",
            "\n",
            "Epoch 4426: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2791e-04 - accuracy: 1.0000 - val_loss: 0.7518 - val_accuracy: 0.8453 - 3s/epoch - 75ms/step\n",
            "Epoch 4427/5000\n",
            "\n",
            "Epoch 4427: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2550e-04 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.8417 - 4s/epoch - 113ms/step\n",
            "Epoch 4428/5000\n",
            "\n",
            "Epoch 4428: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2721e-04 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4429/5000\n",
            "\n",
            "Epoch 4429: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2825e-04 - accuracy: 1.0000 - val_loss: 0.7616 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4430/5000\n",
            "\n",
            "Epoch 4430: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2633e-04 - accuracy: 1.0000 - val_loss: 0.7588 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4431/5000\n",
            "\n",
            "Epoch 4431: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2510e-04 - accuracy: 1.0000 - val_loss: 0.7546 - val_accuracy: 0.8525 - 3s/epoch - 80ms/step\n",
            "Epoch 4432/5000\n",
            "\n",
            "Epoch 4432: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2096e-04 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.8453 - 4s/epoch - 107ms/step\n",
            "Epoch 4433/5000\n",
            "\n",
            "Epoch 4433: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2640e-04 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4434/5000\n",
            "\n",
            "Epoch 4434: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2501e-04 - accuracy: 1.0000 - val_loss: 0.7536 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4435/5000\n",
            "\n",
            "Epoch 4435: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2076e-04 - accuracy: 1.0000 - val_loss: 0.7437 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4436/5000\n",
            "\n",
            "Epoch 4436: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2763e-04 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.8489 - 3s/epoch - 86ms/step\n",
            "Epoch 4437/5000\n",
            "\n",
            "Epoch 4437: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2617e-04 - accuracy: 1.0000 - val_loss: 0.7694 - val_accuracy: 0.8417 - 4s/epoch - 102ms/step\n",
            "Epoch 4438/5000\n",
            "\n",
            "Epoch 4438: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2216e-04 - accuracy: 1.0000 - val_loss: 0.7587 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4439/5000\n",
            "\n",
            "Epoch 4439: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2148e-04 - accuracy: 1.0000 - val_loss: 0.7494 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4440/5000\n",
            "\n",
            "Epoch 4440: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1861e-04 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4441/5000\n",
            "\n",
            "Epoch 4441: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2308e-04 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.8489 - 3s/epoch - 90ms/step\n",
            "Epoch 4442/5000\n",
            "\n",
            "Epoch 4442: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2189e-04 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.8417 - 3s/epoch - 97ms/step\n",
            "Epoch 4443/5000\n",
            "\n",
            "Epoch 4443: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1741e-04 - accuracy: 1.0000 - val_loss: 0.7431 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4444/5000\n",
            "\n",
            "Epoch 4444: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2351e-04 - accuracy: 1.0000 - val_loss: 0.7502 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4445/5000\n",
            "\n",
            "Epoch 4445: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2329e-04 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4446/5000\n",
            "\n",
            "Epoch 4446: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1747e-04 - accuracy: 1.0000 - val_loss: 0.7383 - val_accuracy: 0.8417 - 3s/epoch - 99ms/step\n",
            "Epoch 4447/5000\n",
            "\n",
            "Epoch 4447: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2073e-04 - accuracy: 1.0000 - val_loss: 0.7340 - val_accuracy: 0.8381 - 3s/epoch - 90ms/step\n",
            "Epoch 4448/5000\n",
            "\n",
            "Epoch 4448: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1788e-04 - accuracy: 1.0000 - val_loss: 0.7366 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4449/5000\n",
            "\n",
            "Epoch 4449: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2509e-04 - accuracy: 1.0000 - val_loss: 0.7439 - val_accuracy: 0.8453 - 2s/epoch - 69ms/step\n",
            "Epoch 4450/5000\n",
            "\n",
            "Epoch 4450: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2243e-04 - accuracy: 1.0000 - val_loss: 0.7452 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4451/5000\n",
            "\n",
            "Epoch 4451: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2111e-04 - accuracy: 1.0000 - val_loss: 0.7446 - val_accuracy: 0.8417 - 4s/epoch - 102ms/step\n",
            "Epoch 4452/5000\n",
            "\n",
            "Epoch 4452: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.5816e-04 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.8417 - 3s/epoch - 86ms/step\n",
            "Epoch 4453/5000\n",
            "\n",
            "Epoch 4453: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4603e-04 - accuracy: 1.0000 - val_loss: 0.7507 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4454/5000\n",
            "\n",
            "Epoch 4454: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2600e-04 - accuracy: 1.0000 - val_loss: 0.7485 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4455/5000\n",
            "\n",
            "Epoch 4455: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2548e-04 - accuracy: 1.0000 - val_loss: 0.7504 - val_accuracy: 0.8561 - 2s/epoch - 70ms/step\n",
            "Epoch 4456/5000\n",
            "\n",
            "Epoch 4456: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2202e-04 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.8525 - 4s/epoch - 111ms/step\n",
            "Epoch 4457/5000\n",
            "\n",
            "Epoch 4457: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2270e-04 - accuracy: 1.0000 - val_loss: 0.7558 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 4458/5000\n",
            "\n",
            "Epoch 4458: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2018e-04 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4459/5000\n",
            "\n",
            "Epoch 4459: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2096e-04 - accuracy: 1.0000 - val_loss: 0.7502 - val_accuracy: 0.8561 - 2s/epoch - 70ms/step\n",
            "Epoch 4460/5000\n",
            "\n",
            "Epoch 4460: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2149e-04 - accuracy: 1.0000 - val_loss: 0.7516 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4461/5000\n",
            "\n",
            "Epoch 4461: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2170e-04 - accuracy: 1.0000 - val_loss: 0.7477 - val_accuracy: 0.8525 - 4s/epoch - 115ms/step\n",
            "Epoch 4462/5000\n",
            "\n",
            "Epoch 4462: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1968e-04 - accuracy: 1.0000 - val_loss: 0.7433 - val_accuracy: 0.8489 - 3s/epoch - 73ms/step\n",
            "Epoch 4463/5000\n",
            "\n",
            "Epoch 4463: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1855e-04 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.8561 - 2s/epoch - 70ms/step\n",
            "Epoch 4464/5000\n",
            "\n",
            "Epoch 4464: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3326e-04 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4465/5000\n",
            "\n",
            "Epoch 4465: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2039e-04 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4466/5000\n",
            "\n",
            "Epoch 4466: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1939e-04 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.8489 - 4s/epoch - 119ms/step\n",
            "Epoch 4467/5000\n",
            "\n",
            "Epoch 4467: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2599e-04 - accuracy: 1.0000 - val_loss: 0.7468 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4468/5000\n",
            "\n",
            "Epoch 4468: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4763e-04 - accuracy: 1.0000 - val_loss: 0.7755 - val_accuracy: 0.8273 - 2s/epoch - 71ms/step\n",
            "Epoch 4469/5000\n",
            "\n",
            "Epoch 4469: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3225e-04 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.8345 - 2s/epoch - 70ms/step\n",
            "Epoch 4470/5000\n",
            "\n",
            "Epoch 4470: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2413e-04 - accuracy: 1.0000 - val_loss: 0.7638 - val_accuracy: 0.8345 - 2s/epoch - 70ms/step\n",
            "Epoch 4471/5000\n",
            "\n",
            "Epoch 4471: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2178e-04 - accuracy: 1.0000 - val_loss: 0.7622 - val_accuracy: 0.8381 - 4s/epoch - 118ms/step\n",
            "Epoch 4472/5000\n",
            "\n",
            "Epoch 4472: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2225e-04 - accuracy: 1.0000 - val_loss: 0.7638 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4473/5000\n",
            "\n",
            "Epoch 4473: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.3317e-04 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4474/5000\n",
            "\n",
            "Epoch 4474: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2254e-04 - accuracy: 1.0000 - val_loss: 0.7737 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 4475/5000\n",
            "\n",
            "Epoch 4475: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2243e-04 - accuracy: 1.0000 - val_loss: 0.7680 - val_accuracy: 0.8345 - 3s/epoch - 76ms/step\n",
            "Epoch 4476/5000\n",
            "\n",
            "Epoch 4476: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2070e-04 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.8345 - 4s/epoch - 112ms/step\n",
            "Epoch 4477/5000\n",
            "\n",
            "Epoch 4477: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1722e-04 - accuracy: 1.0000 - val_loss: 0.7545 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4478/5000\n",
            "\n",
            "Epoch 4478: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1952e-04 - accuracy: 1.0000 - val_loss: 0.7545 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4479/5000\n",
            "\n",
            "Epoch 4479: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1906e-04 - accuracy: 1.0000 - val_loss: 0.7502 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4480/5000\n",
            "\n",
            "Epoch 4480: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2086e-04 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.8453 - 3s/epoch - 82ms/step\n",
            "Epoch 4481/5000\n",
            "\n",
            "Epoch 4481: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1998e-04 - accuracy: 1.0000 - val_loss: 0.7525 - val_accuracy: 0.8453 - 4s/epoch - 107ms/step\n",
            "Epoch 4482/5000\n",
            "\n",
            "Epoch 4482: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1606e-04 - accuracy: 1.0000 - val_loss: 0.7472 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4483/5000\n",
            "\n",
            "Epoch 4483: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1594e-04 - accuracy: 1.0000 - val_loss: 0.7449 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4484/5000\n",
            "\n",
            "Epoch 4484: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1638e-04 - accuracy: 1.0000 - val_loss: 0.7439 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4485/5000\n",
            "\n",
            "Epoch 4485: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1965e-04 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.8489 - 3s/epoch - 88ms/step\n",
            "Epoch 4486/5000\n",
            "\n",
            "Epoch 4486: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1803e-04 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.8417 - 3s/epoch - 100ms/step\n",
            "Epoch 4487/5000\n",
            "\n",
            "Epoch 4487: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2313e-04 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4488/5000\n",
            "\n",
            "Epoch 4488: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1389e-04 - accuracy: 1.0000 - val_loss: 0.7497 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4489/5000\n",
            "\n",
            "Epoch 4489: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1750e-04 - accuracy: 1.0000 - val_loss: 0.7430 - val_accuracy: 0.8525 - 3s/epoch - 72ms/step\n",
            "Epoch 4490/5000\n",
            "\n",
            "Epoch 4490: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1896e-04 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.8453 - 3s/epoch - 94ms/step\n",
            "Epoch 4491/5000\n",
            "\n",
            "Epoch 4491: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1682e-04 - accuracy: 1.0000 - val_loss: 0.7468 - val_accuracy: 0.8525 - 3s/epoch - 94ms/step\n",
            "Epoch 4492/5000\n",
            "\n",
            "Epoch 4492: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1781e-04 - accuracy: 1.0000 - val_loss: 0.7526 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4493/5000\n",
            "\n",
            "Epoch 4493: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1632e-04 - accuracy: 1.0000 - val_loss: 0.7449 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4494/5000\n",
            "\n",
            "Epoch 4494: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1538e-04 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4495/5000\n",
            "\n",
            "Epoch 4495: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1357e-04 - accuracy: 1.0000 - val_loss: 0.7503 - val_accuracy: 0.8489 - 3s/epoch - 100ms/step\n",
            "Epoch 4496/5000\n",
            "\n",
            "Epoch 4496: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1885e-04 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.8453 - 3s/epoch - 89ms/step\n",
            "Epoch 4497/5000\n",
            "\n",
            "Epoch 4497: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1809e-04 - accuracy: 1.0000 - val_loss: 0.7477 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4498/5000\n",
            "\n",
            "Epoch 4498: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1600e-04 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4499/5000\n",
            "\n",
            "Epoch 4499: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1513e-04 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 4500/5000\n",
            "\n",
            "Epoch 4500: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2887e-04 - accuracy: 1.0000 - val_loss: 0.7973 - val_accuracy: 0.8345 - 4s/epoch - 109ms/step\n",
            "Epoch 4501/5000\n",
            "\n",
            "Epoch 4501: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2055e-04 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.8453 - 3s/epoch - 80ms/step\n",
            "Epoch 4502/5000\n",
            "\n",
            "Epoch 4502: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2570e-04 - accuracy: 1.0000 - val_loss: 0.7588 - val_accuracy: 0.8453 - 2s/epoch - 69ms/step\n",
            "Epoch 4503/5000\n",
            "\n",
            "Epoch 4503: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1713e-04 - accuracy: 1.0000 - val_loss: 0.7614 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4504/5000\n",
            "\n",
            "Epoch 4504: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1945e-04 - accuracy: 1.0000 - val_loss: 0.7584 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4505/5000\n",
            "\n",
            "Epoch 4505: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1677e-04 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.8489 - 4s/epoch - 112ms/step\n",
            "Epoch 4506/5000\n",
            "\n",
            "Epoch 4506: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1663e-04 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.8489 - 3s/epoch - 76ms/step\n",
            "Epoch 4507/5000\n",
            "\n",
            "Epoch 4507: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1561e-04 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4508/5000\n",
            "\n",
            "Epoch 4508: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1812e-04 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4509/5000\n",
            "\n",
            "Epoch 4509: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1553e-04 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4510/5000\n",
            "\n",
            "Epoch 4510: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1552e-04 - accuracy: 1.0000 - val_loss: 0.7626 - val_accuracy: 0.8453 - 4s/epoch - 119ms/step\n",
            "Epoch 4511/5000\n",
            "\n",
            "Epoch 4511: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1539e-04 - accuracy: 1.0000 - val_loss: 0.7596 - val_accuracy: 0.8489 - 3s/epoch - 73ms/step\n",
            "Epoch 4512/5000\n",
            "\n",
            "Epoch 4512: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2229e-04 - accuracy: 1.0000 - val_loss: 0.7590 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4513/5000\n",
            "\n",
            "Epoch 4513: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1766e-04 - accuracy: 1.0000 - val_loss: 0.7633 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4514/5000\n",
            "\n",
            "Epoch 4514: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1402e-04 - accuracy: 1.0000 - val_loss: 0.7616 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4515/5000\n",
            "\n",
            "Epoch 4515: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.2357e-04 - accuracy: 1.0000 - val_loss: 0.7657 - val_accuracy: 0.8453 - 4s/epoch - 120ms/step\n",
            "Epoch 4516/5000\n",
            "\n",
            "Epoch 4516: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2248e-04 - accuracy: 1.0000 - val_loss: 0.7575 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4517/5000\n",
            "\n",
            "Epoch 4517: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1820e-04 - accuracy: 1.0000 - val_loss: 0.7564 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4518/5000\n",
            "\n",
            "Epoch 4518: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1547e-04 - accuracy: 1.0000 - val_loss: 0.7618 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4519/5000\n",
            "\n",
            "Epoch 4519: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1486e-04 - accuracy: 1.0000 - val_loss: 0.7485 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4520/5000\n",
            "\n",
            "Epoch 4520: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1533e-04 - accuracy: 1.0000 - val_loss: 0.7485 - val_accuracy: 0.8453 - 4s/epoch - 118ms/step\n",
            "Epoch 4521/5000\n",
            "\n",
            "Epoch 4521: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1253e-04 - accuracy: 1.0000 - val_loss: 0.7457 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4522/5000\n",
            "\n",
            "Epoch 4522: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1317e-04 - accuracy: 1.0000 - val_loss: 0.7425 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4523/5000\n",
            "\n",
            "Epoch 4523: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1548e-04 - accuracy: 1.0000 - val_loss: 0.7502 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4524/5000\n",
            "\n",
            "Epoch 4524: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1249e-04 - accuracy: 1.0000 - val_loss: 0.7543 - val_accuracy: 0.8453 - 3s/epoch - 74ms/step\n",
            "Epoch 4525/5000\n",
            "\n",
            "Epoch 4525: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1451e-04 - accuracy: 1.0000 - val_loss: 0.7483 - val_accuracy: 0.8453 - 4s/epoch - 114ms/step\n",
            "Epoch 4526/5000\n",
            "\n",
            "Epoch 4526: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1733e-04 - accuracy: 1.0000 - val_loss: 0.7490 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4527/5000\n",
            "\n",
            "Epoch 4527: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1477e-04 - accuracy: 1.0000 - val_loss: 0.7501 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4528/5000\n",
            "\n",
            "Epoch 4528: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1365e-04 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4529/5000\n",
            "\n",
            "Epoch 4529: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1279e-04 - accuracy: 1.0000 - val_loss: 0.7492 - val_accuracy: 0.8489 - 3s/epoch - 79ms/step\n",
            "Epoch 4530/5000\n",
            "\n",
            "Epoch 4530: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1227e-04 - accuracy: 1.0000 - val_loss: 0.7426 - val_accuracy: 0.8489 - 4s/epoch - 109ms/step\n",
            "Epoch 4531/5000\n",
            "\n",
            "Epoch 4531: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1283e-04 - accuracy: 1.0000 - val_loss: 0.7493 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4532/5000\n",
            "\n",
            "Epoch 4532: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1407e-04 - accuracy: 1.0000 - val_loss: 0.7415 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4533/5000\n",
            "\n",
            "Epoch 4533: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1343e-04 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4534/5000\n",
            "\n",
            "Epoch 4534: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1707e-04 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.8417 - 3s/epoch - 86ms/step\n",
            "Epoch 4535/5000\n",
            "\n",
            "Epoch 4535: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.6391e-04 - accuracy: 1.0000 - val_loss: 0.7298 - val_accuracy: 0.8381 - 4s/epoch - 102ms/step\n",
            "Epoch 4536/5000\n",
            "\n",
            "Epoch 4536: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.5349e-04 - accuracy: 1.0000 - val_loss: 0.7680 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4537/5000\n",
            "\n",
            "Epoch 4537: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.4083e-04 - accuracy: 1.0000 - val_loss: 0.7719 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4538/5000\n",
            "\n",
            "Epoch 4538: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2358e-04 - accuracy: 1.0000 - val_loss: 0.7640 - val_accuracy: 0.8561 - 2s/epoch - 71ms/step\n",
            "Epoch 4539/5000\n",
            "\n",
            "Epoch 4539: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.2243e-04 - accuracy: 1.0000 - val_loss: 0.7582 - val_accuracy: 0.8525 - 3s/epoch - 92ms/step\n",
            "Epoch 4540/5000\n",
            "\n",
            "Epoch 4540: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1908e-04 - accuracy: 1.0000 - val_loss: 0.7595 - val_accuracy: 0.8489 - 3s/epoch - 96ms/step\n",
            "Epoch 4541/5000\n",
            "\n",
            "Epoch 4541: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1752e-04 - accuracy: 1.0000 - val_loss: 0.7684 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4542/5000\n",
            "\n",
            "Epoch 4542: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1825e-04 - accuracy: 1.0000 - val_loss: 0.7677 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4543/5000\n",
            "\n",
            "Epoch 4543: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1974e-04 - accuracy: 1.0000 - val_loss: 0.7649 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4544/5000\n",
            "\n",
            "Epoch 4544: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1735e-04 - accuracy: 1.0000 - val_loss: 0.7597 - val_accuracy: 0.8453 - 3s/epoch - 99ms/step\n",
            "Epoch 4545/5000\n",
            "\n",
            "Epoch 4545: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1583e-04 - accuracy: 1.0000 - val_loss: 0.7656 - val_accuracy: 0.8453 - 3s/epoch - 89ms/step\n",
            "Epoch 4546/5000\n",
            "\n",
            "Epoch 4546: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1910e-04 - accuracy: 1.0000 - val_loss: 0.7671 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4547/5000\n",
            "\n",
            "Epoch 4547: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1541e-04 - accuracy: 1.0000 - val_loss: 0.7663 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4548/5000\n",
            "\n",
            "Epoch 4548: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1654e-04 - accuracy: 1.0000 - val_loss: 0.7661 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4549/5000\n",
            "\n",
            "Epoch 4549: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1740e-04 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.8525 - 4s/epoch - 105ms/step\n",
            "Epoch 4550/5000\n",
            "\n",
            "Epoch 4550: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1429e-04 - accuracy: 1.0000 - val_loss: 0.7659 - val_accuracy: 0.8489 - 3s/epoch - 83ms/step\n",
            "Epoch 4551/5000\n",
            "\n",
            "Epoch 4551: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1510e-04 - accuracy: 1.0000 - val_loss: 0.7631 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4552/5000\n",
            "\n",
            "Epoch 4552: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1591e-04 - accuracy: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4553/5000\n",
            "\n",
            "Epoch 4553: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1503e-04 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4554/5000\n",
            "\n",
            "Epoch 4554: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1343e-04 - accuracy: 1.0000 - val_loss: 0.7661 - val_accuracy: 0.8489 - 4s/epoch - 113ms/step\n",
            "Epoch 4555/5000\n",
            "\n",
            "Epoch 4555: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1641e-04 - accuracy: 1.0000 - val_loss: 0.7686 - val_accuracy: 0.8489 - 3s/epoch - 75ms/step\n",
            "Epoch 4556/5000\n",
            "\n",
            "Epoch 4556: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1402e-04 - accuracy: 1.0000 - val_loss: 0.7610 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4557/5000\n",
            "\n",
            "Epoch 4557: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.2341e-04 - accuracy: 1.0000 - val_loss: 0.7680 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4558/5000\n",
            "\n",
            "Epoch 4558: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1101e-04 - accuracy: 1.0000 - val_loss: 0.7630 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4559/5000\n",
            "\n",
            "Epoch 4559: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1409e-04 - accuracy: 1.0000 - val_loss: 0.7668 - val_accuracy: 0.8453 - 4s/epoch - 119ms/step\n",
            "Epoch 4560/5000\n",
            "\n",
            "Epoch 4560: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1143e-04 - accuracy: 1.0000 - val_loss: 0.7671 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4561/5000\n",
            "\n",
            "Epoch 4561: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1462e-04 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4562/5000\n",
            "\n",
            "Epoch 4562: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1156e-04 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4563/5000\n",
            "\n",
            "Epoch 4563: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1015e-04 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4564/5000\n",
            "\n",
            "Epoch 4564: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1107e-04 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.8489 - 4s/epoch - 119ms/step\n",
            "Epoch 4565/5000\n",
            "\n",
            "Epoch 4565: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1281e-04 - accuracy: 1.0000 - val_loss: 0.7546 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4566/5000\n",
            "\n",
            "Epoch 4566: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1149e-04 - accuracy: 1.0000 - val_loss: 0.7524 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4567/5000\n",
            "\n",
            "Epoch 4567: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1377e-04 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4568/5000\n",
            "\n",
            "Epoch 4568: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1475e-04 - accuracy: 1.0000 - val_loss: 0.7519 - val_accuracy: 0.8489 - 3s/epoch - 76ms/step\n",
            "Epoch 4569/5000\n",
            "\n",
            "Epoch 4569: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1104e-04 - accuracy: 1.0000 - val_loss: 0.7508 - val_accuracy: 0.8489 - 4s/epoch - 114ms/step\n",
            "Epoch 4570/5000\n",
            "\n",
            "Epoch 4570: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0863e-04 - accuracy: 1.0000 - val_loss: 0.7494 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4571/5000\n",
            "\n",
            "Epoch 4571: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1260e-04 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4572/5000\n",
            "\n",
            "Epoch 4572: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1133e-04 - accuracy: 1.0000 - val_loss: 0.7642 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4573/5000\n",
            "\n",
            "Epoch 4573: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1506e-04 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.8489 - 3s/epoch - 81ms/step\n",
            "Epoch 4574/5000\n",
            "\n",
            "Epoch 4574: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1123e-04 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.8489 - 4s/epoch - 109ms/step\n",
            "Epoch 4575/5000\n",
            "\n",
            "Epoch 4575: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1100e-04 - accuracy: 1.0000 - val_loss: 0.7575 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4576/5000\n",
            "\n",
            "Epoch 4576: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1158e-04 - accuracy: 1.0000 - val_loss: 0.7508 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4577/5000\n",
            "\n",
            "Epoch 4577: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1384e-04 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.8453 - 2s/epoch - 69ms/step\n",
            "Epoch 4578/5000\n",
            "\n",
            "Epoch 4578: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1695e-04 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.8381 - 3s/epoch - 87ms/step\n",
            "Epoch 4579/5000\n",
            "\n",
            "Epoch 4579: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1600e-04 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.8417 - 4s/epoch - 102ms/step\n",
            "Epoch 4580/5000\n",
            "\n",
            "Epoch 4580: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1055e-04 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4581/5000\n",
            "\n",
            "Epoch 4581: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1152e-04 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4582/5000\n",
            "\n",
            "Epoch 4582: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1244e-04 - accuracy: 1.0000 - val_loss: 0.7618 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4583/5000\n",
            "\n",
            "Epoch 4583: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1359e-04 - accuracy: 1.0000 - val_loss: 0.7623 - val_accuracy: 0.8453 - 3s/epoch - 94ms/step\n",
            "Epoch 4584/5000\n",
            "\n",
            "Epoch 4584: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1280e-04 - accuracy: 1.0000 - val_loss: 0.7574 - val_accuracy: 0.8489 - 3s/epoch - 94ms/step\n",
            "Epoch 4585/5000\n",
            "\n",
            "Epoch 4585: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1157e-04 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4586/5000\n",
            "\n",
            "Epoch 4586: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0920e-04 - accuracy: 1.0000 - val_loss: 0.7566 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4587/5000\n",
            "\n",
            "Epoch 4587: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0893e-04 - accuracy: 1.0000 - val_loss: 0.7582 - val_accuracy: 0.8489 - 3s/epoch - 75ms/step\n",
            "Epoch 4588/5000\n",
            "\n",
            "Epoch 4588: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1424e-04 - accuracy: 1.0000 - val_loss: 0.7662 - val_accuracy: 0.8453 - 4s/epoch - 105ms/step\n",
            "Epoch 4589/5000\n",
            "\n",
            "Epoch 4589: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1093e-04 - accuracy: 1.0000 - val_loss: 0.7618 - val_accuracy: 0.8417 - 3s/epoch - 83ms/step\n",
            "Epoch 4590/5000\n",
            "\n",
            "Epoch 4590: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1260e-04 - accuracy: 1.0000 - val_loss: 0.7502 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4591/5000\n",
            "\n",
            "Epoch 4591: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1040e-04 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 0.8525 - 3s/epoch - 72ms/step\n",
            "Epoch 4592/5000\n",
            "\n",
            "Epoch 4592: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1312e-04 - accuracy: 1.0000 - val_loss: 0.7472 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4593/5000\n",
            "\n",
            "Epoch 4593: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.7138e-04 - accuracy: 1.0000 - val_loss: 0.7906 - val_accuracy: 0.8381 - 4s/epoch - 112ms/step\n",
            "Epoch 4594/5000\n",
            "\n",
            "Epoch 4594: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1982e-04 - accuracy: 1.0000 - val_loss: 0.7782 - val_accuracy: 0.8525 - 3s/epoch - 76ms/step\n",
            "Epoch 4595/5000\n",
            "\n",
            "Epoch 4595: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1347e-04 - accuracy: 1.0000 - val_loss: 0.7706 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4596/5000\n",
            "\n",
            "Epoch 4596: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1552e-04 - accuracy: 1.0000 - val_loss: 0.7608 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4597/5000\n",
            "\n",
            "Epoch 4597: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1154e-04 - accuracy: 1.0000 - val_loss: 0.7615 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4598/5000\n",
            "\n",
            "Epoch 4598: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1362e-04 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.8489 - 4s/epoch - 117ms/step\n",
            "Epoch 4599/5000\n",
            "\n",
            "Epoch 4599: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1331e-04 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4600/5000\n",
            "\n",
            "Epoch 4600: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1357e-04 - accuracy: 1.0000 - val_loss: 0.7546 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4601/5000\n",
            "\n",
            "Epoch 4601: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1127e-04 - accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4602/5000\n",
            "\n",
            "Epoch 4602: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1026e-04 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4603/5000\n",
            "\n",
            "Epoch 4603: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1031e-04 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.8525 - 4s/epoch - 119ms/step\n",
            "Epoch 4604/5000\n",
            "\n",
            "Epoch 4604: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1084e-04 - accuracy: 1.0000 - val_loss: 0.7572 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4605/5000\n",
            "\n",
            "Epoch 4605: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1309e-04 - accuracy: 1.0000 - val_loss: 0.7618 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4606/5000\n",
            "\n",
            "Epoch 4606: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1001e-04 - accuracy: 1.0000 - val_loss: 0.7596 - val_accuracy: 0.8525 - 3s/epoch - 72ms/step\n",
            "Epoch 4607/5000\n",
            "\n",
            "Epoch 4607: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1279e-04 - accuracy: 1.0000 - val_loss: 0.7610 - val_accuracy: 0.8489 - 3s/epoch - 76ms/step\n",
            "Epoch 4608/5000\n",
            "\n",
            "Epoch 4608: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1093e-04 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.8489 - 4s/epoch - 113ms/step\n",
            "Epoch 4609/5000\n",
            "\n",
            "Epoch 4609: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1046e-04 - accuracy: 1.0000 - val_loss: 0.7529 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4610/5000\n",
            "\n",
            "Epoch 4610: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1091e-04 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4611/5000\n",
            "\n",
            "Epoch 4611: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1140e-04 - accuracy: 1.0000 - val_loss: 0.7475 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4612/5000\n",
            "\n",
            "Epoch 4612: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1389e-04 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.8453 - 3s/epoch - 81ms/step\n",
            "Epoch 4613/5000\n",
            "\n",
            "Epoch 4613: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1575e-04 - accuracy: 1.0000 - val_loss: 0.7661 - val_accuracy: 0.8417 - 4s/epoch - 108ms/step\n",
            "Epoch 4614/5000\n",
            "\n",
            "Epoch 4614: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1623e-04 - accuracy: 1.0000 - val_loss: 0.7641 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 4615/5000\n",
            "\n",
            "Epoch 4615: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0917e-04 - accuracy: 1.0000 - val_loss: 0.7586 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 4616/5000\n",
            "\n",
            "Epoch 4616: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0874e-04 - accuracy: 1.0000 - val_loss: 0.7554 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4617/5000\n",
            "\n",
            "Epoch 4617: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0941e-04 - accuracy: 1.0000 - val_loss: 0.7532 - val_accuracy: 0.8417 - 3s/epoch - 91ms/step\n",
            "Epoch 4618/5000\n",
            "\n",
            "Epoch 4618: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0828e-04 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.8417 - 3s/epoch - 99ms/step\n",
            "Epoch 4619/5000\n",
            "\n",
            "Epoch 4619: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0822e-04 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4620/5000\n",
            "\n",
            "Epoch 4620: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1002e-04 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4621/5000\n",
            "\n",
            "Epoch 4621: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0933e-04 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4622/5000\n",
            "\n",
            "Epoch 4622: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1144e-04 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.8453 - 3s/epoch - 96ms/step\n",
            "Epoch 4623/5000\n",
            "\n",
            "Epoch 4623: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1088e-04 - accuracy: 1.0000 - val_loss: 0.7614 - val_accuracy: 0.8489 - 3s/epoch - 91ms/step\n",
            "Epoch 4624/5000\n",
            "\n",
            "Epoch 4624: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1165e-04 - accuracy: 1.0000 - val_loss: 0.7696 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4625/5000\n",
            "\n",
            "Epoch 4625: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0782e-04 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4626/5000\n",
            "\n",
            "Epoch 4626: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0835e-04 - accuracy: 1.0000 - val_loss: 0.7619 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4627/5000\n",
            "\n",
            "Epoch 4627: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0912e-04 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.8525 - 4s/epoch - 100ms/step\n",
            "Epoch 4628/5000\n",
            "\n",
            "Epoch 4628: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.1073e-04 - accuracy: 1.0000 - val_loss: 0.7564 - val_accuracy: 0.8489 - 3s/epoch - 88ms/step\n",
            "Epoch 4629/5000\n",
            "\n",
            "Epoch 4629: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0991e-04 - accuracy: 1.0000 - val_loss: 0.7518 - val_accuracy: 0.8453 - 2s/epoch - 69ms/step\n",
            "Epoch 4630/5000\n",
            "\n",
            "Epoch 4630: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0727e-04 - accuracy: 1.0000 - val_loss: 0.7620 - val_accuracy: 0.8489 - 2s/epoch - 69ms/step\n",
            "Epoch 4631/5000\n",
            "\n",
            "Epoch 4631: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0807e-04 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4632/5000\n",
            "\n",
            "Epoch 4632: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0842e-04 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.8489 - 4s/epoch - 103ms/step\n",
            "Epoch 4633/5000\n",
            "\n",
            "Epoch 4633: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0637e-04 - accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.8489 - 3s/epoch - 84ms/step\n",
            "Epoch 4634/5000\n",
            "\n",
            "Epoch 4634: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1073e-04 - accuracy: 1.0000 - val_loss: 0.7622 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4635/5000\n",
            "\n",
            "Epoch 4635: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0710e-04 - accuracy: 1.0000 - val_loss: 0.7568 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4636/5000\n",
            "\n",
            "Epoch 4636: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1103e-04 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4637/5000\n",
            "\n",
            "Epoch 4637: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0984e-04 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.8417 - 4s/epoch - 107ms/step\n",
            "Epoch 4638/5000\n",
            "\n",
            "Epoch 4638: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0663e-04 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.8453 - 3s/epoch - 83ms/step\n",
            "Epoch 4639/5000\n",
            "\n",
            "Epoch 4639: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0783e-04 - accuracy: 1.0000 - val_loss: 0.7600 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4640/5000\n",
            "\n",
            "Epoch 4640: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0606e-04 - accuracy: 1.0000 - val_loss: 0.7579 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4641/5000\n",
            "\n",
            "Epoch 4641: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0515e-04 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4642/5000\n",
            "\n",
            "Epoch 4642: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0699e-04 - accuracy: 1.0000 - val_loss: 0.7453 - val_accuracy: 0.8453 - 4s/epoch - 113ms/step\n",
            "Epoch 4643/5000\n",
            "\n",
            "Epoch 4643: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0431e-04 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.8489 - 3s/epoch - 75ms/step\n",
            "Epoch 4644/5000\n",
            "\n",
            "Epoch 4644: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0757e-04 - accuracy: 1.0000 - val_loss: 0.7418 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4645/5000\n",
            "\n",
            "Epoch 4645: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0677e-04 - accuracy: 1.0000 - val_loss: 0.7465 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4646/5000\n",
            "\n",
            "Epoch 4646: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0674e-04 - accuracy: 1.0000 - val_loss: 0.7632 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4647/5000\n",
            "\n",
            "Epoch 4647: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0712e-04 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.8453 - 4s/epoch - 118ms/step\n",
            "Epoch 4648/5000\n",
            "\n",
            "Epoch 4648: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1065e-04 - accuracy: 1.0000 - val_loss: 0.7458 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4649/5000\n",
            "\n",
            "Epoch 4649: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0683e-04 - accuracy: 1.0000 - val_loss: 0.7518 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4650/5000\n",
            "\n",
            "Epoch 4650: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0961e-04 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4651/5000\n",
            "\n",
            "Epoch 4651: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0583e-04 - accuracy: 1.0000 - val_loss: 0.7451 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4652/5000\n",
            "\n",
            "Epoch 4652: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0412e-04 - accuracy: 1.0000 - val_loss: 0.7470 - val_accuracy: 0.8453 - 4s/epoch - 117ms/step\n",
            "Epoch 4653/5000\n",
            "\n",
            "Epoch 4653: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0695e-04 - accuracy: 1.0000 - val_loss: 0.7579 - val_accuracy: 0.8489 - 2s/epoch - 69ms/step\n",
            "Epoch 4654/5000\n",
            "\n",
            "Epoch 4654: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1101e-04 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4655/5000\n",
            "\n",
            "Epoch 4655: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0811e-04 - accuracy: 1.0000 - val_loss: 0.7514 - val_accuracy: 0.8561 - 2s/epoch - 69ms/step\n",
            "Epoch 4656/5000\n",
            "\n",
            "Epoch 4656: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1193e-04 - accuracy: 1.0000 - val_loss: 0.7597 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4657/5000\n",
            "\n",
            "Epoch 4657: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1454e-04 - accuracy: 1.0000 - val_loss: 0.7598 - val_accuracy: 0.8489 - 4s/epoch - 116ms/step\n",
            "Epoch 4658/5000\n",
            "\n",
            "Epoch 4658: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0950e-04 - accuracy: 1.0000 - val_loss: 0.7525 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4659/5000\n",
            "\n",
            "Epoch 4659: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0724e-04 - accuracy: 1.0000 - val_loss: 0.7537 - val_accuracy: 0.8489 - 2s/epoch - 69ms/step\n",
            "Epoch 4660/5000\n",
            "\n",
            "Epoch 4660: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0875e-04 - accuracy: 1.0000 - val_loss: 0.7510 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4661/5000\n",
            "\n",
            "Epoch 4661: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0839e-04 - accuracy: 1.0000 - val_loss: 0.7568 - val_accuracy: 0.8489 - 3s/epoch - 73ms/step\n",
            "Epoch 4662/5000\n",
            "\n",
            "Epoch 4662: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1119e-04 - accuracy: 1.0000 - val_loss: 0.7680 - val_accuracy: 0.8417 - 4s/epoch - 116ms/step\n",
            "Epoch 4663/5000\n",
            "\n",
            "Epoch 4663: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0858e-04 - accuracy: 1.0000 - val_loss: 0.7585 - val_accuracy: 0.8417 - 2s/epoch - 69ms/step\n",
            "Epoch 4664/5000\n",
            "\n",
            "Epoch 4664: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0610e-04 - accuracy: 1.0000 - val_loss: 0.7593 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4665/5000\n",
            "\n",
            "Epoch 4665: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0913e-04 - accuracy: 1.0000 - val_loss: 0.7698 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4666/5000\n",
            "\n",
            "Epoch 4666: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0742e-04 - accuracy: 1.0000 - val_loss: 0.7657 - val_accuracy: 0.8453 - 3s/epoch - 75ms/step\n",
            "Epoch 4667/5000\n",
            "\n",
            "Epoch 4667: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0653e-04 - accuracy: 1.0000 - val_loss: 0.7590 - val_accuracy: 0.8489 - 4s/epoch - 113ms/step\n",
            "Epoch 4668/5000\n",
            "\n",
            "Epoch 4668: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1067e-04 - accuracy: 1.0000 - val_loss: 0.7566 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4669/5000\n",
            "\n",
            "Epoch 4669: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1010e-04 - accuracy: 1.0000 - val_loss: 0.7593 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4670/5000\n",
            "\n",
            "Epoch 4670: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.1316e-04 - accuracy: 1.0000 - val_loss: 0.7558 - val_accuracy: 0.8489 - 2s/epoch - 69ms/step\n",
            "Epoch 4671/5000\n",
            "\n",
            "Epoch 4671: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0965e-04 - accuracy: 1.0000 - val_loss: 0.7629 - val_accuracy: 0.8453 - 3s/epoch - 76ms/step\n",
            "Epoch 4672/5000\n",
            "\n",
            "Epoch 4672: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0716e-04 - accuracy: 1.0000 - val_loss: 0.7616 - val_accuracy: 0.8453 - 4s/epoch - 112ms/step\n",
            "Epoch 4673/5000\n",
            "\n",
            "Epoch 4673: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0705e-04 - accuracy: 1.0000 - val_loss: 0.7659 - val_accuracy: 0.8453 - 2s/epoch - 69ms/step\n",
            "Epoch 4674/5000\n",
            "\n",
            "Epoch 4674: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0931e-04 - accuracy: 1.0000 - val_loss: 0.7651 - val_accuracy: 0.8453 - 2s/epoch - 69ms/step\n",
            "Epoch 4675/5000\n",
            "\n",
            "Epoch 4675: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0600e-04 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4676/5000\n",
            "\n",
            "Epoch 4676: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0819e-04 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.8489 - 3s/epoch - 82ms/step\n",
            "Epoch 4677/5000\n",
            "\n",
            "Epoch 4677: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.1014e-04 - accuracy: 1.0000 - val_loss: 0.7504 - val_accuracy: 0.8489 - 4s/epoch - 105ms/step\n",
            "Epoch 4678/5000\n",
            "\n",
            "Epoch 4678: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0465e-04 - accuracy: 1.0000 - val_loss: 0.7492 - val_accuracy: 0.8489 - 2s/epoch - 69ms/step\n",
            "Epoch 4679/5000\n",
            "\n",
            "Epoch 4679: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0679e-04 - accuracy: 1.0000 - val_loss: 0.7518 - val_accuracy: 0.8489 - 2s/epoch - 69ms/step\n",
            "Epoch 4680/5000\n",
            "\n",
            "Epoch 4680: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0439e-04 - accuracy: 1.0000 - val_loss: 0.7493 - val_accuracy: 0.8489 - 2s/epoch - 69ms/step\n",
            "Epoch 4681/5000\n",
            "\n",
            "Epoch 4681: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0528e-04 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.8453 - 3s/epoch - 84ms/step\n",
            "Epoch 4682/5000\n",
            "\n",
            "Epoch 4682: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0858e-04 - accuracy: 1.0000 - val_loss: 0.7425 - val_accuracy: 0.8525 - 4s/epoch - 104ms/step\n",
            "Epoch 4683/5000\n",
            "\n",
            "Epoch 4683: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0726e-04 - accuracy: 1.0000 - val_loss: 0.7533 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4684/5000\n",
            "\n",
            "Epoch 4684: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0508e-04 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.8489 - 2s/epoch - 69ms/step\n",
            "Epoch 4685/5000\n",
            "\n",
            "Epoch 4685: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0405e-04 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4686/5000\n",
            "\n",
            "Epoch 4686: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0814e-04 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.8489 - 3s/epoch - 90ms/step\n",
            "Epoch 4687/5000\n",
            "\n",
            "Epoch 4687: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0827e-04 - accuracy: 1.0000 - val_loss: 0.7573 - val_accuracy: 0.8417 - 3s/epoch - 98ms/step\n",
            "Epoch 4688/5000\n",
            "\n",
            "Epoch 4688: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0474e-04 - accuracy: 1.0000 - val_loss: 0.7588 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4689/5000\n",
            "\n",
            "Epoch 4689: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0343e-04 - accuracy: 1.0000 - val_loss: 0.7618 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4690/5000\n",
            "\n",
            "Epoch 4690: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0670e-04 - accuracy: 1.0000 - val_loss: 0.7615 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4691/5000\n",
            "\n",
            "Epoch 4691: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0286e-04 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.8489 - 3s/epoch - 94ms/step\n",
            "Epoch 4692/5000\n",
            "\n",
            "Epoch 4692: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0729e-04 - accuracy: 1.0000 - val_loss: 0.7647 - val_accuracy: 0.8417 - 3s/epoch - 94ms/step\n",
            "Epoch 4693/5000\n",
            "\n",
            "Epoch 4693: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0678e-04 - accuracy: 1.0000 - val_loss: 0.7718 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4694/5000\n",
            "\n",
            "Epoch 4694: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0498e-04 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4695/5000\n",
            "\n",
            "Epoch 4695: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0175e-04 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4696/5000\n",
            "\n",
            "Epoch 4696: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0738e-04 - accuracy: 1.0000 - val_loss: 0.7556 - val_accuracy: 0.8417 - 3s/epoch - 98ms/step\n",
            "Epoch 4697/5000\n",
            "\n",
            "Epoch 4697: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0423e-04 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.8489 - 3s/epoch - 90ms/step\n",
            "Epoch 4698/5000\n",
            "\n",
            "Epoch 4698: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0231e-04 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4699/5000\n",
            "\n",
            "Epoch 4699: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0446e-04 - accuracy: 1.0000 - val_loss: 0.7598 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4700/5000\n",
            "\n",
            "Epoch 4700: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0187e-04 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4701/5000\n",
            "\n",
            "Epoch 4701: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0471e-04 - accuracy: 1.0000 - val_loss: 0.7516 - val_accuracy: 0.8489 - 4s/epoch - 104ms/step\n",
            "Epoch 4702/5000\n",
            "\n",
            "Epoch 4702: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0504e-04 - accuracy: 1.0000 - val_loss: 0.7806 - val_accuracy: 0.8489 - 3s/epoch - 83ms/step\n",
            "Epoch 4703/5000\n",
            "\n",
            "Epoch 4703: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0532e-04 - accuracy: 1.0000 - val_loss: 0.7607 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4704/5000\n",
            "\n",
            "Epoch 4704: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0441e-04 - accuracy: 1.0000 - val_loss: 0.7616 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4705/5000\n",
            "\n",
            "Epoch 4705: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0235e-04 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4706/5000\n",
            "\n",
            "Epoch 4706: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0234e-04 - accuracy: 1.0000 - val_loss: 0.7462 - val_accuracy: 0.8453 - 4s/epoch - 109ms/step\n",
            "Epoch 4707/5000\n",
            "\n",
            "Epoch 4707: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0459e-04 - accuracy: 1.0000 - val_loss: 0.7636 - val_accuracy: 0.8381 - 3s/epoch - 78ms/step\n",
            "Epoch 4708/5000\n",
            "\n",
            "Epoch 4708: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0353e-04 - accuracy: 1.0000 - val_loss: 0.7673 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4709/5000\n",
            "\n",
            "Epoch 4709: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0282e-04 - accuracy: 1.0000 - val_loss: 0.7773 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4710/5000\n",
            "\n",
            "Epoch 4710: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0458e-04 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4711/5000\n",
            "\n",
            "Epoch 4711: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0061e-04 - accuracy: 1.0000 - val_loss: 0.7558 - val_accuracy: 0.8417 - 4s/epoch - 115ms/step\n",
            "Epoch 4712/5000\n",
            "\n",
            "Epoch 4712: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0142e-04 - accuracy: 1.0000 - val_loss: 0.7522 - val_accuracy: 0.8453 - 3s/epoch - 74ms/step\n",
            "Epoch 4713/5000\n",
            "\n",
            "Epoch 4713: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0292e-04 - accuracy: 1.0000 - val_loss: 0.7643 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4714/5000\n",
            "\n",
            "Epoch 4714: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0322e-04 - accuracy: 1.0000 - val_loss: 0.7586 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4715/5000\n",
            "\n",
            "Epoch 4715: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0448e-04 - accuracy: 1.0000 - val_loss: 0.7752 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4716/5000\n",
            "\n",
            "Epoch 4716: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0836e-04 - accuracy: 1.0000 - val_loss: 0.7536 - val_accuracy: 0.8453 - 4s/epoch - 117ms/step\n",
            "Epoch 4717/5000\n",
            "\n",
            "Epoch 4717: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0625e-04 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4718/5000\n",
            "\n",
            "Epoch 4718: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0644e-04 - accuracy: 1.0000 - val_loss: 0.7720 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4719/5000\n",
            "\n",
            "Epoch 4719: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0214e-04 - accuracy: 1.0000 - val_loss: 0.7650 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4720/5000\n",
            "\n",
            "Epoch 4720: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0254e-04 - accuracy: 1.0000 - val_loss: 0.7702 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4721/5000\n",
            "\n",
            "Epoch 4721: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0242e-04 - accuracy: 1.0000 - val_loss: 0.7641 - val_accuracy: 0.8417 - 4s/epoch - 118ms/step\n",
            "Epoch 4722/5000\n",
            "\n",
            "Epoch 4722: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0419e-04 - accuracy: 1.0000 - val_loss: 0.7642 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4723/5000\n",
            "\n",
            "Epoch 4723: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0296e-04 - accuracy: 1.0000 - val_loss: 0.7702 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4724/5000\n",
            "\n",
            "Epoch 4724: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0086e-04 - accuracy: 1.0000 - val_loss: 0.7590 - val_accuracy: 0.8453 - 3s/epoch - 73ms/step\n",
            "Epoch 4725/5000\n",
            "\n",
            "Epoch 4725: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0239e-04 - accuracy: 1.0000 - val_loss: 0.7589 - val_accuracy: 0.8489 - 3s/epoch - 76ms/step\n",
            "Epoch 4726/5000\n",
            "\n",
            "Epoch 4726: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0217e-04 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.8489 - 4s/epoch - 114ms/step\n",
            "Epoch 4727/5000\n",
            "\n",
            "Epoch 4727: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0507e-04 - accuracy: 1.0000 - val_loss: 0.7478 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4728/5000\n",
            "\n",
            "Epoch 4728: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0638e-04 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4729/5000\n",
            "\n",
            "Epoch 4729: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0171e-04 - accuracy: 1.0000 - val_loss: 0.7592 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4730/5000\n",
            "\n",
            "Epoch 4730: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0281e-04 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.8417 - 3s/epoch - 80ms/step\n",
            "Epoch 4731/5000\n",
            "\n",
            "Epoch 4731: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0365e-04 - accuracy: 1.0000 - val_loss: 0.7754 - val_accuracy: 0.8417 - 4s/epoch - 110ms/step\n",
            "Epoch 4732/5000\n",
            "\n",
            "Epoch 4732: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0097e-04 - accuracy: 1.0000 - val_loss: 0.7657 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4733/5000\n",
            "\n",
            "Epoch 4733: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0073e-04 - accuracy: 1.0000 - val_loss: 0.7618 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4734/5000\n",
            "\n",
            "Epoch 4734: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0297e-04 - accuracy: 1.0000 - val_loss: 0.7681 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4735/5000\n",
            "\n",
            "Epoch 4735: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0333e-04 - accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.8417 - 3s/epoch - 88ms/step\n",
            "Epoch 4736/5000\n",
            "\n",
            "Epoch 4736: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0207e-04 - accuracy: 1.0000 - val_loss: 0.7820 - val_accuracy: 0.8525 - 4s/epoch - 103ms/step\n",
            "Epoch 4737/5000\n",
            "\n",
            "Epoch 4737: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0533e-04 - accuracy: 1.0000 - val_loss: 0.7580 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4738/5000\n",
            "\n",
            "Epoch 4738: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0516e-04 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4739/5000\n",
            "\n",
            "Epoch 4739: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0888e-04 - accuracy: 1.0000 - val_loss: 0.7815 - val_accuracy: 0.8309 - 3s/epoch - 72ms/step\n",
            "Epoch 4740/5000\n",
            "\n",
            "Epoch 4740: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0469e-04 - accuracy: 1.0000 - val_loss: 0.7776 - val_accuracy: 0.8381 - 3s/epoch - 93ms/step\n",
            "Epoch 4741/5000\n",
            "\n",
            "Epoch 4741: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0188e-04 - accuracy: 1.0000 - val_loss: 0.7918 - val_accuracy: 0.8417 - 3s/epoch - 97ms/step\n",
            "Epoch 4742/5000\n",
            "\n",
            "Epoch 4742: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0226e-04 - accuracy: 1.0000 - val_loss: 0.7873 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4743/5000\n",
            "\n",
            "Epoch 4743: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0126e-04 - accuracy: 1.0000 - val_loss: 0.7720 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4744/5000\n",
            "\n",
            "Epoch 4744: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0588e-04 - accuracy: 1.0000 - val_loss: 0.7785 - val_accuracy: 0.8417 - 3s/epoch - 71ms/step\n",
            "Epoch 4745/5000\n",
            "\n",
            "Epoch 4745: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0326e-04 - accuracy: 1.0000 - val_loss: 0.7722 - val_accuracy: 0.8489 - 4s/epoch - 102ms/step\n",
            "Epoch 4746/5000\n",
            "\n",
            "Epoch 4746: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.8243e-05 - accuracy: 1.0000 - val_loss: 0.7634 - val_accuracy: 0.8489 - 3s/epoch - 88ms/step\n",
            "Epoch 4747/5000\n",
            "\n",
            "Epoch 4747: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0160e-04 - accuracy: 1.0000 - val_loss: 0.7636 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4748/5000\n",
            "\n",
            "Epoch 4748: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0361e-04 - accuracy: 1.0000 - val_loss: 0.7587 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4749/5000\n",
            "\n",
            "Epoch 4749: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0017e-04 - accuracy: 1.0000 - val_loss: 0.7579 - val_accuracy: 0.8525 - 2s/epoch - 71ms/step\n",
            "Epoch 4750/5000\n",
            "\n",
            "Epoch 4750: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0286e-04 - accuracy: 1.0000 - val_loss: 0.7702 - val_accuracy: 0.8453 - 4s/epoch - 113ms/step\n",
            "Epoch 4751/5000\n",
            "\n",
            "Epoch 4751: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0228e-04 - accuracy: 1.0000 - val_loss: 0.7584 - val_accuracy: 0.8417 - 3s/epoch - 77ms/step\n",
            "Epoch 4752/5000\n",
            "\n",
            "Epoch 4752: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0225e-04 - accuracy: 1.0000 - val_loss: 0.7654 - val_accuracy: 0.8417 - 3s/epoch - 71ms/step\n",
            "Epoch 4753/5000\n",
            "\n",
            "Epoch 4753: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0110e-04 - accuracy: 1.0000 - val_loss: 0.7737 - val_accuracy: 0.8381 - 3s/epoch - 71ms/step\n",
            "Epoch 4754/5000\n",
            "\n",
            "Epoch 4754: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0077e-04 - accuracy: 1.0000 - val_loss: 0.7860 - val_accuracy: 0.8309 - 3s/epoch - 71ms/step\n",
            "Epoch 4755/5000\n",
            "\n",
            "Epoch 4755: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0176e-04 - accuracy: 1.0000 - val_loss: 0.7666 - val_accuracy: 0.8453 - 4s/epoch - 120ms/step\n",
            "Epoch 4756/5000\n",
            "\n",
            "Epoch 4756: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0143e-04 - accuracy: 1.0000 - val_loss: 0.7776 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4757/5000\n",
            "\n",
            "Epoch 4757: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0170e-04 - accuracy: 1.0000 - val_loss: 0.7741 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4758/5000\n",
            "\n",
            "Epoch 4758: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.7258e-05 - accuracy: 1.0000 - val_loss: 0.7729 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 4759/5000\n",
            "\n",
            "Epoch 4759: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0255e-04 - accuracy: 1.0000 - val_loss: 0.7813 - val_accuracy: 0.8453 - 3s/epoch - 73ms/step\n",
            "Epoch 4760/5000\n",
            "\n",
            "Epoch 4760: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0140e-04 - accuracy: 1.0000 - val_loss: 0.7690 - val_accuracy: 0.8453 - 4s/epoch - 118ms/step\n",
            "Epoch 4761/5000\n",
            "\n",
            "Epoch 4761: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0012e-04 - accuracy: 1.0000 - val_loss: 0.7717 - val_accuracy: 0.8453 - 3s/epoch - 73ms/step\n",
            "Epoch 4762/5000\n",
            "\n",
            "Epoch 4762: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0096e-04 - accuracy: 1.0000 - val_loss: 0.7680 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 4763/5000\n",
            "\n",
            "Epoch 4763: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.9450e-05 - accuracy: 1.0000 - val_loss: 0.7645 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4764/5000\n",
            "\n",
            "Epoch 4764: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.8044e-05 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.8417 - 3s/epoch - 86ms/step\n",
            "Epoch 4765/5000\n",
            "\n",
            "Epoch 4765: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0123e-04 - accuracy: 1.0000 - val_loss: 0.7502 - val_accuracy: 0.8417 - 4s/epoch - 106ms/step\n",
            "Epoch 4766/5000\n",
            "\n",
            "Epoch 4766: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.9593e-05 - accuracy: 1.0000 - val_loss: 0.7597 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 4767/5000\n",
            "\n",
            "Epoch 4767: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.9961e-05 - accuracy: 1.0000 - val_loss: 0.7650 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4768/5000\n",
            "\n",
            "Epoch 4768: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0196e-04 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 4769/5000\n",
            "\n",
            "Epoch 4769: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.9143e-05 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.8417 - 3s/epoch - 94ms/step\n",
            "Epoch 4770/5000\n",
            "\n",
            "Epoch 4770: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.8959e-05 - accuracy: 1.0000 - val_loss: 0.7605 - val_accuracy: 0.8417 - 3s/epoch - 97ms/step\n",
            "Epoch 4771/5000\n",
            "\n",
            "Epoch 4771: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.9698e-05 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.8525 - 3s/epoch - 72ms/step\n",
            "Epoch 4772/5000\n",
            "\n",
            "Epoch 4772: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0188e-04 - accuracy: 1.0000 - val_loss: 0.7660 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4773/5000\n",
            "\n",
            "Epoch 4773: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0058e-04 - accuracy: 1.0000 - val_loss: 0.8098 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4774/5000\n",
            "\n",
            "Epoch 4774: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0390e-04 - accuracy: 1.0000 - val_loss: 0.7477 - val_accuracy: 0.8453 - 4s/epoch - 108ms/step\n",
            "Epoch 4775/5000\n",
            "\n",
            "Epoch 4775: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.8496e-05 - accuracy: 1.0000 - val_loss: 0.7654 - val_accuracy: 0.8453 - 3s/epoch - 85ms/step\n",
            "Epoch 4776/5000\n",
            "\n",
            "Epoch 4776: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0006e-04 - accuracy: 1.0000 - val_loss: 0.7582 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4777/5000\n",
            "\n",
            "Epoch 4777: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0031e-04 - accuracy: 1.0000 - val_loss: 0.7656 - val_accuracy: 0.8453 - 3s/epoch - 71ms/step\n",
            "Epoch 4778/5000\n",
            "\n",
            "Epoch 4778: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.6659e-05 - accuracy: 1.0000 - val_loss: 0.7574 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4779/5000\n",
            "\n",
            "Epoch 4779: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.8309e-05 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8453 - 4s/epoch - 118ms/step\n",
            "Epoch 4780/5000\n",
            "\n",
            "Epoch 4780: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.9639e-05 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.8453 - 3s/epoch - 74ms/step\n",
            "Epoch 4781/5000\n",
            "\n",
            "Epoch 4781: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.8869e-05 - accuracy: 1.0000 - val_loss: 0.7681 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4782/5000\n",
            "\n",
            "Epoch 4782: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.9007e-05 - accuracy: 1.0000 - val_loss: 0.7672 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4783/5000\n",
            "\n",
            "Epoch 4783: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.7020e-05 - accuracy: 1.0000 - val_loss: 0.7620 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4784/5000\n",
            "\n",
            "Epoch 4784: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.7929e-05 - accuracy: 1.0000 - val_loss: 0.7572 - val_accuracy: 0.8453 - 4s/epoch - 119ms/step\n",
            "Epoch 4785/5000\n",
            "\n",
            "Epoch 4785: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.7557e-05 - accuracy: 1.0000 - val_loss: 0.7443 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4786/5000\n",
            "\n",
            "Epoch 4786: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.8154e-05 - accuracy: 1.0000 - val_loss: 0.7520 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4787/5000\n",
            "\n",
            "Epoch 4787: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0236e-04 - accuracy: 1.0000 - val_loss: 0.7637 - val_accuracy: 0.8489 - 3s/epoch - 74ms/step\n",
            "Epoch 4788/5000\n",
            "\n",
            "Epoch 4788: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0277e-04 - accuracy: 1.0000 - val_loss: 0.7854 - val_accuracy: 0.8345 - 3s/epoch - 79ms/step\n",
            "Epoch 4789/5000\n",
            "\n",
            "Epoch 4789: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0177e-04 - accuracy: 1.0000 - val_loss: 0.7759 - val_accuracy: 0.8417 - 4s/epoch - 113ms/step\n",
            "Epoch 4790/5000\n",
            "\n",
            "Epoch 4790: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.9204e-05 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4791/5000\n",
            "\n",
            "Epoch 4791: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.6384e-05 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 4792/5000\n",
            "\n",
            "Epoch 4792: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.8219e-05 - accuracy: 1.0000 - val_loss: 0.7628 - val_accuracy: 0.8381 - 3s/epoch - 72ms/step\n",
            "Epoch 4793/5000\n",
            "\n",
            "Epoch 4793: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.7615e-05 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.8453 - 3s/epoch - 85ms/step\n",
            "Epoch 4794/5000\n",
            "\n",
            "Epoch 4794: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 1.0089e-04 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8417 - 4s/epoch - 106ms/step\n",
            "Epoch 4795/5000\n",
            "\n",
            "Epoch 4795: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.9820e-05 - accuracy: 1.0000 - val_loss: 0.7686 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4796/5000\n",
            "\n",
            "Epoch 4796: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.8132e-05 - accuracy: 1.0000 - val_loss: 0.7714 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4797/5000\n",
            "\n",
            "Epoch 4797: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.5986e-05 - accuracy: 1.0000 - val_loss: 0.7748 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4798/5000\n",
            "\n",
            "Epoch 4798: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0263e-04 - accuracy: 1.0000 - val_loss: 0.7739 - val_accuracy: 0.8273 - 3s/epoch - 91ms/step\n",
            "Epoch 4799/5000\n",
            "\n",
            "Epoch 4799: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0579e-04 - accuracy: 1.0000 - val_loss: 0.7966 - val_accuracy: 0.8381 - 3s/epoch - 99ms/step\n",
            "Epoch 4800/5000\n",
            "\n",
            "Epoch 4800: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0278e-04 - accuracy: 1.0000 - val_loss: 0.7770 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4801/5000\n",
            "\n",
            "Epoch 4801: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0205e-04 - accuracy: 1.0000 - val_loss: 0.7897 - val_accuracy: 0.8381 - 3s/epoch - 73ms/step\n",
            "Epoch 4802/5000\n",
            "\n",
            "Epoch 4802: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.8400e-05 - accuracy: 1.0000 - val_loss: 0.7803 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4803/5000\n",
            "\n",
            "Epoch 4803: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.7664e-05 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 0.8417 - 3s/epoch - 99ms/step\n",
            "Epoch 4804/5000\n",
            "\n",
            "Epoch 4804: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.7418e-05 - accuracy: 1.0000 - val_loss: 0.7720 - val_accuracy: 0.8417 - 3s/epoch - 91ms/step\n",
            "Epoch 4805/5000\n",
            "\n",
            "Epoch 4805: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.5395e-05 - accuracy: 1.0000 - val_loss: 0.7691 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4806/5000\n",
            "\n",
            "Epoch 4806: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0047e-04 - accuracy: 1.0000 - val_loss: 0.7816 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 4807/5000\n",
            "\n",
            "Epoch 4807: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.6703e-05 - accuracy: 1.0000 - val_loss: 0.7789 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4808/5000\n",
            "\n",
            "Epoch 4808: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.7366e-05 - accuracy: 1.0000 - val_loss: 0.7837 - val_accuracy: 0.8381 - 4s/epoch - 109ms/step\n",
            "Epoch 4809/5000\n",
            "\n",
            "Epoch 4809: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.8092e-05 - accuracy: 1.0000 - val_loss: 0.7787 - val_accuracy: 0.8489 - 3s/epoch - 82ms/step\n",
            "Epoch 4810/5000\n",
            "\n",
            "Epoch 4810: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.6607e-05 - accuracy: 1.0000 - val_loss: 0.7699 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4811/5000\n",
            "\n",
            "Epoch 4811: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.8260e-05 - accuracy: 1.0000 - val_loss: 0.7752 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4812/5000\n",
            "\n",
            "Epoch 4812: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.6831e-05 - accuracy: 1.0000 - val_loss: 0.7514 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4813/5000\n",
            "\n",
            "Epoch 4813: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.6717e-05 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.8453 - 4s/epoch - 119ms/step\n",
            "Epoch 4814/5000\n",
            "\n",
            "Epoch 4814: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 1.0256e-04 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4815/5000\n",
            "\n",
            "Epoch 4815: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.8212e-05 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4816/5000\n",
            "\n",
            "Epoch 4816: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.8372e-05 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4817/5000\n",
            "\n",
            "Epoch 4817: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.6943e-05 - accuracy: 1.0000 - val_loss: 0.7655 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4818/5000\n",
            "\n",
            "Epoch 4818: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.5486e-05 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.8417 - 4s/epoch - 117ms/step\n",
            "Epoch 4819/5000\n",
            "\n",
            "Epoch 4819: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.6792e-05 - accuracy: 1.0000 - val_loss: 0.7983 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4820/5000\n",
            "\n",
            "Epoch 4820: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0189e-04 - accuracy: 1.0000 - val_loss: 0.7794 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4821/5000\n",
            "\n",
            "Epoch 4821: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 1.0185e-04 - accuracy: 1.0000 - val_loss: 0.7815 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4822/5000\n",
            "\n",
            "Epoch 4822: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.7717e-05 - accuracy: 1.0000 - val_loss: 0.7734 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4823/5000\n",
            "\n",
            "Epoch 4823: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.6181e-05 - accuracy: 1.0000 - val_loss: 0.7702 - val_accuracy: 0.8489 - 4s/epoch - 117ms/step\n",
            "Epoch 4824/5000\n",
            "\n",
            "Epoch 4824: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.7814e-05 - accuracy: 1.0000 - val_loss: 0.7783 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4825/5000\n",
            "\n",
            "Epoch 4825: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.6368e-05 - accuracy: 1.0000 - val_loss: 0.7794 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4826/5000\n",
            "\n",
            "Epoch 4826: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.6893e-05 - accuracy: 1.0000 - val_loss: 0.7751 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4827/5000\n",
            "\n",
            "Epoch 4827: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.7909e-05 - accuracy: 1.0000 - val_loss: 0.7855 - val_accuracy: 0.8489 - 3s/epoch - 77ms/step\n",
            "Epoch 4828/5000\n",
            "\n",
            "Epoch 4828: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.7238e-05 - accuracy: 1.0000 - val_loss: 0.7697 - val_accuracy: 0.8525 - 4s/epoch - 111ms/step\n",
            "Epoch 4829/5000\n",
            "\n",
            "Epoch 4829: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.6829e-05 - accuracy: 1.0000 - val_loss: 0.8038 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4830/5000\n",
            "\n",
            "Epoch 4830: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.5307e-05 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 0.8561 - 2s/epoch - 70ms/step\n",
            "Epoch 4831/5000\n",
            "\n",
            "Epoch 4831: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.7204e-05 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4832/5000\n",
            "\n",
            "Epoch 4832: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.5822e-05 - accuracy: 1.0000 - val_loss: 0.7962 - val_accuracy: 0.8561 - 3s/epoch - 81ms/step\n",
            "Epoch 4833/5000\n",
            "\n",
            "Epoch 4833: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.5220e-05 - accuracy: 1.0000 - val_loss: 0.7667 - val_accuracy: 0.8489 - 4s/epoch - 108ms/step\n",
            "Epoch 4834/5000\n",
            "\n",
            "Epoch 4834: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.5770e-05 - accuracy: 1.0000 - val_loss: 0.7697 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4835/5000\n",
            "\n",
            "Epoch 4835: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4577e-05 - accuracy: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4836/5000\n",
            "\n",
            "Epoch 4836: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.3491e-05 - accuracy: 1.0000 - val_loss: 0.7652 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4837/5000\n",
            "\n",
            "Epoch 4837: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.8075e-05 - accuracy: 1.0000 - val_loss: 0.7655 - val_accuracy: 0.8489 - 3s/epoch - 89ms/step\n",
            "Epoch 4838/5000\n",
            "\n",
            "Epoch 4838: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.9226e-05 - accuracy: 1.0000 - val_loss: 0.7593 - val_accuracy: 0.8453 - 3s/epoch - 99ms/step\n",
            "Epoch 4839/5000\n",
            "\n",
            "Epoch 4839: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.8215e-05 - accuracy: 1.0000 - val_loss: 0.7736 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4840/5000\n",
            "\n",
            "Epoch 4840: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.7077e-05 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.8345 - 3s/epoch - 73ms/step\n",
            "Epoch 4841/5000\n",
            "\n",
            "Epoch 4841: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.8527e-05 - accuracy: 1.0000 - val_loss: 0.7801 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4842/5000\n",
            "\n",
            "Epoch 4842: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.5469e-05 - accuracy: 1.0000 - val_loss: 0.7685 - val_accuracy: 0.8381 - 3s/epoch - 96ms/step\n",
            "Epoch 4843/5000\n",
            "\n",
            "Epoch 4843: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.7033e-05 - accuracy: 1.0000 - val_loss: 0.7723 - val_accuracy: 0.8381 - 3s/epoch - 93ms/step\n",
            "Epoch 4844/5000\n",
            "\n",
            "Epoch 4844: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.7572e-05 - accuracy: 1.0000 - val_loss: 0.8058 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4845/5000\n",
            "\n",
            "Epoch 4845: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.3694e-05 - accuracy: 1.0000 - val_loss: 0.7741 - val_accuracy: 0.8417 - 3s/epoch - 73ms/step\n",
            "Epoch 4846/5000\n",
            "\n",
            "Epoch 4846: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.2624e-05 - accuracy: 1.0000 - val_loss: 0.7675 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4847/5000\n",
            "\n",
            "Epoch 4847: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.4150e-05 - accuracy: 1.0000 - val_loss: 0.7674 - val_accuracy: 0.8489 - 4s/epoch - 103ms/step\n",
            "Epoch 4848/5000\n",
            "\n",
            "Epoch 4848: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.5618e-05 - accuracy: 1.0000 - val_loss: 0.7650 - val_accuracy: 0.8417 - 3s/epoch - 84ms/step\n",
            "Epoch 4849/5000\n",
            "\n",
            "Epoch 4849: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.8131e-05 - accuracy: 1.0000 - val_loss: 0.7620 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4850/5000\n",
            "\n",
            "Epoch 4850: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4971e-05 - accuracy: 1.0000 - val_loss: 0.7706 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4851/5000\n",
            "\n",
            "Epoch 4851: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.4111e-05 - accuracy: 1.0000 - val_loss: 0.7667 - val_accuracy: 0.8417 - 3s/epoch - 72ms/step\n",
            "Epoch 4852/5000\n",
            "\n",
            "Epoch 4852: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.8034e-05 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.8381 - 4s/epoch - 111ms/step\n",
            "Epoch 4853/5000\n",
            "\n",
            "Epoch 4853: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.4437e-05 - accuracy: 1.0000 - val_loss: 0.7515 - val_accuracy: 0.8453 - 3s/epoch - 78ms/step\n",
            "Epoch 4854/5000\n",
            "\n",
            "Epoch 4854: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.5316e-05 - accuracy: 1.0000 - val_loss: 0.7748 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4855/5000\n",
            "\n",
            "Epoch 4855: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.5125e-05 - accuracy: 1.0000 - val_loss: 0.7679 - val_accuracy: 0.8453 - 3s/epoch - 71ms/step\n",
            "Epoch 4856/5000\n",
            "\n",
            "Epoch 4856: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.2371e-05 - accuracy: 1.0000 - val_loss: 0.7662 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4857/5000\n",
            "\n",
            "Epoch 4857: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.3045e-05 - accuracy: 1.0000 - val_loss: 0.7579 - val_accuracy: 0.8453 - 4s/epoch - 120ms/step\n",
            "Epoch 4858/5000\n",
            "\n",
            "Epoch 4858: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1714e-05 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4859/5000\n",
            "\n",
            "Epoch 4859: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.2503e-05 - accuracy: 1.0000 - val_loss: 0.7509 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4860/5000\n",
            "\n",
            "Epoch 4860: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.3584e-05 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4861/5000\n",
            "\n",
            "Epoch 4861: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.0107e-05 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4862/5000\n",
            "\n",
            "Epoch 4862: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.3867e-05 - accuracy: 1.0000 - val_loss: 0.7565 - val_accuracy: 0.8453 - 4s/epoch - 119ms/step\n",
            "Epoch 4863/5000\n",
            "\n",
            "Epoch 4863: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.2457e-05 - accuracy: 1.0000 - val_loss: 0.7615 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4864/5000\n",
            "\n",
            "Epoch 4864: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.2493e-05 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.8453 - 3s/epoch - 73ms/step\n",
            "Epoch 4865/5000\n",
            "\n",
            "Epoch 4865: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1870e-05 - accuracy: 1.0000 - val_loss: 0.7624 - val_accuracy: 0.8417 - 2s/epoch - 69ms/step\n",
            "Epoch 4866/5000\n",
            "\n",
            "Epoch 4866: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.3640e-05 - accuracy: 1.0000 - val_loss: 0.7612 - val_accuracy: 0.8453 - 3s/epoch - 75ms/step\n",
            "Epoch 4867/5000\n",
            "\n",
            "Epoch 4867: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.3890e-05 - accuracy: 1.0000 - val_loss: 0.7568 - val_accuracy: 0.8453 - 4s/epoch - 113ms/step\n",
            "Epoch 4868/5000\n",
            "\n",
            "Epoch 4868: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.2358e-05 - accuracy: 1.0000 - val_loss: 0.7624 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4869/5000\n",
            "\n",
            "Epoch 4869: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4655e-05 - accuracy: 1.0000 - val_loss: 0.7615 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4870/5000\n",
            "\n",
            "Epoch 4870: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.7318e-05 - accuracy: 1.0000 - val_loss: 0.7641 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4871/5000\n",
            "\n",
            "Epoch 4871: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.3769e-05 - accuracy: 1.0000 - val_loss: 0.7730 - val_accuracy: 0.8417 - 3s/epoch - 80ms/step\n",
            "Epoch 4872/5000\n",
            "\n",
            "Epoch 4872: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.7840e-05 - accuracy: 1.0000 - val_loss: 0.7884 - val_accuracy: 0.8381 - 4s/epoch - 109ms/step\n",
            "Epoch 4873/5000\n",
            "\n",
            "Epoch 4873: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4872e-05 - accuracy: 1.0000 - val_loss: 0.7698 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4874/5000\n",
            "\n",
            "Epoch 4874: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.3499e-05 - accuracy: 1.0000 - val_loss: 0.7714 - val_accuracy: 0.8345 - 2s/epoch - 70ms/step\n",
            "Epoch 4875/5000\n",
            "\n",
            "Epoch 4875: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4574e-05 - accuracy: 1.0000 - val_loss: 0.7747 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4876/5000\n",
            "\n",
            "Epoch 4876: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.3965e-05 - accuracy: 1.0000 - val_loss: 0.7703 - val_accuracy: 0.8417 - 3s/epoch - 86ms/step\n",
            "Epoch 4877/5000\n",
            "\n",
            "Epoch 4877: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.4327e-05 - accuracy: 1.0000 - val_loss: 0.7650 - val_accuracy: 0.8417 - 4s/epoch - 103ms/step\n",
            "Epoch 4878/5000\n",
            "\n",
            "Epoch 4878: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.0907e-05 - accuracy: 1.0000 - val_loss: 0.7682 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4879/5000\n",
            "\n",
            "Epoch 4879: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.3779e-05 - accuracy: 1.0000 - val_loss: 0.7616 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4880/5000\n",
            "\n",
            "Epoch 4880: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4397e-05 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4881/5000\n",
            "\n",
            "Epoch 4881: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.1535e-05 - accuracy: 1.0000 - val_loss: 0.7747 - val_accuracy: 0.8489 - 3s/epoch - 93ms/step\n",
            "Epoch 4882/5000\n",
            "\n",
            "Epoch 4882: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.3150e-05 - accuracy: 1.0000 - val_loss: 0.7728 - val_accuracy: 0.8381 - 3s/epoch - 95ms/step\n",
            "Epoch 4883/5000\n",
            "\n",
            "Epoch 4883: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4854e-05 - accuracy: 1.0000 - val_loss: 0.7752 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4884/5000\n",
            "\n",
            "Epoch 4884: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4536e-05 - accuracy: 1.0000 - val_loss: 0.7585 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4885/5000\n",
            "\n",
            "Epoch 4885: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.3133e-05 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4886/5000\n",
            "\n",
            "Epoch 4886: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.1497e-05 - accuracy: 1.0000 - val_loss: 0.7524 - val_accuracy: 0.8453 - 3s/epoch - 100ms/step\n",
            "Epoch 4887/5000\n",
            "\n",
            "Epoch 4887: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.3182e-05 - accuracy: 1.0000 - val_loss: 0.7685 - val_accuracy: 0.8417 - 3s/epoch - 87ms/step\n",
            "Epoch 4888/5000\n",
            "\n",
            "Epoch 4888: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1582e-05 - accuracy: 1.0000 - val_loss: 0.7624 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4889/5000\n",
            "\n",
            "Epoch 4889: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.0830e-05 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4890/5000\n",
            "\n",
            "Epoch 4890: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.3166e-05 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.8417 - 2s/epoch - 68ms/step\n",
            "Epoch 4891/5000\n",
            "\n",
            "Epoch 4891: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 8.8477e-05 - accuracy: 1.0000 - val_loss: 0.7677 - val_accuracy: 0.8453 - 4s/epoch - 104ms/step\n",
            "Epoch 4892/5000\n",
            "\n",
            "Epoch 4892: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.3348e-05 - accuracy: 1.0000 - val_loss: 0.7652 - val_accuracy: 0.8417 - 3s/epoch - 82ms/step\n",
            "Epoch 4893/5000\n",
            "\n",
            "Epoch 4893: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1167e-05 - accuracy: 1.0000 - val_loss: 0.7614 - val_accuracy: 0.8345 - 2s/epoch - 70ms/step\n",
            "Epoch 4894/5000\n",
            "\n",
            "Epoch 4894: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.2661e-05 - accuracy: 1.0000 - val_loss: 0.7516 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4895/5000\n",
            "\n",
            "Epoch 4895: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4745e-05 - accuracy: 1.0000 - val_loss: 0.7641 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4896/5000\n",
            "\n",
            "Epoch 4896: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.2543e-05 - accuracy: 1.0000 - val_loss: 0.7812 - val_accuracy: 0.8381 - 4s/epoch - 107ms/step\n",
            "Epoch 4897/5000\n",
            "\n",
            "Epoch 4897: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.3486e-05 - accuracy: 1.0000 - val_loss: 0.7696 - val_accuracy: 0.8345 - 3s/epoch - 80ms/step\n",
            "Epoch 4898/5000\n",
            "\n",
            "Epoch 4898: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1705e-05 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4899/5000\n",
            "\n",
            "Epoch 4899: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.2684e-05 - accuracy: 1.0000 - val_loss: 0.7759 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4900/5000\n",
            "\n",
            "Epoch 4900: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1124e-05 - accuracy: 1.0000 - val_loss: 0.7611 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4901/5000\n",
            "\n",
            "Epoch 4901: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.8446e-05 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.8489 - 4s/epoch - 113ms/step\n",
            "Epoch 4902/5000\n",
            "\n",
            "Epoch 4902: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.7765e-05 - accuracy: 1.0000 - val_loss: 0.7855 - val_accuracy: 0.8381 - 3s/epoch - 74ms/step\n",
            "Epoch 4903/5000\n",
            "\n",
            "Epoch 4903: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.0925e-05 - accuracy: 1.0000 - val_loss: 0.7558 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4904/5000\n",
            "\n",
            "Epoch 4904: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.2222e-05 - accuracy: 1.0000 - val_loss: 0.7690 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4905/5000\n",
            "\n",
            "Epoch 4905: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.3918e-05 - accuracy: 1.0000 - val_loss: 0.7671 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4906/5000\n",
            "\n",
            "Epoch 4906: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.1291e-05 - accuracy: 1.0000 - val_loss: 0.7718 - val_accuracy: 0.8381 - 4s/epoch - 119ms/step\n",
            "Epoch 4907/5000\n",
            "\n",
            "Epoch 4907: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1099e-05 - accuracy: 1.0000 - val_loss: 0.7660 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4908/5000\n",
            "\n",
            "Epoch 4908: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.0440e-05 - accuracy: 1.0000 - val_loss: 0.7733 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4909/5000\n",
            "\n",
            "Epoch 4909: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.5643e-05 - accuracy: 1.0000 - val_loss: 0.7721 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4910/5000\n",
            "\n",
            "Epoch 4910: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.5079e-05 - accuracy: 1.0000 - val_loss: 0.7807 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4911/5000\n",
            "\n",
            "Epoch 4911: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.0854e-05 - accuracy: 1.0000 - val_loss: 0.7673 - val_accuracy: 0.8417 - 4s/epoch - 119ms/step\n",
            "Epoch 4912/5000\n",
            "\n",
            "Epoch 4912: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.2923e-05 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4913/5000\n",
            "\n",
            "Epoch 4913: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4459e-05 - accuracy: 1.0000 - val_loss: 0.7791 - val_accuracy: 0.8273 - 2s/epoch - 70ms/step\n",
            "Epoch 4914/5000\n",
            "\n",
            "Epoch 4914: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4485e-05 - accuracy: 1.0000 - val_loss: 0.7695 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4915/5000\n",
            "\n",
            "Epoch 4915: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 8.8025e-05 - accuracy: 1.0000 - val_loss: 0.7628 - val_accuracy: 0.8417 - 3s/epoch - 74ms/step\n",
            "Epoch 4916/5000\n",
            "\n",
            "Epoch 4916: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.5055e-05 - accuracy: 1.0000 - val_loss: 0.7888 - val_accuracy: 0.8417 - 4s/epoch - 116ms/step\n",
            "Epoch 4917/5000\n",
            "\n",
            "Epoch 4917: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.2754e-05 - accuracy: 1.0000 - val_loss: 0.7762 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 4918/5000\n",
            "\n",
            "Epoch 4918: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1272e-05 - accuracy: 1.0000 - val_loss: 0.7592 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4919/5000\n",
            "\n",
            "Epoch 4919: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.3082e-05 - accuracy: 1.0000 - val_loss: 0.7807 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4920/5000\n",
            "\n",
            "Epoch 4920: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.1864e-05 - accuracy: 1.0000 - val_loss: 0.7620 - val_accuracy: 0.8489 - 3s/epoch - 80ms/step\n",
            "Epoch 4921/5000\n",
            "\n",
            "Epoch 4921: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.2595e-05 - accuracy: 1.0000 - val_loss: 0.7647 - val_accuracy: 0.8489 - 4s/epoch - 108ms/step\n",
            "Epoch 4922/5000\n",
            "\n",
            "Epoch 4922: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4043e-05 - accuracy: 1.0000 - val_loss: 0.7707 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4923/5000\n",
            "\n",
            "Epoch 4923: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.9959e-05 - accuracy: 1.0000 - val_loss: 0.7721 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4924/5000\n",
            "\n",
            "Epoch 4924: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1079e-05 - accuracy: 1.0000 - val_loss: 0.7666 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4925/5000\n",
            "\n",
            "Epoch 4925: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.2519e-05 - accuracy: 1.0000 - val_loss: 0.7533 - val_accuracy: 0.8453 - 3s/epoch - 86ms/step\n",
            "Epoch 4926/5000\n",
            "\n",
            "Epoch 4926: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.1908e-05 - accuracy: 1.0000 - val_loss: 0.7532 - val_accuracy: 0.8489 - 4s/epoch - 102ms/step\n",
            "Epoch 4927/5000\n",
            "\n",
            "Epoch 4927: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.2713e-05 - accuracy: 1.0000 - val_loss: 0.7448 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4928/5000\n",
            "\n",
            "Epoch 4928: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1131e-05 - accuracy: 1.0000 - val_loss: 0.7514 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4929/5000\n",
            "\n",
            "Epoch 4929: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1045e-05 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4930/5000\n",
            "\n",
            "Epoch 4930: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.0005e-05 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.8453 - 3s/epoch - 93ms/step\n",
            "Epoch 4931/5000\n",
            "\n",
            "Epoch 4931: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.0548e-05 - accuracy: 1.0000 - val_loss: 0.7573 - val_accuracy: 0.8525 - 3s/epoch - 96ms/step\n",
            "Epoch 4932/5000\n",
            "\n",
            "Epoch 4932: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.0139e-05 - accuracy: 1.0000 - val_loss: 0.7573 - val_accuracy: 0.8417 - 2s/epoch - 69ms/step\n",
            "Epoch 4933/5000\n",
            "\n",
            "Epoch 4933: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.7852e-05 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4934/5000\n",
            "\n",
            "Epoch 4934: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.9315e-05 - accuracy: 1.0000 - val_loss: 0.7580 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4935/5000\n",
            "\n",
            "Epoch 4935: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 8.7293e-05 - accuracy: 1.0000 - val_loss: 0.7624 - val_accuracy: 0.8489 - 3s/epoch - 93ms/step\n",
            "Epoch 4936/5000\n",
            "\n",
            "Epoch 4936: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.2333e-05 - accuracy: 1.0000 - val_loss: 0.7585 - val_accuracy: 0.8453 - 3s/epoch - 93ms/step\n",
            "Epoch 4937/5000\n",
            "\n",
            "Epoch 4937: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.3524e-05 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4938/5000\n",
            "\n",
            "Epoch 4938: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1558e-05 - accuracy: 1.0000 - val_loss: 0.7595 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4939/5000\n",
            "\n",
            "Epoch 4939: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1984e-05 - accuracy: 1.0000 - val_loss: 0.7736 - val_accuracy: 0.8309 - 2s/epoch - 70ms/step\n",
            "Epoch 4940/5000\n",
            "\n",
            "Epoch 4940: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 8.8963e-05 - accuracy: 1.0000 - val_loss: 0.7609 - val_accuracy: 0.8453 - 4s/epoch - 102ms/step\n",
            "Epoch 4941/5000\n",
            "\n",
            "Epoch 4941: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 8.8092e-05 - accuracy: 1.0000 - val_loss: 0.7565 - val_accuracy: 0.8453 - 3s/epoch - 88ms/step\n",
            "Epoch 4942/5000\n",
            "\n",
            "Epoch 4942: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.7427e-05 - accuracy: 1.0000 - val_loss: 0.7574 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4943/5000\n",
            "\n",
            "Epoch 4943: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.0312e-05 - accuracy: 1.0000 - val_loss: 0.7477 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4944/5000\n",
            "\n",
            "Epoch 4944: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.2512e-05 - accuracy: 1.0000 - val_loss: 0.7481 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4945/5000\n",
            "\n",
            "Epoch 4945: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 8.8153e-05 - accuracy: 1.0000 - val_loss: 0.7673 - val_accuracy: 0.8453 - 4s/epoch - 107ms/step\n",
            "Epoch 4946/5000\n",
            "\n",
            "Epoch 4946: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 8.9077e-05 - accuracy: 1.0000 - val_loss: 0.7460 - val_accuracy: 0.8489 - 3s/epoch - 83ms/step\n",
            "Epoch 4947/5000\n",
            "\n",
            "Epoch 4947: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.6756e-05 - accuracy: 1.0000 - val_loss: 0.7333 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4948/5000\n",
            "\n",
            "Epoch 4948: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.6905e-05 - accuracy: 1.0000 - val_loss: 0.7372 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4949/5000\n",
            "\n",
            "Epoch 4949: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.0315e-05 - accuracy: 1.0000 - val_loss: 0.7431 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4950/5000\n",
            "\n",
            "Epoch 4950: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 8.9209e-05 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.8453 - 4s/epoch - 111ms/step\n",
            "Epoch 4951/5000\n",
            "\n",
            "Epoch 4951: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 8.9150e-05 - accuracy: 1.0000 - val_loss: 0.7693 - val_accuracy: 0.8489 - 3s/epoch - 78ms/step\n",
            "Epoch 4952/5000\n",
            "\n",
            "Epoch 4952: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.9550e-05 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 4953/5000\n",
            "\n",
            "Epoch 4953: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.9610e-05 - accuracy: 1.0000 - val_loss: 0.7467 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4954/5000\n",
            "\n",
            "Epoch 4954: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.0552e-05 - accuracy: 1.0000 - val_loss: 0.7672 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4955/5000\n",
            "\n",
            "Epoch 4955: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.9440e-05 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.8417 - 4s/epoch - 119ms/step\n",
            "Epoch 4956/5000\n",
            "\n",
            "Epoch 4956: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4470e-05 - accuracy: 1.0000 - val_loss: 0.7754 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4957/5000\n",
            "\n",
            "Epoch 4957: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.3819e-05 - accuracy: 1.0000 - val_loss: 0.7778 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4958/5000\n",
            "\n",
            "Epoch 4958: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.9761e-05 - accuracy: 1.0000 - val_loss: 0.7757 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4959/5000\n",
            "\n",
            "Epoch 4959: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 8.9542e-05 - accuracy: 1.0000 - val_loss: 0.7707 - val_accuracy: 0.8453 - 3s/epoch - 72ms/step\n",
            "Epoch 4960/5000\n",
            "\n",
            "Epoch 4960: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 9.1438e-05 - accuracy: 1.0000 - val_loss: 0.7819 - val_accuracy: 0.8417 - 4s/epoch - 119ms/step\n",
            "Epoch 4961/5000\n",
            "\n",
            "Epoch 4961: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1391e-05 - accuracy: 1.0000 - val_loss: 0.7688 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4962/5000\n",
            "\n",
            "Epoch 4962: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.9272e-05 - accuracy: 1.0000 - val_loss: 0.7601 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4963/5000\n",
            "\n",
            "Epoch 4963: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.3267e-05 - accuracy: 1.0000 - val_loss: 0.7752 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4964/5000\n",
            "\n",
            "Epoch 4964: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.1112e-05 - accuracy: 1.0000 - val_loss: 0.7621 - val_accuracy: 0.8417 - 3s/epoch - 76ms/step\n",
            "Epoch 4965/5000\n",
            "\n",
            "Epoch 4965: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 8.8971e-05 - accuracy: 1.0000 - val_loss: 0.7547 - val_accuracy: 0.8417 - 4s/epoch - 113ms/step\n",
            "Epoch 4966/5000\n",
            "\n",
            "Epoch 4966: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.9125e-05 - accuracy: 1.0000 - val_loss: 0.7551 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4967/5000\n",
            "\n",
            "Epoch 4967: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.9252e-05 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.8417 - 2s/epoch - 69ms/step\n",
            "Epoch 4968/5000\n",
            "\n",
            "Epoch 4968: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.7993e-05 - accuracy: 1.0000 - val_loss: 0.7704 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4969/5000\n",
            "\n",
            "Epoch 4969: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 8.7573e-05 - accuracy: 1.0000 - val_loss: 0.7633 - val_accuracy: 0.8453 - 3s/epoch - 79ms/step\n",
            "Epoch 4970/5000\n",
            "\n",
            "Epoch 4970: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 8.7359e-05 - accuracy: 1.0000 - val_loss: 0.7610 - val_accuracy: 0.8417 - 4s/epoch - 108ms/step\n",
            "Epoch 4971/5000\n",
            "\n",
            "Epoch 4971: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.0308e-05 - accuracy: 1.0000 - val_loss: 0.7733 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4972/5000\n",
            "\n",
            "Epoch 4972: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.5213e-05 - accuracy: 1.0000 - val_loss: 0.7648 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4973/5000\n",
            "\n",
            "Epoch 4973: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.5922e-05 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4974/5000\n",
            "\n",
            "Epoch 4974: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 8.5340e-05 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 0.8453 - 3s/epoch - 87ms/step\n",
            "Epoch 4975/5000\n",
            "\n",
            "Epoch 4975: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 8.6711e-05 - accuracy: 1.0000 - val_loss: 0.7483 - val_accuracy: 0.8489 - 4s/epoch - 102ms/step\n",
            "Epoch 4976/5000\n",
            "\n",
            "Epoch 4976: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.6944e-05 - accuracy: 1.0000 - val_loss: 0.7507 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4977/5000\n",
            "\n",
            "Epoch 4977: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.5999e-05 - accuracy: 1.0000 - val_loss: 0.7532 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4978/5000\n",
            "\n",
            "Epoch 4978: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.6370e-05 - accuracy: 1.0000 - val_loss: 0.7554 - val_accuracy: 0.8381 - 2s/epoch - 70ms/step\n",
            "Epoch 4979/5000\n",
            "\n",
            "Epoch 4979: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.0434e-05 - accuracy: 1.0000 - val_loss: 0.7625 - val_accuracy: 0.8417 - 3s/epoch - 91ms/step\n",
            "Epoch 4980/5000\n",
            "\n",
            "Epoch 4980: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 8.7450e-05 - accuracy: 1.0000 - val_loss: 0.7515 - val_accuracy: 0.8453 - 3s/epoch - 99ms/step\n",
            "Epoch 4981/5000\n",
            "\n",
            "Epoch 4981: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.9159e-05 - accuracy: 1.0000 - val_loss: 0.7582 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 4982/5000\n",
            "\n",
            "Epoch 4982: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.1851e-05 - accuracy: 1.0000 - val_loss: 0.7867 - val_accuracy: 0.8453 - 2s/epoch - 71ms/step\n",
            "Epoch 4983/5000\n",
            "\n",
            "Epoch 4983: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.7896e-05 - accuracy: 1.0000 - val_loss: 0.7522 - val_accuracy: 0.8489 - 2s/epoch - 71ms/step\n",
            "Epoch 4984/5000\n",
            "\n",
            "Epoch 4984: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 8.8064e-05 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.8525 - 3s/epoch - 100ms/step\n",
            "Epoch 4985/5000\n",
            "\n",
            "Epoch 4985: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 8.7747e-05 - accuracy: 1.0000 - val_loss: 0.7633 - val_accuracy: 0.8489 - 3s/epoch - 91ms/step\n",
            "Epoch 4986/5000\n",
            "\n",
            "Epoch 4986: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.5881e-05 - accuracy: 1.0000 - val_loss: 0.7572 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4987/5000\n",
            "\n",
            "Epoch 4987: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.5314e-05 - accuracy: 1.0000 - val_loss: 0.7625 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4988/5000\n",
            "\n",
            "Epoch 4988: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.3505e-05 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4989/5000\n",
            "\n",
            "Epoch 4989: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 8.7585e-05 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.8525 - 4s/epoch - 105ms/step\n",
            "Epoch 4990/5000\n",
            "\n",
            "Epoch 4990: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 9.5472e-05 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.8489 - 3s/epoch - 82ms/step\n",
            "Epoch 4991/5000\n",
            "\n",
            "Epoch 4991: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.4106e-05 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.8417 - 2s/epoch - 70ms/step\n",
            "Epoch 4992/5000\n",
            "\n",
            "Epoch 4992: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 9.2365e-05 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.8345 - 2s/epoch - 69ms/step\n",
            "Epoch 4993/5000\n",
            "\n",
            "Epoch 4993: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.6558e-05 - accuracy: 1.0000 - val_loss: 0.7680 - val_accuracy: 0.8453 - 2s/epoch - 69ms/step\n",
            "Epoch 4994/5000\n",
            "\n",
            "Epoch 4994: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 8.5721e-05 - accuracy: 1.0000 - val_loss: 0.7659 - val_accuracy: 0.8453 - 4s/epoch - 107ms/step\n",
            "Epoch 4995/5000\n",
            "\n",
            "Epoch 4995: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 8.6131e-05 - accuracy: 1.0000 - val_loss: 0.7652 - val_accuracy: 0.8525 - 3s/epoch - 82ms/step\n",
            "Epoch 4996/5000\n",
            "\n",
            "Epoch 4996: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.7390e-05 - accuracy: 1.0000 - val_loss: 0.7626 - val_accuracy: 0.8489 - 2s/epoch - 70ms/step\n",
            "Epoch 4997/5000\n",
            "\n",
            "Epoch 4997: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.4821e-05 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.8525 - 2s/epoch - 70ms/step\n",
            "Epoch 4998/5000\n",
            "\n",
            "Epoch 4998: val_accuracy did not improve from 0.85612\n",
            "35/35 - 2s - loss: 8.4544e-05 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.8453 - 2s/epoch - 70ms/step\n",
            "Epoch 4999/5000\n",
            "\n",
            "Epoch 4999: val_accuracy did not improve from 0.85612\n",
            "35/35 - 4s - loss: 8.7083e-05 - accuracy: 1.0000 - val_loss: 0.7612 - val_accuracy: 0.8417 - 4s/epoch - 113ms/step\n",
            "Epoch 5000/5000\n",
            "\n",
            "Epoch 5000: val_accuracy did not improve from 0.85612\n",
            "35/35 - 3s - loss: 8.3617e-05 - accuracy: 1.0000 - val_loss: 0.7616 - val_accuracy: 0.8417 - 3s/epoch - 77ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "modelp = keras.models.load_model(\"pccr_xcorr_nmi.best.hdf5\")\n",
        "y_pred = modelp.predict(X_test)\n",
        "y_pred=np.argmax(y_pred,axis=1)\n",
        "print(\"Test Accuracy\",accuracy_score(y_test, y_pred)*100,\"%\")\n",
        "scores = modelp.evaluate(X_train, y_train)\n",
        "print(\"Train %s: %.2f%%\" % (modelp.metrics_names[1], scores[1]*100))\n",
        "scores = modelp.evaluate(X_test, y_test)\n",
        "print(\"test %s: %.2f%%\" % (modelp.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "id": "_mQ6_u9L7890",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa031d5-b319-47ef-c5c6-bb38200a622f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 15ms/step\n",
            "Test Accuracy 85.61151079136691 %\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 5.3804e-04 - accuracy: 1.0000\n",
            "Train accuracy: 100.00%\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.7005 - accuracy: 0.8561\n",
            "test accuracy: 85.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "srt=\"pccr_xcorr_nmi Model\"\n",
        "plot_accuracy(history6, no_of_epoch,srt)"
      ],
      "metadata": {
        "id": "nr1li3La8EEo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "9b1629eb-eed5-4186-b6a6-223517a49c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history6,no_of_epoch, srt)"
      ],
      "metadata": {
        "id": "kKeHLR_S8F3D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "61a71606-75db-458b-ae36-8164779c0f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "title=\"Confusion Matrix of pccr_xcorr_nmi\"\n",
        "cm=confusion(y_pred,y_test)\n",
        "conf_mat2(cm,class_names,title)"
      ],
      "metadata": {
        "id": "4t1l077K8HJ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "2753983b-8ce1-4683-a9a5-32efd987ab5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "Y1GrMtoB8ItO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24c4e3b6-c5fd-4f20-a8c8-08e1035f2b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.76      0.80        51\n",
            "           1       0.75      0.89      0.81        37\n",
            "           2       0.92      0.92      0.92        50\n",
            "           3       0.88      0.77      0.82        47\n",
            "           4       0.84      0.80      0.82        46\n",
            "           5       0.90      1.00      0.95        47\n",
            "\n",
            "    accuracy                           0.86       278\n",
            "   macro avg       0.85      0.86      0.85       278\n",
            "weighted avg       0.86      0.86      0.85       278\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelp.save(\"pccr_xcorr_nmi.h5\")\n",
        "from google.colab import files\n",
        "files.download(\"pccr_xcorr_nmi.h5\")"
      ],
      "metadata": {
        "id": "2wGtulrn77_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pccr_mi_mean=[]"
      ],
      "metadata": {
        "id": "gP9FPgVfBUF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### data test construction ############\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i in range(0,fall_number):\n",
        "  temp=[]\n",
        "\n",
        "\n",
        "  temp.append(pearson_corr[i])\n",
        "  temp.append(mi_score[i])\n",
        "  temp.append(mean_f[i])\n",
        "\n",
        "  pccr_mi_mean.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #walk_temp=np.stack((xcorr_walk[i],pearson_corr_walk[i],mi_score_walk[i],partial_mi_score_walk[i],mean_f_walk[i]),axis=0)\n",
        "for i in range(0,walk_number):\n",
        "  temp=[]\n",
        "\n",
        "\n",
        "  temp.append(pearson_corr_walk[i])\n",
        "  temp.append(mi_score_walk[i])\n",
        "  temp.append(mean_f_walk[i])\n",
        "\n",
        "  pccr_mi_mean.append(temp)\n",
        "\n",
        "\n",
        "for i in range(0,sit_number):\n",
        "  temp=[]\n",
        "\n",
        "\n",
        "  temp.append(pearson_corr_sit[i])\n",
        "  temp.append(mi_score_sit[i])\n",
        "  temp.append(mean_f_sit[i])\n",
        "\n",
        "  pccr_mi_mean.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,bsc_number):\n",
        "  temp=[]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  temp.append(pearson_corr_bsc[i])\n",
        "  temp.append(mi_score_bsc[i])\n",
        "  temp.append(mean_f_bsc[i])\n",
        "\n",
        "  pccr_mi_mean.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,stand_number):\n",
        "  temp=[]\n",
        "\n",
        "\n",
        "  temp.append(pearson_corr_stand[i])\n",
        "  temp.append(mi_score_stand[i])\n",
        "  temp.append(mean_f_stand[i])\n",
        "\n",
        "  pccr_mi_mean.append(temp)\n",
        "\n",
        "\n",
        "for i in range(0,laying_number):\n",
        "  temp=[]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  temp.append(pearson_corr_laying[i])\n",
        "  temp.append(mi_score_laying[i])\n",
        "  temp.append(mean_f_laying[i])\n",
        "\n",
        "  pccr_mi_mean.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#X_data=pd.DataFrame(data=X_data,columns=[['Xcorr','Pearson','MI','NMI','Mean']])\n",
        "#y_data=pd.DataFrame(data=y_data,columns=['Label'])\n"
      ],
      "metadata": {
        "id": "ZgyLJoH4BSJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pccr_mi_mean=np.array(pccr_mi_mean)\n",
        "print(pccr_mi_mean.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YP49xI1B2v2",
        "outputId": "901b8610-4d1e-4ded-a6dc-042b932959a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1390, 3, 16, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"pccr_mi_mean.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "#es = EarlyStopping(monitor='val_loss', patience=100, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "qbcXN1tQCFDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_data=y_temp\n",
        "yenc = sklearn.preprocessing.LabelEncoder()\n",
        "y_data = yenc.fit_transform(y_data)\n",
        "X_train, X_test, y_train, y_test = train_test_split(pccr_mi_mean, y_data, test_size = 0.20, random_state = 42)\n",
        "\n",
        "#X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.10, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 3,16, 16,1)\n",
        "X_test = X_test.reshape(X_test.shape[0],3, 16,16,1)\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdcYJNogCIzc",
        "outputId": "2696a67f-802e-4044-8473-bfea10fa1a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1112, 3, 16, 16, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7=get_3d_2()\n",
        "model7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0KLlCxOCMFw",
        "outputId": "7ac8374d-0a85-46be-85e0-9459b72c1d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_3 (Conv3D)           (None, 2, 10, 10, 16)     1584      \n",
            "                                                                 \n",
            " conv3d_4 (Conv3D)           (None, 2, 4, 4, 128)      100480    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2, 4, 4, 128)      0         \n",
            "                                                                 \n",
            " conv3d_5 (Conv3D)           (None, 2, 2, 2, 128)      147584    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2, 2, 2, 128)      0         \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPooling  (None, 2, 1, 1, 128)     0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 2, 1, 1, 128)     512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 317,494\n",
            "Trainable params: 317,238\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7.compile(optimizer=Adam(learning_rate = 0.00001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "history7 = model7.fit(X_train, y_train,batch_size = 32, epochs = no_of_epoch, validation_data= (X_test, y_test),callbacks=callbacks_list,verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji7wIg3DCN08",
        "outputId": "79911a06-0d97-4e2f-acb7-cd4a6de6b0a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3751/5000\n",
            "\n",
            "Epoch 3751: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.3064e-04 - accuracy: 1.0000 - val_loss: 0.6930 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 3752/5000\n",
            "\n",
            "Epoch 3752: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 7.0698e-04 - accuracy: 1.0000 - val_loss: 0.6823 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 3753/5000\n",
            "\n",
            "Epoch 3753: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.4101e-04 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 3754/5000\n",
            "\n",
            "Epoch 3754: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 6.5749e-04 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8165 - 4s/epoch - 106ms/step\n",
            "Epoch 3755/5000\n",
            "\n",
            "Epoch 3755: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.3683e-04 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.8165 - 2s/epoch - 71ms/step\n",
            "Epoch 3756/5000\n",
            "\n",
            "Epoch 3756: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.2895e-04 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 3757/5000\n",
            "\n",
            "Epoch 3757: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.3893e-04 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8129 - 2s/epoch - 66ms/step\n",
            "Epoch 3758/5000\n",
            "\n",
            "Epoch 3758: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1549e-04 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 3759/5000\n",
            "\n",
            "Epoch 3759: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.4243e-04 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.8237 - 3s/epoch - 99ms/step\n",
            "Epoch 3760/5000\n",
            "\n",
            "Epoch 3760: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.4584e-04 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.8201 - 3s/epoch - 77ms/step\n",
            "Epoch 3761/5000\n",
            "\n",
            "Epoch 3761: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1198e-04 - accuracy: 1.0000 - val_loss: 0.6898 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 3762/5000\n",
            "\n",
            "Epoch 3762: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.4451e-04 - accuracy: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3763/5000\n",
            "\n",
            "Epoch 3763: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.2629e-04 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3764/5000\n",
            "\n",
            "Epoch 3764: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.2979e-04 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.8309 - 3s/epoch - 90ms/step\n",
            "Epoch 3765/5000\n",
            "\n",
            "Epoch 3765: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.1977e-04 - accuracy: 1.0000 - val_loss: 0.6969 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 3766/5000\n",
            "\n",
            "Epoch 3766: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.2097e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3767/5000\n",
            "\n",
            "Epoch 3767: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1475e-04 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 3768/5000\n",
            "\n",
            "Epoch 3768: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1846e-04 - accuracy: 1.0000 - val_loss: 0.6785 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3769/5000\n",
            "\n",
            "Epoch 3769: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.0265e-04 - accuracy: 1.0000 - val_loss: 0.6804 - val_accuracy: 0.8273 - 3s/epoch - 84ms/step\n",
            "Epoch 3770/5000\n",
            "\n",
            "Epoch 3770: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.2647e-04 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.8273 - 3s/epoch - 92ms/step\n",
            "Epoch 3771/5000\n",
            "\n",
            "Epoch 3771: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.4012e-04 - accuracy: 1.0000 - val_loss: 0.6805 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 3772/5000\n",
            "\n",
            "Epoch 3772: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.2436e-04 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3773/5000\n",
            "\n",
            "Epoch 3773: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.5659e-04 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 3774/5000\n",
            "\n",
            "Epoch 3774: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 7.0795e-04 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.8273 - 3s/epoch - 76ms/step\n",
            "Epoch 3775/5000\n",
            "\n",
            "Epoch 3775: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.4569e-04 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.8165 - 3s/epoch - 100ms/step\n",
            "Epoch 3776/5000\n",
            "\n",
            "Epoch 3776: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.3039e-04 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 3777/5000\n",
            "\n",
            "Epoch 3777: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1917e-04 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3778/5000\n",
            "\n",
            "Epoch 3778: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0470e-04 - accuracy: 1.0000 - val_loss: 0.6825 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3779/5000\n",
            "\n",
            "Epoch 3779: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1978e-04 - accuracy: 1.0000 - val_loss: 0.6783 - val_accuracy: 0.8273 - 2s/epoch - 71ms/step\n",
            "Epoch 3780/5000\n",
            "\n",
            "Epoch 3780: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 6.1095e-04 - accuracy: 1.0000 - val_loss: 0.6721 - val_accuracy: 0.8309 - 4s/epoch - 105ms/step\n",
            "Epoch 3781/5000\n",
            "\n",
            "Epoch 3781: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.6332e-04 - accuracy: 1.0000 - val_loss: 0.6680 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 3782/5000\n",
            "\n",
            "Epoch 3782: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0912e-04 - accuracy: 1.0000 - val_loss: 0.6649 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3783/5000\n",
            "\n",
            "Epoch 3783: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1504e-04 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3784/5000\n",
            "\n",
            "Epoch 3784: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.6288e-04 - accuracy: 1.0000 - val_loss: 0.6773 - val_accuracy: 0.8201 - 2s/epoch - 67ms/step\n",
            "Epoch 3785/5000\n",
            "\n",
            "Epoch 3785: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 6.1988e-04 - accuracy: 1.0000 - val_loss: 0.6664 - val_accuracy: 0.8237 - 4s/epoch - 109ms/step\n",
            "Epoch 3786/5000\n",
            "\n",
            "Epoch 3786: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1123e-04 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3787/5000\n",
            "\n",
            "Epoch 3787: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.2547e-04 - accuracy: 1.0000 - val_loss: 0.6722 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3788/5000\n",
            "\n",
            "Epoch 3788: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1806e-04 - accuracy: 1.0000 - val_loss: 0.6640 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3789/5000\n",
            "\n",
            "Epoch 3789: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1794e-04 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 3790/5000\n",
            "\n",
            "Epoch 3790: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 6.3676e-04 - accuracy: 1.0000 - val_loss: 0.6692 - val_accuracy: 0.8345 - 4s/epoch - 109ms/step\n",
            "Epoch 3791/5000\n",
            "\n",
            "Epoch 3791: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1272e-04 - accuracy: 1.0000 - val_loss: 0.6722 - val_accuracy: 0.8345 - 2s/epoch - 68ms/step\n",
            "Epoch 3792/5000\n",
            "\n",
            "Epoch 3792: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.3666e-04 - accuracy: 1.0000 - val_loss: 0.6630 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 3793/5000\n",
            "\n",
            "Epoch 3793: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0849e-04 - accuracy: 1.0000 - val_loss: 0.6733 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3794/5000\n",
            "\n",
            "Epoch 3794: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1751e-04 - accuracy: 1.0000 - val_loss: 0.6825 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3795/5000\n",
            "\n",
            "Epoch 3795: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 6.9728e-04 - accuracy: 1.0000 - val_loss: 0.6689 - val_accuracy: 0.8345 - 4s/epoch - 104ms/step\n",
            "Epoch 3796/5000\n",
            "\n",
            "Epoch 3796: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.4161e-04 - accuracy: 1.0000 - val_loss: 0.6809 - val_accuracy: 0.8309 - 3s/epoch - 73ms/step\n",
            "Epoch 3797/5000\n",
            "\n",
            "Epoch 3797: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1110e-04 - accuracy: 1.0000 - val_loss: 0.6796 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3798/5000\n",
            "\n",
            "Epoch 3798: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0775e-04 - accuracy: 1.0000 - val_loss: 0.6805 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3799/5000\n",
            "\n",
            "Epoch 3799: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.6660e-04 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3800/5000\n",
            "\n",
            "Epoch 3800: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.0177e-04 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.8237 - 3s/epoch - 94ms/step\n",
            "Epoch 3801/5000\n",
            "\n",
            "Epoch 3801: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.1103e-04 - accuracy: 1.0000 - val_loss: 0.6764 - val_accuracy: 0.8201 - 3s/epoch - 83ms/step\n",
            "Epoch 3802/5000\n",
            "\n",
            "Epoch 3802: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0934e-04 - accuracy: 1.0000 - val_loss: 0.6815 - val_accuracy: 0.8273 - 2s/epoch - 65ms/step\n",
            "Epoch 3803/5000\n",
            "\n",
            "Epoch 3803: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1298e-04 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3804/5000\n",
            "\n",
            "Epoch 3804: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1157e-04 - accuracy: 1.0000 - val_loss: 0.6806 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3805/5000\n",
            "\n",
            "Epoch 3805: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.0241e-04 - accuracy: 1.0000 - val_loss: 0.6849 - val_accuracy: 0.8165 - 3s/epoch - 84ms/step\n",
            "Epoch 3806/5000\n",
            "\n",
            "Epoch 3806: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.8552e-04 - accuracy: 1.0000 - val_loss: 0.6839 - val_accuracy: 0.8309 - 3s/epoch - 93ms/step\n",
            "Epoch 3807/5000\n",
            "\n",
            "Epoch 3807: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1452e-04 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 3808/5000\n",
            "\n",
            "Epoch 3808: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.4393e-04 - accuracy: 1.0000 - val_loss: 0.6952 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 3809/5000\n",
            "\n",
            "Epoch 3809: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1826e-04 - accuracy: 1.0000 - val_loss: 0.6796 - val_accuracy: 0.8273 - 2s/epoch - 65ms/step\n",
            "Epoch 3810/5000\n",
            "\n",
            "Epoch 3810: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.2821e-04 - accuracy: 1.0000 - val_loss: 0.6738 - val_accuracy: 0.8273 - 3s/epoch - 75ms/step\n",
            "Epoch 3811/5000\n",
            "\n",
            "Epoch 3811: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.9191e-04 - accuracy: 1.0000 - val_loss: 0.6809 - val_accuracy: 0.8273 - 4s/epoch - 101ms/step\n",
            "Epoch 3812/5000\n",
            "\n",
            "Epoch 3812: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0682e-04 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 3813/5000\n",
            "\n",
            "Epoch 3813: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0938e-04 - accuracy: 1.0000 - val_loss: 0.6780 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3814/5000\n",
            "\n",
            "Epoch 3814: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1651e-04 - accuracy: 1.0000 - val_loss: 0.6661 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 3815/5000\n",
            "\n",
            "Epoch 3815: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1889e-04 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3816/5000\n",
            "\n",
            "Epoch 3816: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 6.0002e-04 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.8381 - 4s/epoch - 110ms/step\n",
            "Epoch 3817/5000\n",
            "\n",
            "Epoch 3817: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1849e-04 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8345 - 2s/epoch - 68ms/step\n",
            "Epoch 3818/5000\n",
            "\n",
            "Epoch 3818: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.9285e-04 - accuracy: 1.0000 - val_loss: 0.6807 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3819/5000\n",
            "\n",
            "Epoch 3819: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.7896e-04 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3820/5000\n",
            "\n",
            "Epoch 3820: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.8319e-04 - accuracy: 1.0000 - val_loss: 0.6789 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 3821/5000\n",
            "\n",
            "Epoch 3821: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.7414e-04 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.8273 - 4s/epoch - 110ms/step\n",
            "Epoch 3822/5000\n",
            "\n",
            "Epoch 3822: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.8610e-04 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3823/5000\n",
            "\n",
            "Epoch 3823: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.8699e-04 - accuracy: 1.0000 - val_loss: 0.6762 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3824/5000\n",
            "\n",
            "Epoch 3824: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0270e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 3825/5000\n",
            "\n",
            "Epoch 3825: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1021e-04 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3826/5000\n",
            "\n",
            "Epoch 3826: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 6.3155e-04 - accuracy: 1.0000 - val_loss: 0.6973 - val_accuracy: 0.8381 - 4s/epoch - 102ms/step\n",
            "Epoch 3827/5000\n",
            "\n",
            "Epoch 3827: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.8743e-04 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.8237 - 3s/epoch - 73ms/step\n",
            "Epoch 3828/5000\n",
            "\n",
            "Epoch 3828: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.4332e-04 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 3829/5000\n",
            "\n",
            "Epoch 3829: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1213e-04 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3830/5000\n",
            "\n",
            "Epoch 3830: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.9510e-04 - accuracy: 1.0000 - val_loss: 0.6894 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3831/5000\n",
            "\n",
            "Epoch 3831: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.0579e-04 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.8273 - 3s/epoch - 94ms/step\n",
            "Epoch 3832/5000\n",
            "\n",
            "Epoch 3832: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.7291e-04 - accuracy: 1.0000 - val_loss: 0.6808 - val_accuracy: 0.8273 - 3s/epoch - 83ms/step\n",
            "Epoch 3833/5000\n",
            "\n",
            "Epoch 3833: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.9175e-04 - accuracy: 1.0000 - val_loss: 0.6733 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3834/5000\n",
            "\n",
            "Epoch 3834: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.8612e-04 - accuracy: 1.0000 - val_loss: 0.6781 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3835/5000\n",
            "\n",
            "Epoch 3835: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.7758e-04 - accuracy: 1.0000 - val_loss: 0.6708 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3836/5000\n",
            "\n",
            "Epoch 3836: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.9055e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 3837/5000\n",
            "\n",
            "Epoch 3837: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.9017e-04 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.8309 - 3s/epoch - 90ms/step\n",
            "Epoch 3838/5000\n",
            "\n",
            "Epoch 3838: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.9303e-04 - accuracy: 1.0000 - val_loss: 0.6666 - val_accuracy: 0.8381 - 2s/epoch - 67ms/step\n",
            "Epoch 3839/5000\n",
            "\n",
            "Epoch 3839: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.7835e-04 - accuracy: 1.0000 - val_loss: 0.6493 - val_accuracy: 0.8417 - 2s/epoch - 67ms/step\n",
            "Epoch 3840/5000\n",
            "\n",
            "Epoch 3840: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.3916e-04 - accuracy: 1.0000 - val_loss: 0.6620 - val_accuracy: 0.8345 - 2s/epoch - 68ms/step\n",
            "Epoch 3841/5000\n",
            "\n",
            "Epoch 3841: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.1454e-04 - accuracy: 1.0000 - val_loss: 0.6683 - val_accuracy: 0.8417 - 3s/epoch - 80ms/step\n",
            "Epoch 3842/5000\n",
            "\n",
            "Epoch 3842: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.0420e-04 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.8273 - 3s/epoch - 97ms/step\n",
            "Epoch 3843/5000\n",
            "\n",
            "Epoch 3843: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.9842e-04 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3844/5000\n",
            "\n",
            "Epoch 3844: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.7036e-04 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3845/5000\n",
            "\n",
            "Epoch 3845: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.9633e-04 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3846/5000\n",
            "\n",
            "Epoch 3846: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.6664e-04 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.8309 - 3s/epoch - 73ms/step\n",
            "Epoch 3847/5000\n",
            "\n",
            "Epoch 3847: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.7428e-04 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.8309 - 4s/epoch - 104ms/step\n",
            "Epoch 3848/5000\n",
            "\n",
            "Epoch 3848: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.9448e-04 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.8237 - 2s/epoch - 65ms/step\n",
            "Epoch 3849/5000\n",
            "\n",
            "Epoch 3849: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 7.4097e-04 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3850/5000\n",
            "\n",
            "Epoch 3850: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 7.0193e-04 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 3851/5000\n",
            "\n",
            "Epoch 3851: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0453e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 3852/5000\n",
            "\n",
            "Epoch 3852: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 6.2668e-04 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8309 - 4s/epoch - 110ms/step\n",
            "Epoch 3853/5000\n",
            "\n",
            "Epoch 3853: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0115e-04 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3854/5000\n",
            "\n",
            "Epoch 3854: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0709e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8273 - 2s/epoch - 65ms/step\n",
            "Epoch 3855/5000\n",
            "\n",
            "Epoch 3855: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.9155e-04 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3856/5000\n",
            "\n",
            "Epoch 3856: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.7744e-04 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3857/5000\n",
            "\n",
            "Epoch 3857: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 6.0394e-04 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.8309 - 4s/epoch - 107ms/step\n",
            "Epoch 3858/5000\n",
            "\n",
            "Epoch 3858: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.9161e-04 - accuracy: 1.0000 - val_loss: 0.6856 - val_accuracy: 0.8309 - 2s/epoch - 69ms/step\n",
            "Epoch 3859/5000\n",
            "\n",
            "Epoch 3859: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1318e-04 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.8273 - 2s/epoch - 65ms/step\n",
            "Epoch 3860/5000\n",
            "\n",
            "Epoch 3860: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0588e-04 - accuracy: 1.0000 - val_loss: 0.6711 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3861/5000\n",
            "\n",
            "Epoch 3861: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.4582e-04 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3862/5000\n",
            "\n",
            "Epoch 3862: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 6.2580e-04 - accuracy: 1.0000 - val_loss: 0.6513 - val_accuracy: 0.8453 - 4s/epoch - 101ms/step\n",
            "Epoch 3863/5000\n",
            "\n",
            "Epoch 3863: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.0626e-04 - accuracy: 1.0000 - val_loss: 0.6681 - val_accuracy: 0.8381 - 3s/epoch - 76ms/step\n",
            "Epoch 3864/5000\n",
            "\n",
            "Epoch 3864: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0739e-04 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3865/5000\n",
            "\n",
            "Epoch 3865: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.6804e-04 - accuracy: 1.0000 - val_loss: 0.6682 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 3866/5000\n",
            "\n",
            "Epoch 3866: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.5660e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 3867/5000\n",
            "\n",
            "Epoch 3867: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.9847e-04 - accuracy: 1.0000 - val_loss: 0.6711 - val_accuracy: 0.8237 - 3s/epoch - 92ms/step\n",
            "Epoch 3868/5000\n",
            "\n",
            "Epoch 3868: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 6.1147e-04 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.8273 - 3s/epoch - 84ms/step\n",
            "Epoch 3869/5000\n",
            "\n",
            "Epoch 3869: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.7261e-04 - accuracy: 1.0000 - val_loss: 0.6813 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3870/5000\n",
            "\n",
            "Epoch 3870: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.7198e-04 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3871/5000\n",
            "\n",
            "Epoch 3871: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.6898e-04 - accuracy: 1.0000 - val_loss: 0.6834 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3872/5000\n",
            "\n",
            "Epoch 3872: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.8556e-04 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8201 - 3s/epoch - 82ms/step\n",
            "Epoch 3873/5000\n",
            "\n",
            "Epoch 3873: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.7665e-04 - accuracy: 1.0000 - val_loss: 0.6821 - val_accuracy: 0.8273 - 3s/epoch - 95ms/step\n",
            "Epoch 3874/5000\n",
            "\n",
            "Epoch 3874: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1451e-04 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 3875/5000\n",
            "\n",
            "Epoch 3875: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0292e-04 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3876/5000\n",
            "\n",
            "Epoch 3876: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.8344e-04 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3877/5000\n",
            "\n",
            "Epoch 3877: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.7107e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8201 - 3s/epoch - 77ms/step\n",
            "Epoch 3878/5000\n",
            "\n",
            "Epoch 3878: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.6109e-04 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.8201 - 3s/epoch - 99ms/step\n",
            "Epoch 3879/5000\n",
            "\n",
            "Epoch 3879: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.8185e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3880/5000\n",
            "\n",
            "Epoch 3880: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.5415e-04 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3881/5000\n",
            "\n",
            "Epoch 3881: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.6147e-04 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3882/5000\n",
            "\n",
            "Epoch 3882: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.4316e-04 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.8309 - 3s/epoch - 72ms/step\n",
            "Epoch 3883/5000\n",
            "\n",
            "Epoch 3883: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.6605e-04 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.8309 - 4s/epoch - 105ms/step\n",
            "Epoch 3884/5000\n",
            "\n",
            "Epoch 3884: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.8435e-04 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 3885/5000\n",
            "\n",
            "Epoch 3885: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.6863e-04 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3886/5000\n",
            "\n",
            "Epoch 3886: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.6282e-04 - accuracy: 1.0000 - val_loss: 0.6839 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3887/5000\n",
            "\n",
            "Epoch 3887: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.6876e-04 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3888/5000\n",
            "\n",
            "Epoch 3888: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.4721e-04 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.8273 - 4s/epoch - 110ms/step\n",
            "Epoch 3889/5000\n",
            "\n",
            "Epoch 3889: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.6120e-04 - accuracy: 1.0000 - val_loss: 0.6867 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3890/5000\n",
            "\n",
            "Epoch 3890: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.5667e-04 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3891/5000\n",
            "\n",
            "Epoch 3891: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.8154e-04 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3892/5000\n",
            "\n",
            "Epoch 3892: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.5748e-04 - accuracy: 1.0000 - val_loss: 0.6817 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3893/5000\n",
            "\n",
            "Epoch 3893: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.5481e-04 - accuracy: 1.0000 - val_loss: 0.6806 - val_accuracy: 0.8309 - 4s/epoch - 103ms/step\n",
            "Epoch 3894/5000\n",
            "\n",
            "Epoch 3894: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.4925e-04 - accuracy: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.8309 - 3s/epoch - 72ms/step\n",
            "Epoch 3895/5000\n",
            "\n",
            "Epoch 3895: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.6900e-04 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 3896/5000\n",
            "\n",
            "Epoch 3896: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.6396e-04 - accuracy: 1.0000 - val_loss: 0.6705 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3897/5000\n",
            "\n",
            "Epoch 3897: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.6490e-04 - accuracy: 1.0000 - val_loss: 0.6876 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3898/5000\n",
            "\n",
            "Epoch 3898: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.7254e-04 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.8237 - 3s/epoch - 95ms/step\n",
            "Epoch 3899/5000\n",
            "\n",
            "Epoch 3899: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.6944e-04 - accuracy: 1.0000 - val_loss: 0.6665 - val_accuracy: 0.8345 - 3s/epoch - 82ms/step\n",
            "Epoch 3900/5000\n",
            "\n",
            "Epoch 3900: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.9658e-04 - accuracy: 1.0000 - val_loss: 0.6786 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 3901/5000\n",
            "\n",
            "Epoch 3901: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.6824e-04 - accuracy: 1.0000 - val_loss: 0.6650 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3902/5000\n",
            "\n",
            "Epoch 3902: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.5543e-04 - accuracy: 1.0000 - val_loss: 0.6758 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3903/5000\n",
            "\n",
            "Epoch 3903: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.6779e-04 - accuracy: 1.0000 - val_loss: 0.6789 - val_accuracy: 0.8381 - 3s/epoch - 83ms/step\n",
            "Epoch 3904/5000\n",
            "\n",
            "Epoch 3904: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.4439e-04 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.8345 - 3s/epoch - 93ms/step\n",
            "Epoch 3905/5000\n",
            "\n",
            "Epoch 3905: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4274e-04 - accuracy: 1.0000 - val_loss: 0.6721 - val_accuracy: 0.8273 - 2s/epoch - 65ms/step\n",
            "Epoch 3906/5000\n",
            "\n",
            "Epoch 3906: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.5051e-04 - accuracy: 1.0000 - val_loss: 0.6715 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3907/5000\n",
            "\n",
            "Epoch 3907: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4811e-04 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 3908/5000\n",
            "\n",
            "Epoch 3908: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.8395e-04 - accuracy: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.8201 - 3s/epoch - 76ms/step\n",
            "Epoch 3909/5000\n",
            "\n",
            "Epoch 3909: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 6.0918e-04 - accuracy: 1.0000 - val_loss: 0.6769 - val_accuracy: 0.8273 - 4s/epoch - 100ms/step\n",
            "Epoch 3910/5000\n",
            "\n",
            "Epoch 3910: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.7152e-04 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 3911/5000\n",
            "\n",
            "Epoch 3911: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.8915e-04 - accuracy: 1.0000 - val_loss: 0.6882 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3912/5000\n",
            "\n",
            "Epoch 3912: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.5347e-04 - accuracy: 1.0000 - val_loss: 0.6833 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 3913/5000\n",
            "\n",
            "Epoch 3913: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.5716e-04 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 3914/5000\n",
            "\n",
            "Epoch 3914: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.4711e-04 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.8273 - 4s/epoch - 109ms/step\n",
            "Epoch 3915/5000\n",
            "\n",
            "Epoch 3915: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4742e-04 - accuracy: 1.0000 - val_loss: 0.6980 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3916/5000\n",
            "\n",
            "Epoch 3916: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2919e-04 - accuracy: 1.0000 - val_loss: 0.6854 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 3917/5000\n",
            "\n",
            "Epoch 3917: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.6304e-04 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3918/5000\n",
            "\n",
            "Epoch 3918: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.3390e-04 - accuracy: 1.0000 - val_loss: 0.6898 - val_accuracy: 0.8453 - 2s/epoch - 65ms/step\n",
            "Epoch 3919/5000\n",
            "\n",
            "Epoch 3919: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.4707e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8273 - 4s/epoch - 112ms/step\n",
            "Epoch 3920/5000\n",
            "\n",
            "Epoch 3920: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.7067e-04 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3921/5000\n",
            "\n",
            "Epoch 3921: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.1927e-04 - accuracy: 1.0000 - val_loss: 0.6811 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 3922/5000\n",
            "\n",
            "Epoch 3922: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4841e-04 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3923/5000\n",
            "\n",
            "Epoch 3923: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.7826e-04 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3924/5000\n",
            "\n",
            "Epoch 3924: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.4061e-04 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.8381 - 4s/epoch - 100ms/step\n",
            "Epoch 3925/5000\n",
            "\n",
            "Epoch 3925: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.4289e-04 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8273 - 3s/epoch - 75ms/step\n",
            "Epoch 3926/5000\n",
            "\n",
            "Epoch 3926: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.6288e-04 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3927/5000\n",
            "\n",
            "Epoch 3927: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.5823e-04 - accuracy: 1.0000 - val_loss: 0.6940 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 3928/5000\n",
            "\n",
            "Epoch 3928: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.6438e-04 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3929/5000\n",
            "\n",
            "Epoch 3929: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.3021e-04 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.8273 - 3s/epoch - 95ms/step\n",
            "Epoch 3930/5000\n",
            "\n",
            "Epoch 3930: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.4462e-04 - accuracy: 1.0000 - val_loss: 0.6872 - val_accuracy: 0.8309 - 3s/epoch - 83ms/step\n",
            "Epoch 3931/5000\n",
            "\n",
            "Epoch 3931: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4582e-04 - accuracy: 1.0000 - val_loss: 0.6772 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 3932/5000\n",
            "\n",
            "Epoch 3932: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2192e-04 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3933/5000\n",
            "\n",
            "Epoch 3933: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4102e-04 - accuracy: 1.0000 - val_loss: 0.6778 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 3934/5000\n",
            "\n",
            "Epoch 3934: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.5033e-04 - accuracy: 1.0000 - val_loss: 0.6886 - val_accuracy: 0.8309 - 3s/epoch - 90ms/step\n",
            "Epoch 3935/5000\n",
            "\n",
            "Epoch 3935: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.3514e-04 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 3936/5000\n",
            "\n",
            "Epoch 3936: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4441e-04 - accuracy: 1.0000 - val_loss: 0.6883 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3937/5000\n",
            "\n",
            "Epoch 3937: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2892e-04 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3938/5000\n",
            "\n",
            "Epoch 3938: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1999e-04 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3939/5000\n",
            "\n",
            "Epoch 3939: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.2853e-04 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.8381 - 3s/epoch - 82ms/step\n",
            "Epoch 3940/5000\n",
            "\n",
            "Epoch 3940: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.4819e-04 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8273 - 3s/epoch - 94ms/step\n",
            "Epoch 3941/5000\n",
            "\n",
            "Epoch 3941: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.3505e-04 - accuracy: 1.0000 - val_loss: 0.6788 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3942/5000\n",
            "\n",
            "Epoch 3942: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4115e-04 - accuracy: 1.0000 - val_loss: 0.6759 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 3943/5000\n",
            "\n",
            "Epoch 3943: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 7.1550e-04 - accuracy: 1.0000 - val_loss: 0.6621 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 3944/5000\n",
            "\n",
            "Epoch 3944: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 7.0805e-04 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.8273 - 2s/epoch - 71ms/step\n",
            "Epoch 3945/5000\n",
            "\n",
            "Epoch 3945: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 6.2445e-04 - accuracy: 1.0000 - val_loss: 0.6852 - val_accuracy: 0.8273 - 4s/epoch - 104ms/step\n",
            "Epoch 3946/5000\n",
            "\n",
            "Epoch 3946: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.8605e-04 - accuracy: 1.0000 - val_loss: 0.6585 - val_accuracy: 0.8453 - 2s/epoch - 66ms/step\n",
            "Epoch 3947/5000\n",
            "\n",
            "Epoch 3947: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.7991e-04 - accuracy: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 3948/5000\n",
            "\n",
            "Epoch 3948: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.7510e-04 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3949/5000\n",
            "\n",
            "Epoch 3949: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.7729e-04 - accuracy: 1.0000 - val_loss: 0.6856 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 3950/5000\n",
            "\n",
            "Epoch 3950: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.6733e-04 - accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.8309 - 4s/epoch - 111ms/step\n",
            "Epoch 3951/5000\n",
            "\n",
            "Epoch 3951: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4479e-04 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 3952/5000\n",
            "\n",
            "Epoch 3952: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.3158e-04 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3953/5000\n",
            "\n",
            "Epoch 3953: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4567e-04 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3954/5000\n",
            "\n",
            "Epoch 3954: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1562e-04 - accuracy: 1.0000 - val_loss: 0.6809 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3955/5000\n",
            "\n",
            "Epoch 3955: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.3109e-04 - accuracy: 1.0000 - val_loss: 0.6819 - val_accuracy: 0.8345 - 4s/epoch - 110ms/step\n",
            "Epoch 3956/5000\n",
            "\n",
            "Epoch 3956: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.3136e-04 - accuracy: 1.0000 - val_loss: 0.6781 - val_accuracy: 0.8345 - 2s/epoch - 68ms/step\n",
            "Epoch 3957/5000\n",
            "\n",
            "Epoch 3957: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2841e-04 - accuracy: 1.0000 - val_loss: 0.6828 - val_accuracy: 0.8381 - 2s/epoch - 65ms/step\n",
            "Epoch 3958/5000\n",
            "\n",
            "Epoch 3958: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2847e-04 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3959/5000\n",
            "\n",
            "Epoch 3959: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0967e-04 - accuracy: 1.0000 - val_loss: 0.6812 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3960/5000\n",
            "\n",
            "Epoch 3960: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.1955e-04 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.8273 - 4s/epoch - 102ms/step\n",
            "Epoch 3961/5000\n",
            "\n",
            "Epoch 3961: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.1625e-04 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.8309 - 3s/epoch - 74ms/step\n",
            "Epoch 3962/5000\n",
            "\n",
            "Epoch 3962: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2853e-04 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3963/5000\n",
            "\n",
            "Epoch 3963: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2379e-04 - accuracy: 1.0000 - val_loss: 0.6832 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3964/5000\n",
            "\n",
            "Epoch 3964: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0942e-04 - accuracy: 1.0000 - val_loss: 0.6860 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3965/5000\n",
            "\n",
            "Epoch 3965: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.2832e-04 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.8273 - 3s/epoch - 93ms/step\n",
            "Epoch 3966/5000\n",
            "\n",
            "Epoch 3966: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.3221e-04 - accuracy: 1.0000 - val_loss: 0.7238 - val_accuracy: 0.8237 - 3s/epoch - 82ms/step\n",
            "Epoch 3967/5000\n",
            "\n",
            "Epoch 3967: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.4303e-04 - accuracy: 1.0000 - val_loss: 0.6757 - val_accuracy: 0.8309 - 2s/epoch - 68ms/step\n",
            "Epoch 3968/5000\n",
            "\n",
            "Epoch 3968: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.5370e-04 - accuracy: 1.0000 - val_loss: 0.6860 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3969/5000\n",
            "\n",
            "Epoch 3969: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.7136e-04 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3970/5000\n",
            "\n",
            "Epoch 3970: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.4669e-04 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 3971/5000\n",
            "\n",
            "Epoch 3971: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.2574e-04 - accuracy: 1.0000 - val_loss: 0.6867 - val_accuracy: 0.8273 - 3s/epoch - 90ms/step\n",
            "Epoch 3972/5000\n",
            "\n",
            "Epoch 3972: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2838e-04 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3973/5000\n",
            "\n",
            "Epoch 3973: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1749e-04 - accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3974/5000\n",
            "\n",
            "Epoch 3974: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.3050e-04 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3975/5000\n",
            "\n",
            "Epoch 3975: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.3563e-04 - accuracy: 1.0000 - val_loss: 0.6969 - val_accuracy: 0.8273 - 3s/epoch - 75ms/step\n",
            "Epoch 3976/5000\n",
            "\n",
            "Epoch 3976: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.3398e-04 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8237 - 4s/epoch - 101ms/step\n",
            "Epoch 3977/5000\n",
            "\n",
            "Epoch 3977: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1287e-04 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3978/5000\n",
            "\n",
            "Epoch 3978: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2292e-04 - accuracy: 1.0000 - val_loss: 0.6803 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 3979/5000\n",
            "\n",
            "Epoch 3979: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1025e-04 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 3980/5000\n",
            "\n",
            "Epoch 3980: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2107e-04 - accuracy: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.8381 - 2s/epoch - 71ms/step\n",
            "Epoch 3981/5000\n",
            "\n",
            "Epoch 3981: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.3002e-04 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.8381 - 4s/epoch - 105ms/step\n",
            "Epoch 3982/5000\n",
            "\n",
            "Epoch 3982: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0671e-04 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3983/5000\n",
            "\n",
            "Epoch 3983: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1670e-04 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3984/5000\n",
            "\n",
            "Epoch 3984: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2852e-04 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 3985/5000\n",
            "\n",
            "Epoch 3985: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4542e-04 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3986/5000\n",
            "\n",
            "Epoch 3986: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.3165e-04 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.8381 - 4s/epoch - 110ms/step\n",
            "Epoch 3987/5000\n",
            "\n",
            "Epoch 3987: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.3668e-04 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3988/5000\n",
            "\n",
            "Epoch 3988: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0957e-04 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 3989/5000\n",
            "\n",
            "Epoch 3989: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0880e-04 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3990/5000\n",
            "\n",
            "Epoch 3990: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2912e-04 - accuracy: 1.0000 - val_loss: 0.7084 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 3991/5000\n",
            "\n",
            "Epoch 3991: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.6072e-04 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.8273 - 4s/epoch - 109ms/step\n",
            "Epoch 3992/5000\n",
            "\n",
            "Epoch 3992: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2797e-04 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.8273 - 2s/epoch - 68ms/step\n",
            "Epoch 3993/5000\n",
            "\n",
            "Epoch 3993: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.3320e-04 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 3994/5000\n",
            "\n",
            "Epoch 3994: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1645e-04 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 3995/5000\n",
            "\n",
            "Epoch 3995: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9918e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 3996/5000\n",
            "\n",
            "Epoch 3996: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.0210e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8273 - 3s/epoch - 100ms/step\n",
            "Epoch 3997/5000\n",
            "\n",
            "Epoch 3997: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.1522e-04 - accuracy: 1.0000 - val_loss: 0.6952 - val_accuracy: 0.8273 - 3s/epoch - 76ms/step\n",
            "Epoch 3998/5000\n",
            "\n",
            "Epoch 3998: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9066e-04 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 3999/5000\n",
            "\n",
            "Epoch 3999: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1777e-04 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4000/5000\n",
            "\n",
            "Epoch 4000: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2420e-04 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 4001/5000\n",
            "\n",
            "Epoch 4001: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.1597e-04 - accuracy: 1.0000 - val_loss: 0.6951 - val_accuracy: 0.8273 - 3s/epoch - 92ms/step\n",
            "Epoch 4002/5000\n",
            "\n",
            "Epoch 4002: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.1769e-04 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4003/5000\n",
            "\n",
            "Epoch 4003: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2369e-04 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4004/5000\n",
            "\n",
            "Epoch 4004: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9106e-04 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4005/5000\n",
            "\n",
            "Epoch 4005: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0438e-04 - accuracy: 1.0000 - val_loss: 0.6789 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4006/5000\n",
            "\n",
            "Epoch 4006: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.1215e-04 - accuracy: 1.0000 - val_loss: 0.6691 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4007/5000\n",
            "\n",
            "Epoch 4007: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.0208e-04 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8273 - 3s/epoch - 91ms/step\n",
            "Epoch 4008/5000\n",
            "\n",
            "Epoch 4008: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8602e-04 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4009/5000\n",
            "\n",
            "Epoch 4009: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2930e-04 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 0.8237 - 2s/epoch - 65ms/step\n",
            "Epoch 4010/5000\n",
            "\n",
            "Epoch 4010: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.3396e-04 - accuracy: 1.0000 - val_loss: 0.6856 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4011/5000\n",
            "\n",
            "Epoch 4011: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.2795e-04 - accuracy: 1.0000 - val_loss: 0.6835 - val_accuracy: 0.8309 - 3s/epoch - 77ms/step\n",
            "Epoch 4012/5000\n",
            "\n",
            "Epoch 4012: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.0757e-04 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.8309 - 4s/epoch - 100ms/step\n",
            "Epoch 4013/5000\n",
            "\n",
            "Epoch 4013: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1684e-04 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4014/5000\n",
            "\n",
            "Epoch 4014: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2881e-04 - accuracy: 1.0000 - val_loss: 0.6584 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4015/5000\n",
            "\n",
            "Epoch 4015: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0839e-04 - accuracy: 1.0000 - val_loss: 0.6839 - val_accuracy: 0.8237 - 2s/epoch - 69ms/step\n",
            "Epoch 4016/5000\n",
            "\n",
            "Epoch 4016: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.1829e-04 - accuracy: 1.0000 - val_loss: 0.6631 - val_accuracy: 0.8489 - 3s/epoch - 72ms/step\n",
            "Epoch 4017/5000\n",
            "\n",
            "Epoch 4017: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.9252e-04 - accuracy: 1.0000 - val_loss: 0.6807 - val_accuracy: 0.8273 - 4s/epoch - 104ms/step\n",
            "Epoch 4018/5000\n",
            "\n",
            "Epoch 4018: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1775e-04 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4019/5000\n",
            "\n",
            "Epoch 4019: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1959e-04 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4020/5000\n",
            "\n",
            "Epoch 4020: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9807e-04 - accuracy: 1.0000 - val_loss: 0.6747 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4021/5000\n",
            "\n",
            "Epoch 4021: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8894e-04 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4022/5000\n",
            "\n",
            "Epoch 4022: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.0254e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8309 - 4s/epoch - 111ms/step\n",
            "Epoch 4023/5000\n",
            "\n",
            "Epoch 4023: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8615e-04 - accuracy: 1.0000 - val_loss: 0.6771 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4024/5000\n",
            "\n",
            "Epoch 4024: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1501e-04 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4025/5000\n",
            "\n",
            "Epoch 4025: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0724e-04 - accuracy: 1.0000 - val_loss: 0.6691 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4026/5000\n",
            "\n",
            "Epoch 4026: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1178e-04 - accuracy: 1.0000 - val_loss: 0.6780 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4027/5000\n",
            "\n",
            "Epoch 4027: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.9005e-04 - accuracy: 1.0000 - val_loss: 0.6637 - val_accuracy: 0.8453 - 4s/epoch - 110ms/step\n",
            "Epoch 4028/5000\n",
            "\n",
            "Epoch 4028: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8054e-04 - accuracy: 1.0000 - val_loss: 0.6867 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4029/5000\n",
            "\n",
            "Epoch 4029: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8331e-04 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4030/5000\n",
            "\n",
            "Epoch 4030: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9915e-04 - accuracy: 1.0000 - val_loss: 0.6844 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4031/5000\n",
            "\n",
            "Epoch 4031: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0813e-04 - accuracy: 1.0000 - val_loss: 0.6703 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4032/5000\n",
            "\n",
            "Epoch 4032: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.9832e-04 - accuracy: 1.0000 - val_loss: 0.6639 - val_accuracy: 0.8309 - 4s/epoch - 103ms/step\n",
            "Epoch 4033/5000\n",
            "\n",
            "Epoch 4033: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.8977e-04 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8273 - 3s/epoch - 72ms/step\n",
            "Epoch 4034/5000\n",
            "\n",
            "Epoch 4034: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0203e-04 - accuracy: 1.0000 - val_loss: 0.6883 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4035/5000\n",
            "\n",
            "Epoch 4035: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9687e-04 - accuracy: 1.0000 - val_loss: 0.6731 - val_accuracy: 0.8381 - 2s/epoch - 67ms/step\n",
            "Epoch 4036/5000\n",
            "\n",
            "Epoch 4036: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9161e-04 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8381 - 2s/epoch - 65ms/step\n",
            "Epoch 4037/5000\n",
            "\n",
            "Epoch 4037: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.9657e-04 - accuracy: 1.0000 - val_loss: 0.6922 - val_accuracy: 0.8345 - 3s/epoch - 91ms/step\n",
            "Epoch 4038/5000\n",
            "\n",
            "Epoch 4038: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.7858e-04 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8309 - 3s/epoch - 84ms/step\n",
            "Epoch 4039/5000\n",
            "\n",
            "Epoch 4039: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8349e-04 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4040/5000\n",
            "\n",
            "Epoch 4040: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7505e-04 - accuracy: 1.0000 - val_loss: 0.6768 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4041/5000\n",
            "\n",
            "Epoch 4041: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8071e-04 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4042/5000\n",
            "\n",
            "Epoch 4042: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.8277e-04 - accuracy: 1.0000 - val_loss: 0.6696 - val_accuracy: 0.8237 - 3s/epoch - 80ms/step\n",
            "Epoch 4043/5000\n",
            "\n",
            "Epoch 4043: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.7730e-04 - accuracy: 1.0000 - val_loss: 0.6781 - val_accuracy: 0.8237 - 3s/epoch - 95ms/step\n",
            "Epoch 4044/5000\n",
            "\n",
            "Epoch 4044: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9334e-04 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4045/5000\n",
            "\n",
            "Epoch 4045: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8610e-04 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4046/5000\n",
            "\n",
            "Epoch 4046: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6672e-04 - accuracy: 1.0000 - val_loss: 0.6775 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4047/5000\n",
            "\n",
            "Epoch 4047: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.7923e-04 - accuracy: 1.0000 - val_loss: 0.6789 - val_accuracy: 0.8345 - 3s/epoch - 74ms/step\n",
            "Epoch 4048/5000\n",
            "\n",
            "Epoch 4048: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.6804e-04 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.8237 - 4s/epoch - 103ms/step\n",
            "Epoch 4049/5000\n",
            "\n",
            "Epoch 4049: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7913e-04 - accuracy: 1.0000 - val_loss: 0.6671 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4050/5000\n",
            "\n",
            "Epoch 4050: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8183e-04 - accuracy: 1.0000 - val_loss: 0.6499 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4051/5000\n",
            "\n",
            "Epoch 4051: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8061e-04 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4052/5000\n",
            "\n",
            "Epoch 4052: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.8355e-04 - accuracy: 1.0000 - val_loss: 0.6629 - val_accuracy: 0.8453 - 2s/epoch - 66ms/step\n",
            "Epoch 4053/5000\n",
            "\n",
            "Epoch 4053: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 7.7703e-04 - accuracy: 1.0000 - val_loss: 0.6993 - val_accuracy: 0.8309 - 4s/epoch - 110ms/step\n",
            "Epoch 4054/5000\n",
            "\n",
            "Epoch 4054: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.3851e-04 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4055/5000\n",
            "\n",
            "Epoch 4055: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1966e-04 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.8201 - 2s/epoch - 67ms/step\n",
            "Epoch 4056/5000\n",
            "\n",
            "Epoch 4056: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1717e-04 - accuracy: 1.0000 - val_loss: 0.6796 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4057/5000\n",
            "\n",
            "Epoch 4057: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8811e-04 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4058/5000\n",
            "\n",
            "Epoch 4058: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.8591e-04 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8309 - 4s/epoch - 109ms/step\n",
            "Epoch 4059/5000\n",
            "\n",
            "Epoch 4059: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7600e-04 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4060/5000\n",
            "\n",
            "Epoch 4060: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1237e-04 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.8201 - 2s/epoch - 67ms/step\n",
            "Epoch 4061/5000\n",
            "\n",
            "Epoch 4061: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0182e-04 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.8201 - 2s/epoch - 65ms/step\n",
            "Epoch 4062/5000\n",
            "\n",
            "Epoch 4062: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9309e-04 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 4063/5000\n",
            "\n",
            "Epoch 4063: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.9063e-04 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.8201 - 4s/epoch - 101ms/step\n",
            "Epoch 4064/5000\n",
            "\n",
            "Epoch 4064: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.8917e-04 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.8201 - 3s/epoch - 74ms/step\n",
            "Epoch 4065/5000\n",
            "\n",
            "Epoch 4065: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8987e-04 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4066/5000\n",
            "\n",
            "Epoch 4066: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7477e-04 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4067/5000\n",
            "\n",
            "Epoch 4067: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7187e-04 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4068/5000\n",
            "\n",
            "Epoch 4068: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.7152e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8201 - 3s/epoch - 95ms/step\n",
            "Epoch 4069/5000\n",
            "\n",
            "Epoch 4069: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.9091e-04 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8201 - 3s/epoch - 82ms/step\n",
            "Epoch 4070/5000\n",
            "\n",
            "Epoch 4070: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8442e-04 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 4071/5000\n",
            "\n",
            "Epoch 4071: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9797e-04 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 4072/5000\n",
            "\n",
            "Epoch 4072: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4986e-04 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4073/5000\n",
            "\n",
            "Epoch 4073: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.2569e-04 - accuracy: 1.0000 - val_loss: 0.6691 - val_accuracy: 0.8345 - 3s/epoch - 87ms/step\n",
            "Epoch 4074/5000\n",
            "\n",
            "Epoch 4074: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.4502e-04 - accuracy: 1.0000 - val_loss: 0.6684 - val_accuracy: 0.8309 - 3s/epoch - 89ms/step\n",
            "Epoch 4075/5000\n",
            "\n",
            "Epoch 4075: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4036e-04 - accuracy: 1.0000 - val_loss: 0.6785 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4076/5000\n",
            "\n",
            "Epoch 4076: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0755e-04 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4077/5000\n",
            "\n",
            "Epoch 4077: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9950e-04 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4078/5000\n",
            "\n",
            "Epoch 4078: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.7195e-04 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.8345 - 3s/epoch - 78ms/step\n",
            "Epoch 4079/5000\n",
            "\n",
            "Epoch 4079: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.6090e-04 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8273 - 3s/epoch - 98ms/step\n",
            "Epoch 4080/5000\n",
            "\n",
            "Epoch 4080: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7962e-04 - accuracy: 1.0000 - val_loss: 0.6798 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4081/5000\n",
            "\n",
            "Epoch 4081: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7013e-04 - accuracy: 1.0000 - val_loss: 0.6903 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4082/5000\n",
            "\n",
            "Epoch 4082: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7052e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4083/5000\n",
            "\n",
            "Epoch 4083: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0273e-04 - accuracy: 1.0000 - val_loss: 0.7294 - val_accuracy: 0.8237 - 2s/epoch - 70ms/step\n",
            "Epoch 4084/5000\n",
            "\n",
            "Epoch 4084: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 5.0820e-04 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.8237 - 4s/epoch - 106ms/step\n",
            "Epoch 4085/5000\n",
            "\n",
            "Epoch 4085: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0538e-04 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4086/5000\n",
            "\n",
            "Epoch 4086: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9810e-04 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4087/5000\n",
            "\n",
            "Epoch 4087: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9285e-04 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8453 - 2s/epoch - 66ms/step\n",
            "Epoch 4088/5000\n",
            "\n",
            "Epoch 4088: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.1197e-04 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4089/5000\n",
            "\n",
            "Epoch 4089: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.7301e-04 - accuracy: 1.0000 - val_loss: 0.7236 - val_accuracy: 0.8273 - 4s/epoch - 109ms/step\n",
            "Epoch 4090/5000\n",
            "\n",
            "Epoch 4090: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6798e-04 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4091/5000\n",
            "\n",
            "Epoch 4091: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9587e-04 - accuracy: 1.0000 - val_loss: 0.7048 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4092/5000\n",
            "\n",
            "Epoch 4092: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7978e-04 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4093/5000\n",
            "\n",
            "Epoch 4093: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8413e-04 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4094/5000\n",
            "\n",
            "Epoch 4094: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.6657e-04 - accuracy: 1.0000 - val_loss: 0.7015 - val_accuracy: 0.8237 - 4s/epoch - 109ms/step\n",
            "Epoch 4095/5000\n",
            "\n",
            "Epoch 4095: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7410e-04 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4096/5000\n",
            "\n",
            "Epoch 4096: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6794e-04 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4097/5000\n",
            "\n",
            "Epoch 4097: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8978e-04 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4098/5000\n",
            "\n",
            "Epoch 4098: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5398e-04 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4099/5000\n",
            "\n",
            "Epoch 4099: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.6984e-04 - accuracy: 1.0000 - val_loss: 0.6967 - val_accuracy: 0.8309 - 4s/epoch - 101ms/step\n",
            "Epoch 4100/5000\n",
            "\n",
            "Epoch 4100: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.6362e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8273 - 3s/epoch - 75ms/step\n",
            "Epoch 4101/5000\n",
            "\n",
            "Epoch 4101: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6514e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8273 - 2s/epoch - 65ms/step\n",
            "Epoch 4102/5000\n",
            "\n",
            "Epoch 4102: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5674e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4103/5000\n",
            "\n",
            "Epoch 4103: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6111e-04 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4104/5000\n",
            "\n",
            "Epoch 4104: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.9868e-04 - accuracy: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.8273 - 3s/epoch - 95ms/step\n",
            "Epoch 4105/5000\n",
            "\n",
            "Epoch 4105: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.6795e-04 - accuracy: 1.0000 - val_loss: 0.6844 - val_accuracy: 0.8237 - 3s/epoch - 81ms/step\n",
            "Epoch 4106/5000\n",
            "\n",
            "Epoch 4106: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7780e-04 - accuracy: 1.0000 - val_loss: 0.6842 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4107/5000\n",
            "\n",
            "Epoch 4107: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8697e-04 - accuracy: 1.0000 - val_loss: 0.6585 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4108/5000\n",
            "\n",
            "Epoch 4108: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6783e-04 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4109/5000\n",
            "\n",
            "Epoch 4109: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.5707e-04 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.8273 - 3s/epoch - 84ms/step\n",
            "Epoch 4110/5000\n",
            "\n",
            "Epoch 4110: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.5350e-04 - accuracy: 1.0000 - val_loss: 0.6754 - val_accuracy: 0.8273 - 3s/epoch - 92ms/step\n",
            "Epoch 4111/5000\n",
            "\n",
            "Epoch 4111: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6138e-04 - accuracy: 1.0000 - val_loss: 0.6844 - val_accuracy: 0.8273 - 2s/epoch - 65ms/step\n",
            "Epoch 4112/5000\n",
            "\n",
            "Epoch 4112: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6068e-04 - accuracy: 1.0000 - val_loss: 0.6833 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4113/5000\n",
            "\n",
            "Epoch 4113: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7354e-04 - accuracy: 1.0000 - val_loss: 0.6813 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4114/5000\n",
            "\n",
            "Epoch 4114: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.8016e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8273 - 3s/epoch - 78ms/step\n",
            "Epoch 4115/5000\n",
            "\n",
            "Epoch 4115: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.9626e-04 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.8273 - 3s/epoch - 99ms/step\n",
            "Epoch 4116/5000\n",
            "\n",
            "Epoch 4116: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5435e-04 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4117/5000\n",
            "\n",
            "Epoch 4117: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7440e-04 - accuracy: 1.0000 - val_loss: 0.6795 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4118/5000\n",
            "\n",
            "Epoch 4118: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5607e-04 - accuracy: 1.0000 - val_loss: 0.6714 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4119/5000\n",
            "\n",
            "Epoch 4119: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.5514e-04 - accuracy: 1.0000 - val_loss: 0.6824 - val_accuracy: 0.8273 - 3s/epoch - 71ms/step\n",
            "Epoch 4120/5000\n",
            "\n",
            "Epoch 4120: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.6507e-04 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.8309 - 4s/epoch - 105ms/step\n",
            "Epoch 4121/5000\n",
            "\n",
            "Epoch 4121: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5233e-04 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4122/5000\n",
            "\n",
            "Epoch 4122: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4399e-04 - accuracy: 1.0000 - val_loss: 0.6863 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4123/5000\n",
            "\n",
            "Epoch 4123: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5019e-04 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4124/5000\n",
            "\n",
            "Epoch 4124: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5259e-04 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.8273 - 2s/epoch - 65ms/step\n",
            "Epoch 4125/5000\n",
            "\n",
            "Epoch 4125: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.7399e-04 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8345 - 4s/epoch - 110ms/step\n",
            "Epoch 4126/5000\n",
            "\n",
            "Epoch 4126: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6798e-04 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.8273 - 2s/epoch - 65ms/step\n",
            "Epoch 4127/5000\n",
            "\n",
            "Epoch 4127: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5686e-04 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4128/5000\n",
            "\n",
            "Epoch 4128: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4953e-04 - accuracy: 1.0000 - val_loss: 0.6803 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4129/5000\n",
            "\n",
            "Epoch 4129: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4866e-04 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4130/5000\n",
            "\n",
            "Epoch 4130: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.5276e-04 - accuracy: 1.0000 - val_loss: 0.6766 - val_accuracy: 0.8309 - 4s/epoch - 104ms/step\n",
            "Epoch 4131/5000\n",
            "\n",
            "Epoch 4131: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.5963e-04 - accuracy: 1.0000 - val_loss: 0.6776 - val_accuracy: 0.8309 - 3s/epoch - 73ms/step\n",
            "Epoch 4132/5000\n",
            "\n",
            "Epoch 4132: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8017e-04 - accuracy: 1.0000 - val_loss: 0.6631 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4133/5000\n",
            "\n",
            "Epoch 4133: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5960e-04 - accuracy: 1.0000 - val_loss: 0.6757 - val_accuracy: 0.8273 - 2s/epoch - 65ms/step\n",
            "Epoch 4134/5000\n",
            "\n",
            "Epoch 4134: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3504e-04 - accuracy: 1.0000 - val_loss: 0.6842 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4135/5000\n",
            "\n",
            "Epoch 4135: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.5167e-04 - accuracy: 1.0000 - val_loss: 0.6903 - val_accuracy: 0.8345 - 3s/epoch - 95ms/step\n",
            "Epoch 4136/5000\n",
            "\n",
            "Epoch 4136: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.5983e-04 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.8345 - 3s/epoch - 81ms/step\n",
            "Epoch 4137/5000\n",
            "\n",
            "Epoch 4137: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5228e-04 - accuracy: 1.0000 - val_loss: 0.6681 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4138/5000\n",
            "\n",
            "Epoch 4138: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4862e-04 - accuracy: 1.0000 - val_loss: 0.6899 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4139/5000\n",
            "\n",
            "Epoch 4139: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5378e-04 - accuracy: 1.0000 - val_loss: 0.6922 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4140/5000\n",
            "\n",
            "Epoch 4140: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.0334e-04 - accuracy: 1.0000 - val_loss: 0.6674 - val_accuracy: 0.8309 - 3s/epoch - 88ms/step\n",
            "Epoch 4141/5000\n",
            "\n",
            "Epoch 4141: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.5839e-04 - accuracy: 1.0000 - val_loss: 0.6952 - val_accuracy: 0.8273 - 3s/epoch - 89ms/step\n",
            "Epoch 4142/5000\n",
            "\n",
            "Epoch 4142: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4924e-04 - accuracy: 1.0000 - val_loss: 0.6993 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4143/5000\n",
            "\n",
            "Epoch 4143: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7917e-04 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4144/5000\n",
            "\n",
            "Epoch 4144: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4679e-04 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4145/5000\n",
            "\n",
            "Epoch 4145: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.6927e-04 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.8201 - 3s/epoch - 79ms/step\n",
            "Epoch 4146/5000\n",
            "\n",
            "Epoch 4146: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.5563e-04 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8237 - 3s/epoch - 97ms/step\n",
            "Epoch 4147/5000\n",
            "\n",
            "Epoch 4147: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 7.7813e-04 - accuracy: 1.0000 - val_loss: 0.6379 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4148/5000\n",
            "\n",
            "Epoch 4148: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.7838e-04 - accuracy: 1.0000 - val_loss: 0.6563 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4149/5000\n",
            "\n",
            "Epoch 4149: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.5667e-04 - accuracy: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4150/5000\n",
            "\n",
            "Epoch 4150: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0784e-04 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8309 - 2s/epoch - 68ms/step\n",
            "Epoch 4151/5000\n",
            "\n",
            "Epoch 4151: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.7748e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8273 - 4s/epoch - 107ms/step\n",
            "Epoch 4152/5000\n",
            "\n",
            "Epoch 4152: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5619e-04 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4153/5000\n",
            "\n",
            "Epoch 4153: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4869e-04 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4154/5000\n",
            "\n",
            "Epoch 4154: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4623e-04 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4155/5000\n",
            "\n",
            "Epoch 4155: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5062e-04 - accuracy: 1.0000 - val_loss: 0.7002 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4156/5000\n",
            "\n",
            "Epoch 4156: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.5614e-04 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8273 - 4s/epoch - 110ms/step\n",
            "Epoch 4157/5000\n",
            "\n",
            "Epoch 4157: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.0294e-04 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4158/5000\n",
            "\n",
            "Epoch 4158: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7349e-04 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4159/5000\n",
            "\n",
            "Epoch 4159: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4324e-04 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4160/5000\n",
            "\n",
            "Epoch 4160: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3728e-04 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 4161/5000\n",
            "\n",
            "Epoch 4161: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.5244e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8237 - 4s/epoch - 109ms/step\n",
            "Epoch 4162/5000\n",
            "\n",
            "Epoch 4162: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5230e-04 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4163/5000\n",
            "\n",
            "Epoch 4163: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4734e-04 - accuracy: 1.0000 - val_loss: 0.6995 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4164/5000\n",
            "\n",
            "Epoch 4164: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6740e-04 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4165/5000\n",
            "\n",
            "Epoch 4165: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4903e-04 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4166/5000\n",
            "\n",
            "Epoch 4166: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.4007e-04 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.8273 - 4s/epoch - 103ms/step\n",
            "Epoch 4167/5000\n",
            "\n",
            "Epoch 4167: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.4846e-04 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8237 - 3s/epoch - 75ms/step\n",
            "Epoch 4168/5000\n",
            "\n",
            "Epoch 4168: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3238e-04 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4169/5000\n",
            "\n",
            "Epoch 4169: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3277e-04 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4170/5000\n",
            "\n",
            "Epoch 4170: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5424e-04 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4171/5000\n",
            "\n",
            "Epoch 4171: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.5656e-04 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.8309 - 3s/epoch - 96ms/step\n",
            "Epoch 4172/5000\n",
            "\n",
            "Epoch 4172: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.3618e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8273 - 3s/epoch - 80ms/step\n",
            "Epoch 4173/5000\n",
            "\n",
            "Epoch 4173: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4179e-04 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4174/5000\n",
            "\n",
            "Epoch 4174: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4102e-04 - accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4175/5000\n",
            "\n",
            "Epoch 4175: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8737e-04 - accuracy: 1.0000 - val_loss: 0.6951 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4176/5000\n",
            "\n",
            "Epoch 4176: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.8090e-04 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.8381 - 3s/epoch - 87ms/step\n",
            "Epoch 4177/5000\n",
            "\n",
            "Epoch 4177: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.3708e-04 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.8381 - 3s/epoch - 89ms/step\n",
            "Epoch 4178/5000\n",
            "\n",
            "Epoch 4178: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4385e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4179/5000\n",
            "\n",
            "Epoch 4179: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3449e-04 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8381 - 2s/epoch - 67ms/step\n",
            "Epoch 4180/5000\n",
            "\n",
            "Epoch 4180: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6602e-04 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4181/5000\n",
            "\n",
            "Epoch 4181: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.3872e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8381 - 3s/epoch - 82ms/step\n",
            "Epoch 4182/5000\n",
            "\n",
            "Epoch 4182: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.3828e-04 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.8345 - 3s/epoch - 95ms/step\n",
            "Epoch 4183/5000\n",
            "\n",
            "Epoch 4183: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3799e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4184/5000\n",
            "\n",
            "Epoch 4184: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4577e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4185/5000\n",
            "\n",
            "Epoch 4185: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2743e-04 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4186/5000\n",
            "\n",
            "Epoch 4186: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.3389e-04 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.8273 - 3s/epoch - 75ms/step\n",
            "Epoch 4187/5000\n",
            "\n",
            "Epoch 4187: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 6.5257e-04 - accuracy: 1.0000 - val_loss: 0.7311 - val_accuracy: 0.8309 - 4s/epoch - 103ms/step\n",
            "Epoch 4188/5000\n",
            "\n",
            "Epoch 4188: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.5870e-04 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4189/5000\n",
            "\n",
            "Epoch 4189: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8276e-04 - accuracy: 1.0000 - val_loss: 0.6993 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4190/5000\n",
            "\n",
            "Epoch 4190: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6251e-04 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4191/5000\n",
            "\n",
            "Epoch 4191: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6422e-04 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4192/5000\n",
            "\n",
            "Epoch 4192: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.6049e-04 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.8309 - 4s/epoch - 111ms/step\n",
            "Epoch 4193/5000\n",
            "\n",
            "Epoch 4193: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3928e-04 - accuracy: 1.0000 - val_loss: 0.7195 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4194/5000\n",
            "\n",
            "Epoch 4194: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6814e-04 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4195/5000\n",
            "\n",
            "Epoch 4195: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5738e-04 - accuracy: 1.0000 - val_loss: 0.7047 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4196/5000\n",
            "\n",
            "Epoch 4196: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6375e-04 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4197/5000\n",
            "\n",
            "Epoch 4197: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.3367e-04 - accuracy: 1.0000 - val_loss: 0.7214 - val_accuracy: 0.8345 - 4s/epoch - 110ms/step\n",
            "Epoch 4198/5000\n",
            "\n",
            "Epoch 4198: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3595e-04 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4199/5000\n",
            "\n",
            "Epoch 4199: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5122e-04 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4200/5000\n",
            "\n",
            "Epoch 4200: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4024e-04 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4201/5000\n",
            "\n",
            "Epoch 4201: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4315e-04 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4202/5000\n",
            "\n",
            "Epoch 4202: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.3201e-04 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8273 - 4s/epoch - 105ms/step\n",
            "Epoch 4203/5000\n",
            "\n",
            "Epoch 4203: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2786e-04 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.8273 - 2s/epoch - 71ms/step\n",
            "Epoch 4204/5000\n",
            "\n",
            "Epoch 4204: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.9971e-04 - accuracy: 1.0000 - val_loss: 0.6848 - val_accuracy: 0.8417 - 2s/epoch - 67ms/step\n",
            "Epoch 4205/5000\n",
            "\n",
            "Epoch 4205: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5536e-04 - accuracy: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.8381 - 2s/epoch - 67ms/step\n",
            "Epoch 4206/5000\n",
            "\n",
            "Epoch 4206: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3360e-04 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4207/5000\n",
            "\n",
            "Epoch 4207: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.3188e-04 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.8309 - 3s/epoch - 96ms/step\n",
            "Epoch 4208/5000\n",
            "\n",
            "Epoch 4208: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.4809e-04 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8273 - 3s/epoch - 80ms/step\n",
            "Epoch 4209/5000\n",
            "\n",
            "Epoch 4209: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6141e-04 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4210/5000\n",
            "\n",
            "Epoch 4210: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2759e-04 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4211/5000\n",
            "\n",
            "Epoch 4211: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3223e-04 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4212/5000\n",
            "\n",
            "Epoch 4212: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.3494e-04 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.8273 - 3s/epoch - 89ms/step\n",
            "Epoch 4213/5000\n",
            "\n",
            "Epoch 4213: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.2886e-04 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8273 - 3s/epoch - 88ms/step\n",
            "Epoch 4214/5000\n",
            "\n",
            "Epoch 4214: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4161e-04 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4215/5000\n",
            "\n",
            "Epoch 4215: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3135e-04 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4216/5000\n",
            "\n",
            "Epoch 4216: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3377e-04 - accuracy: 1.0000 - val_loss: 0.6981 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4217/5000\n",
            "\n",
            "Epoch 4217: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.2693e-04 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4218/5000\n",
            "\n",
            "Epoch 4218: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.2008e-04 - accuracy: 1.0000 - val_loss: 0.6781 - val_accuracy: 0.8345 - 3s/epoch - 92ms/step\n",
            "Epoch 4219/5000\n",
            "\n",
            "Epoch 4219: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4238e-04 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4220/5000\n",
            "\n",
            "Epoch 4220: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3829e-04 - accuracy: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4221/5000\n",
            "\n",
            "Epoch 4221: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1079e-04 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4222/5000\n",
            "\n",
            "Epoch 4222: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.2754e-04 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.8345 - 3s/epoch - 77ms/step\n",
            "Epoch 4223/5000\n",
            "\n",
            "Epoch 4223: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.7357e-04 - accuracy: 1.0000 - val_loss: 0.6680 - val_accuracy: 0.8381 - 3s/epoch - 100ms/step\n",
            "Epoch 4224/5000\n",
            "\n",
            "Epoch 4224: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2294e-04 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4225/5000\n",
            "\n",
            "Epoch 4225: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4179e-04 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4226/5000\n",
            "\n",
            "Epoch 4226: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5066e-04 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8417 - 2s/epoch - 66ms/step\n",
            "Epoch 4227/5000\n",
            "\n",
            "Epoch 4227: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5434e-04 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.8417 - 2s/epoch - 71ms/step\n",
            "Epoch 4228/5000\n",
            "\n",
            "Epoch 4228: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.2132e-04 - accuracy: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.8309 - 4s/epoch - 106ms/step\n",
            "Epoch 4229/5000\n",
            "\n",
            "Epoch 4229: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3225e-04 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4230/5000\n",
            "\n",
            "Epoch 4230: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3324e-04 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4231/5000\n",
            "\n",
            "Epoch 4231: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2200e-04 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4232/5000\n",
            "\n",
            "Epoch 4232: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2010e-04 - accuracy: 1.0000 - val_loss: 0.6856 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4233/5000\n",
            "\n",
            "Epoch 4233: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.2409e-04 - accuracy: 1.0000 - val_loss: 0.6901 - val_accuracy: 0.8309 - 4s/epoch - 111ms/step\n",
            "Epoch 4234/5000\n",
            "\n",
            "Epoch 4234: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5360e-04 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4235/5000\n",
            "\n",
            "Epoch 4235: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1082e-04 - accuracy: 1.0000 - val_loss: 0.7032 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4236/5000\n",
            "\n",
            "Epoch 4236: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1791e-04 - accuracy: 1.0000 - val_loss: 0.6803 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4237/5000\n",
            "\n",
            "Epoch 4237: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3504e-04 - accuracy: 1.0000 - val_loss: 0.6832 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4238/5000\n",
            "\n",
            "Epoch 4238: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.1342e-04 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.8381 - 4s/epoch - 108ms/step\n",
            "Epoch 4239/5000\n",
            "\n",
            "Epoch 4239: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6215e-04 - accuracy: 1.0000 - val_loss: 0.6827 - val_accuracy: 0.8309 - 2s/epoch - 69ms/step\n",
            "Epoch 4240/5000\n",
            "\n",
            "Epoch 4240: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 6.0442e-04 - accuracy: 1.0000 - val_loss: 0.6500 - val_accuracy: 0.8453 - 2s/epoch - 65ms/step\n",
            "Epoch 4241/5000\n",
            "\n",
            "Epoch 4241: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6648e-04 - accuracy: 1.0000 - val_loss: 0.6845 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4242/5000\n",
            "\n",
            "Epoch 4242: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6899e-04 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 0.8381 - 2s/epoch - 65ms/step\n",
            "Epoch 4243/5000\n",
            "\n",
            "Epoch 4243: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.4647e-04 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8381 - 3s/epoch - 96ms/step\n",
            "Epoch 4244/5000\n",
            "\n",
            "Epoch 4244: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.2264e-04 - accuracy: 1.0000 - val_loss: 0.6825 - val_accuracy: 0.8417 - 3s/epoch - 81ms/step\n",
            "Epoch 4245/5000\n",
            "\n",
            "Epoch 4245: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2217e-04 - accuracy: 1.0000 - val_loss: 0.6897 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4246/5000\n",
            "\n",
            "Epoch 4246: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3826e-04 - accuracy: 1.0000 - val_loss: 0.6820 - val_accuracy: 0.8453 - 2s/epoch - 66ms/step\n",
            "Epoch 4247/5000\n",
            "\n",
            "Epoch 4247: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3080e-04 - accuracy: 1.0000 - val_loss: 0.7093 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4248/5000\n",
            "\n",
            "Epoch 4248: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.3124e-04 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8381 - 3s/epoch - 86ms/step\n",
            "Epoch 4249/5000\n",
            "\n",
            "Epoch 4249: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.1834e-04 - accuracy: 1.0000 - val_loss: 0.6933 - val_accuracy: 0.8381 - 3s/epoch - 90ms/step\n",
            "Epoch 4250/5000\n",
            "\n",
            "Epoch 4250: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2815e-04 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4251/5000\n",
            "\n",
            "Epoch 4251: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1772e-04 - accuracy: 1.0000 - val_loss: 0.6838 - val_accuracy: 0.8381 - 2s/epoch - 67ms/step\n",
            "Epoch 4252/5000\n",
            "\n",
            "Epoch 4252: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5302e-04 - accuracy: 1.0000 - val_loss: 0.7545 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4253/5000\n",
            "\n",
            "Epoch 4253: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.3193e-04 - accuracy: 1.0000 - val_loss: 0.6980 - val_accuracy: 0.8345 - 3s/epoch - 78ms/step\n",
            "Epoch 4254/5000\n",
            "\n",
            "Epoch 4254: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.2164e-04 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.8345 - 3s/epoch - 99ms/step\n",
            "Epoch 4255/5000\n",
            "\n",
            "Epoch 4255: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4235e-04 - accuracy: 1.0000 - val_loss: 0.6616 - val_accuracy: 0.8453 - 2s/epoch - 67ms/step\n",
            "Epoch 4256/5000\n",
            "\n",
            "Epoch 4256: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2470e-04 - accuracy: 1.0000 - val_loss: 0.6798 - val_accuracy: 0.8417 - 2s/epoch - 67ms/step\n",
            "Epoch 4257/5000\n",
            "\n",
            "Epoch 4257: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2431e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4258/5000\n",
            "\n",
            "Epoch 4258: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1669e-04 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 4259/5000\n",
            "\n",
            "Epoch 4259: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.1781e-04 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.8345 - 4s/epoch - 105ms/step\n",
            "Epoch 4260/5000\n",
            "\n",
            "Epoch 4260: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0588e-04 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4261/5000\n",
            "\n",
            "Epoch 4261: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1298e-04 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4262/5000\n",
            "\n",
            "Epoch 4262: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0753e-04 - accuracy: 1.0000 - val_loss: 0.6899 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4263/5000\n",
            "\n",
            "Epoch 4263: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1816e-04 - accuracy: 1.0000 - val_loss: 0.6864 - val_accuracy: 0.8381 - 2s/epoch - 67ms/step\n",
            "Epoch 4264/5000\n",
            "\n",
            "Epoch 4264: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.1709e-04 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.8345 - 4s/epoch - 110ms/step\n",
            "Epoch 4265/5000\n",
            "\n",
            "Epoch 4265: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1439e-04 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4266/5000\n",
            "\n",
            "Epoch 4266: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0315e-04 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4267/5000\n",
            "\n",
            "Epoch 4267: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1768e-04 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4268/5000\n",
            "\n",
            "Epoch 4268: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2686e-04 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 0.8381 - 2s/epoch - 67ms/step\n",
            "Epoch 4269/5000\n",
            "\n",
            "Epoch 4269: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.0666e-04 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.8273 - 4s/epoch - 108ms/step\n",
            "Epoch 4270/5000\n",
            "\n",
            "Epoch 4270: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9972e-04 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4271/5000\n",
            "\n",
            "Epoch 4271: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0626e-04 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4272/5000\n",
            "\n",
            "Epoch 4272: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9927e-04 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4273/5000\n",
            "\n",
            "Epoch 4273: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0832e-04 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4274/5000\n",
            "\n",
            "Epoch 4274: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.1109e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8237 - 4s/epoch - 103ms/step\n",
            "Epoch 4275/5000\n",
            "\n",
            "Epoch 4275: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.1000e-04 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.8237 - 3s/epoch - 74ms/step\n",
            "Epoch 4276/5000\n",
            "\n",
            "Epoch 4276: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0399e-04 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4277/5000\n",
            "\n",
            "Epoch 4277: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0012e-04 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4278/5000\n",
            "\n",
            "Epoch 4278: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0978e-04 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.8417 - 2s/epoch - 67ms/step\n",
            "Epoch 4279/5000\n",
            "\n",
            "Epoch 4279: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.1920e-04 - accuracy: 1.0000 - val_loss: 0.6716 - val_accuracy: 0.8345 - 3s/epoch - 96ms/step\n",
            "Epoch 4280/5000\n",
            "\n",
            "Epoch 4280: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.1006e-04 - accuracy: 1.0000 - val_loss: 0.6781 - val_accuracy: 0.8309 - 3s/epoch - 81ms/step\n",
            "Epoch 4281/5000\n",
            "\n",
            "Epoch 4281: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0879e-04 - accuracy: 1.0000 - val_loss: 0.6753 - val_accuracy: 0.8273 - 2s/epoch - 65ms/step\n",
            "Epoch 4282/5000\n",
            "\n",
            "Epoch 4282: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0757e-04 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4283/5000\n",
            "\n",
            "Epoch 4283: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0639e-04 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4284/5000\n",
            "\n",
            "Epoch 4284: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.9094e-04 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.8273 - 3s/epoch - 87ms/step\n",
            "Epoch 4285/5000\n",
            "\n",
            "Epoch 4285: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.0482e-04 - accuracy: 1.0000 - val_loss: 0.6894 - val_accuracy: 0.8273 - 3s/epoch - 89ms/step\n",
            "Epoch 4286/5000\n",
            "\n",
            "Epoch 4286: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0344e-04 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4287/5000\n",
            "\n",
            "Epoch 4287: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0030e-04 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4288/5000\n",
            "\n",
            "Epoch 4288: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0075e-04 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4289/5000\n",
            "\n",
            "Epoch 4289: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.0208e-04 - accuracy: 1.0000 - val_loss: 0.6764 - val_accuracy: 0.8309 - 3s/epoch - 80ms/step\n",
            "Epoch 4290/5000\n",
            "\n",
            "Epoch 4290: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.0235e-04 - accuracy: 1.0000 - val_loss: 0.6799 - val_accuracy: 0.8273 - 3s/epoch - 100ms/step\n",
            "Epoch 4291/5000\n",
            "\n",
            "Epoch 4291: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3051e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8201 - 2s/epoch - 68ms/step\n",
            "Epoch 4292/5000\n",
            "\n",
            "Epoch 4292: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0543e-04 - accuracy: 1.0000 - val_loss: 0.6894 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4293/5000\n",
            "\n",
            "Epoch 4293: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9080e-04 - accuracy: 1.0000 - val_loss: 0.6776 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4294/5000\n",
            "\n",
            "Epoch 4294: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.0248e-04 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.8273 - 3s/epoch - 74ms/step\n",
            "Epoch 4295/5000\n",
            "\n",
            "Epoch 4295: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.0916e-04 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.8309 - 4s/epoch - 102ms/step\n",
            "Epoch 4296/5000\n",
            "\n",
            "Epoch 4296: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0165e-04 - accuracy: 1.0000 - val_loss: 0.6795 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4297/5000\n",
            "\n",
            "Epoch 4297: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1834e-04 - accuracy: 1.0000 - val_loss: 0.6796 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4298/5000\n",
            "\n",
            "Epoch 4298: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4043e-04 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 0.8453 - 2s/epoch - 66ms/step\n",
            "Epoch 4299/5000\n",
            "\n",
            "Epoch 4299: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4609e-04 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4300/5000\n",
            "\n",
            "Epoch 4300: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.2217e-04 - accuracy: 1.0000 - val_loss: 0.6707 - val_accuracy: 0.8381 - 4s/epoch - 110ms/step\n",
            "Epoch 4301/5000\n",
            "\n",
            "Epoch 4301: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1626e-04 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4302/5000\n",
            "\n",
            "Epoch 4302: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1077e-04 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8273 - 2s/epoch - 65ms/step\n",
            "Epoch 4303/5000\n",
            "\n",
            "Epoch 4303: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0552e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4304/5000\n",
            "\n",
            "Epoch 4304: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1567e-04 - accuracy: 1.0000 - val_loss: 0.7038 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4305/5000\n",
            "\n",
            "Epoch 4305: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.0686e-04 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.8273 - 4s/epoch - 106ms/step\n",
            "Epoch 4306/5000\n",
            "\n",
            "Epoch 4306: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9400e-04 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.8309 - 2s/epoch - 70ms/step\n",
            "Epoch 4307/5000\n",
            "\n",
            "Epoch 4307: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0570e-04 - accuracy: 1.0000 - val_loss: 0.6728 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4308/5000\n",
            "\n",
            "Epoch 4308: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8701e-04 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4309/5000\n",
            "\n",
            "Epoch 4309: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3317e-04 - accuracy: 1.0000 - val_loss: 0.7203 - val_accuracy: 0.8094 - 2s/epoch - 66ms/step\n",
            "Epoch 4310/5000\n",
            "\n",
            "Epoch 4310: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 9.0125e-04 - accuracy: 1.0000 - val_loss: 0.7798 - val_accuracy: 0.8165 - 3s/epoch - 98ms/step\n",
            "Epoch 4311/5000\n",
            "\n",
            "Epoch 4311: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 7.8401e-04 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.8345 - 3s/epoch - 77ms/step\n",
            "Epoch 4312/5000\n",
            "\n",
            "Epoch 4312: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.6745 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4313/5000\n",
            "\n",
            "Epoch 4313: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.6813 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4314/5000\n",
            "\n",
            "Epoch 4314: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 9.8031e-04 - accuracy: 1.0000 - val_loss: 0.7389 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4315/5000\n",
            "\n",
            "Epoch 4315: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.8853e-04 - accuracy: 1.0000 - val_loss: 0.7362 - val_accuracy: 0.8345 - 3s/epoch - 90ms/step\n",
            "Epoch 4316/5000\n",
            "\n",
            "Epoch 4316: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.1313e-04 - accuracy: 1.0000 - val_loss: 0.7363 - val_accuracy: 0.8417 - 3s/epoch - 87ms/step\n",
            "Epoch 4317/5000\n",
            "\n",
            "Epoch 4317: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.3354e-04 - accuracy: 1.0000 - val_loss: 0.7300 - val_accuracy: 0.8417 - 2s/epoch - 67ms/step\n",
            "Epoch 4318/5000\n",
            "\n",
            "Epoch 4318: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8055e-04 - accuracy: 1.0000 - val_loss: 0.7288 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4319/5000\n",
            "\n",
            "Epoch 4319: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.4746e-04 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4320/5000\n",
            "\n",
            "Epoch 4320: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 5.0573e-04 - accuracy: 1.0000 - val_loss: 0.7312 - val_accuracy: 0.8345 - 3s/epoch - 81ms/step\n",
            "Epoch 4321/5000\n",
            "\n",
            "Epoch 4321: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.9848e-04 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.8381 - 3s/epoch - 94ms/step\n",
            "Epoch 4322/5000\n",
            "\n",
            "Epoch 4322: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3828e-04 - accuracy: 1.0000 - val_loss: 0.7310 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4323/5000\n",
            "\n",
            "Epoch 4323: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4701e-04 - accuracy: 1.0000 - val_loss: 0.7320 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4324/5000\n",
            "\n",
            "Epoch 4324: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5009e-04 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4325/5000\n",
            "\n",
            "Epoch 4325: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.7597e-04 - accuracy: 1.0000 - val_loss: 0.7323 - val_accuracy: 0.8309 - 3s/epoch - 74ms/step\n",
            "Epoch 4326/5000\n",
            "\n",
            "Epoch 4326: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.6754e-04 - accuracy: 1.0000 - val_loss: 0.7303 - val_accuracy: 0.8345 - 4s/epoch - 103ms/step\n",
            "Epoch 4327/5000\n",
            "\n",
            "Epoch 4327: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5998e-04 - accuracy: 1.0000 - val_loss: 0.7283 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4328/5000\n",
            "\n",
            "Epoch 4328: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.8536e-04 - accuracy: 1.0000 - val_loss: 0.7238 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4329/5000\n",
            "\n",
            "Epoch 4329: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.2156e-04 - accuracy: 1.0000 - val_loss: 0.7372 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4330/5000\n",
            "\n",
            "Epoch 4330: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4719e-04 - accuracy: 1.0000 - val_loss: 0.7386 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4331/5000\n",
            "\n",
            "Epoch 4331: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.5172e-04 - accuracy: 1.0000 - val_loss: 0.7375 - val_accuracy: 0.8345 - 4s/epoch - 110ms/step\n",
            "Epoch 4332/5000\n",
            "\n",
            "Epoch 4332: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4257e-04 - accuracy: 1.0000 - val_loss: 0.7369 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4333/5000\n",
            "\n",
            "Epoch 4333: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3447e-04 - accuracy: 1.0000 - val_loss: 0.7361 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4334/5000\n",
            "\n",
            "Epoch 4334: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4859e-04 - accuracy: 1.0000 - val_loss: 0.7358 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4335/5000\n",
            "\n",
            "Epoch 4335: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4511e-04 - accuracy: 1.0000 - val_loss: 0.7348 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4336/5000\n",
            "\n",
            "Epoch 4336: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.2074e-04 - accuracy: 1.0000 - val_loss: 0.7339 - val_accuracy: 0.8309 - 4s/epoch - 109ms/step\n",
            "Epoch 4337/5000\n",
            "\n",
            "Epoch 4337: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3548e-04 - accuracy: 1.0000 - val_loss: 0.7333 - val_accuracy: 0.8309 - 2s/epoch - 68ms/step\n",
            "Epoch 4338/5000\n",
            "\n",
            "Epoch 4338: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3345e-04 - accuracy: 1.0000 - val_loss: 0.7322 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4339/5000\n",
            "\n",
            "Epoch 4339: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3197e-04 - accuracy: 1.0000 - val_loss: 0.7336 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4340/5000\n",
            "\n",
            "Epoch 4340: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2914e-04 - accuracy: 1.0000 - val_loss: 0.7341 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4341/5000\n",
            "\n",
            "Epoch 4341: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.4755e-04 - accuracy: 1.0000 - val_loss: 0.7349 - val_accuracy: 0.8309 - 4s/epoch - 103ms/step\n",
            "Epoch 4342/5000\n",
            "\n",
            "Epoch 4342: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.5185e-04 - accuracy: 1.0000 - val_loss: 0.7327 - val_accuracy: 0.8309 - 3s/epoch - 74ms/step\n",
            "Epoch 4343/5000\n",
            "\n",
            "Epoch 4343: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3534e-04 - accuracy: 1.0000 - val_loss: 0.7312 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4344/5000\n",
            "\n",
            "Epoch 4344: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.7149e-04 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4345/5000\n",
            "\n",
            "Epoch 4345: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.6028e-04 - accuracy: 1.0000 - val_loss: 0.7365 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4346/5000\n",
            "\n",
            "Epoch 4346: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.5924e-04 - accuracy: 1.0000 - val_loss: 0.7414 - val_accuracy: 0.8381 - 3s/epoch - 98ms/step\n",
            "Epoch 4347/5000\n",
            "\n",
            "Epoch 4347: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.3760e-04 - accuracy: 1.0000 - val_loss: 0.7320 - val_accuracy: 0.8381 - 3s/epoch - 78ms/step\n",
            "Epoch 4348/5000\n",
            "\n",
            "Epoch 4348: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3897e-04 - accuracy: 1.0000 - val_loss: 0.7330 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4349/5000\n",
            "\n",
            "Epoch 4349: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2825e-04 - accuracy: 1.0000 - val_loss: 0.7320 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4350/5000\n",
            "\n",
            "Epoch 4350: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1595e-04 - accuracy: 1.0000 - val_loss: 0.7315 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4351/5000\n",
            "\n",
            "Epoch 4351: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.1791e-04 - accuracy: 1.0000 - val_loss: 0.7337 - val_accuracy: 0.8345 - 3s/epoch - 90ms/step\n",
            "Epoch 4352/5000\n",
            "\n",
            "Epoch 4352: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.2117e-04 - accuracy: 1.0000 - val_loss: 0.7341 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 4353/5000\n",
            "\n",
            "Epoch 4353: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2063e-04 - accuracy: 1.0000 - val_loss: 0.7381 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4354/5000\n",
            "\n",
            "Epoch 4354: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0031e-04 - accuracy: 1.0000 - val_loss: 0.7368 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4355/5000\n",
            "\n",
            "Epoch 4355: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2566e-04 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4356/5000\n",
            "\n",
            "Epoch 4356: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.2366e-04 - accuracy: 1.0000 - val_loss: 0.7347 - val_accuracy: 0.8309 - 3s/epoch - 82ms/step\n",
            "Epoch 4357/5000\n",
            "\n",
            "Epoch 4357: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.1729e-04 - accuracy: 1.0000 - val_loss: 0.7340 - val_accuracy: 0.8309 - 3s/epoch - 94ms/step\n",
            "Epoch 4358/5000\n",
            "\n",
            "Epoch 4358: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2460e-04 - accuracy: 1.0000 - val_loss: 0.7277 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4359/5000\n",
            "\n",
            "Epoch 4359: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9727e-04 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4360/5000\n",
            "\n",
            "Epoch 4360: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1593e-04 - accuracy: 1.0000 - val_loss: 0.7269 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4361/5000\n",
            "\n",
            "Epoch 4361: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.0947e-04 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.8345 - 3s/epoch - 77ms/step\n",
            "Epoch 4362/5000\n",
            "\n",
            "Epoch 4362: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.1309e-04 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.8345 - 4s/epoch - 100ms/step\n",
            "Epoch 4363/5000\n",
            "\n",
            "Epoch 4363: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.3010e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4364/5000\n",
            "\n",
            "Epoch 4364: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3581e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4365/5000\n",
            "\n",
            "Epoch 4365: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1482e-04 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4366/5000\n",
            "\n",
            "Epoch 4366: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0802e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4367/5000\n",
            "\n",
            "Epoch 4367: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.3035e-04 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.8309 - 4s/epoch - 110ms/step\n",
            "Epoch 4368/5000\n",
            "\n",
            "Epoch 4368: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0999e-04 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4369/5000\n",
            "\n",
            "Epoch 4369: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0572e-04 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4370/5000\n",
            "\n",
            "Epoch 4370: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1207e-04 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4371/5000\n",
            "\n",
            "Epoch 4371: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0825e-04 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4372/5000\n",
            "\n",
            "Epoch 4372: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.0438e-04 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8273 - 4s/epoch - 110ms/step\n",
            "Epoch 4373/5000\n",
            "\n",
            "Epoch 4373: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1793e-04 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4374/5000\n",
            "\n",
            "Epoch 4374: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.3993e-04 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4375/5000\n",
            "\n",
            "Epoch 4375: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0489e-04 - accuracy: 1.0000 - val_loss: 0.7140 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4376/5000\n",
            "\n",
            "Epoch 4376: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0685e-04 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4377/5000\n",
            "\n",
            "Epoch 4377: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.0283e-04 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.8273 - 4s/epoch - 104ms/step\n",
            "Epoch 4378/5000\n",
            "\n",
            "Epoch 4378: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.6059e-04 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.8345 - 3s/epoch - 72ms/step\n",
            "Epoch 4379/5000\n",
            "\n",
            "Epoch 4379: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0479e-04 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4380/5000\n",
            "\n",
            "Epoch 4380: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.4521e-04 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4381/5000\n",
            "\n",
            "Epoch 4381: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9096e-04 - accuracy: 1.0000 - val_loss: 0.7176 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4382/5000\n",
            "\n",
            "Epoch 4382: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.9669e-04 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.8273 - 3s/epoch - 95ms/step\n",
            "Epoch 4383/5000\n",
            "\n",
            "Epoch 4383: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.1129e-04 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.8273 - 3s/epoch - 83ms/step\n",
            "Epoch 4384/5000\n",
            "\n",
            "Epoch 4384: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9649e-04 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4385/5000\n",
            "\n",
            "Epoch 4385: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1953e-04 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4386/5000\n",
            "\n",
            "Epoch 4386: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0679e-04 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4387/5000\n",
            "\n",
            "Epoch 4387: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.0301e-04 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8309 - 3s/epoch - 87ms/step\n",
            "Epoch 4388/5000\n",
            "\n",
            "Epoch 4388: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.9081e-04 - accuracy: 1.0000 - val_loss: 0.7109 - val_accuracy: 0.8309 - 3s/epoch - 89ms/step\n",
            "Epoch 4389/5000\n",
            "\n",
            "Epoch 4389: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0804e-04 - accuracy: 1.0000 - val_loss: 0.7093 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4390/5000\n",
            "\n",
            "Epoch 4390: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2358e-04 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4391/5000\n",
            "\n",
            "Epoch 4391: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9397e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4392/5000\n",
            "\n",
            "Epoch 4392: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.9257e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8309 - 3s/epoch - 76ms/step\n",
            "Epoch 4393/5000\n",
            "\n",
            "Epoch 4393: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.9572e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8309 - 3s/epoch - 100ms/step\n",
            "Epoch 4394/5000\n",
            "\n",
            "Epoch 4394: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9949e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4395/5000\n",
            "\n",
            "Epoch 4395: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1799e-04 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4396/5000\n",
            "\n",
            "Epoch 4396: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2331e-04 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4397/5000\n",
            "\n",
            "Epoch 4397: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1523e-04 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8273 - 2s/epoch - 71ms/step\n",
            "Epoch 4398/5000\n",
            "\n",
            "Epoch 4398: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.1233e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8417 - 4s/epoch - 106ms/step\n",
            "Epoch 4399/5000\n",
            "\n",
            "Epoch 4399: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9515e-04 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4400/5000\n",
            "\n",
            "Epoch 4400: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9439e-04 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4401/5000\n",
            "\n",
            "Epoch 4401: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8507e-04 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4402/5000\n",
            "\n",
            "Epoch 4402: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0646e-04 - accuracy: 1.0000 - val_loss: 0.6963 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4403/5000\n",
            "\n",
            "Epoch 4403: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.9056e-04 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.8309 - 4s/epoch - 109ms/step\n",
            "Epoch 4404/5000\n",
            "\n",
            "Epoch 4404: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8912e-04 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4405/5000\n",
            "\n",
            "Epoch 4405: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8581e-04 - accuracy: 1.0000 - val_loss: 0.6951 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4406/5000\n",
            "\n",
            "Epoch 4406: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9065e-04 - accuracy: 1.0000 - val_loss: 0.6993 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4407/5000\n",
            "\n",
            "Epoch 4407: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9972e-04 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4408/5000\n",
            "\n",
            "Epoch 4408: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.9509e-04 - accuracy: 1.0000 - val_loss: 0.7038 - val_accuracy: 0.8273 - 4s/epoch - 110ms/step\n",
            "Epoch 4409/5000\n",
            "\n",
            "Epoch 4409: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.5263e-04 - accuracy: 1.0000 - val_loss: 0.6963 - val_accuracy: 0.8237 - 2s/epoch - 68ms/step\n",
            "Epoch 4410/5000\n",
            "\n",
            "Epoch 4410: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9816e-04 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4411/5000\n",
            "\n",
            "Epoch 4411: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0256e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4412/5000\n",
            "\n",
            "Epoch 4412: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9967e-04 - accuracy: 1.0000 - val_loss: 0.7038 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4413/5000\n",
            "\n",
            "Epoch 4413: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.9904e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8273 - 4s/epoch - 105ms/step\n",
            "Epoch 4414/5000\n",
            "\n",
            "Epoch 4414: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.9742e-04 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.8273 - 3s/epoch - 72ms/step\n",
            "Epoch 4415/5000\n",
            "\n",
            "Epoch 4415: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8937e-04 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4416/5000\n",
            "\n",
            "Epoch 4416: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9364e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4417/5000\n",
            "\n",
            "Epoch 4417: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8553e-04 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4418/5000\n",
            "\n",
            "Epoch 4418: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.8328e-04 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8273 - 3s/epoch - 96ms/step\n",
            "Epoch 4419/5000\n",
            "\n",
            "Epoch 4419: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.9205e-04 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.8273 - 3s/epoch - 81ms/step\n",
            "Epoch 4420/5000\n",
            "\n",
            "Epoch 4420: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8863e-04 - accuracy: 1.0000 - val_loss: 0.7033 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4421/5000\n",
            "\n",
            "Epoch 4421: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9284e-04 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4422/5000\n",
            "\n",
            "Epoch 4422: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0418e-04 - accuracy: 1.0000 - val_loss: 0.7224 - val_accuracy: 0.8201 - 2s/epoch - 67ms/step\n",
            "Epoch 4423/5000\n",
            "\n",
            "Epoch 4423: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.7890e-04 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8201 - 3s/epoch - 86ms/step\n",
            "Epoch 4424/5000\n",
            "\n",
            "Epoch 4424: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.7960e-04 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8273 - 3s/epoch - 89ms/step\n",
            "Epoch 4425/5000\n",
            "\n",
            "Epoch 4425: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9153e-04 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4426/5000\n",
            "\n",
            "Epoch 4426: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8721e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4427/5000\n",
            "\n",
            "Epoch 4427: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8602e-04 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4428/5000\n",
            "\n",
            "Epoch 4428: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.8891e-04 - accuracy: 1.0000 - val_loss: 0.7056 - val_accuracy: 0.8237 - 3s/epoch - 79ms/step\n",
            "Epoch 4429/5000\n",
            "\n",
            "Epoch 4429: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.0188e-04 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.8237 - 4s/epoch - 113ms/step\n",
            "Epoch 4430/5000\n",
            "\n",
            "Epoch 4430: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.8254e-04 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.8201 - 3s/epoch - 75ms/step\n",
            "Epoch 4431/5000\n",
            "\n",
            "Epoch 4431: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.7776e-04 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.8165 - 3s/epoch - 75ms/step\n",
            "Epoch 4432/5000\n",
            "\n",
            "Epoch 4432: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8539e-04 - accuracy: 1.0000 - val_loss: 0.7101 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4433/5000\n",
            "\n",
            "Epoch 4433: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.8928e-04 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8237 - 3s/epoch - 92ms/step\n",
            "Epoch 4434/5000\n",
            "\n",
            "Epoch 4434: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.8822e-04 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.8237 - 3s/epoch - 86ms/step\n",
            "Epoch 4435/5000\n",
            "\n",
            "Epoch 4435: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9077e-04 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4436/5000\n",
            "\n",
            "Epoch 4436: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8568e-04 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4437/5000\n",
            "\n",
            "Epoch 4437: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9545e-04 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4438/5000\n",
            "\n",
            "Epoch 4438: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.8283e-04 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.8273 - 3s/epoch - 85ms/step\n",
            "Epoch 4439/5000\n",
            "\n",
            "Epoch 4439: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.8301e-04 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8237 - 3s/epoch - 92ms/step\n",
            "Epoch 4440/5000\n",
            "\n",
            "Epoch 4440: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9667e-04 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4441/5000\n",
            "\n",
            "Epoch 4441: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8294e-04 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4442/5000\n",
            "\n",
            "Epoch 4442: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8385e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8201 - 2s/epoch - 67ms/step\n",
            "Epoch 4443/5000\n",
            "\n",
            "Epoch 4443: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.8184e-04 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.8237 - 3s/epoch - 78ms/step\n",
            "Epoch 4444/5000\n",
            "\n",
            "Epoch 4444: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.7961e-04 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.8237 - 3s/epoch - 98ms/step\n",
            "Epoch 4445/5000\n",
            "\n",
            "Epoch 4445: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9482e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4446/5000\n",
            "\n",
            "Epoch 4446: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8767e-04 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4447/5000\n",
            "\n",
            "Epoch 4447: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7763e-04 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4448/5000\n",
            "\n",
            "Epoch 4448: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.8387e-04 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.8345 - 3s/epoch - 72ms/step\n",
            "Epoch 4449/5000\n",
            "\n",
            "Epoch 4449: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.9105e-04 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8273 - 4s/epoch - 106ms/step\n",
            "Epoch 4450/5000\n",
            "\n",
            "Epoch 4450: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7700e-04 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4451/5000\n",
            "\n",
            "Epoch 4451: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8118e-04 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.8381 - 2s/epoch - 67ms/step\n",
            "Epoch 4452/5000\n",
            "\n",
            "Epoch 4452: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8196e-04 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4453/5000\n",
            "\n",
            "Epoch 4453: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8926e-04 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4454/5000\n",
            "\n",
            "Epoch 4454: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.7844e-04 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.8345 - 4s/epoch - 111ms/step\n",
            "Epoch 4455/5000\n",
            "\n",
            "Epoch 4455: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7147e-04 - accuracy: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4456/5000\n",
            "\n",
            "Epoch 4456: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7740e-04 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4457/5000\n",
            "\n",
            "Epoch 4457: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0101e-04 - accuracy: 1.0000 - val_loss: 0.7032 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4458/5000\n",
            "\n",
            "Epoch 4458: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7949e-04 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4459/5000\n",
            "\n",
            "Epoch 4459: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.7727e-04 - accuracy: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.8381 - 4s/epoch - 112ms/step\n",
            "Epoch 4460/5000\n",
            "\n",
            "Epoch 4460: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7452e-04 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4461/5000\n",
            "\n",
            "Epoch 4461: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6770e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4462/5000\n",
            "\n",
            "Epoch 4462: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8427e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4463/5000\n",
            "\n",
            "Epoch 4463: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9455e-04 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.8381 - 2s/epoch - 68ms/step\n",
            "Epoch 4464/5000\n",
            "\n",
            "Epoch 4464: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.7527e-04 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.8309 - 4s/epoch - 107ms/step\n",
            "Epoch 4465/5000\n",
            "\n",
            "Epoch 4465: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6945e-04 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 4466/5000\n",
            "\n",
            "Epoch 4466: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0198e-04 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4467/5000\n",
            "\n",
            "Epoch 4467: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6613e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4468/5000\n",
            "\n",
            "Epoch 4468: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6008e-04 - accuracy: 1.0000 - val_loss: 0.7065 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4469/5000\n",
            "\n",
            "Epoch 4469: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.6975e-04 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.8345 - 3s/epoch - 98ms/step\n",
            "Epoch 4470/5000\n",
            "\n",
            "Epoch 4470: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.7463e-04 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8273 - 3s/epoch - 79ms/step\n",
            "Epoch 4471/5000\n",
            "\n",
            "Epoch 4471: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7301e-04 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4472/5000\n",
            "\n",
            "Epoch 4472: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6742e-04 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4473/5000\n",
            "\n",
            "Epoch 4473: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6407e-04 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4474/5000\n",
            "\n",
            "Epoch 4474: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.7609e-04 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.8309 - 3s/epoch - 90ms/step\n",
            "Epoch 4475/5000\n",
            "\n",
            "Epoch 4475: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.8615e-04 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4476/5000\n",
            "\n",
            "Epoch 4476: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.7728e-04 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.8309 - 3s/epoch - 74ms/step\n",
            "Epoch 4477/5000\n",
            "\n",
            "Epoch 4477: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7512e-04 - accuracy: 1.0000 - val_loss: 0.6954 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4478/5000\n",
            "\n",
            "Epoch 4478: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5435e-04 - accuracy: 1.0000 - val_loss: 0.6961 - val_accuracy: 0.8381 - 2s/epoch - 68ms/step\n",
            "Epoch 4479/5000\n",
            "\n",
            "Epoch 4479: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.5660e-04 - accuracy: 1.0000 - val_loss: 0.6980 - val_accuracy: 0.8345 - 3s/epoch - 91ms/step\n",
            "Epoch 4480/5000\n",
            "\n",
            "Epoch 4480: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.7141e-04 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8381 - 3s/epoch - 86ms/step\n",
            "Epoch 4481/5000\n",
            "\n",
            "Epoch 4481: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7058e-04 - accuracy: 1.0000 - val_loss: 0.6867 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4482/5000\n",
            "\n",
            "Epoch 4482: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6686e-04 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4483/5000\n",
            "\n",
            "Epoch 4483: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8105e-04 - accuracy: 1.0000 - val_loss: 0.6928 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4484/5000\n",
            "\n",
            "Epoch 4484: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.8393e-04 - accuracy: 1.0000 - val_loss: 0.6882 - val_accuracy: 0.8345 - 3s/epoch - 80ms/step\n",
            "Epoch 4485/5000\n",
            "\n",
            "Epoch 4485: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.6682e-04 - accuracy: 1.0000 - val_loss: 0.6845 - val_accuracy: 0.8381 - 3s/epoch - 95ms/step\n",
            "Epoch 4486/5000\n",
            "\n",
            "Epoch 4486: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6330e-04 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4487/5000\n",
            "\n",
            "Epoch 4487: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7729e-04 - accuracy: 1.0000 - val_loss: 0.7316 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 4488/5000\n",
            "\n",
            "Epoch 4488: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6611e-04 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4489/5000\n",
            "\n",
            "Epoch 4489: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.5889e-04 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8273 - 3s/epoch - 74ms/step\n",
            "Epoch 4490/5000\n",
            "\n",
            "Epoch 4490: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.9776e-04 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.8381 - 4s/epoch - 102ms/step\n",
            "Epoch 4491/5000\n",
            "\n",
            "Epoch 4491: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7742e-04 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4492/5000\n",
            "\n",
            "Epoch 4492: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7907e-04 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.8381 - 2s/epoch - 67ms/step\n",
            "Epoch 4493/5000\n",
            "\n",
            "Epoch 4493: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6645e-04 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4494/5000\n",
            "\n",
            "Epoch 4494: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8373e-04 - accuracy: 1.0000 - val_loss: 0.6933 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4495/5000\n",
            "\n",
            "Epoch 4495: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.7855e-04 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8381 - 4s/epoch - 110ms/step\n",
            "Epoch 4496/5000\n",
            "\n",
            "Epoch 4496: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7405e-04 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4497/5000\n",
            "\n",
            "Epoch 4497: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.0128e-04 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4498/5000\n",
            "\n",
            "Epoch 4498: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9728e-04 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4499/5000\n",
            "\n",
            "Epoch 4499: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 5.8657e-04 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8345 - 2s/epoch - 68ms/step\n",
            "Epoch 4500/5000\n",
            "\n",
            "Epoch 4500: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 4.3689e-04 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8381 - 4s/epoch - 109ms/step\n",
            "Epoch 4501/5000\n",
            "\n",
            "Epoch 4501: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2924e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4502/5000\n",
            "\n",
            "Epoch 4502: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9032e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4503/5000\n",
            "\n",
            "Epoch 4503: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9998e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4504/5000\n",
            "\n",
            "Epoch 4504: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7420e-04 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4505/5000\n",
            "\n",
            "Epoch 4505: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.7708e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8273 - 4s/epoch - 108ms/step\n",
            "Epoch 4506/5000\n",
            "\n",
            "Epoch 4506: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7069e-04 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.8237 - 2s/epoch - 70ms/step\n",
            "Epoch 4507/5000\n",
            "\n",
            "Epoch 4507: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8726e-04 - accuracy: 1.0000 - val_loss: 0.7290 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4508/5000\n",
            "\n",
            "Epoch 4508: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9303e-04 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.8201 - 2s/epoch - 67ms/step\n",
            "Epoch 4509/5000\n",
            "\n",
            "Epoch 4509: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6933e-04 - accuracy: 1.0000 - val_loss: 0.7390 - val_accuracy: 0.8165 - 2s/epoch - 67ms/step\n",
            "Epoch 4510/5000\n",
            "\n",
            "Epoch 4510: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.6065e-04 - accuracy: 1.0000 - val_loss: 0.7292 - val_accuracy: 0.8237 - 3s/epoch - 100ms/step\n",
            "Epoch 4511/5000\n",
            "\n",
            "Epoch 4511: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.5842e-04 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.8201 - 3s/epoch - 78ms/step\n",
            "Epoch 4512/5000\n",
            "\n",
            "Epoch 4512: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7078e-04 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4513/5000\n",
            "\n",
            "Epoch 4513: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7230e-04 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4514/5000\n",
            "\n",
            "Epoch 4514: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5298e-04 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4515/5000\n",
            "\n",
            "Epoch 4515: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.5226e-04 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.8201 - 3s/epoch - 93ms/step\n",
            "Epoch 4516/5000\n",
            "\n",
            "Epoch 4516: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.8983e-04 - accuracy: 1.0000 - val_loss: 0.7217 - val_accuracy: 0.8237 - 3s/epoch - 83ms/step\n",
            "Epoch 4517/5000\n",
            "\n",
            "Epoch 4517: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7768e-04 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4518/5000\n",
            "\n",
            "Epoch 4518: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5403e-04 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.8201 - 2s/epoch - 67ms/step\n",
            "Epoch 4519/5000\n",
            "\n",
            "Epoch 4519: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6476e-04 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.8237 - 2s/epoch - 68ms/step\n",
            "Epoch 4520/5000\n",
            "\n",
            "Epoch 4520: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.7693e-04 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 0.8237 - 3s/epoch - 89ms/step\n",
            "Epoch 4521/5000\n",
            "\n",
            "Epoch 4521: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.6503e-04 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.8237 - 3s/epoch - 88ms/step\n",
            "Epoch 4522/5000\n",
            "\n",
            "Epoch 4522: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5781e-04 - accuracy: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4523/5000\n",
            "\n",
            "Epoch 4523: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5891e-04 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4524/5000\n",
            "\n",
            "Epoch 4524: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5268e-04 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4525/5000\n",
            "\n",
            "Epoch 4525: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.5287e-04 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8237 - 3s/epoch - 84ms/step\n",
            "Epoch 4526/5000\n",
            "\n",
            "Epoch 4526: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.6260e-04 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.8237 - 3s/epoch - 94ms/step\n",
            "Epoch 4527/5000\n",
            "\n",
            "Epoch 4527: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6289e-04 - accuracy: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4528/5000\n",
            "\n",
            "Epoch 4528: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5919e-04 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4529/5000\n",
            "\n",
            "Epoch 4529: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6042e-04 - accuracy: 1.0000 - val_loss: 0.6867 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4530/5000\n",
            "\n",
            "Epoch 4530: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.6599e-04 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.8309 - 3s/epoch - 75ms/step\n",
            "Epoch 4531/5000\n",
            "\n",
            "Epoch 4531: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.6178e-04 - accuracy: 1.0000 - val_loss: 0.6967 - val_accuracy: 0.8309 - 4s/epoch - 101ms/step\n",
            "Epoch 4532/5000\n",
            "\n",
            "Epoch 4532: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7541e-04 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4533/5000\n",
            "\n",
            "Epoch 4533: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5120e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4534/5000\n",
            "\n",
            "Epoch 4534: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5090e-04 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4535/5000\n",
            "\n",
            "Epoch 4535: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6153e-04 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 4536/5000\n",
            "\n",
            "Epoch 4536: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.5492e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8273 - 4s/epoch - 106ms/step\n",
            "Epoch 4537/5000\n",
            "\n",
            "Epoch 4537: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6946e-04 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4538/5000\n",
            "\n",
            "Epoch 4538: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6841e-04 - accuracy: 1.0000 - val_loss: 0.6981 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4539/5000\n",
            "\n",
            "Epoch 4539: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6581e-04 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4540/5000\n",
            "\n",
            "Epoch 4540: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6353e-04 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4541/5000\n",
            "\n",
            "Epoch 4541: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.5390e-04 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.8237 - 4s/epoch - 109ms/step\n",
            "Epoch 4542/5000\n",
            "\n",
            "Epoch 4542: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5302e-04 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4543/5000\n",
            "\n",
            "Epoch 4543: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5662e-04 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4544/5000\n",
            "\n",
            "Epoch 4544: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6124e-04 - accuracy: 1.0000 - val_loss: 0.7327 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 4545/5000\n",
            "\n",
            "Epoch 4545: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5113e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8201 - 2s/epoch - 67ms/step\n",
            "Epoch 4546/5000\n",
            "\n",
            "Epoch 4546: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.5940e-04 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.8309 - 4s/epoch - 106ms/step\n",
            "Epoch 4547/5000\n",
            "\n",
            "Epoch 4547: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4311e-04 - accuracy: 1.0000 - val_loss: 0.7038 - val_accuracy: 0.8345 - 2s/epoch - 71ms/step\n",
            "Epoch 4548/5000\n",
            "\n",
            "Epoch 4548: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4961e-04 - accuracy: 1.0000 - val_loss: 0.6969 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4549/5000\n",
            "\n",
            "Epoch 4549: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4392e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4550/5000\n",
            "\n",
            "Epoch 4550: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.7104e-04 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4551/5000\n",
            "\n",
            "Epoch 4551: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.4983e-04 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.8237 - 3s/epoch - 97ms/step\n",
            "Epoch 4552/5000\n",
            "\n",
            "Epoch 4552: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.3646e-04 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8273 - 3s/epoch - 78ms/step\n",
            "Epoch 4553/5000\n",
            "\n",
            "Epoch 4553: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4467e-04 - accuracy: 1.0000 - val_loss: 0.7031 - val_accuracy: 0.8237 - 2s/epoch - 65ms/step\n",
            "Epoch 4554/5000\n",
            "\n",
            "Epoch 4554: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4572e-04 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4555/5000\n",
            "\n",
            "Epoch 4555: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5613e-04 - accuracy: 1.0000 - val_loss: 0.6886 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4556/5000\n",
            "\n",
            "Epoch 4556: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.5390e-04 - accuracy: 1.0000 - val_loss: 0.6825 - val_accuracy: 0.8345 - 3s/epoch - 89ms/step\n",
            "Epoch 4557/5000\n",
            "\n",
            "Epoch 4557: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.4074e-04 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.8273 - 3s/epoch - 88ms/step\n",
            "Epoch 4558/5000\n",
            "\n",
            "Epoch 4558: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5967e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4559/5000\n",
            "\n",
            "Epoch 4559: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4526e-04 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4560/5000\n",
            "\n",
            "Epoch 4560: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6445e-04 - accuracy: 1.0000 - val_loss: 0.6974 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4561/5000\n",
            "\n",
            "Epoch 4561: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.7239e-04 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.8345 - 3s/epoch - 84ms/step\n",
            "Epoch 4562/5000\n",
            "\n",
            "Epoch 4562: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.6678e-04 - accuracy: 1.0000 - val_loss: 0.7272 - val_accuracy: 0.8237 - 3s/epoch - 93ms/step\n",
            "Epoch 4563/5000\n",
            "\n",
            "Epoch 4563: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5041e-04 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.8201 - 2s/epoch - 67ms/step\n",
            "Epoch 4564/5000\n",
            "\n",
            "Epoch 4564: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4367e-04 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8201 - 2s/epoch - 68ms/step\n",
            "Epoch 4565/5000\n",
            "\n",
            "Epoch 4565: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6779e-04 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4566/5000\n",
            "\n",
            "Epoch 4566: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.3898e-04 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.8237 - 3s/epoch - 77ms/step\n",
            "Epoch 4567/5000\n",
            "\n",
            "Epoch 4567: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.6115e-04 - accuracy: 1.0000 - val_loss: 0.7289 - val_accuracy: 0.8273 - 4s/epoch - 100ms/step\n",
            "Epoch 4568/5000\n",
            "\n",
            "Epoch 4568: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5311e-04 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4569/5000\n",
            "\n",
            "Epoch 4569: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4494e-04 - accuracy: 1.0000 - val_loss: 0.7235 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4570/5000\n",
            "\n",
            "Epoch 4570: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4695e-04 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4571/5000\n",
            "\n",
            "Epoch 4571: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4354e-04 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 0.8237 - 2s/epoch - 69ms/step\n",
            "Epoch 4572/5000\n",
            "\n",
            "Epoch 4572: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.5908e-04 - accuracy: 1.0000 - val_loss: 0.7696 - val_accuracy: 0.8273 - 4s/epoch - 107ms/step\n",
            "Epoch 4573/5000\n",
            "\n",
            "Epoch 4573: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.8918e-04 - accuracy: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4574/5000\n",
            "\n",
            "Epoch 4574: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1396e-04 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4575/5000\n",
            "\n",
            "Epoch 4575: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.1014e-04 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4576/5000\n",
            "\n",
            "Epoch 4576: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6195e-04 - accuracy: 1.0000 - val_loss: 0.7393 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4577/5000\n",
            "\n",
            "Epoch 4577: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.5002e-04 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.8273 - 4s/epoch - 109ms/step\n",
            "Epoch 4578/5000\n",
            "\n",
            "Epoch 4578: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5242e-04 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4579/5000\n",
            "\n",
            "Epoch 4579: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5238e-04 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4580/5000\n",
            "\n",
            "Epoch 4580: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4447e-04 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.8201 - 2s/epoch - 67ms/step\n",
            "Epoch 4581/5000\n",
            "\n",
            "Epoch 4581: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5420e-04 - accuracy: 1.0000 - val_loss: 0.7279 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4582/5000\n",
            "\n",
            "Epoch 4582: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.4944e-04 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.8201 - 4s/epoch - 107ms/step\n",
            "Epoch 4583/5000\n",
            "\n",
            "Epoch 4583: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3341e-04 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.8237 - 2s/epoch - 69ms/step\n",
            "Epoch 4584/5000\n",
            "\n",
            "Epoch 4584: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4029e-04 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 4585/5000\n",
            "\n",
            "Epoch 4585: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3842e-04 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.8201 - 2s/epoch - 65ms/step\n",
            "Epoch 4586/5000\n",
            "\n",
            "Epoch 4586: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3706e-04 - accuracy: 1.0000 - val_loss: 0.7059 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4587/5000\n",
            "\n",
            "Epoch 4587: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.3322e-04 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8201 - 3s/epoch - 99ms/step\n",
            "Epoch 4588/5000\n",
            "\n",
            "Epoch 4588: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.3900e-04 - accuracy: 1.0000 - val_loss: 0.6856 - val_accuracy: 0.8345 - 3s/epoch - 77ms/step\n",
            "Epoch 4589/5000\n",
            "\n",
            "Epoch 4589: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4982e-04 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4590/5000\n",
            "\n",
            "Epoch 4590: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4327e-04 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4591/5000\n",
            "\n",
            "Epoch 4591: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4114e-04 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4592/5000\n",
            "\n",
            "Epoch 4592: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.4986e-04 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.8309 - 3s/epoch - 93ms/step\n",
            "Epoch 4593/5000\n",
            "\n",
            "Epoch 4593: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.3628e-04 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.8273 - 3s/epoch - 84ms/step\n",
            "Epoch 4594/5000\n",
            "\n",
            "Epoch 4594: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4647e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4595/5000\n",
            "\n",
            "Epoch 4595: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3409e-04 - accuracy: 1.0000 - val_loss: 0.7015 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4596/5000\n",
            "\n",
            "Epoch 4596: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2491e-04 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4597/5000\n",
            "\n",
            "Epoch 4597: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.3357e-04 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.8201 - 3s/epoch - 83ms/step\n",
            "Epoch 4598/5000\n",
            "\n",
            "Epoch 4598: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.4390e-04 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.8237 - 3s/epoch - 93ms/step\n",
            "Epoch 4599/5000\n",
            "\n",
            "Epoch 4599: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3544e-04 - accuracy: 1.0000 - val_loss: 0.6716 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4600/5000\n",
            "\n",
            "Epoch 4600: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3712e-04 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4601/5000\n",
            "\n",
            "Epoch 4601: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4236e-04 - accuracy: 1.0000 - val_loss: 0.6783 - val_accuracy: 0.8273 - 2s/epoch - 65ms/step\n",
            "Epoch 4602/5000\n",
            "\n",
            "Epoch 4602: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.4200e-04 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.8237 - 3s/epoch - 79ms/step\n",
            "Epoch 4603/5000\n",
            "\n",
            "Epoch 4603: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.4447e-04 - accuracy: 1.0000 - val_loss: 0.6981 - val_accuracy: 0.8273 - 3s/epoch - 100ms/step\n",
            "Epoch 4604/5000\n",
            "\n",
            "Epoch 4604: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3123e-04 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4605/5000\n",
            "\n",
            "Epoch 4605: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2683e-04 - accuracy: 1.0000 - val_loss: 0.6769 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4606/5000\n",
            "\n",
            "Epoch 4606: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1895e-04 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4607/5000\n",
            "\n",
            "Epoch 4607: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2962e-04 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.8273 - 2s/epoch - 71ms/step\n",
            "Epoch 4608/5000\n",
            "\n",
            "Epoch 4608: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.3202e-04 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.8273 - 4s/epoch - 106ms/step\n",
            "Epoch 4609/5000\n",
            "\n",
            "Epoch 4609: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5288e-04 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4610/5000\n",
            "\n",
            "Epoch 4610: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3519e-04 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4611/5000\n",
            "\n",
            "Epoch 4611: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3943e-04 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4612/5000\n",
            "\n",
            "Epoch 4612: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5117e-04 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4613/5000\n",
            "\n",
            "Epoch 4613: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.3370e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8273 - 4s/epoch - 110ms/step\n",
            "Epoch 4614/5000\n",
            "\n",
            "Epoch 4614: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3431e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4615/5000\n",
            "\n",
            "Epoch 4615: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3557e-04 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4616/5000\n",
            "\n",
            "Epoch 4616: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9976e-04 - accuracy: 1.0000 - val_loss: 0.6864 - val_accuracy: 0.8417 - 2s/epoch - 68ms/step\n",
            "Epoch 4617/5000\n",
            "\n",
            "Epoch 4617: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5156e-04 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4618/5000\n",
            "\n",
            "Epoch 4618: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.4021e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.8381 - 4s/epoch - 112ms/step\n",
            "Epoch 4619/5000\n",
            "\n",
            "Epoch 4619: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3691e-04 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4620/5000\n",
            "\n",
            "Epoch 4620: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3501e-04 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4621/5000\n",
            "\n",
            "Epoch 4621: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3497e-04 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4622/5000\n",
            "\n",
            "Epoch 4622: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1761e-04 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4623/5000\n",
            "\n",
            "Epoch 4623: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.2651e-04 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8273 - 4s/epoch - 106ms/step\n",
            "Epoch 4624/5000\n",
            "\n",
            "Epoch 4624: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1984e-04 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.8237 - 2s/epoch - 71ms/step\n",
            "Epoch 4625/5000\n",
            "\n",
            "Epoch 4625: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3435e-04 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4626/5000\n",
            "\n",
            "Epoch 4626: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2959e-04 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4627/5000\n",
            "\n",
            "Epoch 4627: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2482e-04 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4628/5000\n",
            "\n",
            "Epoch 4628: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.4098e-04 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.8417 - 4s/epoch - 101ms/step\n",
            "Epoch 4629/5000\n",
            "\n",
            "Epoch 4629: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.4092e-04 - accuracy: 1.0000 - val_loss: 0.7059 - val_accuracy: 0.8309 - 3s/epoch - 75ms/step\n",
            "Epoch 4630/5000\n",
            "\n",
            "Epoch 4630: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3895e-04 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4631/5000\n",
            "\n",
            "Epoch 4631: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3669e-04 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4632/5000\n",
            "\n",
            "Epoch 4632: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3797e-04 - accuracy: 1.0000 - val_loss: 0.7031 - val_accuracy: 0.8201 - 2s/epoch - 67ms/step\n",
            "Epoch 4633/5000\n",
            "\n",
            "Epoch 4633: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2975e-04 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.8201 - 3s/epoch - 96ms/step\n",
            "Epoch 4634/5000\n",
            "\n",
            "Epoch 4634: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2220e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8273 - 3s/epoch - 80ms/step\n",
            "Epoch 4635/5000\n",
            "\n",
            "Epoch 4635: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3402e-04 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.8201 - 2s/epoch - 67ms/step\n",
            "Epoch 4636/5000\n",
            "\n",
            "Epoch 4636: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0984e-04 - accuracy: 1.0000 - val_loss: 0.7084 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4637/5000\n",
            "\n",
            "Epoch 4637: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1841e-04 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4638/5000\n",
            "\n",
            "Epoch 4638: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2305e-04 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8201 - 3s/epoch - 87ms/step\n",
            "Epoch 4639/5000\n",
            "\n",
            "Epoch 4639: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2395e-04 - accuracy: 1.0000 - val_loss: 0.6989 - val_accuracy: 0.8309 - 3s/epoch - 89ms/step\n",
            "Epoch 4640/5000\n",
            "\n",
            "Epoch 4640: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4499e-04 - accuracy: 1.0000 - val_loss: 0.7239 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4641/5000\n",
            "\n",
            "Epoch 4641: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3825e-04 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4642/5000\n",
            "\n",
            "Epoch 4642: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2506e-04 - accuracy: 1.0000 - val_loss: 0.7263 - val_accuracy: 0.8381 - 2s/epoch - 67ms/step\n",
            "Epoch 4643/5000\n",
            "\n",
            "Epoch 4643: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.3510e-04 - accuracy: 1.0000 - val_loss: 0.7252 - val_accuracy: 0.8273 - 3s/epoch - 79ms/step\n",
            "Epoch 4644/5000\n",
            "\n",
            "Epoch 4644: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.3514e-04 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.8345 - 3s/epoch - 97ms/step\n",
            "Epoch 4645/5000\n",
            "\n",
            "Epoch 4645: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2672e-04 - accuracy: 1.0000 - val_loss: 0.7299 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4646/5000\n",
            "\n",
            "Epoch 4646: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2464e-04 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.8273 - 2s/epoch - 68ms/step\n",
            "Epoch 4647/5000\n",
            "\n",
            "Epoch 4647: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5140e-04 - accuracy: 1.0000 - val_loss: 0.7417 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4648/5000\n",
            "\n",
            "Epoch 4648: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2870e-04 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.8237 - 3s/epoch - 75ms/step\n",
            "Epoch 4649/5000\n",
            "\n",
            "Epoch 4649: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.2552e-04 - accuracy: 1.0000 - val_loss: 0.7214 - val_accuracy: 0.8273 - 4s/epoch - 103ms/step\n",
            "Epoch 4650/5000\n",
            "\n",
            "Epoch 4650: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1859e-04 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4651/5000\n",
            "\n",
            "Epoch 4651: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2344e-04 - accuracy: 1.0000 - val_loss: 0.7350 - val_accuracy: 0.8201 - 2s/epoch - 67ms/step\n",
            "Epoch 4652/5000\n",
            "\n",
            "Epoch 4652: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3176e-04 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4653/5000\n",
            "\n",
            "Epoch 4653: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1716e-04 - accuracy: 1.0000 - val_loss: 0.6985 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4654/5000\n",
            "\n",
            "Epoch 4654: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.1331e-04 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.8201 - 4s/epoch - 109ms/step\n",
            "Epoch 4655/5000\n",
            "\n",
            "Epoch 4655: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3412e-04 - accuracy: 1.0000 - val_loss: 0.7533 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4656/5000\n",
            "\n",
            "Epoch 4656: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1692e-04 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4657/5000\n",
            "\n",
            "Epoch 4657: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2072e-04 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4658/5000\n",
            "\n",
            "Epoch 4658: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3417e-04 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4659/5000\n",
            "\n",
            "Epoch 4659: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.3304e-04 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.8309 - 4s/epoch - 111ms/step\n",
            "Epoch 4660/5000\n",
            "\n",
            "Epoch 4660: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1275e-04 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8309 - 2s/epoch - 68ms/step\n",
            "Epoch 4661/5000\n",
            "\n",
            "Epoch 4661: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1770e-04 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4662/5000\n",
            "\n",
            "Epoch 4662: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2248e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4663/5000\n",
            "\n",
            "Epoch 4663: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1279e-04 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4664/5000\n",
            "\n",
            "Epoch 4664: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.2131e-04 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.8345 - 4s/epoch - 106ms/step\n",
            "Epoch 4665/5000\n",
            "\n",
            "Epoch 4665: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2378e-04 - accuracy: 1.0000 - val_loss: 0.6987 - val_accuracy: 0.8309 - 2s/epoch - 70ms/step\n",
            "Epoch 4666/5000\n",
            "\n",
            "Epoch 4666: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1348e-04 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4667/5000\n",
            "\n",
            "Epoch 4667: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1642e-04 - accuracy: 1.0000 - val_loss: 0.7272 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4668/5000\n",
            "\n",
            "Epoch 4668: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1679e-04 - accuracy: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4669/5000\n",
            "\n",
            "Epoch 4669: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.0868e-04 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8237 - 3s/epoch - 98ms/step\n",
            "Epoch 4670/5000\n",
            "\n",
            "Epoch 4670: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.3464e-04 - accuracy: 1.0000 - val_loss: 0.7225 - val_accuracy: 0.8273 - 3s/epoch - 79ms/step\n",
            "Epoch 4671/5000\n",
            "\n",
            "Epoch 4671: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1906e-04 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4672/5000\n",
            "\n",
            "Epoch 4672: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1868e-04 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4673/5000\n",
            "\n",
            "Epoch 4673: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4751e-04 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4674/5000\n",
            "\n",
            "Epoch 4674: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.1292e-04 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8345 - 3s/epoch - 90ms/step\n",
            "Epoch 4675/5000\n",
            "\n",
            "Epoch 4675: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.3174e-04 - accuracy: 1.0000 - val_loss: 0.6982 - val_accuracy: 0.8309 - 3s/epoch - 87ms/step\n",
            "Epoch 4676/5000\n",
            "\n",
            "Epoch 4676: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3087e-04 - accuracy: 1.0000 - val_loss: 0.6961 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4677/5000\n",
            "\n",
            "Epoch 4677: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1252e-04 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4678/5000\n",
            "\n",
            "Epoch 4678: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1682e-04 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4679/5000\n",
            "\n",
            "Epoch 4679: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.1330e-04 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8309 - 3s/epoch - 79ms/step\n",
            "Epoch 4680/5000\n",
            "\n",
            "Epoch 4680: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.0825e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8237 - 3s/epoch - 97ms/step\n",
            "Epoch 4681/5000\n",
            "\n",
            "Epoch 4681: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5920e-04 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.8417 - 2s/epoch - 66ms/step\n",
            "Epoch 4682/5000\n",
            "\n",
            "Epoch 4682: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.9510e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4683/5000\n",
            "\n",
            "Epoch 4683: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3374e-04 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4684/5000\n",
            "\n",
            "Epoch 4684: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.4391e-04 - accuracy: 1.0000 - val_loss: 0.7236 - val_accuracy: 0.8273 - 3s/epoch - 73ms/step\n",
            "Epoch 4685/5000\n",
            "\n",
            "Epoch 4685: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.4635e-04 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.8273 - 4s/epoch - 104ms/step\n",
            "Epoch 4686/5000\n",
            "\n",
            "Epoch 4686: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2269e-04 - accuracy: 1.0000 - val_loss: 0.7066 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4687/5000\n",
            "\n",
            "Epoch 4687: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2252e-04 - accuracy: 1.0000 - val_loss: 0.7066 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4688/5000\n",
            "\n",
            "Epoch 4688: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3102e-04 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4689/5000\n",
            "\n",
            "Epoch 4689: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1994e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4690/5000\n",
            "\n",
            "Epoch 4690: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.1521e-04 - accuracy: 1.0000 - val_loss: 0.7093 - val_accuracy: 0.8417 - 4s/epoch - 111ms/step\n",
            "Epoch 4691/5000\n",
            "\n",
            "Epoch 4691: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0656e-04 - accuracy: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4692/5000\n",
            "\n",
            "Epoch 4692: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2904e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4693/5000\n",
            "\n",
            "Epoch 4693: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1309e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4694/5000\n",
            "\n",
            "Epoch 4694: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1018e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4695/5000\n",
            "\n",
            "Epoch 4695: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.1197e-04 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8309 - 4s/epoch - 109ms/step\n",
            "Epoch 4696/5000\n",
            "\n",
            "Epoch 4696: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0351e-04 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4697/5000\n",
            "\n",
            "Epoch 4697: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9701e-04 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4698/5000\n",
            "\n",
            "Epoch 4698: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1088e-04 - accuracy: 1.0000 - val_loss: 0.6713 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4699/5000\n",
            "\n",
            "Epoch 4699: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4551e-04 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4700/5000\n",
            "\n",
            "Epoch 4700: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.3317e-04 - accuracy: 1.0000 - val_loss: 0.6721 - val_accuracy: 0.8309 - 4s/epoch - 101ms/step\n",
            "Epoch 4701/5000\n",
            "\n",
            "Epoch 4701: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2026e-04 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.8345 - 3s/epoch - 74ms/step\n",
            "Epoch 4702/5000\n",
            "\n",
            "Epoch 4702: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2886e-04 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4703/5000\n",
            "\n",
            "Epoch 4703: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1710e-04 - accuracy: 1.0000 - val_loss: 0.6803 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4704/5000\n",
            "\n",
            "Epoch 4704: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1435e-04 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4705/5000\n",
            "\n",
            "Epoch 4705: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.0280e-04 - accuracy: 1.0000 - val_loss: 0.6867 - val_accuracy: 0.8309 - 3s/epoch - 100ms/step\n",
            "Epoch 4706/5000\n",
            "\n",
            "Epoch 4706: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.1069e-04 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.8381 - 3s/epoch - 79ms/step\n",
            "Epoch 4707/5000\n",
            "\n",
            "Epoch 4707: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2347e-04 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4708/5000\n",
            "\n",
            "Epoch 4708: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2216e-04 - accuracy: 1.0000 - val_loss: 0.6886 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4709/5000\n",
            "\n",
            "Epoch 4709: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1174e-04 - accuracy: 1.0000 - val_loss: 0.6736 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4710/5000\n",
            "\n",
            "Epoch 4710: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.1676e-04 - accuracy: 1.0000 - val_loss: 0.7302 - val_accuracy: 0.8273 - 3s/epoch - 92ms/step\n",
            "Epoch 4711/5000\n",
            "\n",
            "Epoch 4711: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2546e-04 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.8309 - 3s/epoch - 85ms/step\n",
            "Epoch 4712/5000\n",
            "\n",
            "Epoch 4712: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0515e-04 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4713/5000\n",
            "\n",
            "Epoch 4713: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2067e-04 - accuracy: 1.0000 - val_loss: 0.6686 - val_accuracy: 0.8417 - 2s/epoch - 66ms/step\n",
            "Epoch 4714/5000\n",
            "\n",
            "Epoch 4714: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3777e-04 - accuracy: 1.0000 - val_loss: 0.7234 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4715/5000\n",
            "\n",
            "Epoch 4715: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 0.0022 - accuracy: 0.9982 - val_loss: 0.7161 - val_accuracy: 0.8273 - 3s/epoch - 84ms/step\n",
            "Epoch 4716/5000\n",
            "\n",
            "Epoch 4716: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.6801 - val_accuracy: 0.8165 - 3s/epoch - 93ms/step\n",
            "Epoch 4717/5000\n",
            "\n",
            "Epoch 4717: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7428 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 4718/5000\n",
            "\n",
            "Epoch 4718: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 4.2468e-04 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8237 - 2s/epoch - 67ms/step\n",
            "Epoch 4719/5000\n",
            "\n",
            "Epoch 4719: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6698e-04 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4720/5000\n",
            "\n",
            "Epoch 4720: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.8492e-04 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.8273 - 3s/epoch - 79ms/step\n",
            "Epoch 4721/5000\n",
            "\n",
            "Epoch 4721: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.7877e-04 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.8309 - 3s/epoch - 97ms/step\n",
            "Epoch 4722/5000\n",
            "\n",
            "Epoch 4722: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4093e-04 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4723/5000\n",
            "\n",
            "Epoch 4723: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5047e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4724/5000\n",
            "\n",
            "Epoch 4724: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4669e-04 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4725/5000\n",
            "\n",
            "Epoch 4725: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.6773e-04 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8273 - 2s/epoch - 71ms/step\n",
            "Epoch 4726/5000\n",
            "\n",
            "Epoch 4726: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.4758e-04 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8237 - 4s/epoch - 105ms/step\n",
            "Epoch 4727/5000\n",
            "\n",
            "Epoch 4727: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4352e-04 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4728/5000\n",
            "\n",
            "Epoch 4728: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5411e-04 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4729/5000\n",
            "\n",
            "Epoch 4729: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3783e-04 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4730/5000\n",
            "\n",
            "Epoch 4730: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3278e-04 - accuracy: 1.0000 - val_loss: 0.7135 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4731/5000\n",
            "\n",
            "Epoch 4731: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.3549e-04 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8237 - 4s/epoch - 110ms/step\n",
            "Epoch 4732/5000\n",
            "\n",
            "Epoch 4732: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4913e-04 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4733/5000\n",
            "\n",
            "Epoch 4733: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4694e-04 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4734/5000\n",
            "\n",
            "Epoch 4734: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5148e-04 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4735/5000\n",
            "\n",
            "Epoch 4735: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3245e-04 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4736/5000\n",
            "\n",
            "Epoch 4736: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.3056e-04 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.8237 - 4s/epoch - 109ms/step\n",
            "Epoch 4737/5000\n",
            "\n",
            "Epoch 4737: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2679e-04 - accuracy: 1.0000 - val_loss: 0.7199 - val_accuracy: 0.8273 - 2s/epoch - 68ms/step\n",
            "Epoch 4738/5000\n",
            "\n",
            "Epoch 4738: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3848e-04 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4739/5000\n",
            "\n",
            "Epoch 4739: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2472e-04 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4740/5000\n",
            "\n",
            "Epoch 4740: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2539e-04 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4741/5000\n",
            "\n",
            "Epoch 4741: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.6596e-04 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.8345 - 4s/epoch - 101ms/step\n",
            "Epoch 4742/5000\n",
            "\n",
            "Epoch 4742: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2903e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8345 - 3s/epoch - 75ms/step\n",
            "Epoch 4743/5000\n",
            "\n",
            "Epoch 4743: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3325e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4744/5000\n",
            "\n",
            "Epoch 4744: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3504e-04 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4745/5000\n",
            "\n",
            "Epoch 4745: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3741e-04 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4746/5000\n",
            "\n",
            "Epoch 4746: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.5360e-04 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.8309 - 3s/epoch - 94ms/step\n",
            "Epoch 4747/5000\n",
            "\n",
            "Epoch 4747: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.3700e-04 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8309 - 3s/epoch - 83ms/step\n",
            "Epoch 4748/5000\n",
            "\n",
            "Epoch 4748: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2893e-04 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4749/5000\n",
            "\n",
            "Epoch 4749: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2725e-04 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4750/5000\n",
            "\n",
            "Epoch 4750: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3708e-04 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4751/5000\n",
            "\n",
            "Epoch 4751: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.1932e-04 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.8345 - 3s/epoch - 88ms/step\n",
            "Epoch 4752/5000\n",
            "\n",
            "Epoch 4752: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2960e-04 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.8345 - 3s/epoch - 88ms/step\n",
            "Epoch 4753/5000\n",
            "\n",
            "Epoch 4753: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1746e-04 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4754/5000\n",
            "\n",
            "Epoch 4754: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1465e-04 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4755/5000\n",
            "\n",
            "Epoch 4755: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1722e-04 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4756/5000\n",
            "\n",
            "Epoch 4756: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.3952e-04 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.8345 - 3s/epoch - 82ms/step\n",
            "Epoch 4757/5000\n",
            "\n",
            "Epoch 4757: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2220e-04 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.8345 - 3s/epoch - 95ms/step\n",
            "Epoch 4758/5000\n",
            "\n",
            "Epoch 4758: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2452e-04 - accuracy: 1.0000 - val_loss: 0.7204 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4759/5000\n",
            "\n",
            "Epoch 4759: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2117e-04 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4760/5000\n",
            "\n",
            "Epoch 4760: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4164e-04 - accuracy: 1.0000 - val_loss: 0.7056 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4761/5000\n",
            "\n",
            "Epoch 4761: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2913e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8309 - 3s/epoch - 75ms/step\n",
            "Epoch 4762/5000\n",
            "\n",
            "Epoch 4762: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.2558e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8345 - 4s/epoch - 101ms/step\n",
            "Epoch 4763/5000\n",
            "\n",
            "Epoch 4763: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1463e-04 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4764/5000\n",
            "\n",
            "Epoch 4764: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2332e-04 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8273 - 2s/epoch - 68ms/step\n",
            "Epoch 4765/5000\n",
            "\n",
            "Epoch 4765: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1960e-04 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4766/5000\n",
            "\n",
            "Epoch 4766: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2161e-04 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8309 - 2s/epoch - 71ms/step\n",
            "Epoch 4767/5000\n",
            "\n",
            "Epoch 4767: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.2182e-04 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8309 - 4s/epoch - 106ms/step\n",
            "Epoch 4768/5000\n",
            "\n",
            "Epoch 4768: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2182e-04 - accuracy: 1.0000 - val_loss: 0.7101 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4769/5000\n",
            "\n",
            "Epoch 4769: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2484e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4770/5000\n",
            "\n",
            "Epoch 4770: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2608e-04 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4771/5000\n",
            "\n",
            "Epoch 4771: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1494e-04 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4772/5000\n",
            "\n",
            "Epoch 4772: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.3715e-04 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8309 - 4s/epoch - 110ms/step\n",
            "Epoch 4773/5000\n",
            "\n",
            "Epoch 4773: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2312e-04 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4774/5000\n",
            "\n",
            "Epoch 4774: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2344e-04 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4775/5000\n",
            "\n",
            "Epoch 4775: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1469e-04 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4776/5000\n",
            "\n",
            "Epoch 4776: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1353e-04 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4777/5000\n",
            "\n",
            "Epoch 4777: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.1399e-04 - accuracy: 1.0000 - val_loss: 0.7104 - val_accuracy: 0.8309 - 4s/epoch - 110ms/step\n",
            "Epoch 4778/5000\n",
            "\n",
            "Epoch 4778: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0417e-04 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4779/5000\n",
            "\n",
            "Epoch 4779: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0710e-04 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4780/5000\n",
            "\n",
            "Epoch 4780: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1208e-04 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4781/5000\n",
            "\n",
            "Epoch 4781: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0077e-04 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4782/5000\n",
            "\n",
            "Epoch 4782: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.0655e-04 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.8273 - 3s/epoch - 99ms/step\n",
            "Epoch 4783/5000\n",
            "\n",
            "Epoch 4783: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.0585e-04 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.8273 - 3s/epoch - 77ms/step\n",
            "Epoch 4784/5000\n",
            "\n",
            "Epoch 4784: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2648e-04 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4785/5000\n",
            "\n",
            "Epoch 4785: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0963e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4786/5000\n",
            "\n",
            "Epoch 4786: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0634e-04 - accuracy: 1.0000 - val_loss: 0.7076 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4787/5000\n",
            "\n",
            "Epoch 4787: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2389e-04 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8381 - 3s/epoch - 92ms/step\n",
            "Epoch 4788/5000\n",
            "\n",
            "Epoch 4788: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2429e-04 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.8345 - 3s/epoch - 85ms/step\n",
            "Epoch 4789/5000\n",
            "\n",
            "Epoch 4789: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1176e-04 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4790/5000\n",
            "\n",
            "Epoch 4790: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2101e-04 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4791/5000\n",
            "\n",
            "Epoch 4791: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1433e-04 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4792/5000\n",
            "\n",
            "Epoch 4792: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.9708e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8345 - 3s/epoch - 84ms/step\n",
            "Epoch 4793/5000\n",
            "\n",
            "Epoch 4793: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.1208e-04 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.8345 - 3s/epoch - 93ms/step\n",
            "Epoch 4794/5000\n",
            "\n",
            "Epoch 4794: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0313e-04 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4795/5000\n",
            "\n",
            "Epoch 4795: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0470e-04 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4796/5000\n",
            "\n",
            "Epoch 4796: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0514e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4797/5000\n",
            "\n",
            "Epoch 4797: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.0453e-04 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8345 - 3s/epoch - 73ms/step\n",
            "Epoch 4798/5000\n",
            "\n",
            "Epoch 4798: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.9764e-04 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.8345 - 4s/epoch - 103ms/step\n",
            "Epoch 4799/5000\n",
            "\n",
            "Epoch 4799: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.9920e-04 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8309 - 3s/epoch - 72ms/step\n",
            "Epoch 4800/5000\n",
            "\n",
            "Epoch 4800: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0548e-04 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4801/5000\n",
            "\n",
            "Epoch 4801: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9681e-04 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4802/5000\n",
            "\n",
            "Epoch 4802: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0766e-04 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.8309 - 2s/epoch - 71ms/step\n",
            "Epoch 4803/5000\n",
            "\n",
            "Epoch 4803: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.0880e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8309 - 4s/epoch - 106ms/step\n",
            "Epoch 4804/5000\n",
            "\n",
            "Epoch 4804: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.3275e-04 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4805/5000\n",
            "\n",
            "Epoch 4805: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1593e-04 - accuracy: 1.0000 - val_loss: 0.7073 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4806/5000\n",
            "\n",
            "Epoch 4806: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0494e-04 - accuracy: 1.0000 - val_loss: 0.7076 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4807/5000\n",
            "\n",
            "Epoch 4807: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0009e-04 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4808/5000\n",
            "\n",
            "Epoch 4808: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.9832e-04 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8345 - 4s/epoch - 110ms/step\n",
            "Epoch 4809/5000\n",
            "\n",
            "Epoch 4809: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0658e-04 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4810/5000\n",
            "\n",
            "Epoch 4810: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0121e-04 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4811/5000\n",
            "\n",
            "Epoch 4811: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.2952e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4812/5000\n",
            "\n",
            "Epoch 4812: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0463e-04 - accuracy: 1.0000 - val_loss: 0.7297 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4813/5000\n",
            "\n",
            "Epoch 4813: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.0258e-04 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8309 - 4s/epoch - 108ms/step\n",
            "Epoch 4814/5000\n",
            "\n",
            "Epoch 4814: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1185e-04 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.8345 - 2s/epoch - 68ms/step\n",
            "Epoch 4815/5000\n",
            "\n",
            "Epoch 4815: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0686e-04 - accuracy: 1.0000 - val_loss: 0.6745 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4816/5000\n",
            "\n",
            "Epoch 4816: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1450e-04 - accuracy: 1.0000 - val_loss: 0.6733 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4817/5000\n",
            "\n",
            "Epoch 4817: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1778e-04 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4818/5000\n",
            "\n",
            "Epoch 4818: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.9969e-04 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.8345 - 3s/epoch - 98ms/step\n",
            "Epoch 4819/5000\n",
            "\n",
            "Epoch 4819: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.9513e-04 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.8309 - 3s/epoch - 78ms/step\n",
            "Epoch 4820/5000\n",
            "\n",
            "Epoch 4820: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0151e-04 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4821/5000\n",
            "\n",
            "Epoch 4821: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0056e-04 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4822/5000\n",
            "\n",
            "Epoch 4822: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0240e-04 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4823/5000\n",
            "\n",
            "Epoch 4823: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.0511e-04 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.8273 - 3s/epoch - 93ms/step\n",
            "Epoch 4824/5000\n",
            "\n",
            "Epoch 4824: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.0899e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8309 - 3s/epoch - 86ms/step\n",
            "Epoch 4825/5000\n",
            "\n",
            "Epoch 4825: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9760e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4826/5000\n",
            "\n",
            "Epoch 4826: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0565e-04 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4827/5000\n",
            "\n",
            "Epoch 4827: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9636e-04 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4828/5000\n",
            "\n",
            "Epoch 4828: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.0092e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8309 - 3s/epoch - 82ms/step\n",
            "Epoch 4829/5000\n",
            "\n",
            "Epoch 4829: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.9272e-04 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8309 - 3s/epoch - 94ms/step\n",
            "Epoch 4830/5000\n",
            "\n",
            "Epoch 4830: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0849e-04 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4831/5000\n",
            "\n",
            "Epoch 4831: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0268e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4832/5000\n",
            "\n",
            "Epoch 4832: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9582e-04 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4833/5000\n",
            "\n",
            "Epoch 4833: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8935e-04 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8273 - 3s/epoch - 75ms/step\n",
            "Epoch 4834/5000\n",
            "\n",
            "Epoch 4834: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.0277e-04 - accuracy: 1.0000 - val_loss: 0.7051 - val_accuracy: 0.8309 - 4s/epoch - 102ms/step\n",
            "Epoch 4835/5000\n",
            "\n",
            "Epoch 4835: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8394e-04 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4836/5000\n",
            "\n",
            "Epoch 4836: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9232e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4837/5000\n",
            "\n",
            "Epoch 4837: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.1384e-04 - accuracy: 1.0000 - val_loss: 0.7002 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4838/5000\n",
            "\n",
            "Epoch 4838: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.2814e-04 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8309 - 3s/epoch - 73ms/step\n",
            "Epoch 4839/5000\n",
            "\n",
            "Epoch 4839: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.9096e-04 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.8309 - 4s/epoch - 105ms/step\n",
            "Epoch 4840/5000\n",
            "\n",
            "Epoch 4840: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0590e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4841/5000\n",
            "\n",
            "Epoch 4841: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9348e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4842/5000\n",
            "\n",
            "Epoch 4842: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9292e-04 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4843/5000\n",
            "\n",
            "Epoch 4843: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.4891e-04 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4844/5000\n",
            "\n",
            "Epoch 4844: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.0824e-04 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8273 - 4s/epoch - 110ms/step\n",
            "Epoch 4845/5000\n",
            "\n",
            "Epoch 4845: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9740e-04 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4846/5000\n",
            "\n",
            "Epoch 4846: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9327e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4847/5000\n",
            "\n",
            "Epoch 4847: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0402e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4848/5000\n",
            "\n",
            "Epoch 4848: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8920e-04 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4849/5000\n",
            "\n",
            "Epoch 4849: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.9503e-04 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8273 - 4s/epoch - 107ms/step\n",
            "Epoch 4850/5000\n",
            "\n",
            "Epoch 4850: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9328e-04 - accuracy: 1.0000 - val_loss: 0.6985 - val_accuracy: 0.8273 - 2s/epoch - 69ms/step\n",
            "Epoch 4851/5000\n",
            "\n",
            "Epoch 4851: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9244e-04 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4852/5000\n",
            "\n",
            "Epoch 4852: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9889e-04 - accuracy: 1.0000 - val_loss: 0.6900 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4853/5000\n",
            "\n",
            "Epoch 4853: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8735e-04 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4854/5000\n",
            "\n",
            "Epoch 4854: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.8793e-04 - accuracy: 1.0000 - val_loss: 0.6980 - val_accuracy: 0.8237 - 4s/epoch - 101ms/step\n",
            "Epoch 4855/5000\n",
            "\n",
            "Epoch 4855: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8197e-04 - accuracy: 1.0000 - val_loss: 0.6973 - val_accuracy: 0.8237 - 3s/epoch - 77ms/step\n",
            "Epoch 4856/5000\n",
            "\n",
            "Epoch 4856: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8582e-04 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4857/5000\n",
            "\n",
            "Epoch 4857: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0571e-04 - accuracy: 1.0000 - val_loss: 0.6848 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4858/5000\n",
            "\n",
            "Epoch 4858: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0597e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.8237 - 2s/epoch - 65ms/step\n",
            "Epoch 4859/5000\n",
            "\n",
            "Epoch 4859: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8479e-04 - accuracy: 1.0000 - val_loss: 0.7038 - val_accuracy: 0.8201 - 3s/epoch - 92ms/step\n",
            "Epoch 4860/5000\n",
            "\n",
            "Epoch 4860: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8744e-04 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.8237 - 3s/epoch - 84ms/step\n",
            "Epoch 4861/5000\n",
            "\n",
            "Epoch 4861: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8949e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4862/5000\n",
            "\n",
            "Epoch 4862: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9700e-04 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4863/5000\n",
            "\n",
            "Epoch 4863: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8957e-04 - accuracy: 1.0000 - val_loss: 0.7032 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4864/5000\n",
            "\n",
            "Epoch 4864: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8390e-04 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.8273 - 3s/epoch - 86ms/step\n",
            "Epoch 4865/5000\n",
            "\n",
            "Epoch 4865: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8329e-04 - accuracy: 1.0000 - val_loss: 0.6963 - val_accuracy: 0.8273 - 3s/epoch - 91ms/step\n",
            "Epoch 4866/5000\n",
            "\n",
            "Epoch 4866: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8867e-04 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4867/5000\n",
            "\n",
            "Epoch 4867: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8334e-04 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4868/5000\n",
            "\n",
            "Epoch 4868: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9760e-04 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4869/5000\n",
            "\n",
            "Epoch 4869: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.9202e-04 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8345 - 3s/epoch - 83ms/step\n",
            "Epoch 4870/5000\n",
            "\n",
            "Epoch 4870: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8773e-04 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.8309 - 3s/epoch - 95ms/step\n",
            "Epoch 4871/5000\n",
            "\n",
            "Epoch 4871: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8777e-04 - accuracy: 1.0000 - val_loss: 0.6969 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4872/5000\n",
            "\n",
            "Epoch 4872: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8371e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4873/5000\n",
            "\n",
            "Epoch 4873: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8823e-04 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4874/5000\n",
            "\n",
            "Epoch 4874: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8990e-04 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.8381 - 3s/epoch - 75ms/step\n",
            "Epoch 4875/5000\n",
            "\n",
            "Epoch 4875: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.7970e-04 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.8309 - 4s/epoch - 100ms/step\n",
            "Epoch 4876/5000\n",
            "\n",
            "Epoch 4876: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9893e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4877/5000\n",
            "\n",
            "Epoch 4877: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9572e-04 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4878/5000\n",
            "\n",
            "Epoch 4878: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9223e-04 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4879/5000\n",
            "\n",
            "Epoch 4879: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9209e-04 - accuracy: 1.0000 - val_loss: 0.6864 - val_accuracy: 0.8309 - 2s/epoch - 71ms/step\n",
            "Epoch 4880/5000\n",
            "\n",
            "Epoch 4880: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.0812e-04 - accuracy: 1.0000 - val_loss: 0.6987 - val_accuracy: 0.8273 - 4s/epoch - 107ms/step\n",
            "Epoch 4881/5000\n",
            "\n",
            "Epoch 4881: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8987e-04 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4882/5000\n",
            "\n",
            "Epoch 4882: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9371e-04 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4883/5000\n",
            "\n",
            "Epoch 4883: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7855e-04 - accuracy: 1.0000 - val_loss: 0.6927 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4884/5000\n",
            "\n",
            "Epoch 4884: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9119e-04 - accuracy: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.8381 - 2s/epoch - 68ms/step\n",
            "Epoch 4885/5000\n",
            "\n",
            "Epoch 4885: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.8290e-04 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.8345 - 4s/epoch - 110ms/step\n",
            "Epoch 4886/5000\n",
            "\n",
            "Epoch 4886: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8017e-04 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4887/5000\n",
            "\n",
            "Epoch 4887: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8147e-04 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4888/5000\n",
            "\n",
            "Epoch 4888: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8381e-04 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4889/5000\n",
            "\n",
            "Epoch 4889: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9270e-04 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4890/5000\n",
            "\n",
            "Epoch 4890: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.8306e-04 - accuracy: 1.0000 - val_loss: 0.6979 - val_accuracy: 0.8309 - 4s/epoch - 108ms/step\n",
            "Epoch 4891/5000\n",
            "\n",
            "Epoch 4891: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7837e-04 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.8237 - 2s/epoch - 68ms/step\n",
            "Epoch 4892/5000\n",
            "\n",
            "Epoch 4892: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8272e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4893/5000\n",
            "\n",
            "Epoch 4893: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7838e-04 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4894/5000\n",
            "\n",
            "Epoch 4894: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7191e-04 - accuracy: 1.0000 - val_loss: 0.6954 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4895/5000\n",
            "\n",
            "Epoch 4895: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.7804e-04 - accuracy: 1.0000 - val_loss: 0.6940 - val_accuracy: 0.8237 - 4s/epoch - 103ms/step\n",
            "Epoch 4896/5000\n",
            "\n",
            "Epoch 4896: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8678e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8273 - 3s/epoch - 74ms/step\n",
            "Epoch 4897/5000\n",
            "\n",
            "Epoch 4897: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8591e-04 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4898/5000\n",
            "\n",
            "Epoch 4898: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7760e-04 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4899/5000\n",
            "\n",
            "Epoch 4899: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9443e-04 - accuracy: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.8417 - 2s/epoch - 66ms/step\n",
            "Epoch 4900/5000\n",
            "\n",
            "Epoch 4900: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 4.8837e-04 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.8273 - 3s/epoch - 99ms/step\n",
            "Epoch 4901/5000\n",
            "\n",
            "Epoch 4901: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 3.4952e-04 - accuracy: 1.0000 - val_loss: 0.6982 - val_accuracy: 0.8345 - 3s/epoch - 78ms/step\n",
            "Epoch 4902/5000\n",
            "\n",
            "Epoch 4902: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.5419e-04 - accuracy: 1.0000 - val_loss: 0.7451 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4903/5000\n",
            "\n",
            "Epoch 4903: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8989e-04 - accuracy: 1.0000 - val_loss: 0.7305 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4904/5000\n",
            "\n",
            "Epoch 4904: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9592e-04 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4905/5000\n",
            "\n",
            "Epoch 4905: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.9273e-04 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.8273 - 3s/epoch - 89ms/step\n",
            "Epoch 4906/5000\n",
            "\n",
            "Epoch 4906: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8162e-04 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.8273 - 3s/epoch - 87ms/step\n",
            "Epoch 4907/5000\n",
            "\n",
            "Epoch 4907: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8770e-04 - accuracy: 1.0000 - val_loss: 0.7263 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4908/5000\n",
            "\n",
            "Epoch 4908: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9392e-04 - accuracy: 1.0000 - val_loss: 0.7225 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4909/5000\n",
            "\n",
            "Epoch 4909: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8993e-04 - accuracy: 1.0000 - val_loss: 0.7223 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4910/5000\n",
            "\n",
            "Epoch 4910: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.9479e-04 - accuracy: 1.0000 - val_loss: 0.7191 - val_accuracy: 0.8273 - 3s/epoch - 80ms/step\n",
            "Epoch 4911/5000\n",
            "\n",
            "Epoch 4911: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8275e-04 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8273 - 3s/epoch - 96ms/step\n",
            "Epoch 4912/5000\n",
            "\n",
            "Epoch 4912: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8221e-04 - accuracy: 1.0000 - val_loss: 0.7113 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4913/5000\n",
            "\n",
            "Epoch 4913: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8319e-04 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4914/5000\n",
            "\n",
            "Epoch 4914: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8902e-04 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4915/5000\n",
            "\n",
            "Epoch 4915: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8200e-04 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.8237 - 3s/epoch - 74ms/step\n",
            "Epoch 4916/5000\n",
            "\n",
            "Epoch 4916: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 3.0194e-04 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.8273 - 4s/epoch - 105ms/step\n",
            "Epoch 4917/5000\n",
            "\n",
            "Epoch 4917: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.9360e-04 - accuracy: 1.0000 - val_loss: 0.7060 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4918/5000\n",
            "\n",
            "Epoch 4918: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8626e-04 - accuracy: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4919/5000\n",
            "\n",
            "Epoch 4919: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7975e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4920/5000\n",
            "\n",
            "Epoch 4920: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8056e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8345 - 2s/epoch - 67ms/step\n",
            "Epoch 4921/5000\n",
            "\n",
            "Epoch 4921: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.8542e-04 - accuracy: 1.0000 - val_loss: 0.7002 - val_accuracy: 0.8309 - 4s/epoch - 110ms/step\n",
            "Epoch 4922/5000\n",
            "\n",
            "Epoch 4922: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8131e-04 - accuracy: 1.0000 - val_loss: 0.7059 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4923/5000\n",
            "\n",
            "Epoch 4923: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8426e-04 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4924/5000\n",
            "\n",
            "Epoch 4924: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8314e-04 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4925/5000\n",
            "\n",
            "Epoch 4925: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8561e-04 - accuracy: 1.0000 - val_loss: 0.6995 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4926/5000\n",
            "\n",
            "Epoch 4926: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.7330e-04 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.8273 - 4s/epoch - 109ms/step\n",
            "Epoch 4927/5000\n",
            "\n",
            "Epoch 4927: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7944e-04 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8309 - 2s/epoch - 68ms/step\n",
            "Epoch 4928/5000\n",
            "\n",
            "Epoch 4928: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8375e-04 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4929/5000\n",
            "\n",
            "Epoch 4929: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8202e-04 - accuracy: 1.0000 - val_loss: 0.6746 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4930/5000\n",
            "\n",
            "Epoch 4930: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8928e-04 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4931/5000\n",
            "\n",
            "Epoch 4931: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.8113e-04 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8345 - 4s/epoch - 102ms/step\n",
            "Epoch 4932/5000\n",
            "\n",
            "Epoch 4932: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8601e-04 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8381 - 3s/epoch - 76ms/step\n",
            "Epoch 4933/5000\n",
            "\n",
            "Epoch 4933: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7310e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8381 - 2s/epoch - 67ms/step\n",
            "Epoch 4934/5000\n",
            "\n",
            "Epoch 4934: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8050e-04 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4935/5000\n",
            "\n",
            "Epoch 4935: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7569e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4936/5000\n",
            "\n",
            "Epoch 4936: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.7127e-04 - accuracy: 1.0000 - val_loss: 0.6982 - val_accuracy: 0.8273 - 3s/epoch - 94ms/step\n",
            "Epoch 4937/5000\n",
            "\n",
            "Epoch 4937: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.7065e-04 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8345 - 3s/epoch - 83ms/step\n",
            "Epoch 4938/5000\n",
            "\n",
            "Epoch 4938: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7667e-04 - accuracy: 1.0000 - val_loss: 0.7086 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4939/5000\n",
            "\n",
            "Epoch 4939: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7519e-04 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4940/5000\n",
            "\n",
            "Epoch 4940: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6827e-04 - accuracy: 1.0000 - val_loss: 0.7065 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4941/5000\n",
            "\n",
            "Epoch 4941: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8607e-04 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.8345 - 3s/epoch - 83ms/step\n",
            "Epoch 4942/5000\n",
            "\n",
            "Epoch 4942: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8327e-04 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.8345 - 3s/epoch - 92ms/step\n",
            "Epoch 4943/5000\n",
            "\n",
            "Epoch 4943: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7827e-04 - accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4944/5000\n",
            "\n",
            "Epoch 4944: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7535e-04 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4945/5000\n",
            "\n",
            "Epoch 4945: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7849e-04 - accuracy: 1.0000 - val_loss: 0.6954 - val_accuracy: 0.8273 - 2s/epoch - 67ms/step\n",
            "Epoch 4946/5000\n",
            "\n",
            "Epoch 4946: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.7928e-04 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8345 - 3s/epoch - 74ms/step\n",
            "Epoch 4947/5000\n",
            "\n",
            "Epoch 4947: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.7456e-04 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.8345 - 4s/epoch - 101ms/step\n",
            "Epoch 4948/5000\n",
            "\n",
            "Epoch 4948: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7806e-04 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4949/5000\n",
            "\n",
            "Epoch 4949: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6787e-04 - accuracy: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.8309 - 2s/epoch - 65ms/step\n",
            "Epoch 4950/5000\n",
            "\n",
            "Epoch 4950: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7543e-04 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4951/5000\n",
            "\n",
            "Epoch 4951: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6745e-04 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4952/5000\n",
            "\n",
            "Epoch 4952: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.6294e-04 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8345 - 4s/epoch - 110ms/step\n",
            "Epoch 4953/5000\n",
            "\n",
            "Epoch 4953: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7065e-04 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4954/5000\n",
            "\n",
            "Epoch 4954: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7974e-04 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4955/5000\n",
            "\n",
            "Epoch 4955: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6708e-04 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4956/5000\n",
            "\n",
            "Epoch 4956: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7409e-04 - accuracy: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4957/5000\n",
            "\n",
            "Epoch 4957: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.7496e-04 - accuracy: 1.0000 - val_loss: 0.6747 - val_accuracy: 0.8453 - 4s/epoch - 109ms/step\n",
            "Epoch 4958/5000\n",
            "\n",
            "Epoch 4958: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8736e-04 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.8309 - 2s/epoch - 67ms/step\n",
            "Epoch 4959/5000\n",
            "\n",
            "Epoch 4959: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 3.0524e-04 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4960/5000\n",
            "\n",
            "Epoch 4960: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8002e-04 - accuracy: 1.0000 - val_loss: 0.7048 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4961/5000\n",
            "\n",
            "Epoch 4961: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7770e-04 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4962/5000\n",
            "\n",
            "Epoch 4962: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.6520e-04 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.8273 - 4s/epoch - 102ms/step\n",
            "Epoch 4963/5000\n",
            "\n",
            "Epoch 4963: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.6549e-04 - accuracy: 1.0000 - val_loss: 0.7119 - val_accuracy: 0.8165 - 3s/epoch - 75ms/step\n",
            "Epoch 4964/5000\n",
            "\n",
            "Epoch 4964: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6888e-04 - accuracy: 1.0000 - val_loss: 0.7065 - val_accuracy: 0.8201 - 2s/epoch - 65ms/step\n",
            "Epoch 4965/5000\n",
            "\n",
            "Epoch 4965: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6100e-04 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4966/5000\n",
            "\n",
            "Epoch 4966: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6938e-04 - accuracy: 1.0000 - val_loss: 0.6963 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4967/5000\n",
            "\n",
            "Epoch 4967: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.7853e-04 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.8309 - 3s/epoch - 93ms/step\n",
            "Epoch 4968/5000\n",
            "\n",
            "Epoch 4968: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.7232e-04 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.8273 - 3s/epoch - 83ms/step\n",
            "Epoch 4969/5000\n",
            "\n",
            "Epoch 4969: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6407e-04 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4970/5000\n",
            "\n",
            "Epoch 4970: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6452e-04 - accuracy: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.8345 - 2s/epoch - 65ms/step\n",
            "Epoch 4971/5000\n",
            "\n",
            "Epoch 4971: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6744e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4972/5000\n",
            "\n",
            "Epoch 4972: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.8925e-04 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 0.8237 - 3s/epoch - 84ms/step\n",
            "Epoch 4973/5000\n",
            "\n",
            "Epoch 4973: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.7931e-04 - accuracy: 1.0000 - val_loss: 0.7328 - val_accuracy: 0.8094 - 3s/epoch - 92ms/step\n",
            "Epoch 4974/5000\n",
            "\n",
            "Epoch 4974: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7624e-04 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4975/5000\n",
            "\n",
            "Epoch 4975: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7287e-04 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4976/5000\n",
            "\n",
            "Epoch 4976: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7776e-04 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4977/5000\n",
            "\n",
            "Epoch 4977: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.7019e-04 - accuracy: 1.0000 - val_loss: 0.6875 - val_accuracy: 0.8345 - 3s/epoch - 78ms/step\n",
            "Epoch 4978/5000\n",
            "\n",
            "Epoch 4978: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.7969e-04 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8273 - 3s/epoch - 99ms/step\n",
            "Epoch 4979/5000\n",
            "\n",
            "Epoch 4979: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6426e-04 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4980/5000\n",
            "\n",
            "Epoch 4980: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6713e-04 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.8201 - 2s/epoch - 66ms/step\n",
            "Epoch 4981/5000\n",
            "\n",
            "Epoch 4981: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8363e-04 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4982/5000\n",
            "\n",
            "Epoch 4982: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.8454e-04 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8309 - 2s/epoch - 71ms/step\n",
            "Epoch 4983/5000\n",
            "\n",
            "Epoch 4983: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.7233e-04 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.8309 - 4s/epoch - 106ms/step\n",
            "Epoch 4984/5000\n",
            "\n",
            "Epoch 4984: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6971e-04 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4985/5000\n",
            "\n",
            "Epoch 4985: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7428e-04 - accuracy: 1.0000 - val_loss: 0.7066 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4986/5000\n",
            "\n",
            "Epoch 4986: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6795e-04 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4987/5000\n",
            "\n",
            "Epoch 4987: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7907e-04 - accuracy: 1.0000 - val_loss: 0.7093 - val_accuracy: 0.8309 - 2s/epoch - 66ms/step\n",
            "Epoch 4988/5000\n",
            "\n",
            "Epoch 4988: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.6756e-04 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.8381 - 4s/epoch - 109ms/step\n",
            "Epoch 4989/5000\n",
            "\n",
            "Epoch 4989: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7754e-04 - accuracy: 1.0000 - val_loss: 0.7048 - val_accuracy: 0.8381 - 2s/epoch - 66ms/step\n",
            "Epoch 4990/5000\n",
            "\n",
            "Epoch 4990: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6614e-04 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4991/5000\n",
            "\n",
            "Epoch 4991: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7428e-04 - accuracy: 1.0000 - val_loss: 0.7476 - val_accuracy: 0.8165 - 2s/epoch - 66ms/step\n",
            "Epoch 4992/5000\n",
            "\n",
            "Epoch 4992: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.7476e-04 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8345 - 2s/epoch - 68ms/step\n",
            "Epoch 4993/5000\n",
            "\n",
            "Epoch 4993: val_accuracy did not improve from 0.85971\n",
            "35/35 - 4s - loss: 2.6646e-04 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.8381 - 4s/epoch - 106ms/step\n",
            "Epoch 4994/5000\n",
            "\n",
            "Epoch 4994: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6196e-04 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8345 - 2s/epoch - 70ms/step\n",
            "Epoch 4995/5000\n",
            "\n",
            "Epoch 4995: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6069e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n",
            "Epoch 4996/5000\n",
            "\n",
            "Epoch 4996: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6186e-04 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.8273 - 2s/epoch - 66ms/step\n",
            "Epoch 4997/5000\n",
            "\n",
            "Epoch 4997: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.6353e-04 - accuracy: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.8345 - 2s/epoch - 66ms/step\n",
            "Epoch 4998/5000\n",
            "\n",
            "Epoch 4998: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.5811e-04 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.8309 - 3s/epoch - 96ms/step\n",
            "Epoch 4999/5000\n",
            "\n",
            "Epoch 4999: val_accuracy did not improve from 0.85971\n",
            "35/35 - 3s - loss: 2.6106e-04 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8237 - 3s/epoch - 78ms/step\n",
            "Epoch 5000/5000\n",
            "\n",
            "Epoch 5000: val_accuracy did not improve from 0.85971\n",
            "35/35 - 2s - loss: 2.5330e-04 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.8237 - 2s/epoch - 66ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "modelp = keras.models.load_model(\"pccr_mi_mean.best.hdf5\")\n",
        "y_pred = modelp.predict(X_test)\n",
        "y_pred=np.argmax(y_pred,axis=1)\n",
        "print(\"Test Accuracy\",accuracy_score(y_test, y_pred)*100,\"%\")\n",
        "\n",
        "scores = modelp.evaluate(X_train, y_train)\n",
        "print(\"Train %s: %.2f%%\" % (modelp.metrics_names[1], scores[1]*100))\n",
        "\n",
        "scores = modelp.evaluate(X_test, y_test)\n",
        "print(\"test %s: %.2f%%\" % (modelp.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdAsToV1EFaS",
        "outputId": "b45811f7-7fe6-4b4d-8c3a-7a49cd1e4cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 29ms/step\n",
            "Test Accuracy 85.97122302158273 %\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 0.0344 - accuracy: 1.0000\n",
            "Train accuracy: 100.00%\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.6219 - accuracy: 0.8597\n",
            "test accuracy: 85.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "srt=\"pccr_mi_mean Model\"\n",
        "plot_accuracy(history7, no_of_epoch,srt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "ODP4tczOEJ9e",
        "outputId": "d5e11b0b-34f9-45b6-c5d8-c0db139d2136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x504 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7AAAAG5CAYAAAC3LdgjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABowUlEQVR4nO3dd5wU9f3H8ffnOr2DVLEhFhQUsSv2rrGLxh5b1NgSNcaC0Z8xxhh77CX2bjBq7MZeECsgiohSpApHPa7s9/fHd5ad3du724Pdm9v19Xw84HZnZmc+Ozs7O5/5NnPOCQAAAACA1q4o6gAAAAAAAMgECSwAAAAAIC+QwAIAAAAA8gIJLAAAAAAgL5DAAgAAAADyAgksAAAAACAvkMACQCthZgPNzJlZSQbLHmdm77REXIXIzJaY2do5WK+Z2b1mtsDMPsr2+tEwM7vNzC6JOo7WpDnnCTO7z8yuzHVMALC6SGABYBWY2VQzqzaz7inTPw2S0IERhYYMOOfaO+em5GDV20naTVI/59yI1VkRNymaxzl3qnPuiqjjWBWhm1efpkzvHpxnpkYUGgC0OiSwALDqvpc0Kv7EzIZIahtdOK1DJiXIBWxNSVOdc0ujDiQfPod8iLGFtTWzjUPPj5Q/zwAAAiSwALDqHpB0TOj5sZL+FV7AzDqZ2b/MbK6Z/WBmF5tZUTCv2MyuNbN5ZjZF0j5pXnu3mf1kZjPM7EozK84kMDN7wsxmmVmlmb1lZhuF5rUxs78H8VSa2Ttm1iaYt52ZvWdmC81smpkdF0x/08x+E1pHUulgUHp0upl9K+nbYNoNwToWmdknZrZ9aPliM7vIzL4zs8XB/P5mdouZ/T3lvYwxs3PSvMd6Va7DcZrZumb2v+A9zjOzx1LiXTd4fF+w3eeDWD40s3VCy+5uZpOC9dwarPM3SmFmJ0q6S9LWQRXly4Pp+5rZZ8E+fc/MNgm95sLQPphgZgcG0zeQdFtoXQtX43NocPtNCdb3OzObEuzDv8WP32D+SWY2MRT/ZsH0/mb2dHDczzezm0Pxvmtm/zCz+ZJGN7Lt8LILgxi2CaZPM7M5ZnZsaPkmq8Ca2Ugzm25m5wev/8nMfmVme5vZN2b2s5ldFFq+KPQZzTezx82sa2h+Y9+zRo+rBjwgfx6JO0b1zykbBMfBQjMbb2b7h+Z1C74vi8xXYV8n5bWDzeyV4H1OMrPDmogHAFodElgAWHUfSOoYXFAWSzpC0oMpy9wkqZOktSXtKH9Benww7yRJ+0oaJmm4pENSXnufpFpJ6wbL7C6pXuLUgBclrSepp6Rxkh4KzbtW0uaStpHUVdL5kmJmtmbwupsk9ZA0VNJnGW5Pkn4laUtJGwbPPw7W0VXSw5KeMLOKYN658qXXe0vqKOkEScsk3S9plCWS/O6Sdg1e31xXSHpZUhdJ/YL31ZAjJF0eLDtZ0v+Ftv+kpD9K6iZpkvx+q8c5d7ekUyW9H1RRvszMhkm6R9IpwetvlzTGzMqDl30naXv5Y+RySQ+aWW/n3MSUdXVuxvv+lYLPoantBwn5rU2s70D543MzSQfIf1Yys0PlE9Bj5D/D/SXND74L/5H0g6SBkvpKejS0vi0lTZHUS8F+bsSWkr4IYn84WM8W8t+JX0u62czaN7GOVGtIqgjiulTSncG6Npf/LC4xs7WCZc+U3587SuojaYGkW0Lraux7JjVwXDXiQUlHmL/Bs6Gk9pI+jM80s1JJz8kf1z2D+B4ys/WDRW6RVCWpt/zndELote0kvSK/H3sGsd0abAcA8gYJLACsnngp7G6SJkqaEZ8RSmr/6Jxb7JybKunvko4OFjlM0vXOuWnOuZ8l/SX02l7yyd3Zzrmlzrk5kv4RrK9Jzrl7gm2ukE8yNjVfolskf1F7lnNuhnOuzjn3XrDckZJedc494pyrcc7Nd8591ox98Rfn3M/OueVBDA8G66h1zv1dUrmk+IX2byRd7Jyb5LzPg2U/klQpaZdguSMkvemcm92MOOJq5Kv09nHOVTnnGmtP+oxz7iPnXK18EjI0mL63pPHOuaeDeTdKmtWMGE6WdLtz7sNgX98vaYWkrSTJOfeEc26mcy7mnHtMvtR0tdrOKvlzaGr7v3XO/baJ9f01WN+Pkq5Xotr8byRd45z7OPgMJzvnfgji7yPpD8Gxm7rvZzrnbgqOi+VNbPt759y9zrk6SY9J6i/pz865Fc65lyVVyyezzVEj6f+cczXyCXF3STcE35fxkiZI2jRY9lRJf3LOTQ99lw6xoNS/oe9ZaFsNHVcNmS5/k2RX+fPKAynzt5JPaq92zlU7516Xv1kwKjjfHCzp0mC/fyV/QyhuX/nq7fcG+/5TSU9JOrTJPQYArQgJLACsngfkE7/jlFLVT/7CuFS+JCruB/mSH8lf5E9LmRe3ZvDan4KqggvlS896NhVQUHpzdVDtcZGkqaF4usuXPn2X5qX9G5ieqfB7kZn9PqheWhnE3ynYflPbul++REzB39SL+EydL8kkfRRUtTyhkWXDSeky+SRBSvmMnHNOPsnI1JqSzot/hsF+6B+sV2Z2TKh670JJGyuxj1ZV+HNodPursL4fQq9t6DPsL+mHIGlran1NCd+4iN8YSZ3W3BLY+UFCvHKdabYTX+eakp4J7buJkuok9WriexbX0HHVmH/Jn09Gqf6x30fSNOdcLDQtfk7pIalEjZ9Ttkw5Fo6SL5EGgLxBAgsAqyEocfpevqTu6ZTZ85QoBYwboEQp7U/yF/vheXHT5EvKujvnOgf/OjrnNlLTjpSv6rmrfNI4MJhuQUxVSmkbF9pmQ230liq5g6p0F70u/sB8e9fz5UuZuwRVYCuDGJra1oOSDjCzTSVtIOnZRmJSQ3E552Y5505yzvWRr0J7qwXtXpvhJ/nqx5L8MDnh5xmYJl/a1zn0r61z7pGgyvadks6Q1C3YR18psY9cmvU163NobPvNeA+px+jM0LobOo4GWMMdNKV7X63VNEl7pey/CufcDDX+PVsdT8m3h58SlHqHzZTU30LtkJU4p8yVb3LQ2Dnlfynvpb1z7rTVjBcAWhQJLACsvhMl7exSep4NSnkel/R/ZtYhSFjOVaKd7OOSfmdm/cysi6QLQ6/9Sb6d29/NrGPQmcw6ZrZjBvF0kE9+58snO1eF1huTbxN5nZn1CUqRtg7aRD4kaVczO8zMSoIOYYYGL/1M0kFm1jZIAk/MIIZa+YvqEjO7VL6dZNxdkq4ws/XM28TMugUxTpdvP/uApKcaqmbqnJsrf+H+6+B9nKBQQmVmh5pZPNlcIJ84xeqvqVHPSxpivqOfEkmnq3klVndKOtXMtgzeZzsz28fMOkhqF8Q0N4j3ePkS2LjZkvqZWVlo2mdq3ufQ2PYz9Qcz62Jm/SWdJV+VV/Kf4e/NbPNg3esGx/hH8on/1cH2Ksxs22ZsrzW5Tf77u6YkmVkPMzsgmNfg92x1BOeRnZW+vfuH8iW555tZqZmNlLSfpEeD883TkkYHx8eGSu4Q6j+SBpnZ0cFrS81sC/MdhgFA3iCBBYDV5Jz7zjk3toHZZ8qXmk2R9I58Byr3BPPulPSSpM/lO4BJLcE9RlKZfJu8BfKdCfXOIKR/yVcdnBG89oOU+b+X9KV8kvizpL9KKgpKe/aWdF4w/TMl2gL+Q7694Wz5Kr6pndWkeknSfyV9E8RSpeSqjdfJJ/AvS1ok6W5JbULz75c0RE1XHz5J0h/kk4iNJL0XmreFpA/NbImkMfLtfps19qtzbp58G8Frgm1sKGmsfOKSyevHBjHeLP8ZTpavHirn3AT5NtHvy+/XIZLeDb38dUnjJc0ys3nBtGZ9Do1tX5LM7DYzu62Jt/FvSZ/IHw/Py39Wcs49Id8p0cOSFsuXlHcNEqn95Num/ihf5frwJrbRWt0gf+y8bGaL5b9LWwbzmvqerTLn3FjnXL3q2c65avl9u5d8bYpbJR3jnPs6WOQM+WrKs+Q7gbs39NrF8h3BHSFfkjtL/rsf71AMAPKC+eY8AAC0Hma2g3xJ9ZquFf1QBVU3p0s6yjn3RtTx5JqZOUnrOecmRx0LAAASJbAAgFbG/FAhZ0m6qzUkr2a2h5l1DqpZXyTfxjFrpW0AACBzJLAAgFYjaI+3UL6q9PWRBpOwtXxvu/Pkq2/+KoPhX5CBoArzkjT/mqrW3Ng6L2pgnS9mM3YAQDSoQgwAAAAAyAuUwAIAAAAA8kJDY7S1Wt27d3cDBw6MOgwAAAAAQA588skn85xzPdLNy7sEduDAgRo7tqHRKgAAAAAA+czMfmhoHlWIAQAAAAB5gQQWAAAAAJAXSGABAAAAAHkh79rAplNTU6Pp06erqqoq6lByrqKiQv369VNpaWnUoQAAAABAiyqIBHb69Onq0KGDBg4cKDOLOpyccc5p/vz5mj59utZaa62owwEAAACAFlUQVYirqqrUrVu3gk5eJcnM1K1bt19ESTMAAAAApCqIBFZSwSevcb+U9wkAAAAAqQomgQUAAAAAFDYS2CyYP3++hg4dqqFDh2qNNdZQ3759Vz6vrq5u9LVjx47V7373uxaKFAAAAADyV0F04hS1bt266bPPPpMkjR49Wu3bt9fvf//7lfNra2tVUpJ+Vw8fPlzDhw9viTABAAAAIK9RApsjxx13nE499VRtueWWOv/88/XRRx9p66231rBhw7TNNtto0qRJkqQ333xT++67rySf/J5wwgkaOXKk1l57bd14441RvgUAAAAAaFUKrgT28ufGa8LMRVld54Z9Ouqy/TZq9uumT5+u9957T8XFxVq0aJHefvttlZSU6NVXX9VFF12kp556qt5rvv76a73xxhtavHix1l9/fZ122mmM+QoAAAAAymECa2b3SNpX0hzn3MZp5pukGyTtLWmZpOOcc+NyFU8UDj30UBUXF0uSKisrdeyxx+rbb7+Vmammpibta/bZZx+Vl5ervLxcPXv21OzZs9WvX7+WDBsAAAAAWqVclsDeJ+lmSf9qYP5ektYL/m0p6Z/B39WyKiWludKuXbuVjy+55BLttNNOeuaZZzR16lSNHDky7WvKy8tXPi4uLlZtbW2uwwQAAACAvJCzBNY595aZDWxkkQMk/cs55yR9YGadzay3c+6nXMUUpcrKSvXt21eSdN9990UbTAFYVFWjtqXFKilO34y7ti6mpdV16tSmVNW1MVXXxdS+vES1dTEtq6lTxwpfLXvekhVauqJWvTpWaOmKWi2rrlNxkaljm1IVmfTz0mpV18bUu1Mb/bysWlU1dWpXVqL2FSWasWC5SopNa3dvp5mVVYrFnCqX16h9eYmKi/x4vXOXrFBFSbFq6mIqLjJ1a1+m+UuqVVJsWrqiVqXFRSouMlXXxrRGpwotr65TVY2Pt6YupnZlJepQUaL5S31v1iapuMhUG3OqqYupbVmxnJPKSoq0oiam2lhMXdqWqaTYtHBZopS/qqZOHSpKtbS6VnUxpzalxVpRG5NzTm3LSrSsulZFRaYiM7Up9bUGltfUSZLKS4pUXRtTRTC9qqZOFaXFWlFbp5KiItXUxWQmxZxUUVqkqpqY2pQWq7o2ptISk8lWrsvkY62tc0nz4tuMi0+ri7mV+zK8XE1dTJJUmvL5L6+pU0VpkUymFbV1Ki/xy8djNfOvjTklbbOh9cU5uSD+5HGY4+8rvs2wupiTk1Ms5t9zpqprYyoqkkqKilaup6io/rbTWV5Tp5IiU8y5le892+LvOfUza0pz3scvQcw5FeVgXG8nt/I7mC/C33O0vKbOf42piznVxmJZP99wTLR+uTqH5RMnJ+eUt/thvZ7tVZSn37Mo28D2lTQt9Hx6MK0gE9jzzz9fxx57rK688krts88+UYfTavj7F5KFvvz3vfu9zEzHbL2mzExzFlfplQmz9emPC/XkJ9P19vk7aftr3tB6Pdvr7mO3UK9O5dr7hre1Qe+O2m3DXnr96zn692cz622rR4dyDejaVp/8sKDF3h8AAADQ2kz48x5qW5af3SFZPIHIycp9Cex/GmgD+x9JVzvn3gmevybpAufc2DTLnizpZEkaMGDA5j/88EPS/IkTJ2qDDTbI/htopfL1/R5370f6Ynqlxl2y28ppt7wxWX97aZKuP3yotluvu/7z+UyNfm5ChFG2PiPW6qrq2pg+m7YwadpH3/+ctFy/Lm1kJk37ebkkqX15iZasSFRBP2Tzfnryk+mNbmvbdbvpsOH9tWBptZ79bKY+m7ZQI9bqqgFd22rnwT01Z1GVRj83QUduOUC1dTF1b1+uRz+epg4VJRrav7PalpWocnm1dt2gl859/HNt0LujTth2oB7+6EeVFhVpjU4V6teljW598zsN6dtJR2+1pt78Zo62XruburX31eeXVdfp9a9na/M1u+qj7+drre7tNahXe702cY42W7OLeneq0NipC1Qbi2mrtbutjL0u5vTS+FnaoHdH/by0Wne/871+t/O6Gty7o976Zq46ty1TcZH08fcL1LNjufbYaI2Vd/jj+3LEWl3T7pdb3pis8TMX6R+Hb7qypOHnpdV6d/I8VdfGNKRfJw3q1WHl8lPmLtHn0yvVvX25zKTt1u3e6H4Pe/vbeepYUaJN+3eWJL341Sx1a1fWYGxxMxcu1+tfz9E3s5do3Z7tdMzWAzPeZqZmLlyuNybNUUVJsXbZoJc6t828g7lM38cvwf3vTdWH3/+s6w8f2qzS+UxMnrNE381dot03XEP5UCjwU2WVPpgyX9us0029OlZEHc4vUlPnv8Z8Mb1Slcurtf16PbIWz9c/LdLXsxZrz43XWFnzB63LT5VVuuI/EzRqRP+sfvb55qoXJmrJilpddeCQqENZJbtv2KvBmoytgZl94pxLO9ZolAns7ZLedM49EjyfJGlkU1WIhw8f7saOTc5x8zWhW1Wt/f3W1sV0+1tTdMzWa6pDRalmLlyuPp3baOCFz0uS3j5/J02Zt1RnPfppUjXXKN1x9ObauG8n9e5Uoa9mLNKCZdWat2SFZixYrr2GrKEDb31PN40apvEzF+norddU29JiFZnp3vem6vt5SzRyUE9ttU43lRX7aqovj5+tXTfsKeek8574XOfsup7W7dlBK2rrVFZcpJo6p9Jif3VpZnp38jxt1KejOrctUyzm0lbpqK2L6dWJc7THRr2SSqwlX+00fiEcLtV2ztVbFs3nnFNNnct6soFfLr6bAPIZ5zCP/ZA7rTWB3UfSGfK9EG8p6Ubn3Iim1kkC23rfb13MKeacnv/iJ5392GdJ83p2KNecxStWa/3brdtdX82srJf0Fpn04UW76rpXJqlruzKtv0ZHbb5mF81ZVKWqmpjW7dle381donE/LtAGvTtq+3W7q6o2pqfHTdeItbqqX5e2al+en1UoAAAAgELTWAKby2F0HpE0UlJ3M5su6TJJpZLknLtN0gvyyetk+WF0js9VLMi9WMzp+Ps+1lvfzFXfzm3qzW9u8loUdAokSR9dtIt6hqqWLa6q0fLqOn07Z4l+Xlqt/TbtI0n6y0GbJK0jHEePDuVJ1U3bFxflpIolAAAAgNzJZS/Eo5qY7ySdnqvtI7fuffd7bbV2N/XsUK5vZi/RJf/+SpPnLJEkzVi4POP1nLLj2rr9f1NWPr/v+C103L0fa+fBvfSnfTZQeUlRUvIqSR0qStWhorTedAAAAACFjXqTaLZl1bW6fBU7Wtpq7a76YMrP+tcJI7Ttut1VXGQ6b7f15eS7Yy8tLtJtv95cW6/TTZ3aZN5BDAAAAIDCRwKLZhv251ea/ZqxF++q7kEvs6lSO8bZc+M1VikuAAAAAIWNLjWzYKeddtJLL72UNO3666/Xaaedlnb5kSNHKrUjqnyyojaW0XLd2pXp2K3X1CeNJK8AAAAAkClKYLNg1KhRevTRR7XHHnusnPboo4/qmmuuiTCq1fPWN3NVXGRaVl2nJStqdOCwftrtuv9pQNe2aZc/cssBK8fBoktxAAAAALlAApsFhxxyiC6++GJVV1errKxMU6dO1cyZM/XII4/o3HPP1fLly3XIIYfo8ssvjzrUjB1zz0dJz8957HNJ0rdBR02pwukqySsAAACAXCi8BPbFC6VZX2Z3nWsMkfa6usHZXbt21YgRI/Tiiy/qgAMO0KOPPqrDDjtMF110kbp27aq6ujrtsssu+uKLL7TJJps0uJ7WoKqmTp/+uDCjZctKitS9XZlmVlapuIikFQAAAEBu0QY2S+LViCVffXjUqFF6/PHHtdlmm2nYsGEaP368JkxYtZ57W9K1L03SqDs/yGjZgzfrq9fOG6nDh/fXObsOynFkAAAAAH7pCq8EtpGS0lw64IADdM4552jcuHFatmyZunbtqmuvvVYff/yxunTpouOOO05VVVWRxNYcMyszH8P10n03UpuyYv31kNZdqgwAAACgMFACmyXt27fXTjvtpBNOOEGjRo3SokWL1K5dO3Xq1EmzZ8/Wiy++GHWIjfrdI5/qzUlzVFFa3OAyn16ymz66aBd1KC/RfcdvoTZlDS8LAAAAANlWeCWwERo1apQOPPBAPfrooxo8eLCGDRumwYMHq3///tp2222jDi+tgRc+r4OG9dWYz2dqzOczG122S7sySdKXl+/R6HIAAAAAkAsksFn0q1/9Ss65lc/vu+++tMu9+eabLRNQhp7+dEbUIQAAAABAk0hg0aRL9t1Qv95qQNRhAAAAAPiFow3sL1i4tLgxZcWm8hLauwIAAACIVsEksJkmY/kum+/zyxmVaae/ff5OSc/NGOMVAAAAQPQKIoGtqKjQ/PnzCz6Jdc5p/vz5qqioWO11jfl8pva/+d16082k/l3b6pQd1k6aBgAAAABRK4g2sP369dP06dM1d+7cqEPJuYqKCvXr12+VXz/uxwVatqJOv3vk07Tzd16/pyTp/D0Ha4dBPXT8vR9r58E9V3l7AAAAAJAtlm+llsOHD3djx46NOoy8NfDC5xuc169LG71yzo6M7woAAAAgMmb2iXNueLp5BVECi8wsWVHb4LypV+/TgpEAAAAAQPMVRBtYNO7NSXM0dd5SbXzZS2nnP3jili0cEQAAAAA0HyWwvwDH3ftxg/Mu3mcDbbde9xaMBgAAAABWDSWwv3C/2X7tphcCAAAAgFaABLbAzV+yosF53duXt2AkAAAAALB6qEJcoCqX1+jw29/X17MWp53fq2O5LttvoxaOCgAAAABWHQlsgXpp/KwGk9f//WGk1uzWroUjAgAAAIDVQxXiAmUNTN9hUA+SVwAAAAB5iQT2F+aqAzeOOgQAAAAAWCUksAXKLH0ZbL8ubVs4EgAAAADIDhLYAvTj/GX6/ROf15v+9RV7RhANAAAAAGQHCWwBOvORcWmnl5fwcQMAAADIX2Q0BaamLqbPp1emnddQtWIAAAAAyAcksAXmxte+jToEAAAAAMgJxoEtAMur6zRp9mK9O3mevpu7JGne4cP765zdBunnpdURRQcAAAAA2UECWwCOvecjfTT157Tz/nrIJpKkNTpVtGRIAAAAAJB1VCEuAA0lrwAAAABQSEhgAQAAAAB5gQQWAAAAAJAXaANboMZdspvalBZHHQYAAAAAZA0JbAHaZp1u6tquLOowAAAAACCrqEJcgBgyBwAAAEAhIoHNc898Or3etGsP3TSCSAAAAAAgt0hg89iy6lqd89jnSdOuOGAjbdy3U0QRAQAAAEDukMDmqdq6mE5/aFy96UdvPbDlgwEAAACAFkACm6c+mPKz3pg0N2na+3/cOaJoAAAAACD3SGDz1Pfzl9ab1rtTmwgiAQAAAICWQQKbhx77+Edd8uxXK5/37dxGH/9p1wgjAgAAAIDcI4HNQxc89WXS80v23UA9OpRHFA0AAAAAtAwS2AJQF4s6AgAAAADIPRLYArDFWl2iDgEAAAAAcq4k6gDQPD+EOm86ftuBumy/jSKMBgAAAABaDiWweeb0hxNjv+4zpHeEkQAAAABAyyKBzQMLl1Vrl7+/qfEzK/XVjEUrp7evoAAdAAAAwC8HCWwe+N83c/Xd3KW6ODR0jiSVlxRHFBEi9cFt0vhnoo4CAAAAaHEU4eWB0mJ/n+HTHxcmTS8psgiiQeT+e4H/u9GB0cYBAAAAtDBKYPNAcQOJaqe2pS0cCQAAAABEhwQ2D5QW109g1+zWVh0rSGDRiv3wvvTIKClWF3UkAAAAKBAksHmguKj+x9SpDckrWrnHfi1NekFaNl9aPEtaMDXqiIDsWbFYmvVV/enTP5HqaqVFP0kLfmj5uJB9c7+Rlv0cdRTNs/BHadHMqKNAY6Z9JDkXdRRAXiKBzVO1dZz00MrFav3fohLp7+tLN2wabTxANj15onTbtlLtisS0WV9Kd+0svX6FdN1g6YZNoosP2XPLFtJt20UdRfNcP0S6boOoo0BDvn5Buns36ZN7o44EyEsksHkgFqufrG4/qHsEkfzCPHiw9NXTUUfRsDG/k974i/TaFU0vG4tJl3eRRnfyJUctIZ7ANvcO87s3Sk+f3Pgynz4oPXDQqsUVF4tJd4z0FxKZ+vJJ6d69G1/mieOlW7eRHj92tcLTm1dL//3j6q0jF6qXSbfvIP34YWbL//C+3x81yxtf7p1/NP2558ryBdJNm/sENFM/feb/XtnTf69qlkuf3B/M+7zx19ZW+4RoypurEm3T6mql23eUvn01N+v/JVo0o/60ly+RXvpTy8eC3Fo8S7pxM2n+dw0vs2KJdPMWvsZF3LgHfLOZTCz43v/98A7ptu39OUGSpo/1612xJHn5N/8qPXdW5u9hVTx9ij+XPXmCdMdO6c/Z372RHC9ar+9e97/VdTVRR5ITJLB5oKYuVm/aH3ZfP4JIfkFqq6XJr0pPHp/Z8lWLpO/flia/ln5+TZVPhmuq/IX/d683fZGbat63yT+o4+6X/ne19Pa16Zef+Zm0ZI40Z6I0+yvJBcfRtI+k799K/nH64X3/HlbXF49LXzzhY12ZwIbawKar0jbrq8T0GeOkVy6Rvnis8e38+3Tpu9d8Ejr5VX+C/u51/7ixNreLZ/n9Ujld+uopaeanPmlaPNtPT2feZP9v8mvSUydKP7ybiHXxbGnO18lVRcc/Lc0ZL014Nnk9U9+tf1ESNvcb6efv/fuoq5Xe/Iv0wa2N74dVVVvtL0RWxcxP/bH7yqV+P86e0PjyL57v98eciY0v9+po/7kvX7Bqca2O79+S5k/2Nw3iViz234uw+d8lvoNl7ZPn/TxF+vhO/7h6aWL6F0/U396sL3yyPOZ36eOZ+an/7jZk+tjGq7Qume0T7CdP8O8tKotnJZ/naldkJ2l3zifnqd/1hdP8ceac9O0r/vyQiQVT/fevud67UXr/ZmnGJ9LS+Y0vu3SeXy4TC6f571Xq+WzhNGn2+MTzpo4TqeEbiM5JE8b442jxbH/sL5qZOJdmau4kadJ/fZXlfDZhTOLYHP+M9PN30oe3Nbz8jLHSvG+kVy9LTBtzhm82k5Ggb5O5E/35YMks//yVy/x6Z45LXvzNq6RP7stw3U1YMNX/bsV9/bw/jr541D//6im//XgTiQU/JM7fY8708S6e6Y/pic817ya1c03/TrekuZP8/pg93v+eNSR+TpnztT/Xx019t+UKBcKaileS/n2GP/8untUyMbUwhtHJA3VpSmBLirn3kFPVoUTj+7eltbZvfPmnT5K++a9/fPQz0jo7J8//9AHphd9L+90oPRe6aB1dmXlMNw/PfFlJumNHqV1PaWnKBc7s8T5JHPpr6Ve3SFWV0r17SuvsIh29GiXOtdV+P8QVBaeX8A/V9ZtIl85Lft1t20oyafRC6c6dmrfNj+/0CVK3dX0CIkm7Xyltc2b65W8Z4d9vmBX5KoJVlek/j5s3rz/NOR9rhz7+h1zyr23oR3nRT9J9e0sb7C8d/kADsW2ReLz979Mvky2vXe4vvH/zmtSvmcdVPMFs00X6x0b+cSbHsWU47NfDh0snvty8mHLhieP8hdYFP0htOvtpN23m/46ulIpT+iEoLk88nv5R4vHTv5H6byF1GZiYdtcu/m9dA6UYd4yU2veSft9AUnXXLlKPwdLpDZSCx9e7olK6fz/p7K+kzv3TL5tLNw2Xqhcnjo8XL/BVJk97X+q14aqv9/u3pIcOlna8UNopVEvh+o3930Pu9Tcf975WGnFS+nWExZs3NOd8HHbnzlLXtaXffdrwMnft6kvdMtlG/H1I0q6XS9udnTw9vo47Rkptu0nnT1GDvn1ZGrRH/elzv5YeP1oadrT0+SP+huO0D6V+I/yN0WPGSGvv2HSst4xIPF7V/Re1WMzvCyn4bpf5xw19PyWtTEDTqVkulbZpfJup50MrTp6eywQvfLwvnCY9eqQ0eN/6y8V/K+NNIUZXJm6EW5GvIfTl49IZn0jd181s29++LD18WPJxHaXw8Ss1fAx/+aQ/l4eXWzrP/66vv7c06pHcxZjOP7dJxNGQ+DFkhZkvFOa7KiCnPfiJ/vJi4k7Z+Xuur/N2GxRhRKto/LPSP4ZIz/9eevyYhpf7+Xvpyl4N3w2f+Jx07aDkdmeZ+OlzXzXmnesT0/65nb8AuHb9xBf9zauD5f6RWO7+fRNVC5cvkK7qK019J3n94bviDxzo1xH+99nDft6ylORtdCfpxQt98ve3df1+WhXv35J+emryKvnkVZI+e9B/Hh/80z//7rVErPG4U0slP3tEum6j+ndcl86XruyRPC1eAvvRHaFpNf4O5pVrSG9dK90wNJjh/POwqwf4O4zXrO1LsW7aXPo8pWQ2Xq0vnrxKDd9tvHv3+smr5C8YwtNf+pP00GHp1xF3eedgW6ES5XH/qn8ndnQnX4oXL5ELV1GtnCFd0UP66Yv6608tVV8y1++zaR/VXzadmZ9J/9e74X0xd5L/e9cuyd+JjASffbofxW9eSv7+fP+Wv1ufTk2V/2wn/id5+vSx/u/E//jvRE2Vf/7dG375L5+UrlnHf0737yd9fJdPlL562m+7OVXCV0pzMTojKAGpq/HV1V+/Mnl+UUoC21jJcUPVpxf/5M938TvpL14oPXOqf7xktvT3wYnv4o8fJh5LPgFpSOr5ccnshpdtzI8f+u/hqnZgVB36Pnxyf6K932cPNX9dd4yU3rjKv/9/7e+nhW8UvHp54vGyoDT0hd/72K/qmyhNv2Ydv47qZU1v86U/Jf9e/aV/wyWNP08JzlFBKda7N0j37JmYH68y2lzzv/V/r+iZmBY/BiT/Xm/ZUrprN5+Y1CxPnp/unCcljtc5ExPn6u9eT9Qwaap0R5KWL8zoLTTb54/5KryN1VjJ1NR3pL8OrB/ryxdLjx7lzynj7k9Mv3pNX2NJSl/iGa/yG080p77tvyfhJi3375+oWl5b7T+X0Z2kb8I35lLOOTcO88fO1Lf9cxfztaL+upY05X+Zvdd3b/Tb+SBUcjz1ncR5465dk4+NFYully7yj79OOQ9L/iZReHkpUVPr25d98iol33x97ybpHxv736z79vXf2Vu2TOzLxT/5v419H547KxHzLVv538rUa6rUuFbFW3+rP+2d6/0NqVQrUmqoffmk9Ld1/ON0v+Hp1NX6m/hfPe2vg67qm1nNhfv39+/32d/68/HCafWXcS6xX+Lf7XjMk19JLPf9236Z61bjBmIrQQlsK/fiV8kXoL8dmeFdrijNm+x/NJcvkPpu5ksmnz3Nz4tXsaur8SUYS+ZK37zoS7J6b+qr7NRW+R+UPf6v/rpfvjioHve5LyWNl3QuX+gv7tfbTZrwb38HdcBWvipMp37SI0f45V69TNriRH9hPTuUTFQvkSo6+Wqbkq8aFvbujVKHNXxJX/US6b59pIPukoqKfalaZZoTSli8OtBrf64/78N/+jvkS+f60sQ+Q/3Fw5dPSuvtLvVY398hb8xLF0lbn+4fT3mzfoLdkPjnERb/rCRfBeW0YF3LfpaeDS6u66qlkqDE6ZuXfXWqhrxzXfLzTx+Qapf7jm7CUp9XVfofk2XzE3c+X7lU2vTwxDLv3lB/e6Vtgxhr/I9y7Qof77QGSquqFiYeP3iwL3WTpLH3SMNPaPh9pRpzpi8NSXXvnr4kSEq+6/7Nf31cY++W9kvzPuJ+/t5XS65d7ktNO/5F+uh2P2/ax/443+VSfxPms4f8nfQPbpVqlvmkb+gof9Ex9R2p3xZ+u/G76JL/TnQeILXt6kv1OqxRP4YZ4/x3bvKr0oCt/bRJzyfmj3/WVz98/+ZgnaOl7c5JrpKbetNj0Qz/2T52lPTHNBfLL13kvxNT3pDW30v674V++adO9PPj24pXkY1X93/yeOnA26Vu6/hjaOw90s4X+xIy5/z5Yf29/PH70xf+ptgaQ+pvP76PJr/ib+58F2oe8P3b9W9GxZOqdN69Qdr2bH8ueimlXXNtlb8Y7LaePxeExS/2JOme3dOvOxbz541tzpS6rOnPv/GL4Li7dvHbH/+0P0Y3P87/W7md2f6YKu/gS5I/ul3qv2WiKv/Dh/vXHfGQP+dJfl+Of0baYD9/Tpz2UfqSPslXuw7XPHn/Zn9+n/I/X1OjtEL64T1pjU18qd/Mz3wJVo/1/YVe3QpfXXZmSglnuNlD+Dzz4e2JxzM+8fHdu6f/nsU/twXfS702qh/r189La+0olbdPHGNxKxb58/Kmo3wv6/Xe52TpmVP8d+iVS/20hT/6mjBxL18sbR1Uw6yc5s9PW53mv78TnpU2PDB5nZ8+6PdTXcpNiXGhmhzhmxmpvb3HSxMlf+H76QM+2Y4n8Knn7vixk7q96mU+Ydn4YF+Vss+w+k095n/nj2fnpDU2VpMWz/LVZXtv6pPWqkpfU+DZ0/z3b8ls/zmExY+H3pv6c/zLF0trbiOVtZP6bObPY3U1/nu90YH+HLR8gb+ptvAHaf+b/bLv3ZRY53/OTjyuWujPGXGV0/33dskcn9i++Ac/Pbyfnz01uVrp9I/8v0F7+nNYfNmHD5V++6HUc3Dyd1vy7+nF8xPPZ33h38vyn+ufW5Yv8Of+buv4m5ETnvXHUbzZyn8vkLY61d84fXV0KK6Pk9cz60tp4hhlbNJ/Ezelnj8vMd3FfHOFQXv5/bxsvk9Cp76dOJ6eO8uX9sd/Bz65T9r8eF9Ve8MDpfBoG+EbB3MnJl+TNGbcA/46zsw38fjfX6W1d/Lfr4qO/mboty9LGwb7M/WmpJSoEl67wp8LKjr6c/OUlCY38d8hKflm7qKf/I26pXOlNl39cbDt2f7G0MYH+2Mw3DTt+iH+ONnqtz72PkPrx/R9cAMjfuPv5ZR299+/nfz79PixvsZPTfAdf+4sqaKzJOc/Q8n//saP7TxFAtuKuZQLvv+e3UQ11tYiXOWyXQ//RU719nXSyAuk1//sS64kqfv60rygZKihqjul7fzfu3fzfy+ZLxWXSE8c6xO3Q+7xJ1JJ6ti3fscbxWW+GltqCUBTHRLE7zSGxZOqXS6rP6+5HviV/xurS+6td1V6KPzXAasfT9zsL32JWL/h0kOHJKbXViUS2IcPbd46U6teNiZcsio13RGQlIjr7b8nbkhkKp68StJ/zvE/sM3x6JHpp7+Qrkpw/PvdRNXaG4cmHluxdPv2iRImSfrxPZ/ElnfwScKMTxIlcCXBxeuzp/lkfu2R/nvSpkvyNuI/qJ0HSGen6cgoXLU73Z36J45t/D1I9TuSCJ/fnv1t/eXjVdAfOcJXk2pqGKa1dvDJbPue9eP5+gXp4ln+wvuJY30V7V0u8ftSSlSfC8cUT2DTXTzdn6a6XU0jJXqfP+L/7X5l4nwXVtIm/Toz8dWT/kbUx3f6/ZSuyrskvXu9/7vwR58IrrWj1HUtP+3evfyFZFh4f8dLOj+6018YS/7C98njpZ0vkX583393zvtG6tCr/rbjVa/DnEuf9I+u9M0f4o9v3TL9+5EabnsWL7WUpJKKxONwJzjpqmjOHu+/w5uOkg5soP1j1ULfw3Rjwufg64ckn0feuyk5eZKkLU6SPv2XP+fslXJjREp/g3TMGem3nVr6Ht5Ht22XfMOuManr+fIJv//GPdDwDcvw55xJdeLbd/RtPwftmWiCE5au85n48TA6uMH54W2Jtqr9t/TNDz641d9AcLFEchE//pf9LO3QjCYa/9xWuvAHXwo2N9SOf0yomUo4eQ1L952+dUsfezyesHBp+aujpdMbqHHzxHGZtSV/4Q/1k9awh49oeh1hjxze8LyvnvL/4jdxwzc441JvrMW/54eYtHFQgp2uRDKewDUl3Xfix/f9zddRD/ub5O/fLB37n6abhd04LH3HbekUh1KpD2+r/9nGb7K+30CfFt/8N3H8Z/K9mfDv5Oepx9n3/6u/z9L9Rv9jo/yt9i/JUpOk1m748OFu7NhGSnsKyL/en6pL/52omjr16n1aZsOzJ0j/3Drx/OK5/ofg/4ILk9GV/m75vXv556kXLdmo2pHOJof70qhwtbELf/R3rTLd5rq7JVenCDvoruQ2DvnmjE98dbc545tednWd+Kp0966r9tqRf2x+YhlX0saXRBaSAVv7H9lMDDnUX0g2ptcQ/8O7PKj2OXD7+hcOxeX1S1ji/jTbf9cPvN3XOIi318yGLX7jq/we/ay/89vcdt2ZWG8P6duXGl9ms2N9SWK8pKX/VtK0D7IfS0vY6U/SG0FtldQ29lHY7tz6tS6ao9eQ5NoxubL+3r6kNFzaFpU/fOdLWl9t4mboFielrzXTlNK20kUzE00f0invWL+a5KC9fA2pY/7d/BujJW2kIx/z1ZMfPMiXPnUZ6G8sZuqUt/3FekMdFaZq00W6YKpPXt+9wd9cmfpO/dKzqKXb19l20U/SVb1zu41s2f9madMjfBV9V9dE2+NAeSfpj0Gye9Pm9W92p7PB/okS5z2uSlSfzoay9v73Mt47fTZscnjTHVqurlaewJrZJ865tBcKtIFtxb6e1UI9m035nzTpxcTzr55Mnv/fC31X3HHPnZ1IXiV/R/H1/8v9QO9fPJacvEq+CtunD2a+joaSVyl98rp7miomrdXNm7dM8irV72G3OVY1eZUKL3mVMk9epeTejhsy+8tE8irVT16lhpNXKVHa88wp2U1eJZ+8Sr7Ndq669m8qeZV8dcBw4pJanS+fxJNXqfHkdc+rfQl7rq1O8iq1TPIq+d5iW0PyKvkSmtRaEensnsGQaenULEsuMUznxDS/jd8E1wWrUqundrmv7fS/v/rnXz3VvORV8tcemSavklbWZinv4P9+eFvrS16l3CevUqLZVHNtf17Ty4TtdoW0yRG+47SdL05M3/oMXyKeidcu97Xyapc3nLx2T+n7ZUVlok+JTJJXKfkadXWS1zXTjAldvSSRvJa0kQ6+u+HXn/quvzkU7vgvnVwnr3mOBLYVq6trodLxf+2fONnV1SYPASH5Nnrxqr1S/WqtyxdIb10jPfUb//qW9NxZfkiVXNlkFX8E8k2PZg54n9o2DE3rPXT115F6AycX0g11lG2xWl8NPSrxdpxxq9rJUTbtd6N0eiPV/VbHnn/17cBOaoUX8/BVsZc3cQN4u3PT92y79sjMtvFpA72fS/646DlYWncVa9U0ZO7EhvseyES8Q6lMpe7DdM2Xcm3IYb6GUtQyrXYrSZ0GSGtu69vF73Jp87Yz5BDpoNt9FeAd/uB7T9/9St/G/cSXMysEWDrXDxOUaqdQQnxQqDPILkHTh9u2a96N0B8y7BukMZ36S8enqR4dtv6efr/EbwZsfIi0Veg6dY2NpSMflS6e7atcb5XBNWzPNO31G5Npz8N5Vgs3jAS2laqujemxsU10DJT1jS7zvao1NvZZY757TboiTSc2+Sy1A4konfK2b5u1Kpo6mR37XP2qJK28aslq2ypNu8tcueAHX0WqNQkP6xLWWGdE2TLljcyGTFp3t9xsP9yJldR0Mp3pdyE8fFOvIdK+12ce0+bHSj0GJUotuq1Xf5mKTtLxL9af3pi1dki0Wy1p4o6/JB32gH+/v2nGWKDNsWkD7cTzUfiGwNrNHAIsVbiznbiND/Z/h58o7dpA9eJj/p1+upRcIha31zWJx6ODocP6Bm1Xf/1UYlrqcXb0s/43KJ3RlemP12zp3sC49/2D9qR7hGr1jO6UvnOeTLQLetL/U5re20c1URp28Rwfy8F3+mGztsyw46FMbNbIyA0X/pj4zPa8uuHl4uLLjq5MDPvUZ6h0/Av1OxMcXZm+g8HOayYehzsJk/zQX+Hz4DZnJm8z/q+p88DoSmnHPySW7zMsMW/oUYnHV3RPPN6kkTa6jem6TubLHh/0ch8/3tunafO/TVATZpdLfeyH3J3ocDRcwm3mh8Da86rE+0z3HVt/H+m37wXfyzRtxSVp/5uS9+9ljfSKH9ZY3w2tHAlsK3T03R9q0MXJPx6/2zkHvQ/Pmeg7jYi7qnfmHTw0128/kE5+UzpuVYa4iFBpG2nDLHSKtHuomt8hq9Axk+Qvunf7s3RAA0PmNLr9KxM94aYTr3KVatCe6ac3pU3XVXtdS0rX+dav/ll/2qo4/CHfrieuuKzhfZxqdS+EMzXs6KaXGZIynNBaOyQ/z/Qu77ZnNb1MOo1VdV4dk5pxHjo8wyFf9r8p+eKkbdfk8aTT6Zumw6WD7vTVz9oHPdf2C41TWFTqe1zNxBZpmkSUd0g+f5SFjskOfYJpQUd5uarmuPc1vm3i4Y00/Vh7pHTEI9JRKc1Ztj7DJwbnhjrTGfprP6ZkWLr3LvlSprDw71FFSj8K+1zna+CsF+pZOXzT69D7fOK3R1ByFAvVPopf4A/9te8Jd/29/e9f2P43+XGYyxo4L+x/k78Bsv/NyYnoSa9LZ47zv6mnBiWUZ45Ln6xudqw/9w/7tXTeJP/bs8VvpN995rfdmHD1z/1v8m3pe23sawpscoRvxzlwez/uudS8oe22aaCq+66Xp7+xuGy+Px6OfMJvP97pWqdgbOOSsvqvycQmRyQfY79+2ifq6Uq6B+3hb/SGf8t3+pPvVfiIh+vfHNrtcumwf0mnvuPjTrXPdf57sPMl0vmhIWXSHbuD9/W/39ud6/f39r+XjnteOuqp5OM2PlRQuGrqgXf4GE5528ca1nVtv18b+90bcqjf578PVdP9dWi8+Hhne82V+n1rjnRjiu94QfK1Wrjn74YM+7XfJye85EuP48Ln3EPv98frQXf6mxjxZhjHv+BvHsWrPI84xSfZe1+bvrbVurv4de14YeMx9d7EfybrhXqd7xf6nVhza3/sxG06yn+vh6bpFf3UdxPjC6ez6+X1h4PLIySwrdDb3yb3QrhOj3Y6d/cG7kCuCuf80Au3btVybYB6buC/3AO39Sfe+A9PLow4Of30tXbwJ6L1904/v7yjtOtofxe227qJhC/dAN+pKjonHpd1SFzUxG1zhv9hXn8ffxGQquvaja+/bTcfU/ue/qQbHvYjNSEeHnTvXhYqPS4pl0aclHgev1gNz5f80ARhe13jO0vIRL8R0jnjfU/Rx6XpqVZqvH3NYQ/4mPfPsHpyQ59jUyo6+R5YSyuSp+92hR9eJa7XkKY/+3CVu7bdE6/bYF9ps1CC2JwEdlVuUKQTvgseFy59aepu9fbnSfteJ7Vfw3+nOvT2x3V8HR37pk9CtggdZwO399sZ1kgJQmpJRUVnfyxtemTTvYOvikyT7va9/IXaBsExEL5oSK3OteMFvpSkTZfEuW3ni/0QM3Hpbpj0DfqmCJ8Tuqzpq59tc6avKhfuDXf/YHivcJX/dFXLtj0rUXqXmlgMOcwnWIc/JJ3zpY/5hJd8yVHbbomkuvem/pje7c8+jvCwO1JyyUzf4f6iq7xj+vnhc1R5B98L7Ab71W8n1mOw39Z+N0qD904udWnbzVdL3OtqqWMfn0y07eZLL7Y723eE1K6HLxXd5++JfRTfx5K/6NwtGMpsrR3979GJr/qL3WP+nXzjbfC+vmrkUaEe6PcMlfRtFAx3M+zX/pyy4/n+PffYwCcZZR2kHc7zie6oR5Lfi+SrFfYb7qt2x5V1kEZeJK2ziz+eKjr680jbUFx9N/fDp/TcIDFUTbd1pM2OS15/r43978U2Z/pzSoc1fDXPomLf+3S/JjpQKyr2ydRmx/h/xSV+qJPNj/X75Y/T/Hk+XrJ08F3p17PzJb6K6krm2/Juf17y/j78Qf857vkXf4OirIM/Rjv09tscvLc0aHf/ePcr/Wt3CtoxZvpb0CGlU6M9rvJD7x3+oD+f9RgsrRPcQNwrNEbohr/ySdNaO/jf8nhJ7Ta/81WvB6fpYLOk3CdUawzxcW86yt9QiNviRP892OH3/vM96C5fKya83biKTv73e9fL/P7e5RJp4HbSeilVvocc6s+fp4c6pNv0cB9D7018rKkG712/pln/LRNVicva+X3evodvitB3c6l7qEAltQQ2U1v8xp97jngkuUS3y1qN39yS6t9YX3M7fyyEb1A1dA0Sttc1fp+075F842Cfa32p7MYHSxv9yh+vmxzmqwbHte/pb7TFqzBvdrS/STXipOQhgeLM/LoyudkyeG9/c0TyCWjqaAhbnOhvvlV09qXuGx+UfptrbOx/T8LCzeK2O3vVb/60AvRC3AoNvDC5fv2gXu318jk7Zm8DL5yfGEeyOco7+YbzqyJdFbxs91a8yeGJdhJVlX7A57ARp/i7/1IwsHlKFYuGqgl++pD079/6C+ovn5BiNY2/n9GVvrOAa9ZKv+7KGdI/NvQXMIc00tA/vr61dpSOTRmrbdKLiXbLoyuT92V4W/Hp+1znT3rx5+GeWrc9298tlvzwGneMrL+eD29PHqMu1S6XSdufmz7+/W5IDF+x88UNV++Kb++H9/2Yjenmhc3/Lv3wHKk9FW91ur/IffkSP77vrpf7E3c4xsH7+jEuJT+M0YKp0mnvS702bLyHw4vnSFcGd3rjQ0FsdKC/aJX8MBE/fSZdttBXm33gwMRr2/dKbns55NDERWBzvxujK6WnT5G+eDQx7YSXpHv2SAwZk/Z1wXZ2u0J6JWWZyxamv9MdVrVIurq/TwpdzPd2+qcGOkR694bE2JiHP5gYR7Ox4ze+/1paSRs/7E42zZtcf4ibrc/w7ck3P67hsYBrqnyv0AO2kU4I1cyJ77NNj5Q+fzg0Pdh/C6dJ12/sL1gOWoXzfUPC57nRnXwJzKXzG1620wB/Xo5/p9N9l79+3g9fs8dVifGsJT8EzF+CcQrb9/LVEzP15Am+46BzJvjzbUPbThdz6rLXrO1LAcPH6qo0sfjbuol2mfHXj703MQ7pAbdKw45K+9KMrE5s2TDh374n/L3+Jm0ZupH82NGJ3l/X3kk65tnEvL8HY6Kubsx/GZB8fRLunfvgu/24nRsd5NvkLpqRfM5vSZl+RuFz4slv1r8Bkq3trKr4+i+Z17yh8ZpaX2PxhpeZ/Koft32XS5NvjN+3r++48E+zkkvSY3XSn7v6/ZhaG2J1PHSoH1u2oSHEovbIqOQaR/FzWNtuvvpyK9dYL8SMA5sH+nROU50lE3U10qNH+Tss7Xr6u7QjTsk8eT3yieQxPuMDWMcd8Ygfb2/FEn8HMj6m16C9fDJTUuF7iWtqQPMDbvFDicSTkW3OrD9OXtj+NyX3qDj8BH/3NFz1KFw95ain/Al2wFaJab/90I8/t3yh1KZz4z1AxquIFJf4MTKXNXCxFhYukU1t09Cprx+HrKk74HGHp+l8I/UO5Emv+6S9qZ4sf/epL33v0MuPeViz3N/JjeszzCe7A1PGSNviJF9KPHFM+nEsUzvFkXxJyPzJvupVPIEtSSn1PPtLPzB9fDxKqelql3Hd1vGl+b2H+rji43UWlyUnsLuODmIMTnfhqn6nvSfN/Tq5us7SoAZEx+BufbwUcMTJfl3TxybaiRaXSVue6tuNl3fwSWOvUInYMc/6RNusflXBk173A4kvnpVc8pWJA+/wd47bdk9U+9/vBmneN9LMcb5EYsBWvgRxrQxufm19ho+7Yx9fM0NqOnmVEiX3zvlqavGSibTbODORwA7e199IGBKMLXzuRN8bc78tkl+TWnq405/8cdi+l08EFs+SXvqjn3fc8/6ziQ9FcvZXPoFrrlPebvx9rKpu6/gSpcdCCUrbrtIxY5LPTalKK/xx1XPD5Omnve+PuXbdfdLTdR1pWaj2Tuf+vh3jGptk932EnfpOouZBOie/6c/N7Xv60pv190y/3Pp7+2M1tfp8eYdE8tHcqor73+RLVTr19ef7eNXoVXHa+9np6Ou4F6RbUo7xTv0Sj1e1j4O4sz7PTa2FTG2wv/+9jZfKxu3zd2nokf5GV+rxeMyY5ON2VaXeXC8q9lWrJ7/qzzMd+/haBbFa3+NtQ9WYc+23H0plbZte7sxx/txeOV1aY9MmF68nfn7ItWwkr1Jm8Z45LvF43V3T/74d/oA079v61cCLin1P292z3FZ7/5v8OLOtMXmV/HB4cyZK94SucU55q35thDxEApsHbj4yTSlTJj57uP6QElVN3I3r2NffndxgP1/tJe6wB/zF1n37+ATzh/f9Rf/gUNWdnhtKcyb4C+n4l7l3IxdP257lf9CGBSUx8VLBNbf1F/1FxdLE5+q/bqOD/HAczkmzvvAJzOZpBmk+4FZ/5ym1mo3k48v0hBOvIlJc5pOajg188Xf/v0S37kVFPs51d02/D5oaRDssXVuR1OSioeQnPm7gBkHCFa6q3NBF8xYn1p9WVOSrWvXbIn0CqzTJTt/N/L/qBjoJ2PEC354kdWiPeNurPsN8iXBj4sn3pqMSCezBd0nv35QYPDxeRWZlAluXeH2vjZITTslfML9/c+ImxAE3Sa9d4UuHikultUM/mGbSyAv9oPLbnetLbMPadEncqAgPdt5/K1+NO3zx2hyD90lU++rU1/8trZAOu9/flY5Xf1+3iWFwtj/Pfz5FRX7ZWKzx5VMVl/mSwa1/m1ytPZ2iIh/XjHF+v8VLwSV/cRmv8hqW2gZ2xzS1AGZ94atLDtzOryeewHbuL/3qNn8zLD681AG3SD9PSR7Oo+9wXx2zqMRXt2rsnLU6zHx15JEXSTM+kRb+6EtH459fY9J9V8PHWvx7kHpuyrS97Kpq6jMPlxrFO5JKx6zhY3XDA6QPbvVVUZujrF3i/aerOtmQLU+tf84N/17sOjrzYTtS9Rjk29qFOxHrPdQfv+vtnr4aYHM01DFbSzFL/3vbvmdy84ywHoMkDUo/rzk2P85fl+xzrfTihb5mQsfe/saRlPxdiNc4ikKmx2I87ubc2AxL/S1q7TKJN75P4tKdM9p0kfqPqD9danj66uiwhv/XWlV0lAakDGeU2lQsT5HA5oH25av4MaUbTys+JltDhhziq/rFuy+PV8fcMEiAGqve8dtmjGcpJdoixfXcwCewnQf4NkMzxvkEtm235FLP8vb+DtITx/uL14burA87avWqY8XFE6zURCfVNmckPz90FTtrao6m2qfuc63/ly1tOiceF5X49lvv3VS/V9ewcMlJvDfJzY5NtF9KVdExcZxlWpXWLPnYLO/gE9hwRyQ9gm2HS3vTWX/P5JKitUfWH6qiy0BfzVjyP5inZzBURLy91/ATfdvSxvQa4sfD7NBHWhwa1qapqq2dB0hnNGMoltQhE5p7AW2WXK21KeF22JnIpDQp3EY0tS350FH+3+hOvp1V/GZZ7Qp/k+L0j4ML6BY08oKW3V6+Ky71tRVayl5N/EZud07j85uS2tlS+x7Sac0cLgb1havg//a96OL4pUhtqoM8kEGtqjyS0wTWzPaUdIOkYkl3OeeuTpk/QNL9kjoHy1zonMuzbmpbAeekN67yw3R0W8cnoGuPlD66s/nr2uli32FB/C7h2V/WrzqcKztf7O+2xxPFvpv5oRxmjPXtLzsNkI4O9X4XH692daqGZWL9PX1HH5lW+c2W875pvIvzM8clV1VuaWd/lRhyqbEEtqTM33CoWuRLnk/+n79ZkYlzJyaXmK6OjQ/2SUw2PseT35SWNHOMwS5r+tdlMp7b8c/76rHtevj21LFaf0OqJe70njepeT2K5tKqjBV79pf1OxY5/WOfKMTtcpk/Hlo6eQWAQtCS14ZYfb/7LPfXyi0sZwmsmRVLukXSbpKmS/rYzMY45yaEFrtY0uPOuX+a2YaSXpA0MFcxFaTaal9t961rfDvAY8Yk2pllauD2vkri0nk+2egbqrLcvoekHLQHS6e4NHnbku8+vNs6vpH8fjcmV7fb4ypJLrM2fqur/xZNL5NtTVVxTq1O09I6rJHo6bipITfCVVb6DM18Gx37NL1MOunab5pl73Ns06Xp9sbpZNoRR0WnRDXGcA+kLaE1VYc64iHpg3/6Gx+LM+xUKbVKulQ/UU09zyFzB9zqf3MA/HK15LUhVl9TNc/yUC5LYEdImuycmyJJZvaopAMkhX/5nKR4v/udJM3UL1xqr9Bn79pEg/MxZ0hfBANs/zxF+nszSxR6DM6su/EotensB1hP1X1d6ag046sht9Ye6dt8miU66Eodlidq8TE0B2wdbRxYPQO2aryDI7S8bDTLAABgNeQyge0raVro+XRJKS2JNVrSy2Z2pqR2ktK0/pfM7GRJJ0vSgAFp7q4XkCc+mb7y8X6b9tGpOzZSyjbz00TyKqVv89qYc8Ynj9sHZOKIR6Slc/zj9fbw1aubU6raErquLZ0x1o8pBwAAgIIRdSdOoyTd55z7u5ltLekBM9vYueQGdc65OyTdIflxYCOIs0V8MGW+zn/yi5XPrz10E5WXpBmeJO7OJnoYTXXsc9I3L/n2dN3WXfUeUPHLVtZWKhvoHxcVRVO9OhPZ7i4fAAAAkctlAjtDUv/Q837BtLATJe0pSc65982sQlJ3SXNyGFerNWdxouOUEQO7Np68SpJrZuc2a+3g/wEAAABAHlrNQcca9bGk9cxsLTMrk3SEpDEpy/woaRdJMrMNJFVIambXnoXjd48kxrxsXxG6t/Cfc6Wp7/qehq9cQ5r5mfRjE8N2/CY07MCRT0gX/pjdYAEAAACgheWsBNY5V2tmZ0h6SX6InHucc+PN7M+Sxjrnxkg6T9KdZnaOfIdOx7nUXox+oSpKg3sLM8ZJY+/2/+Lu2LH++J9r7yRNeSPxvO9mfszDyhl+sOeiJkpzAQAAAKCVy2kb2GBM1xdSpl0aejxB0ra5jCEf/FS5XG98nVzwXBGvPnznTulftKIy8fjUd31vsK9eLr1znZ9mJh1wSw6iBQAAAIBoRN2JEyQdd8/HmjQ7eUDo4QO7SrUrGnhFyHnfJMYL3fkSaevTpdI2OYgSAAAAAKJFAtsKzF9af/ibUSP6S8t+bvyFW5+RSF4l3yNsu+5Zjg4AAAAAWodcduKE1WBm0opFjS+05SktEwwAAAAAtAIksK2AWQMzVixuYEagiAJ0AAAAAL8cZECtQEP5a4MJ7G5/lhb+KHXsk6uQAAAAAKDVIYFtZd74/UiVlQQF4+kS2K3PkLY9q2WDAgAAAIBWgAS2FQhXIe7TuULllVOl0ZvLD40bOOJhafA+LR0aAAAAALQatIFtBSxUibhs3gTpps2UlLzueIE0aK+WDwwAAAAAWhES2FYgXAJrt21Xf4Htz/ND5AAAAADALxhViFuBnyqrGp45urLlAgEAAACAVoxivVaka7uyqEMAAAAAgFaLBLYV6du5jVTRKTFhp4ujCwYAAAAAWhkS2IjV1sVWPv5r33elqlCV4R3/EEFEAAAAANA6kcBGbEVtIoHdcPaYxIwTX4kgGgAAAABovUhgIzZk9EuSpGLVSe16+IlHPi71HxFhVAAAAADQ+tALcYTqYk6xYLjX7yqOlqZI6jRAGrRHpHEBAAAAQGtECWyEFi6rrj+xc/+WDwQAAAAA8gAJbISW19TVn7jGkJYPBAAAAADyAAlshKpqYvUnlnds+UAAAAAAIA/QBjZCK2rrtH/Re4rJEhM79IouIAAAAABoxUhgI1RVE9ONZTcnTyxpE00wAAAAANDKUYU4Qsuqa+tPLCpu+UAAAAAAIA+QwEZk2s/LNO6HhWnmWJppAAAAAACqEEdk+2vekCSdVRFxIAAAAACQJyiBbW2MElgAAAAASIcEtrWhDSwAAAAApEUC29pssH/UEQAAAABAq0QC29oUl0YdAQAAAAC0SiSwESlWnV4u+0PUYQAAAABA3iCBjUhXLdagohlRhwEAAAAAeYMENgJT5i6RyUUdBgAAAADkFRLYCLw/Zb7KrCbqMAAAAAAgr5REHcAvUU1tTOUKJbD9tpD2uU5aMju6oAAAAACglSOBjUBNnVOZahMTjnpSatM5sngAAAAAIB9QhTgC1XUxlYVLYEleAQAAAKBJJLARuO6Vb1aWwL7W59SIowEAAACA/EACG4G6mFvZidMue/wq2mAAAAAAIE+QwEZkZRvYkrJoAwEAAACAPEEC28I+m7ZQkhJtYIvLowsGAAAAAPIICWwLm7FguSSpfGUJLAksAAAAAGSCBLaFmfm/8TawKqYKMQAAAABkggQ2Ek7Xlt7uH5Z3iDYUAAAAAMgTJLAR6KrFiSdl7aMLBAAAAADyCAlsBNawnxNP6IUYAAAAADJCAtvCTNLWRRP8k93+HGksAAAAAJBPSGBb2IyFy7W2/eSfbPGbaIMBAAAAgDxSEnUAvyTOOV35/ERNrXjNTyhrF21AAAAAAJBHKIFtQbe++V3UIQAAAABA3iKBbUHPfjoj6hAAAAAAIG+RwLagspIibWxTog4DAAAAAPISCWwLqq1zWtPmRB0GAAAAAOQlEtgWVBuLyUUdBAAAAADkKRLYFhRzUonq/JMB20QbDAAAAADkGRLYFlQbi6mXLfBPjngo2mAAAAAAIM+QwLagujqnEUVfq8oqpLZdow4HAAAAAPIKCWwLqok5rWczVGulUYcCAAAAAHmHBLYF1cWcululPmq7Q9ShAAAAAEDeIYFtQbZ0rtpbleaU9Ik6FAAAAADIOySwLeT97+Zr86JvJEmLijpFHA0AAAAA5B8S2BYy6s4PVBoMoTOlbFDE0QAAAABA/iGBbUFlqpEkbdS/R8SRAAAAAED+IYFtQWVWK0k6apv1Io4EAAAAAPIPCWwLipfAFpVWRBwJAAAAAOQfEtgWtKH94B+UlEUbCAAAAADkIRLYFtTFlvgHZe2jDQQAAAAA8lCTCayZ7WdmJLqraUubqD2LP9aKkg5SUXHU4QAAAABA3skkMT1c0rdmdo2ZDc51QIVqt+KxkqTy2sURRwIAAAAA+anJBNY592tJwyR9J+k+M3vfzE42sw45jw4AAAAAgEBGVYOdc4skPSnpUUm9JR0oaZyZnZnD2ApKkZx/UNo22kAAAAAAIE9l0gZ2fzN7RtKbkkoljXDO7SVpU0nn5Ta8wuCc0xZFX/snbbpGGwwAAAAA5KmSDJY5WNI/nHNvhSc655aZ2Ym5CauwxJy0VG38kyMejDYYAAAAAMhTmSSwoyX9FH9iZm0k9XLOTXXOvZarwArJF9/9qK2KJvonfYZFGwwAAAAA5KlM2sA+ISkWel4XTEOGHnvgtqhDAAAAAIC8l0kCW+Kcq44/CR6XZbJyM9vTzCaZ2WQzu7CBZQ4zswlmNt7MHs4s7PxyddGtUYcAAAAAAHkvkyrEc81sf+fcGEkyswMkzWvqRWZWLOkWSbtJmi7pYzMb45ybEFpmPUl/lLStc26BmfVclTcBAAAAACh8mZTAnirpIjP70cymSbpA0ikZvG6EpMnOuSlBqe2jkg5IWeYkSbc45xZIknNuTuah55/za06KOgQAAAAAyFtNJrDOue+cc1tJ2lDSBs65bZxzkzNYd19J00LPpwfTwgZJGmRm75rZB2a2Z7oVmdnJZjbWzMbOnTs3g023LjNcN0nSS3VbRBwJAAAAAOSvTKoQy8z2kbSRpAozkyQ55/6cpe2vJ2mkpH6S3jKzIc65heGFnHN3SLpDkoYPH+6ysN0W88bXc9TOddcPsV6qVPuowwEAAACAvNVkCayZ3SbpcElnSjJJh0paM4N1z5DUP/S8XzAtbLqkMc65Gufc95K+kU9oC8aUeUvVViu0TOVRhwIAAAAAeS2TNrDbOOeOkbTAOXe5pK3lq/425WNJ65nZWmZWJukISWNSlnlWvvRVZtY9WO+UzELPD0UmtdEKVZHAAgAAAMBqySSBrQr+LjOzPpJqJPVu6kXOuVpJZ0h6SdJESY8758ab2Z/NbP9gsZckzTezCZLekPQH59z85r6J1qy4yNTGVmiZK9er5+4QdTgAAAAAkLcyaQP7nJl1lvQ3SeMkOUl3ZrJy59wLkl5ImXZp6LGTdG7wryAVma2sQrxuzw5RhwMAAAAAeavRBNbMiiS9FnSq9JSZ/UdShXOusiWCKwRFZmqjaqoQAwAAAMBqarQKsXMuJumW0PMVJK/NU2J1KrcaLXMksAAAAACwOjJpA/uamR1s8fFz0Cx9574tSSq12ogjAQAAAID8lkkCe4qkJyStMLNFZrbYzBblOK6CMXTC3yRJA21WxJEAAAAAQH5rMoF1znVwzhU558qccx2D5x1bIrhCMK/ntpKkp+rogRgAAAAAVkeTvRCbWdrMyzn3VvbDKTyL2w2QJI2NZTJ0LgAAAACgIZkMo/OH0OMKSSMkfSJp55xEVGBc7QpJUk1GuxoAAAAA0JAmsyrn3H7h52bWX9L1uQqo0Lz85XQNKSWBBQAAAIDVlUknTqmmS9og24EUqlKrVZ0z3X38llGHAgAAAAB5LZM2sDdJcsHTIklDJY3LYUwFpWu5VFNbou3W7R51KAAAAACQ1zKp1zo29LhW0iPOuXdzFE/B6damSLGlJaooXpXCbgAAAABAXCYJ7JOSqpxzdZJkZsVm1tY5tyy3oRUGi9WoVqVRhwEAAAAAeS+TYsHXJLUJPW8j6dXchFN4il2N6owOnAAAAABgdWWSwFY455bEnwSP2+YupMJSFKslgQUAAACALMgkgV1qZpvFn5jZ5pKW5y6kwlLkalRnVCEGAAAAgNWVSdHg2ZKeMLOZkkzSGpIOz2VQhaQ4RhViAAAAAMiGJjMr59zHZjZY0vrBpEnOuZrchlU4ilydYsUksAAAAACwupqsQmxmp0tq55z7yjn3laT2Zvbb3IdWGIqpQgwAAAAAWZFJG9iTnHML40+ccwsknZSziApMUaxGKiaBBQAAAIDVlUkCW2xmFn9iZsWSynIXUuGIxZwUq5EVs7sAAAAAYHVl0jjzv5IeM7Pbg+enSHoxdyEVjmU1dSpVrayEElgAAAAAWF2ZJLAXSDpZ0qnB8y/keyJGE6riCSxViAEAAABgtTVZhdg5F5P0oaSpkkZI2lnSxNyGVRiWV9dpSNFUFSsWdSgAAAAAkPcaLIE1s0GSRgX/5kl6TJKcczu1TGj5b/GSxZKk3nPfjTgSAAAAAMh/jZXAfi1f2rqvc24759xNkupaJqzCcNYD70UdAgAAAAAUjMYS2IMk/STpDTO708x2kWSNLI8Q55wWLl4qSZo18FfRBgMAAAAABaDBBNY596xz7ghJgyW9IelsST3N7J9mtnsLxZe3amNO5VYrSarstWXE0QAAAABA/sukE6elzrmHnXP7Seon6VP5nonRCOekMtVIkuqK6IUYAAAAAFZXkwlsmHNugXPuDufcLrkKqFDEnFOZfAmslZRHHA0AAAAA5L9mJbDIXMw5latakjSob8+IowEAAACA/EcCmyOVy2v07/JLJUnFbTpGHA0AAAAA5D8S2By5fMyExJPyDtEFAgAAAAAFggQ2RxZV1SSedOoXXSAAAAAAUCBIYHMk5lziSZsu0QUCAAAAAAWCBDZHXKwu6hAAAAAAoKCQwObIgJrvow4BAAAAAAoKCWyOtIktlST9X/e/RhwJAAAAABQGEtgcqYgtkyStKG4XcSQAAAAAUBhIYHMknsAuLyKBBQAAAIBsIIHNkTaxJZIogQUAAACAbCGBzZF+iz6VJK2gBBYAAAAAsoIENkc6aLkkqa6oLOJIAAAAAKAwkMDmSE9bqFfrhsmK2MUAAAAAkA1kVznSRlVaqjZauwdViAEAAAAgG0hgc6TCarTCleqcXQdFHQoAAAAAFAQS2BwpV7WqVKayYnYxAAAAAGQD2VWOtLEarVCpioos6lAAAAAAoCCQwOaCcypXjbp26hh1JAAAAABQMEhgc6GuRkWKqa6oPOpIAAAAAKBgkMDmQm2VJKmGBBYAAAAAsoYENheCBLauqCziQAAAAACgcJDA5kKQwNZSAgsAAAAAWUMCmwNLli6RJH23oC7iSAAAAACgcJDA5sCM8e9JkuZVMYQOAAAAAGQLCWwOrP/eeZKkFSqNOBIAAAAAKBwksDlUVEwCCwAAAADZQgKbQ6dv0yPqEAAAAACgYJDA5tDSbkOiDgEAAAAACgYJbLZVVUqS7q7dSzUd+kccDAAAAAAUDhLYbJs3WZL0vVtDRUX0QgwAAAAA2UICm23L5kuSxscGqshIYAEAAAAgW0hgsy1WK0mqVomKSWABAAAAIGtIYLMtSGDrVKwi9i4AAAAAZA0pVrYFCWytiqhCDAAAAABZRAKbbbE6Sb4EtphOnAAAAAAga0hgs40SWAAAAADICRLYbIu3gXXFWlFTF3EwAAAAAFA4SGCzbWUJbLEWVdVEHAwAAAAAFA4S2Gxb2QtxkdqVl0QcDAAAAAAUDhLYbAs6capVsbZbt3vEwQAAAABA4SCBzbaYrzZcpyIZnTgBAAAAQNaQwGZb7QpJUrVKIw4EAAAAAAoLCWy21VVLkqpF+1cAAAAAyKacJrBmtqeZTTKzyWZ2YSPLHWxmzsyG5zKeFlG7QitciSSqDwMAAABANuUsgTWzYkm3SNpL0oaSRpnZhmmW6yDpLEkf5iqWFlVXrRpKXwEAAAAg63JZAjtC0mTn3BTnXLWkRyUdkGa5KyT9VVJVDmNpObUrqD4MAAAAADmQywS2r6RpoefTg2krmdlmkvo7555vbEVmdrKZjTWzsXPnzs1+pFnkapZqucqjDgMAAAAACk5knTiZWZGk6ySd19Syzrk7nHPDnXPDe/TokfvgVseinzTbdYk6CgAAAAAoOLlMYGdI6h963i+YFtdB0saS3jSzqZK2kjQm3ztycjXLtMS1iToMAAAAACg4uUxgP5a0npmtZWZlko6QNCY+0zlX6Zzr7pwb6JwbKOkDSfs758bmMKbcc1EHAAAAAACFKWcJrHOuVtIZkl6SNFHS48658Wb2ZzPbP1fbjZyLRR0BAAAAABSknHaX65x7QdILKdMubWDZkbmMpeU4OcaABQAAAICsi6wTp0LlHAksAAAAAOQCCWy2OUczWAAAAADIARLYHKAEFgAAAACyjwQ2yyh/BQAAAIDcIIHNNtrAAgAAAEBOkMBmG21gAQAAACAnSGCzzpfAXrT34KgDAQAAAICCQgKbZUuraiSZvpuzNOpQAAAAAKCgkMBm2ZIVtXKS3p8yP+pQAAAAAKCgkMBmWbz7ppq6WKRxAAAAAEChIYHNMjM/DmxNHV05AQAAAEA2kcBmWVHQiVNtjBJYAAAAAMgmEtgsa1NaJCfp8v03ijoUAAAAACgoJLBZZkEJ7Aa9O0YdCgAAAAAUFBLYLHPBvyKzphYFAAAAADQDCWyWmXznTUXkrwAAAACQVSSw2eZ8L8SUwAIAAABAdpHAZplzTiKBBQAAAICsI4HNOufbwLJnAQAAACCrSLOyLN4LMSWwAAAAAJBdJLBZ5mgDCwAAAAA5QQKbdfRCDAAAAAC5QAKbbS7eBpYMFgAAAACyiQQ2yxZXVVOFGAAAAABygAQ2y+rqYkECG3UkAAAAAFBYSGCzzBRvBQsAAAAAyCYS2JwwlZWwawEAAAAgm0qiDqDQtC0rUlldkdqWsWsBAAAAIJsoJswyk1RazG4FAAAAgGwj08o6J5/GAgAAAACyiQQ2y0xOjgQWAAAAALKOBDbrnMQYsAAAAACQdSSwWWaOKsQAAAAAkAsksFnmRAEsAAAAAOQCCWyWWeh/AAAAAED2kMBmHW1gAQAAACAXSGCzzBwJLAAAAADkAgls1tGJEwAAAADkAglslhlViAEAAAAgJ0hgs4zyVwAAAADIDRLYLKMXYgAAAADIDRLYrKMKMQAAAADkAglslpmjEjEAAAAA5AIJbJbRiRMAAAAA5AYJbC6QwAIAAABA1pHA5gQJLAAAAABkGwls1jnSVwAAAADIARLYLKMNLAAAAADkBglslpHAAgAAAEBukMBmm5NoAwsAAAAA2UcCm2WUwAIAAABAbpDA5oBRAgsAAAAAWUcCm3WOAlgAAAAAyAES2CzzVYjZrQAAAACQbWRaWWah/wEAAAAA2UMCm2V04gQAAAAAuUECm3VORgILAAAAAFlHApsTJLAAAAAAkG0ksFlmK/8DAAAAAGQTCWyWmRzjwAIAAABADpDAZh2dOAEAAABALpDAZpmvQkwCCwAAAADZRgKbZVQhBgAAAIDcIIHNBUpgAQAAACDrSGCzrEiO/BUAAAAAcoAENifYrQAAAACQbWRa2eScJMkoggUAAACArCOBzaYggaUOMQAAAABkHwlsVlECCwAAAAC5QgKbCySwAAAAAJB1JLDZFG8DG3EYAAAAAFCISGCzijawAAAAAJArJLDZRC/EAAAAAJAzOU1gzWxPM5tkZpPN7MI08881swlm9oWZvWZma+YyntwLSmC5LwAAAAAAWZezTMvMiiXdImkvSRtKGmVmG6Ys9qmk4c65TSQ9KemaXMXTEpyLSaIGMQAAAADkQi6LCkdImuycm+Kcq5b0qKQDwgs4595wzi0Lnn4gqV8O48m5WLwA1iiBBQAAAIBsy2Wm1VfStNDz6cG0hpwo6cV0M8zsZDMba2Zj586dm8UQsysWC0pgI44DAAAAAApRqygqNLNfSxou6W/p5jvn7nDODXfODe/Ro0fLBtcMsaAKMXWIAQAAACD7SnK47hmS+oee9wumJTGzXSX9SdKOzrkVOYwn51yMXogBAAAAIFdyWQL7saT1zGwtMyuTdISkMeEFzGyYpNsl7e+cm5PDWFpEbGUnTiSwAAAAAJBtOUtgnXO1ks6Q9JKkiZIed86NN7M/m9n+wWJ/k9Re0hNm9pmZjWlgdXkhFu/FiU6cAAAAACDrclmFWM65FyS9kDLt0tDjXXO5/ZYWc0EV4ojjAAAAAIBCRFFhFiX6cCKFBQAAAIBsI4HNInohBgAAAIDcIYHNIhejEycAAAAAyBUS2CyKt4GlBBYAAAAAso8ENouKg7y1XVlptIEAAAAAQAEigc2iLm194rphn04RRwIAAAAAhYcEFgAAAACQF0hgs4k2sAAAAACQMySwWRUksCKBBQAAAIBsI4HNJkpgAQAAACBnSGCzyjW9CAAAAABglZDA5gIlsAAAAACQdSSw2eQogQUAAACAXCmJOoCC0qaLdOxzUrd1o44EAAAAAAoOCWw2lZRJa+0QdRQAAAAAUJCoQgwAAAAAyAsksAAAAACAvEACCwAAAADICySwAAAAAIC8QAILAAAAAMgLJLAAAAAAgLxAAgsAAAAAyAsksAAAAACAvEACCwAAAADICySwAAAAAIC8QAILAAAAAMgLJLAAAAAAgLxAAgsAAAAAyAsksAAAAACAvEACCwAAAADIC+acizqGZjGzuZJ+iDqORnSXNC/qIABxLKJ14DhEa8GxiNaA4xCtQT4ch2s653qkm5F3CWxrZ2ZjnXPDo44D4FhEa8BxiNaCYxGtAcchWoN8Pw6pQgwAAAAAyAsksAAAAACAvEACm313RB0AEOBYRGvAcYjWgmMRrQHHIVqDvD4OaQMLAAAAAMgLlMACAAAAAPICCSwAAAAAIC+QwGaRme1pZpPMbLKZXRh1PCgsZnaPmc0xs69C07qa2Stm9m3wt0sw3czsxuBY/MLMNgu95thg+W/N7Ngo3gvyl5n1N7M3zGyCmY03s7OC6RyLaFFmVmFmH5nZ58GxeHkwfS0z+zA45h4zs7JgennwfHIwf2BoXX8Mpk8ysz0iekvIY2ZWbGafmtl/gucch2hxZjbVzL40s8/MbGwwreB+n0lgs8TMiiXdImkvSRtKGmVmG0YbFQrMfZL2TJl2oaTXnHPrSXoteC7543C94N/Jkv4p+ZOYpMskbSlphKTL4icyIEO1ks5zzm0oaStJpwfnOo5FtLQVknZ2zm0qaaikPc1sK0l/lfQP59y6khZIOjFY/kRJC4Lp/wiWU3D8HiFpI/lz7K3BbzrQHGdJmhh6znGIqOzknBsaGue14H6fSWCzZ4Skyc65Kc65akmPSjog4phQQJxzb0n6OWXyAZLuDx7fL+lXoen/ct4HkjqbWW9Je0h6xTn3s3NugaRXVD8pBhrknPvJOTcueLxY/oKtrzgW0cKCY2pJ8LQ0+Ock7SzpyWB66rEYP0aflLSLmVkw/VHn3Arn3PeSJsv/pgMZMbN+kvaRdFfw3MRxiNaj4H6fSWCzp6+kaaHn04NpQC71cs79FDyeJalX8Lih45HjFFkTVH0bJulDcSwiAkG1zc8kzZG/yPpO0kLnXG2wSPi4WnnMBfMrJXUTxyJW3/WSzpcUC553E8chouEkvWxmn5jZycG0gvt9Lok6AADZ4ZxzZsa4WGgRZtZe0lOSznbOLfIFCB7HIlqKc65O0lAz6yzpGUmDo40IvzRmtq+kOc65T8xsZMThANs552aYWU9Jr5jZ1+GZhfL7TAls9syQ1D/0vF8wDcil2UF1DwV/5wTTGzoeOU6x2sysVD55fcg593QwmWMRkXHOLZT0hqSt5avBxW/Qh4+rlcdcML+TpPniWMTq2VbS/mY2Vb752M6SbhDHISLgnJsR/J0jf1NvhArw95kENns+lrRe0OtcmXxD/DERx4TCN0ZSvHe4YyX9OzT9mKCHua0kVQbVR16StLuZdQka5O8eTAMyErTVulvSROfcdaFZHItoUWbWIyh5lZm1kbSbfJvsNyQdEiyWeizGj9FDJL3unHPB9COC3mHXku/Q5KMWeRPIe865Pzrn+jnnBspf+73unDtKHIdoYWbWzsw6xB/L/65+pQL8faYKcZY452rN7Az5D7hY0j3OufERh4UCYmaPSBopqbuZTZfvIe5qSY+b2YmSfpB0WLD4C5L2lu8EYpmk4yXJOfezmV0hf8NFkv7snEvtGApozLaSjpb0ZdD2UJIuEsciWl5vSfcHPbUWSXrcOfcfM5sg6VEzu1LSp/I3XBT8fcDMJst3iHeEJDnnxpvZ45ImyPeyfXpQNRlYHReI4xAtq5ekZ4ImPSWSHnbO/dfMPlaB/T6bv+kDAAAAAEDrRhViAAAAAEBeIIEFAAAAAOQFElgAAAAAQF4ggQUAAAAA5AUSWAAAAABAXiCBBQCgBZhZnZl9Fvp3YRbXPdDMvsrW+gAAaK0YBxYAgJax3Dk3NOogAADIZ5TAAgAQITObambXmNmXZvaRma0bTB9oZq+b2Rdm9pqZDQim9zKzZ8zs8+DfNsGqis3sTjMbb2Yvm1mbyN4UAAA5QgILAEDLaJNShfjw0LxK59wQSTdLuj6YdpOk+51zm0h6SNKNwfQbJf3PObeppM0kjQ+mryfpFufcRpIWSjo4p+8GAIAImHMu6hgAACh4ZrbEOdc+zfSpknZ2zk0xs1JJs5xz3cxsnqTezrmaYPpPzrnuZjZXUj/n3IrQOgZKesU5t17w/AJJpc65K1vgrQEA0GIogQUAIHqugcfNsSL0uE70cwEAKEAksAAARO/w0N/3g8fvSToieHyUpLeDx69JOk2SzKzYzDq1VJAAAESNu7MAALSMNmb2Wej5f51z8aF0upjZF/KlqKOCaWdKutfM/iBprqTjg+lnSbrDzE6UL2k9TdJPuQ4eAIDWgDawAABEKGgDO9w5Ny/qWAAAaO2oQgwAAAAAyAuUwAIAAAAA8gIlsAAAAACAvEACCwAAAADICySwAAAAAIC8QAILAAAAAMgLJLAAAAAAgLzw//Jt42+WNkhlAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history7,no_of_epoch, srt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "MjnEgDakELzH",
        "outputId": "1d59fcdb-fdfc-4087-ed0d-4a964ac9d30b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title=\"Confusion Matrix of pccr_mi_mean\"\n",
        "cm=confusion(y_pred,y_test)\n",
        "conf_mat2(cm,class_names,title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "umfCcjh_EN6z",
        "outputId": "e1c32cad-37a5-455b-a2f5-47878677eb9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsdgaYrHEP0A",
        "outputId": "b4d7ed5b-bbc4-4914-820f-07a31e94061b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.86      0.87        51\n",
            "           1       0.76      0.84      0.79        37\n",
            "           2       0.90      0.94      0.92        50\n",
            "           3       0.87      0.70      0.78        47\n",
            "           4       0.79      0.80      0.80        46\n",
            "           5       0.94      1.00      0.97        47\n",
            "\n",
            "    accuracy                           0.86       278\n",
            "   macro avg       0.86      0.86      0.85       278\n",
            "weighted avg       0.86      0.86      0.86       278\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelp.save(\"pccr_mi_mean.h5\")\n",
        "from google.colab import files\n",
        "files.download(\"pccr_mi_mean.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nuWNIIEoERxe",
        "outputId": "21f80bb2-a3d9-49f5-fea9-4edf08c28c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_647adc70-2498-4000-9090-9daf1a056966\", \"pccr_mi_mean.h5\", 3866768)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xcorr_mi_nmi_mean=[]"
      ],
      "metadata": {
        "id": "Y_4ky9gAI3sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### data test construction ############\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i in range(0,fall_number):\n",
        "  temp=[]\n",
        "\n",
        "  temp.append(xcorr[i])\n",
        "  temp.append(mi_score[i])\n",
        "  temp.append(partial_mi_score[i])\n",
        "  temp.append(mean_f[i])\n",
        "\n",
        "  xcorr_mi_nmi_mean.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #walk_temp=np.stack((xcorr_walk[i],pearson_corr_walk[i],mi_score_walk[i],partial_mi_score_walk[i],mean_f_walk[i]),axis=0)\n",
        "for i in range(0,walk_number):\n",
        "  temp=[]\n",
        "\n",
        "\n",
        "\n",
        "  temp.append(xcorr_walk[i])\n",
        "  temp.append(mi_score_walk[i])\n",
        "  temp.append(partial_mi_score_walk[i])\n",
        "  temp.append(mean_f_walk[i])\n",
        "\n",
        "  xcorr_mi_nmi_mean.append(temp)\n",
        "\n",
        "\n",
        "for i in range(0,sit_number):\n",
        "  temp=[]\n",
        "\n",
        "  temp.append(xcorr_sit[i])\n",
        "  temp.append(mi_score_sit[i])\n",
        "  temp.append(partial_mi_score_sit[i])\n",
        "  temp.append(mean_f_sit[i])\n",
        "\n",
        "  xcorr_mi_nmi_mean.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,bsc_number):\n",
        "  temp=[]\n",
        "\n",
        "\n",
        "\n",
        "  temp.append(xcorr_bsc[i])\n",
        "  temp.append(mi_score_bsc[i])\n",
        "  temp.append(partial_mi_score_bsc[i])\n",
        "  temp.append(mean_f_bsc[i])\n",
        "\n",
        "  xcorr_mi_nmi_mean.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,stand_number):\n",
        "  temp=[]\n",
        "\n",
        "  temp.append(xcorr_stand[i])\n",
        "  temp.append(mi_score_stand[i])\n",
        "  temp.append(partial_mi_score_stand[i])\n",
        "  temp.append(mean_f_stand[i])\n",
        "\n",
        "  xcorr_mi_nmi_mean.append(temp)\n",
        "\n",
        "\n",
        "for i in range(0,laying_number):\n",
        "  temp=[]\n",
        "\n",
        "\n",
        "  temp.append(xcorr_laying[i])\n",
        "  temp.append(mi_score_laying[i])\n",
        "  temp.append(partial_mi_score_laying[i])\n",
        "  temp.append(mean_f_laying[i])\n",
        "\n",
        "  xcorr_mi_nmi_mean.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#X_data=pd.DataFrame(data=X_data,columns=[['Xcorr','Pearson','MI','NMI','Mean']])\n",
        "#y_data=pd.DataFrame(data=y_data,columns=['Label'])\n"
      ],
      "metadata": {
        "id": "5zQrCM5hJnUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xcorr_mi_nmi_mean=np.array(xcorr_mi_nmi_mean)\n",
        "print(xcorr_mi_nmi_mean.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJRzw_5kJ8sZ",
        "outputId": "2cdecf1b-5cca-4f0e-8d7d-d3ae65b7258c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1390, 4, 16, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "def get_3d_3():\n",
        "  model1 = Sequential()\n",
        "  model1.add(Conv3D(16, (2, 7,7),kernel_initializer='normal', activation = 'relu', input_shape = (4,16,16,1)))\n",
        "\n",
        "\n",
        "  model1.add(Conv3D(128, (1, 7,7), activation='relu'))\n",
        "  model1.add(Dropout(0.25))\n",
        "\n",
        "  model1.add(Conv3D(128, (1, 3,3), activation='relu'))\n",
        "  model1.add(Dropout(0.25))\n",
        "\n",
        "  model1.add(MaxPool3D((1, 2,2)))\n",
        "  model1.add(BatchNormalization())\n",
        "\n",
        "  model1.add(Flatten())\n",
        "\n",
        "  model1.add(Dense(256, activation = 'relu'))\n",
        "  model1.add(Dropout(0.25))\n",
        "\n",
        "  model1.add(Dense(6, activation='softmax',kernel_regularizer=l2(0.01)))\n",
        "  return model1"
      ],
      "metadata": {
        "id": "qDHLc1R1KTN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"xcorr_mi_nmi_mean.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "#es = EarlyStopping(monitor='val_loss', patience=100, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "yJPGl1x8KX6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_data=y_temp\n",
        "yenc = sklearn.preprocessing.LabelEncoder()\n",
        "y_data = yenc.fit_transform(y_data)\n",
        "X_train, X_test, y_train, y_test = train_test_split(xcorr_mi_nmi_mean, y_data, test_size = 0.20, random_state = 42)\n",
        "\n",
        "#X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.10, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 4,16, 16,1)\n",
        "X_test = X_test.reshape(X_test.shape[0],4, 16,16,1)\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOMasYgSKakp",
        "outputId": "0c038e76-cc7c-4001-e0f6-62609b2e65c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1112, 4, 16, 16, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8=get_3d_3()\n",
        "model8.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8jPKLrtKcwB",
        "outputId": "0400390e-99ba-4036-cca6-ab4466d5c6d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 3, 10, 10, 16)     1584      \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 3, 4, 4, 128)      100480    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 3, 4, 4, 128)      0         \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 3, 2, 2, 128)      147584    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3, 2, 2, 128)      0         \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 3, 1, 1, 128)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 3, 1, 1, 128)     512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 384)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               98560     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 350,262\n",
            "Trainable params: 350,006\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8.compile(optimizer=Adam(learning_rate = 0.00001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "history8 = model8.fit(X_train, y_train,batch_size = 128, epochs = no_of_epoch, validation_data= (X_test, y_test),callbacks=callbacks_list,verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3uG4KZ5Ke_x",
        "outputId": "8d2663a5-a207-4887-bec3-702b9cdc258a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3751/5000\n",
            "\n",
            "Epoch 3751: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8165 - val_accuracy: 0.7662 - 4s/epoch - 429ms/step\n",
            "Epoch 3752/5000\n",
            "\n",
            "Epoch 3752: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8121 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 3753/5000\n",
            "\n",
            "Epoch 3753: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8037 - val_accuracy: 0.7698 - 2s/epoch - 278ms/step\n",
            "Epoch 3754/5000\n",
            "\n",
            "Epoch 3754: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7936 - val_accuracy: 0.7770 - 3s/epoch - 294ms/step\n",
            "Epoch 3755/5000\n",
            "\n",
            "Epoch 3755: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7947 - val_accuracy: 0.7734 - 4s/epoch - 393ms/step\n",
            "Epoch 3756/5000\n",
            "\n",
            "Epoch 3756: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7995 - val_accuracy: 0.7734 - 3s/epoch - 375ms/step\n",
            "Epoch 3757/5000\n",
            "\n",
            "Epoch 3757: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8060 - val_accuracy: 0.7698 - 3s/epoch - 284ms/step\n",
            "Epoch 3758/5000\n",
            "\n",
            "Epoch 3758: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.7973 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 3759/5000\n",
            "\n",
            "Epoch 3759: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.7734 - 3s/epoch - 303ms/step\n",
            "Epoch 3760/5000\n",
            "\n",
            "Epoch 3760: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.7698 - 4s/epoch - 493ms/step\n",
            "Epoch 3761/5000\n",
            "\n",
            "Epoch 3761: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7734 - 3s/epoch - 288ms/step\n",
            "Epoch 3762/5000\n",
            "\n",
            "Epoch 3762: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8064 - val_accuracy: 0.7734 - 3s/epoch - 281ms/step\n",
            "Epoch 3763/5000\n",
            "\n",
            "Epoch 3763: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 3764/5000\n",
            "\n",
            "Epoch 3764: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8059 - val_accuracy: 0.7770 - 3s/epoch - 356ms/step\n",
            "Epoch 3765/5000\n",
            "\n",
            "Epoch 3765: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8072 - val_accuracy: 0.7662 - 4s/epoch - 421ms/step\n",
            "Epoch 3766/5000\n",
            "\n",
            "Epoch 3766: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8082 - val_accuracy: 0.7662 - 3s/epoch - 293ms/step\n",
            "Epoch 3767/5000\n",
            "\n",
            "Epoch 3767: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8100 - val_accuracy: 0.7662 - 3s/epoch - 302ms/step\n",
            "Epoch 3768/5000\n",
            "\n",
            "Epoch 3768: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.7662 - 3s/epoch - 288ms/step\n",
            "Epoch 3769/5000\n",
            "\n",
            "Epoch 3769: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.7662 - 4s/epoch - 417ms/step\n",
            "Epoch 3770/5000\n",
            "\n",
            "Epoch 3770: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7662 - 3s/epoch - 349ms/step\n",
            "Epoch 3771/5000\n",
            "\n",
            "Epoch 3771: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.7662 - 3s/epoch - 296ms/step\n",
            "Epoch 3772/5000\n",
            "\n",
            "Epoch 3772: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.7626 - 3s/epoch - 282ms/step\n",
            "Epoch 3773/5000\n",
            "\n",
            "Epoch 3773: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.7662 - 3s/epoch - 295ms/step\n",
            "Epoch 3774/5000\n",
            "\n",
            "Epoch 3774: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.7662 - 4s/epoch - 481ms/step\n",
            "Epoch 3775/5000\n",
            "\n",
            "Epoch 3775: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.7698 - 3s/epoch - 279ms/step\n",
            "Epoch 3776/5000\n",
            "\n",
            "Epoch 3776: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7989 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 3777/5000\n",
            "\n",
            "Epoch 3777: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7995 - val_accuracy: 0.7698 - 2s/epoch - 276ms/step\n",
            "Epoch 3778/5000\n",
            "\n",
            "Epoch 3778: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.7698 - 3s/epoch - 313ms/step\n",
            "Epoch 3779/5000\n",
            "\n",
            "Epoch 3779: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7897 - val_accuracy: 0.7734 - 4s/epoch - 463ms/step\n",
            "Epoch 3780/5000\n",
            "\n",
            "Epoch 3780: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7903 - val_accuracy: 0.7734 - 3s/epoch - 290ms/step\n",
            "Epoch 3781/5000\n",
            "\n",
            "Epoch 3781: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.7734 - 3s/epoch - 292ms/step\n",
            "Epoch 3782/5000\n",
            "\n",
            "Epoch 3782: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8028 - val_accuracy: 0.7734 - 3s/epoch - 282ms/step\n",
            "Epoch 3783/5000\n",
            "\n",
            "Epoch 3783: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.7662 - 3s/epoch - 385ms/step\n",
            "Epoch 3784/5000\n",
            "\n",
            "Epoch 3784: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7662 - 3s/epoch - 386ms/step\n",
            "Epoch 3785/5000\n",
            "\n",
            "Epoch 3785: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 3786/5000\n",
            "\n",
            "Epoch 3786: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.7734 - 3s/epoch - 282ms/step\n",
            "Epoch 3787/5000\n",
            "\n",
            "Epoch 3787: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 3788/5000\n",
            "\n",
            "Epoch 3788: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.7698 - 4s/epoch - 447ms/step\n",
            "Epoch 3789/5000\n",
            "\n",
            "Epoch 3789: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8095 - val_accuracy: 0.7626 - 3s/epoch - 308ms/step\n",
            "Epoch 3790/5000\n",
            "\n",
            "Epoch 3790: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8063 - val_accuracy: 0.7662 - 3s/epoch - 295ms/step\n",
            "Epoch 3791/5000\n",
            "\n",
            "Epoch 3791: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.7698 - 3s/epoch - 298ms/step\n",
            "Epoch 3792/5000\n",
            "\n",
            "Epoch 3792: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 3793/5000\n",
            "\n",
            "Epoch 3793: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.7662 - 4s/epoch - 460ms/step\n",
            "Epoch 3794/5000\n",
            "\n",
            "Epoch 3794: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.7662 - 3s/epoch - 295ms/step\n",
            "Epoch 3795/5000\n",
            "\n",
            "Epoch 3795: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.7590 - 3s/epoch - 280ms/step\n",
            "Epoch 3796/5000\n",
            "\n",
            "Epoch 3796: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7972 - val_accuracy: 0.7590 - 3s/epoch - 292ms/step\n",
            "Epoch 3797/5000\n",
            "\n",
            "Epoch 3797: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.7662 - 3s/epoch - 371ms/step\n",
            "Epoch 3798/5000\n",
            "\n",
            "Epoch 3798: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7953 - val_accuracy: 0.7626 - 4s/epoch - 402ms/step\n",
            "Epoch 3799/5000\n",
            "\n",
            "Epoch 3799: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7945 - val_accuracy: 0.7662 - 3s/epoch - 295ms/step\n",
            "Epoch 3800/5000\n",
            "\n",
            "Epoch 3800: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.7770 - 3s/epoch - 284ms/step\n",
            "Epoch 3801/5000\n",
            "\n",
            "Epoch 3801: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8065 - val_accuracy: 0.7734 - 3s/epoch - 292ms/step\n",
            "Epoch 3802/5000\n",
            "\n",
            "Epoch 3802: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8097 - val_accuracy: 0.7734 - 4s/epoch - 422ms/step\n",
            "Epoch 3803/5000\n",
            "\n",
            "Epoch 3803: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8072 - val_accuracy: 0.7770 - 3s/epoch - 348ms/step\n",
            "Epoch 3804/5000\n",
            "\n",
            "Epoch 3804: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 3805/5000\n",
            "\n",
            "Epoch 3805: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8082 - val_accuracy: 0.7626 - 3s/epoch - 295ms/step\n",
            "Epoch 3806/5000\n",
            "\n",
            "Epoch 3806: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.7626 - 3s/epoch - 299ms/step\n",
            "Epoch 3807/5000\n",
            "\n",
            "Epoch 3807: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8204 - val_accuracy: 0.7698 - 4s/epoch - 478ms/step\n",
            "Epoch 3808/5000\n",
            "\n",
            "Epoch 3808: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8204 - val_accuracy: 0.7626 - 3s/epoch - 282ms/step\n",
            "Epoch 3809/5000\n",
            "\n",
            "Epoch 3809: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8236 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 3810/5000\n",
            "\n",
            "Epoch 3810: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 3811/5000\n",
            "\n",
            "Epoch 3811: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8037 - val_accuracy: 0.7770 - 3s/epoch - 379ms/step\n",
            "Epoch 3812/5000\n",
            "\n",
            "Epoch 3812: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.7770 - 3s/epoch - 383ms/step\n",
            "Epoch 3813/5000\n",
            "\n",
            "Epoch 3813: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8059 - val_accuracy: 0.7734 - 3s/epoch - 289ms/step\n",
            "Epoch 3814/5000\n",
            "\n",
            "Epoch 3814: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.7734 - 3s/epoch - 288ms/step\n",
            "Epoch 3815/5000\n",
            "\n",
            "Epoch 3815: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 3816/5000\n",
            "\n",
            "Epoch 3816: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7943 - val_accuracy: 0.7806 - 4s/epoch - 428ms/step\n",
            "Epoch 3817/5000\n",
            "\n",
            "Epoch 3817: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7945 - val_accuracy: 0.7770 - 3s/epoch - 335ms/step\n",
            "Epoch 3818/5000\n",
            "\n",
            "Epoch 3818: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.7770 - 2s/epoch - 278ms/step\n",
            "Epoch 3819/5000\n",
            "\n",
            "Epoch 3819: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7945 - val_accuracy: 0.7806 - 3s/epoch - 279ms/step\n",
            "Epoch 3820/5000\n",
            "\n",
            "Epoch 3820: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7935 - val_accuracy: 0.7806 - 3s/epoch - 298ms/step\n",
            "Epoch 3821/5000\n",
            "\n",
            "Epoch 3821: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7977 - val_accuracy: 0.7806 - 4s/epoch - 495ms/step\n",
            "Epoch 3822/5000\n",
            "\n",
            "Epoch 3822: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.7806 - 3s/epoch - 295ms/step\n",
            "Epoch 3823/5000\n",
            "\n",
            "Epoch 3823: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.7698 - 2s/epoch - 270ms/step\n",
            "Epoch 3824/5000\n",
            "\n",
            "Epoch 3824: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8000 - val_accuracy: 0.7698 - 3s/epoch - 278ms/step\n",
            "Epoch 3825/5000\n",
            "\n",
            "Epoch 3825: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8016 - val_accuracy: 0.7698 - 3s/epoch - 301ms/step\n",
            "Epoch 3826/5000\n",
            "\n",
            "Epoch 3826: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.7734 - 4s/epoch - 458ms/step\n",
            "Epoch 3827/5000\n",
            "\n",
            "Epoch 3827: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8073 - val_accuracy: 0.7770 - 3s/epoch - 292ms/step\n",
            "Epoch 3828/5000\n",
            "\n",
            "Epoch 3828: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7969 - val_accuracy: 0.7806 - 3s/epoch - 285ms/step\n",
            "Epoch 3829/5000\n",
            "\n",
            "Epoch 3829: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7930 - val_accuracy: 0.7770 - 3s/epoch - 278ms/step\n",
            "Epoch 3830/5000\n",
            "\n",
            "Epoch 3830: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7977 - val_accuracy: 0.7734 - 3s/epoch - 384ms/step\n",
            "Epoch 3831/5000\n",
            "\n",
            "Epoch 3831: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.7842 - 3s/epoch - 385ms/step\n",
            "Epoch 3832/5000\n",
            "\n",
            "Epoch 3832: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.7770 - 3s/epoch - 287ms/step\n",
            "Epoch 3833/5000\n",
            "\n",
            "Epoch 3833: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.7770 - 3s/epoch - 280ms/step\n",
            "Epoch 3834/5000\n",
            "\n",
            "Epoch 3834: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7969 - val_accuracy: 0.7806 - 2s/epoch - 275ms/step\n",
            "Epoch 3835/5000\n",
            "\n",
            "Epoch 3835: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.7770 - 4s/epoch - 398ms/step\n",
            "Epoch 3836/5000\n",
            "\n",
            "Epoch 3836: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7975 - val_accuracy: 0.7770 - 3s/epoch - 360ms/step\n",
            "Epoch 3837/5000\n",
            "\n",
            "Epoch 3837: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7937 - val_accuracy: 0.7806 - 3s/epoch - 290ms/step\n",
            "Epoch 3838/5000\n",
            "\n",
            "Epoch 3838: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.7806 - 3s/epoch - 299ms/step\n",
            "Epoch 3839/5000\n",
            "\n",
            "Epoch 3839: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7845 - val_accuracy: 0.7806 - 3s/epoch - 305ms/step\n",
            "Epoch 3840/5000\n",
            "\n",
            "Epoch 3840: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7904 - val_accuracy: 0.7770 - 4s/epoch - 483ms/step\n",
            "Epoch 3841/5000\n",
            "\n",
            "Epoch 3841: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 3842/5000\n",
            "\n",
            "Epoch 3842: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 3843/5000\n",
            "\n",
            "Epoch 3843: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.7806 - 3s/epoch - 294ms/step\n",
            "Epoch 3844/5000\n",
            "\n",
            "Epoch 3844: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8007 - val_accuracy: 0.7806 - 3s/epoch - 319ms/step\n",
            "Epoch 3845/5000\n",
            "\n",
            "Epoch 3845: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.7734 - 4s/epoch - 455ms/step\n",
            "Epoch 3846/5000\n",
            "\n",
            "Epoch 3846: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.7734 - 3s/epoch - 284ms/step\n",
            "Epoch 3847/5000\n",
            "\n",
            "Epoch 3847: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7899 - val_accuracy: 0.7770 - 3s/epoch - 303ms/step\n",
            "Epoch 3848/5000\n",
            "\n",
            "Epoch 3848: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7919 - val_accuracy: 0.7770 - 3s/epoch - 289ms/step\n",
            "Epoch 3849/5000\n",
            "\n",
            "Epoch 3849: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7909 - val_accuracy: 0.7734 - 4s/epoch - 400ms/step\n",
            "Epoch 3850/5000\n",
            "\n",
            "Epoch 3850: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7930 - val_accuracy: 0.7698 - 4s/epoch - 399ms/step\n",
            "Epoch 3851/5000\n",
            "\n",
            "Epoch 3851: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7951 - val_accuracy: 0.7662 - 3s/epoch - 298ms/step\n",
            "Epoch 3852/5000\n",
            "\n",
            "Epoch 3852: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7966 - val_accuracy: 0.7770 - 3s/epoch - 284ms/step\n",
            "Epoch 3853/5000\n",
            "\n",
            "Epoch 3853: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7945 - val_accuracy: 0.7770 - 2s/epoch - 270ms/step\n",
            "Epoch 3854/5000\n",
            "\n",
            "Epoch 3854: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7982 - val_accuracy: 0.7770 - 4s/epoch - 450ms/step\n",
            "Epoch 3855/5000\n",
            "\n",
            "Epoch 3855: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8011 - val_accuracy: 0.7734 - 3s/epoch - 322ms/step\n",
            "Epoch 3856/5000\n",
            "\n",
            "Epoch 3856: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8071 - val_accuracy: 0.7770 - 2s/epoch - 276ms/step\n",
            "Epoch 3857/5000\n",
            "\n",
            "Epoch 3857: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8117 - val_accuracy: 0.7806 - 3s/epoch - 296ms/step\n",
            "Epoch 3858/5000\n",
            "\n",
            "Epoch 3858: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8075 - val_accuracy: 0.7806 - 2s/epoch - 272ms/step\n",
            "Epoch 3859/5000\n",
            "\n",
            "Epoch 3859: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8075 - val_accuracy: 0.7734 - 4s/epoch - 483ms/step\n",
            "Epoch 3860/5000\n",
            "\n",
            "Epoch 3860: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8116 - val_accuracy: 0.7734 - 3s/epoch - 303ms/step\n",
            "Epoch 3861/5000\n",
            "\n",
            "Epoch 3861: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8118 - val_accuracy: 0.7734 - 3s/epoch - 293ms/step\n",
            "Epoch 3862/5000\n",
            "\n",
            "Epoch 3862: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8066 - val_accuracy: 0.7770 - 3s/epoch - 290ms/step\n",
            "Epoch 3863/5000\n",
            "\n",
            "Epoch 3863: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.7698 - 3s/epoch - 386ms/step\n",
            "Epoch 3864/5000\n",
            "\n",
            "Epoch 3864: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8027 - val_accuracy: 0.7698 - 3s/epoch - 384ms/step\n",
            "Epoch 3865/5000\n",
            "\n",
            "Epoch 3865: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8089 - val_accuracy: 0.7734 - 3s/epoch - 292ms/step\n",
            "Epoch 3866/5000\n",
            "\n",
            "Epoch 3866: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8059 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 3867/5000\n",
            "\n",
            "Epoch 3867: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8072 - val_accuracy: 0.7734 - 3s/epoch - 278ms/step\n",
            "Epoch 3868/5000\n",
            "\n",
            "Epoch 3868: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8094 - val_accuracy: 0.7734 - 4s/epoch - 439ms/step\n",
            "Epoch 3869/5000\n",
            "\n",
            "Epoch 3869: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8016 - val_accuracy: 0.7662 - 3s/epoch - 327ms/step\n",
            "Epoch 3870/5000\n",
            "\n",
            "Epoch 3870: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7919 - val_accuracy: 0.7770 - 3s/epoch - 288ms/step\n",
            "Epoch 3871/5000\n",
            "\n",
            "Epoch 3871: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7816 - val_accuracy: 0.7770 - 3s/epoch - 299ms/step\n",
            "Epoch 3872/5000\n",
            "\n",
            "Epoch 3872: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7815 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 3873/5000\n",
            "\n",
            "Epoch 3873: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7915 - val_accuracy: 0.7662 - 4s/epoch - 473ms/step\n",
            "Epoch 3874/5000\n",
            "\n",
            "Epoch 3874: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7995 - val_accuracy: 0.7662 - 3s/epoch - 295ms/step\n",
            "Epoch 3875/5000\n",
            "\n",
            "Epoch 3875: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7982 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 3876/5000\n",
            "\n",
            "Epoch 3876: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7875 - val_accuracy: 0.7806 - 3s/epoch - 282ms/step\n",
            "Epoch 3877/5000\n",
            "\n",
            "Epoch 3877: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7813 - val_accuracy: 0.7770 - 4s/epoch - 395ms/step\n",
            "Epoch 3878/5000\n",
            "\n",
            "Epoch 3878: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7788 - val_accuracy: 0.7734 - 3s/epoch - 381ms/step\n",
            "Epoch 3879/5000\n",
            "\n",
            "Epoch 3879: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7928 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 3880/5000\n",
            "\n",
            "Epoch 3880: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.7698 - 3s/epoch - 294ms/step\n",
            "Epoch 3881/5000\n",
            "\n",
            "Epoch 3881: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8007 - val_accuracy: 0.7662 - 3s/epoch - 298ms/step\n",
            "Epoch 3882/5000\n",
            "\n",
            "Epoch 3882: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7995 - val_accuracy: 0.7662 - 4s/epoch - 460ms/step\n",
            "Epoch 3883/5000\n",
            "\n",
            "Epoch 3883: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.7626 - 3s/epoch - 285ms/step\n",
            "Epoch 3884/5000\n",
            "\n",
            "Epoch 3884: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.7662 - 3s/epoch - 295ms/step\n",
            "Epoch 3885/5000\n",
            "\n",
            "Epoch 3885: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8071 - val_accuracy: 0.7662 - 3s/epoch - 291ms/step\n",
            "Epoch 3886/5000\n",
            "\n",
            "Epoch 3886: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8160 - val_accuracy: 0.7698 - 3s/epoch - 299ms/step\n",
            "Epoch 3887/5000\n",
            "\n",
            "Epoch 3887: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7954 - val_accuracy: 0.7770 - 4s/epoch - 466ms/step\n",
            "Epoch 3888/5000\n",
            "\n",
            "Epoch 3888: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7838 - val_accuracy: 0.7698 - 3s/epoch - 298ms/step\n",
            "Epoch 3889/5000\n",
            "\n",
            "Epoch 3889: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7828 - val_accuracy: 0.7662 - 3s/epoch - 300ms/step\n",
            "Epoch 3890/5000\n",
            "\n",
            "Epoch 3890: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.7662 - 3s/epoch - 296ms/step\n",
            "Epoch 3891/5000\n",
            "\n",
            "Epoch 3891: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.7698 - 4s/epoch - 419ms/step\n",
            "Epoch 3892/5000\n",
            "\n",
            "Epoch 3892: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7933 - val_accuracy: 0.7698 - 3s/epoch - 351ms/step\n",
            "Epoch 3893/5000\n",
            "\n",
            "Epoch 3893: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7971 - val_accuracy: 0.7698 - 3s/epoch - 287ms/step\n",
            "Epoch 3894/5000\n",
            "\n",
            "Epoch 3894: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7967 - val_accuracy: 0.7698 - 3s/epoch - 297ms/step\n",
            "Epoch 3895/5000\n",
            "\n",
            "Epoch 3895: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7884 - val_accuracy: 0.7662 - 3s/epoch - 296ms/step\n",
            "Epoch 3896/5000\n",
            "\n",
            "Epoch 3896: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7805 - val_accuracy: 0.7662 - 4s/epoch - 479ms/step\n",
            "Epoch 3897/5000\n",
            "\n",
            "Epoch 3897: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7786 - val_accuracy: 0.7698 - 2s/epoch - 269ms/step\n",
            "Epoch 3898/5000\n",
            "\n",
            "Epoch 3898: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7812 - val_accuracy: 0.7662 - 3s/epoch - 278ms/step\n",
            "Epoch 3899/5000\n",
            "\n",
            "Epoch 3899: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7814 - val_accuracy: 0.7734 - 2s/epoch - 275ms/step\n",
            "Epoch 3900/5000\n",
            "\n",
            "Epoch 3900: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.7698 - 3s/epoch - 300ms/step\n",
            "Epoch 3901/5000\n",
            "\n",
            "Epoch 3901: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8006 - val_accuracy: 0.7698 - 4s/epoch - 475ms/step\n",
            "Epoch 3902/5000\n",
            "\n",
            "Epoch 3902: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7933 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 3903/5000\n",
            "\n",
            "Epoch 3903: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7922 - val_accuracy: 0.7698 - 3s/epoch - 285ms/step\n",
            "Epoch 3904/5000\n",
            "\n",
            "Epoch 3904: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7933 - val_accuracy: 0.7698 - 3s/epoch - 284ms/step\n",
            "Epoch 3905/5000\n",
            "\n",
            "Epoch 3905: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.7662 - 3s/epoch - 376ms/step\n",
            "Epoch 3906/5000\n",
            "\n",
            "Epoch 3906: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7886 - val_accuracy: 0.7662 - 3s/epoch - 376ms/step\n",
            "Epoch 3907/5000\n",
            "\n",
            "Epoch 3907: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7902 - val_accuracy: 0.7662 - 3s/epoch - 298ms/step\n",
            "Epoch 3908/5000\n",
            "\n",
            "Epoch 3908: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7777 - val_accuracy: 0.7662 - 3s/epoch - 312ms/step\n",
            "Epoch 3909/5000\n",
            "\n",
            "Epoch 3909: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7767 - val_accuracy: 0.7734 - 3s/epoch - 334ms/step\n",
            "Epoch 3910/5000\n",
            "\n",
            "Epoch 3910: val_accuracy did not improve from 0.78417\n",
            "9/9 - 5s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7780 - val_accuracy: 0.7698 - 5s/epoch - 503ms/step\n",
            "Epoch 3911/5000\n",
            "\n",
            "Epoch 3911: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7836 - val_accuracy: 0.7698 - 3s/epoch - 331ms/step\n",
            "Epoch 3912/5000\n",
            "\n",
            "Epoch 3912: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7892 - val_accuracy: 0.7698 - 3s/epoch - 299ms/step\n",
            "Epoch 3913/5000\n",
            "\n",
            "Epoch 3913: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7911 - val_accuracy: 0.7698 - 3s/epoch - 315ms/step\n",
            "Epoch 3914/5000\n",
            "\n",
            "Epoch 3914: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7919 - val_accuracy: 0.7698 - 3s/epoch - 367ms/step\n",
            "Epoch 3915/5000\n",
            "\n",
            "Epoch 3915: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7885 - val_accuracy: 0.7734 - 4s/epoch - 474ms/step\n",
            "Epoch 3916/5000\n",
            "\n",
            "Epoch 3916: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7947 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 3917/5000\n",
            "\n",
            "Epoch 3917: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.7734 - 3s/epoch - 303ms/step\n",
            "Epoch 3918/5000\n",
            "\n",
            "Epoch 3918: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7932 - val_accuracy: 0.7698 - 3s/epoch - 316ms/step\n",
            "Epoch 3919/5000\n",
            "\n",
            "Epoch 3919: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7929 - val_accuracy: 0.7698 - 4s/epoch - 447ms/step\n",
            "Epoch 3920/5000\n",
            "\n",
            "Epoch 3920: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7964 - val_accuracy: 0.7662 - 3s/epoch - 336ms/step\n",
            "Epoch 3921/5000\n",
            "\n",
            "Epoch 3921: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7957 - val_accuracy: 0.7662 - 3s/epoch - 315ms/step\n",
            "Epoch 3922/5000\n",
            "\n",
            "Epoch 3922: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 3923/5000\n",
            "\n",
            "Epoch 3923: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7884 - val_accuracy: 0.7698 - 3s/epoch - 307ms/step\n",
            "Epoch 3924/5000\n",
            "\n",
            "Epoch 3924: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7866 - val_accuracy: 0.7662 - 4s/epoch - 484ms/step\n",
            "Epoch 3925/5000\n",
            "\n",
            "Epoch 3925: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7898 - val_accuracy: 0.7662 - 3s/epoch - 282ms/step\n",
            "Epoch 3926/5000\n",
            "\n",
            "Epoch 3926: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7860 - val_accuracy: 0.7698 - 3s/epoch - 293ms/step\n",
            "Epoch 3927/5000\n",
            "\n",
            "Epoch 3927: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7814 - val_accuracy: 0.7698 - 3s/epoch - 303ms/step\n",
            "Epoch 3928/5000\n",
            "\n",
            "Epoch 3928: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7853 - val_accuracy: 0.7698 - 4s/epoch - 413ms/step\n",
            "Epoch 3929/5000\n",
            "\n",
            "Epoch 3929: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7887 - val_accuracy: 0.7662 - 4s/epoch - 409ms/step\n",
            "Epoch 3930/5000\n",
            "\n",
            "Epoch 3930: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7935 - val_accuracy: 0.7662 - 3s/epoch - 302ms/step\n",
            "Epoch 3931/5000\n",
            "\n",
            "Epoch 3931: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.7662 - 3s/epoch - 302ms/step\n",
            "Epoch 3932/5000\n",
            "\n",
            "Epoch 3932: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7860 - val_accuracy: 0.7662 - 3s/epoch - 304ms/step\n",
            "Epoch 3933/5000\n",
            "\n",
            "Epoch 3933: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7876 - val_accuracy: 0.7698 - 4s/epoch - 454ms/step\n",
            "Epoch 3934/5000\n",
            "\n",
            "Epoch 3934: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7910 - val_accuracy: 0.7662 - 3s/epoch - 342ms/step\n",
            "Epoch 3935/5000\n",
            "\n",
            "Epoch 3935: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8018 - val_accuracy: 0.7590 - 3s/epoch - 309ms/step\n",
            "Epoch 3936/5000\n",
            "\n",
            "Epoch 3936: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.7626 - 3s/epoch - 312ms/step\n",
            "Epoch 3937/5000\n",
            "\n",
            "Epoch 3937: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7908 - val_accuracy: 0.7590 - 3s/epoch - 344ms/step\n",
            "Epoch 3938/5000\n",
            "\n",
            "Epoch 3938: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.7590 - 4s/epoch - 433ms/step\n",
            "Epoch 3939/5000\n",
            "\n",
            "Epoch 3939: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7830 - val_accuracy: 0.7626 - 3s/epoch - 295ms/step\n",
            "Epoch 3940/5000\n",
            "\n",
            "Epoch 3940: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7839 - val_accuracy: 0.7662 - 3s/epoch - 309ms/step\n",
            "Epoch 3941/5000\n",
            "\n",
            "Epoch 3941: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7750 - val_accuracy: 0.7698 - 3s/epoch - 312ms/step\n",
            "Epoch 3942/5000\n",
            "\n",
            "Epoch 3942: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 0.7734 - 4s/epoch - 418ms/step\n",
            "Epoch 3943/5000\n",
            "\n",
            "Epoch 3943: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.7734 - 3s/epoch - 381ms/step\n",
            "Epoch 3944/5000\n",
            "\n",
            "Epoch 3944: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7937 - val_accuracy: 0.7662 - 3s/epoch - 314ms/step\n",
            "Epoch 3945/5000\n",
            "\n",
            "Epoch 3945: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7929 - val_accuracy: 0.7590 - 3s/epoch - 309ms/step\n",
            "Epoch 3946/5000\n",
            "\n",
            "Epoch 3946: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7965 - val_accuracy: 0.7590 - 3s/epoch - 287ms/step\n",
            "Epoch 3947/5000\n",
            "\n",
            "Epoch 3947: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.7698 - 4s/epoch - 479ms/step\n",
            "Epoch 3948/5000\n",
            "\n",
            "Epoch 3948: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7865 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 3949/5000\n",
            "\n",
            "Epoch 3949: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7898 - val_accuracy: 0.7806 - 3s/epoch - 297ms/step\n",
            "Epoch 3950/5000\n",
            "\n",
            "Epoch 3950: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7915 - val_accuracy: 0.7806 - 3s/epoch - 294ms/step\n",
            "Epoch 3951/5000\n",
            "\n",
            "Epoch 3951: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.7806 - 3s/epoch - 363ms/step\n",
            "Epoch 3952/5000\n",
            "\n",
            "Epoch 3952: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.7806 - 4s/epoch - 445ms/step\n",
            "Epoch 3953/5000\n",
            "\n",
            "Epoch 3953: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.7734 - 3s/epoch - 298ms/step\n",
            "Epoch 3954/5000\n",
            "\n",
            "Epoch 3954: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7915 - val_accuracy: 0.7734 - 3s/epoch - 309ms/step\n",
            "Epoch 3955/5000\n",
            "\n",
            "Epoch 3955: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7931 - val_accuracy: 0.7734 - 3s/epoch - 314ms/step\n",
            "Epoch 3956/5000\n",
            "\n",
            "Epoch 3956: val_accuracy did not improve from 0.78417\n",
            "9/9 - 5s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7874 - val_accuracy: 0.7734 - 5s/epoch - 526ms/step\n",
            "Epoch 3957/5000\n",
            "\n",
            "Epoch 3957: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7821 - val_accuracy: 0.7770 - 3s/epoch - 310ms/step\n",
            "Epoch 3958/5000\n",
            "\n",
            "Epoch 3958: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7834 - val_accuracy: 0.7698 - 3s/epoch - 280ms/step\n",
            "Epoch 3959/5000\n",
            "\n",
            "Epoch 3959: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7885 - val_accuracy: 0.7734 - 3s/epoch - 281ms/step\n",
            "Epoch 3960/5000\n",
            "\n",
            "Epoch 3960: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.7862 - val_accuracy: 0.7698 - 3s/epoch - 307ms/step\n",
            "Epoch 3961/5000\n",
            "\n",
            "Epoch 3961: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7926 - val_accuracy: 0.7698 - 4s/epoch - 469ms/step\n",
            "Epoch 3962/5000\n",
            "\n",
            "Epoch 3962: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7966 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 3963/5000\n",
            "\n",
            "Epoch 3963: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8043 - val_accuracy: 0.7590 - 3s/epoch - 299ms/step\n",
            "Epoch 3964/5000\n",
            "\n",
            "Epoch 3964: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8113 - val_accuracy: 0.7662 - 3s/epoch - 291ms/step\n",
            "Epoch 3965/5000\n",
            "\n",
            "Epoch 3965: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8126 - val_accuracy: 0.7698 - 3s/epoch - 362ms/step\n",
            "Epoch 3966/5000\n",
            "\n",
            "Epoch 3966: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8061 - val_accuracy: 0.7698 - 4s/epoch - 398ms/step\n",
            "Epoch 3967/5000\n",
            "\n",
            "Epoch 3967: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.7698 - 3s/epoch - 293ms/step\n",
            "Epoch 3968/5000\n",
            "\n",
            "Epoch 3968: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7995 - val_accuracy: 0.7662 - 3s/epoch - 333ms/step\n",
            "Epoch 3969/5000\n",
            "\n",
            "Epoch 3969: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8024 - val_accuracy: 0.7698 - 3s/epoch - 322ms/step\n",
            "Epoch 3970/5000\n",
            "\n",
            "Epoch 3970: val_accuracy did not improve from 0.78417\n",
            "9/9 - 5s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8069 - val_accuracy: 0.7734 - 5s/epoch - 524ms/step\n",
            "Epoch 3971/5000\n",
            "\n",
            "Epoch 3971: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8070 - val_accuracy: 0.7734 - 3s/epoch - 310ms/step\n",
            "Epoch 3972/5000\n",
            "\n",
            "Epoch 3972: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.7662 - 3s/epoch - 298ms/step\n",
            "Epoch 3973/5000\n",
            "\n",
            "Epoch 3973: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8007 - val_accuracy: 0.7734 - 3s/epoch - 306ms/step\n",
            "Epoch 3974/5000\n",
            "\n",
            "Epoch 3974: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8030 - val_accuracy: 0.7626 - 3s/epoch - 314ms/step\n",
            "Epoch 3975/5000\n",
            "\n",
            "Epoch 3975: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8061 - val_accuracy: 0.7698 - 4s/epoch - 496ms/step\n",
            "Epoch 3976/5000\n",
            "\n",
            "Epoch 3976: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8069 - val_accuracy: 0.7698 - 3s/epoch - 305ms/step\n",
            "Epoch 3977/5000\n",
            "\n",
            "Epoch 3977: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8010 - val_accuracy: 0.7698 - 3s/epoch - 310ms/step\n",
            "Epoch 3978/5000\n",
            "\n",
            "Epoch 3978: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.7698 - 3s/epoch - 308ms/step\n",
            "Epoch 3979/5000\n",
            "\n",
            "Epoch 3979: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8013 - val_accuracy: 0.7698 - 4s/epoch - 422ms/step\n",
            "Epoch 3980/5000\n",
            "\n",
            "Epoch 3980: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8008 - val_accuracy: 0.7698 - 4s/epoch - 397ms/step\n",
            "Epoch 3981/5000\n",
            "\n",
            "Epoch 3981: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.7770 - 3s/epoch - 307ms/step\n",
            "Epoch 3982/5000\n",
            "\n",
            "Epoch 3982: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.7698 - 3s/epoch - 301ms/step\n",
            "Epoch 3983/5000\n",
            "\n",
            "Epoch 3983: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.7698 - 3s/epoch - 298ms/step\n",
            "Epoch 3984/5000\n",
            "\n",
            "Epoch 3984: val_accuracy did not improve from 0.78417\n",
            "9/9 - 5s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8061 - val_accuracy: 0.7698 - 5s/epoch - 513ms/step\n",
            "Epoch 3985/5000\n",
            "\n",
            "Epoch 3985: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8126 - val_accuracy: 0.7662 - 3s/epoch - 284ms/step\n",
            "Epoch 3986/5000\n",
            "\n",
            "Epoch 3986: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8166 - val_accuracy: 0.7662 - 3s/epoch - 309ms/step\n",
            "Epoch 3987/5000\n",
            "\n",
            "Epoch 3987: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.7698 - 3s/epoch - 313ms/step\n",
            "Epoch 3988/5000\n",
            "\n",
            "Epoch 3988: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.7770 - 3s/epoch - 361ms/step\n",
            "Epoch 3989/5000\n",
            "\n",
            "Epoch 3989: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.7734 - 4s/epoch - 441ms/step\n",
            "Epoch 3990/5000\n",
            "\n",
            "Epoch 3990: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7974 - val_accuracy: 0.7662 - 3s/epoch - 313ms/step\n",
            "Epoch 3991/5000\n",
            "\n",
            "Epoch 3991: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.7626 - 3s/epoch - 300ms/step\n",
            "Epoch 3992/5000\n",
            "\n",
            "Epoch 3992: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.7626 - 3s/epoch - 302ms/step\n",
            "Epoch 3993/5000\n",
            "\n",
            "Epoch 3993: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8081 - val_accuracy: 0.7626 - 4s/epoch - 470ms/step\n",
            "Epoch 3994/5000\n",
            "\n",
            "Epoch 3994: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.7662 - 3s/epoch - 327ms/step\n",
            "Epoch 3995/5000\n",
            "\n",
            "Epoch 3995: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7626 - 3s/epoch - 304ms/step\n",
            "Epoch 3996/5000\n",
            "\n",
            "Epoch 3996: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.7626 - 3s/epoch - 297ms/step\n",
            "Epoch 3997/5000\n",
            "\n",
            "Epoch 3997: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7983 - val_accuracy: 0.7626 - 3s/epoch - 290ms/step\n",
            "Epoch 3998/5000\n",
            "\n",
            "Epoch 3998: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.7626 - 4s/epoch - 485ms/step\n",
            "Epoch 3999/5000\n",
            "\n",
            "Epoch 3999: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.7662 - 3s/epoch - 301ms/step\n",
            "Epoch 4000/5000\n",
            "\n",
            "Epoch 4000: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.7698 - 3s/epoch - 302ms/step\n",
            "Epoch 4001/5000\n",
            "\n",
            "Epoch 4001: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8128 - val_accuracy: 0.7698 - 3s/epoch - 303ms/step\n",
            "Epoch 4002/5000\n",
            "\n",
            "Epoch 4002: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8068 - val_accuracy: 0.7698 - 4s/epoch - 389ms/step\n",
            "Epoch 4003/5000\n",
            "\n",
            "Epoch 4003: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7987 - val_accuracy: 0.7662 - 4s/epoch - 413ms/step\n",
            "Epoch 4004/5000\n",
            "\n",
            "Epoch 4004: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7972 - val_accuracy: 0.7662 - 3s/epoch - 298ms/step\n",
            "Epoch 4005/5000\n",
            "\n",
            "Epoch 4005: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7979 - val_accuracy: 0.7626 - 3s/epoch - 296ms/step\n",
            "Epoch 4006/5000\n",
            "\n",
            "Epoch 4006: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7980 - val_accuracy: 0.7626 - 3s/epoch - 311ms/step\n",
            "Epoch 4007/5000\n",
            "\n",
            "Epoch 4007: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.7662 - 4s/epoch - 431ms/step\n",
            "Epoch 4008/5000\n",
            "\n",
            "Epoch 4008: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8077 - val_accuracy: 0.7626 - 3s/epoch - 339ms/step\n",
            "Epoch 4009/5000\n",
            "\n",
            "Epoch 4009: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8074 - val_accuracy: 0.7662 - 3s/epoch - 300ms/step\n",
            "Epoch 4010/5000\n",
            "\n",
            "Epoch 4010: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8055 - val_accuracy: 0.7662 - 3s/epoch - 323ms/step\n",
            "Epoch 4011/5000\n",
            "\n",
            "Epoch 4011: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8035 - val_accuracy: 0.7626 - 3s/epoch - 315ms/step\n",
            "Epoch 4012/5000\n",
            "\n",
            "Epoch 4012: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.7698 - 4s/epoch - 492ms/step\n",
            "Epoch 4013/5000\n",
            "\n",
            "Epoch 4013: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8011 - val_accuracy: 0.7662 - 3s/epoch - 288ms/step\n",
            "Epoch 4014/5000\n",
            "\n",
            "Epoch 4014: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7662 - 3s/epoch - 316ms/step\n",
            "Epoch 4015/5000\n",
            "\n",
            "Epoch 4015: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.7770 - 3s/epoch - 305ms/step\n",
            "Epoch 4016/5000\n",
            "\n",
            "Epoch 4016: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7770 - 3s/epoch - 379ms/step\n",
            "Epoch 4017/5000\n",
            "\n",
            "Epoch 4017: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7999 - val_accuracy: 0.7734 - 4s/epoch - 412ms/step\n",
            "Epoch 4018/5000\n",
            "\n",
            "Epoch 4018: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.7662 - 3s/epoch - 300ms/step\n",
            "Epoch 4019/5000\n",
            "\n",
            "Epoch 4019: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7969 - val_accuracy: 0.7626 - 3s/epoch - 295ms/step\n",
            "Epoch 4020/5000\n",
            "\n",
            "Epoch 4020: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7989 - val_accuracy: 0.7590 - 3s/epoch - 313ms/step\n",
            "Epoch 4021/5000\n",
            "\n",
            "Epoch 4021: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.7626 - 4s/epoch - 497ms/step\n",
            "Epoch 4022/5000\n",
            "\n",
            "Epoch 4022: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.7626 - 3s/epoch - 327ms/step\n",
            "Epoch 4023/5000\n",
            "\n",
            "Epoch 4023: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.7626 - 3s/epoch - 312ms/step\n",
            "Epoch 4024/5000\n",
            "\n",
            "Epoch 4024: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.7662 - 3s/epoch - 298ms/step\n",
            "Epoch 4025/5000\n",
            "\n",
            "Epoch 4025: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.7626 - 3s/epoch - 322ms/step\n",
            "Epoch 4026/5000\n",
            "\n",
            "Epoch 4026: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8129 - val_accuracy: 0.7554 - 4s/epoch - 454ms/step\n",
            "Epoch 4027/5000\n",
            "\n",
            "Epoch 4027: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.7662 - 3s/epoch - 307ms/step\n",
            "Epoch 4028/5000\n",
            "\n",
            "Epoch 4028: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7914 - val_accuracy: 0.7806 - 3s/epoch - 309ms/step\n",
            "Epoch 4029/5000\n",
            "\n",
            "Epoch 4029: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7917 - val_accuracy: 0.7734 - 3s/epoch - 313ms/step\n",
            "Epoch 4030/5000\n",
            "\n",
            "Epoch 4030: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7869 - val_accuracy: 0.7770 - 4s/epoch - 405ms/step\n",
            "Epoch 4031/5000\n",
            "\n",
            "Epoch 4031: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7887 - val_accuracy: 0.7770 - 3s/epoch - 380ms/step\n",
            "Epoch 4032/5000\n",
            "\n",
            "Epoch 4032: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7918 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4033/5000\n",
            "\n",
            "Epoch 4033: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.7698 - 3s/epoch - 289ms/step\n",
            "Epoch 4034/5000\n",
            "\n",
            "Epoch 4034: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7698 - 3s/epoch - 292ms/step\n",
            "Epoch 4035/5000\n",
            "\n",
            "Epoch 4035: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8010 - val_accuracy: 0.7662 - 4s/epoch - 461ms/step\n",
            "Epoch 4036/5000\n",
            "\n",
            "Epoch 4036: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8040 - val_accuracy: 0.7662 - 3s/epoch - 332ms/step\n",
            "Epoch 4037/5000\n",
            "\n",
            "Epoch 4037: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.7698 - 3s/epoch - 315ms/step\n",
            "Epoch 4038/5000\n",
            "\n",
            "Epoch 4038: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8136 - val_accuracy: 0.7662 - 3s/epoch - 318ms/step\n",
            "Epoch 4039/5000\n",
            "\n",
            "Epoch 4039: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8120 - val_accuracy: 0.7662 - 3s/epoch - 379ms/step\n",
            "Epoch 4040/5000\n",
            "\n",
            "Epoch 4040: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8099 - val_accuracy: 0.7662 - 4s/epoch - 409ms/step\n",
            "Epoch 4041/5000\n",
            "\n",
            "Epoch 4041: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8071 - val_accuracy: 0.7662 - 3s/epoch - 306ms/step\n",
            "Epoch 4042/5000\n",
            "\n",
            "Epoch 4042: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8037 - val_accuracy: 0.7662 - 3s/epoch - 286ms/step\n",
            "Epoch 4043/5000\n",
            "\n",
            "Epoch 4043: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.7698 - 3s/epoch - 280ms/step\n",
            "Epoch 4044/5000\n",
            "\n",
            "Epoch 4044: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7880 - val_accuracy: 0.7698 - 4s/epoch - 441ms/step\n",
            "Epoch 4045/5000\n",
            "\n",
            "Epoch 4045: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7869 - val_accuracy: 0.7698 - 3s/epoch - 352ms/step\n",
            "Epoch 4046/5000\n",
            "\n",
            "Epoch 4046: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7890 - val_accuracy: 0.7698 - 3s/epoch - 318ms/step\n",
            "Epoch 4047/5000\n",
            "\n",
            "Epoch 4047: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.7662 - 3s/epoch - 289ms/step\n",
            "Epoch 4048/5000\n",
            "\n",
            "Epoch 4048: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.7626 - 3s/epoch - 308ms/step\n",
            "Epoch 4049/5000\n",
            "\n",
            "Epoch 4049: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7976 - val_accuracy: 0.7626 - 4s/epoch - 481ms/step\n",
            "Epoch 4050/5000\n",
            "\n",
            "Epoch 4050: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.7662 - 3s/epoch - 310ms/step\n",
            "Epoch 4051/5000\n",
            "\n",
            "Epoch 4051: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.7662 - 3s/epoch - 281ms/step\n",
            "Epoch 4052/5000\n",
            "\n",
            "Epoch 4052: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8016 - val_accuracy: 0.7698 - 3s/epoch - 287ms/step\n",
            "Epoch 4053/5000\n",
            "\n",
            "Epoch 4053: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7958 - val_accuracy: 0.7698 - 3s/epoch - 363ms/step\n",
            "Epoch 4054/5000\n",
            "\n",
            "Epoch 4054: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7850 - val_accuracy: 0.7770 - 4s/epoch - 440ms/step\n",
            "Epoch 4055/5000\n",
            "\n",
            "Epoch 4055: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.7842 - 3s/epoch - 304ms/step\n",
            "Epoch 4056/5000\n",
            "\n",
            "Epoch 4056: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7911 - val_accuracy: 0.7770 - 3s/epoch - 315ms/step\n",
            "Epoch 4057/5000\n",
            "\n",
            "Epoch 4057: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7965 - val_accuracy: 0.7698 - 3s/epoch - 299ms/step\n",
            "Epoch 4058/5000\n",
            "\n",
            "Epoch 4058: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7981 - val_accuracy: 0.7734 - 4s/epoch - 472ms/step\n",
            "Epoch 4059/5000\n",
            "\n",
            "Epoch 4059: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.7698 - 3s/epoch - 345ms/step\n",
            "Epoch 4060/5000\n",
            "\n",
            "Epoch 4060: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7949 - val_accuracy: 0.7698 - 3s/epoch - 300ms/step\n",
            "Epoch 4061/5000\n",
            "\n",
            "Epoch 4061: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7987 - val_accuracy: 0.7734 - 3s/epoch - 301ms/step\n",
            "Epoch 4062/5000\n",
            "\n",
            "Epoch 4062: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8046 - val_accuracy: 0.7770 - 3s/epoch - 299ms/step\n",
            "Epoch 4063/5000\n",
            "\n",
            "Epoch 4063: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.7698 - 4s/epoch - 483ms/step\n",
            "Epoch 4064/5000\n",
            "\n",
            "Epoch 4064: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8030 - val_accuracy: 0.7662 - 3s/epoch - 306ms/step\n",
            "Epoch 4065/5000\n",
            "\n",
            "Epoch 4065: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8064 - val_accuracy: 0.7662 - 3s/epoch - 311ms/step\n",
            "Epoch 4066/5000\n",
            "\n",
            "Epoch 4066: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.7734 - 3s/epoch - 308ms/step\n",
            "Epoch 4067/5000\n",
            "\n",
            "Epoch 4067: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7972 - val_accuracy: 0.7734 - 4s/epoch - 435ms/step\n",
            "Epoch 4068/5000\n",
            "\n",
            "Epoch 4068: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.7698 - 3s/epoch - 354ms/step\n",
            "Epoch 4069/5000\n",
            "\n",
            "Epoch 4069: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8026 - val_accuracy: 0.7626 - 3s/epoch - 293ms/step\n",
            "Epoch 4070/5000\n",
            "\n",
            "Epoch 4070: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8041 - val_accuracy: 0.7626 - 3s/epoch - 315ms/step\n",
            "Epoch 4071/5000\n",
            "\n",
            "Epoch 4071: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.7662 - 3s/epoch - 311ms/step\n",
            "Epoch 4072/5000\n",
            "\n",
            "Epoch 4072: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8037 - val_accuracy: 0.7734 - 4s/epoch - 498ms/step\n",
            "Epoch 4073/5000\n",
            "\n",
            "Epoch 4073: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8110 - val_accuracy: 0.7698 - 3s/epoch - 304ms/step\n",
            "Epoch 4074/5000\n",
            "\n",
            "Epoch 4074: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8177 - val_accuracy: 0.7662 - 3s/epoch - 296ms/step\n",
            "Epoch 4075/5000\n",
            "\n",
            "Epoch 4075: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8147 - val_accuracy: 0.7698 - 3s/epoch - 300ms/step\n",
            "Epoch 4076/5000\n",
            "\n",
            "Epoch 4076: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.7626 - 3s/epoch - 350ms/step\n",
            "Epoch 4077/5000\n",
            "\n",
            "Epoch 4077: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8058 - val_accuracy: 0.7626 - 4s/epoch - 428ms/step\n",
            "Epoch 4078/5000\n",
            "\n",
            "Epoch 4078: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8065 - val_accuracy: 0.7698 - 3s/epoch - 280ms/step\n",
            "Epoch 4079/5000\n",
            "\n",
            "Epoch 4079: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8034 - val_accuracy: 0.7698 - 3s/epoch - 312ms/step\n",
            "Epoch 4080/5000\n",
            "\n",
            "Epoch 4080: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8013 - val_accuracy: 0.7734 - 3s/epoch - 300ms/step\n",
            "Epoch 4081/5000\n",
            "\n",
            "Epoch 4081: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8025 - val_accuracy: 0.7734 - 4s/epoch - 438ms/step\n",
            "Epoch 4082/5000\n",
            "\n",
            "Epoch 4082: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8077 - val_accuracy: 0.7698 - 3s/epoch - 387ms/step\n",
            "Epoch 4083/5000\n",
            "\n",
            "Epoch 4083: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8107 - val_accuracy: 0.7662 - 3s/epoch - 318ms/step\n",
            "Epoch 4084/5000\n",
            "\n",
            "Epoch 4084: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8133 - val_accuracy: 0.7626 - 3s/epoch - 312ms/step\n",
            "Epoch 4085/5000\n",
            "\n",
            "Epoch 4085: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.7662 - 3s/epoch - 338ms/step\n",
            "Epoch 4086/5000\n",
            "\n",
            "Epoch 4086: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8068 - val_accuracy: 0.7698 - 4s/epoch - 496ms/step\n",
            "Epoch 4087/5000\n",
            "\n",
            "Epoch 4087: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.7734 - 3s/epoch - 290ms/step\n",
            "Epoch 4088/5000\n",
            "\n",
            "Epoch 4088: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8046 - val_accuracy: 0.7734 - 3s/epoch - 309ms/step\n",
            "Epoch 4089/5000\n",
            "\n",
            "Epoch 4089: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8062 - val_accuracy: 0.7734 - 3s/epoch - 308ms/step\n",
            "Epoch 4090/5000\n",
            "\n",
            "Epoch 4090: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8069 - val_accuracy: 0.7734 - 4s/epoch - 411ms/step\n",
            "Epoch 4091/5000\n",
            "\n",
            "Epoch 4091: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.7698 - 3s/epoch - 381ms/step\n",
            "Epoch 4092/5000\n",
            "\n",
            "Epoch 4092: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8084 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4093/5000\n",
            "\n",
            "Epoch 4093: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8096 - val_accuracy: 0.7770 - 3s/epoch - 298ms/step\n",
            "Epoch 4094/5000\n",
            "\n",
            "Epoch 4094: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8085 - val_accuracy: 0.7770 - 3s/epoch - 300ms/step\n",
            "Epoch 4095/5000\n",
            "\n",
            "Epoch 4095: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7853 - val_accuracy: 0.7770 - 4s/epoch - 488ms/step\n",
            "Epoch 4096/5000\n",
            "\n",
            "Epoch 4096: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7958 - val_accuracy: 0.7698 - 3s/epoch - 313ms/step\n",
            "Epoch 4097/5000\n",
            "\n",
            "Epoch 4097: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8127 - val_accuracy: 0.7734 - 3s/epoch - 282ms/step\n",
            "Epoch 4098/5000\n",
            "\n",
            "Epoch 4098: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8169 - val_accuracy: 0.7770 - 3s/epoch - 281ms/step\n",
            "Epoch 4099/5000\n",
            "\n",
            "Epoch 4099: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8172 - val_accuracy: 0.7806 - 3s/epoch - 293ms/step\n",
            "Epoch 4100/5000\n",
            "\n",
            "Epoch 4100: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8093 - val_accuracy: 0.7770 - 4s/epoch - 461ms/step\n",
            "Epoch 4101/5000\n",
            "\n",
            "Epoch 4101: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8041 - val_accuracy: 0.7734 - 3s/epoch - 293ms/step\n",
            "Epoch 4102/5000\n",
            "\n",
            "Epoch 4102: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8029 - val_accuracy: 0.7734 - 3s/epoch - 282ms/step\n",
            "Epoch 4103/5000\n",
            "\n",
            "Epoch 4103: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8052 - val_accuracy: 0.7626 - 3s/epoch - 295ms/step\n",
            "Epoch 4104/5000\n",
            "\n",
            "Epoch 4104: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8073 - val_accuracy: 0.7626 - 3s/epoch - 363ms/step\n",
            "Epoch 4105/5000\n",
            "\n",
            "Epoch 4105: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8122 - val_accuracy: 0.7662 - 3s/epoch - 389ms/step\n",
            "Epoch 4106/5000\n",
            "\n",
            "Epoch 4106: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8133 - val_accuracy: 0.7662 - 3s/epoch - 281ms/step\n",
            "Epoch 4107/5000\n",
            "\n",
            "Epoch 4107: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.7698 - 3s/epoch - 284ms/step\n",
            "Epoch 4108/5000\n",
            "\n",
            "Epoch 4108: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8061 - val_accuracy: 0.7698 - 3s/epoch - 293ms/step\n",
            "Epoch 4109/5000\n",
            "\n",
            "Epoch 4109: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.7662 - 4s/epoch - 409ms/step\n",
            "Epoch 4110/5000\n",
            "\n",
            "Epoch 4110: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.7698 - 3s/epoch - 361ms/step\n",
            "Epoch 4111/5000\n",
            "\n",
            "Epoch 4111: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7999 - val_accuracy: 0.7734 - 3s/epoch - 298ms/step\n",
            "Epoch 4112/5000\n",
            "\n",
            "Epoch 4112: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8034 - val_accuracy: 0.7734 - 3s/epoch - 290ms/step\n",
            "Epoch 4113/5000\n",
            "\n",
            "Epoch 4113: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8103 - val_accuracy: 0.7734 - 3s/epoch - 300ms/step\n",
            "Epoch 4114/5000\n",
            "\n",
            "Epoch 4114: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8211 - val_accuracy: 0.7698 - 4s/epoch - 474ms/step\n",
            "Epoch 4115/5000\n",
            "\n",
            "Epoch 4115: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8189 - val_accuracy: 0.7662 - 3s/epoch - 295ms/step\n",
            "Epoch 4116/5000\n",
            "\n",
            "Epoch 4116: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.7698 - 3s/epoch - 293ms/step\n",
            "Epoch 4117/5000\n",
            "\n",
            "Epoch 4117: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8176 - val_accuracy: 0.7698 - 2s/epoch - 277ms/step\n",
            "Epoch 4118/5000\n",
            "\n",
            "Epoch 4118: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8165 - val_accuracy: 0.7698 - 3s/epoch - 306ms/step\n",
            "Epoch 4119/5000\n",
            "\n",
            "Epoch 4119: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8190 - val_accuracy: 0.7770 - 4s/epoch - 439ms/step\n",
            "Epoch 4120/5000\n",
            "\n",
            "Epoch 4120: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8140 - val_accuracy: 0.7770 - 3s/epoch - 300ms/step\n",
            "Epoch 4121/5000\n",
            "\n",
            "Epoch 4121: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8116 - val_accuracy: 0.7734 - 3s/epoch - 292ms/step\n",
            "Epoch 4122/5000\n",
            "\n",
            "Epoch 4122: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.7698 - 3s/epoch - 293ms/step\n",
            "Epoch 4123/5000\n",
            "\n",
            "Epoch 4123: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.7662 - 3s/epoch - 361ms/step\n",
            "Epoch 4124/5000\n",
            "\n",
            "Epoch 4124: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8089 - val_accuracy: 0.7662 - 4s/epoch - 445ms/step\n",
            "Epoch 4125/5000\n",
            "\n",
            "Epoch 4125: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8113 - val_accuracy: 0.7662 - 3s/epoch - 319ms/step\n",
            "Epoch 4126/5000\n",
            "\n",
            "Epoch 4126: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8112 - val_accuracy: 0.7698 - 3s/epoch - 327ms/step\n",
            "Epoch 4127/5000\n",
            "\n",
            "Epoch 4127: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8083 - val_accuracy: 0.7698 - 3s/epoch - 302ms/step\n",
            "Epoch 4128/5000\n",
            "\n",
            "Epoch 4128: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.7662 - 4s/epoch - 463ms/step\n",
            "Epoch 4129/5000\n",
            "\n",
            "Epoch 4129: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8084 - val_accuracy: 0.7662 - 3s/epoch - 288ms/step\n",
            "Epoch 4130/5000\n",
            "\n",
            "Epoch 4130: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.7662 - 2s/epoch - 268ms/step\n",
            "Epoch 4131/5000\n",
            "\n",
            "Epoch 4131: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8111 - val_accuracy: 0.7626 - 3s/epoch - 284ms/step\n",
            "Epoch 4132/5000\n",
            "\n",
            "Epoch 4132: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8141 - val_accuracy: 0.7662 - 3s/epoch - 338ms/step\n",
            "Epoch 4133/5000\n",
            "\n",
            "Epoch 4133: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8121 - val_accuracy: 0.7662 - 4s/epoch - 430ms/step\n",
            "Epoch 4134/5000\n",
            "\n",
            "Epoch 4134: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.7662 - 3s/epoch - 295ms/step\n",
            "Epoch 4135/5000\n",
            "\n",
            "Epoch 4135: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.7662 - 3s/epoch - 297ms/step\n",
            "Epoch 4136/5000\n",
            "\n",
            "Epoch 4136: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8041 - val_accuracy: 0.7770 - 2s/epoch - 277ms/step\n",
            "Epoch 4137/5000\n",
            "\n",
            "Epoch 4137: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8000 - val_accuracy: 0.7770 - 4s/epoch - 436ms/step\n",
            "Epoch 4138/5000\n",
            "\n",
            "Epoch 4138: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.7770 - 3s/epoch - 332ms/step\n",
            "Epoch 4139/5000\n",
            "\n",
            "Epoch 4139: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8142 - val_accuracy: 0.7734 - 3s/epoch - 292ms/step\n",
            "Epoch 4140/5000\n",
            "\n",
            "Epoch 4140: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8250 - val_accuracy: 0.7734 - 2s/epoch - 270ms/step\n",
            "Epoch 4141/5000\n",
            "\n",
            "Epoch 4141: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8302 - val_accuracy: 0.7734 - 3s/epoch - 285ms/step\n",
            "Epoch 4142/5000\n",
            "\n",
            "Epoch 4142: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8277 - val_accuracy: 0.7662 - 4s/epoch - 470ms/step\n",
            "Epoch 4143/5000\n",
            "\n",
            "Epoch 4143: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8227 - val_accuracy: 0.7662 - 3s/epoch - 283ms/step\n",
            "Epoch 4144/5000\n",
            "\n",
            "Epoch 4144: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8154 - val_accuracy: 0.7662 - 3s/epoch - 293ms/step\n",
            "Epoch 4145/5000\n",
            "\n",
            "Epoch 4145: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.7626 - 3s/epoch - 280ms/step\n",
            "Epoch 4146/5000\n",
            "\n",
            "Epoch 4146: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8104 - val_accuracy: 0.7698 - 3s/epoch - 301ms/step\n",
            "Epoch 4147/5000\n",
            "\n",
            "Epoch 4147: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8115 - val_accuracy: 0.7662 - 4s/epoch - 470ms/step\n",
            "Epoch 4148/5000\n",
            "\n",
            "Epoch 4148: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.7953 - val_accuracy: 0.7806 - 3s/epoch - 285ms/step\n",
            "Epoch 4149/5000\n",
            "\n",
            "Epoch 4149: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7956 - val_accuracy: 0.7770 - 3s/epoch - 294ms/step\n",
            "Epoch 4150/5000\n",
            "\n",
            "Epoch 4150: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4151/5000\n",
            "\n",
            "Epoch 4151: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8248 - val_accuracy: 0.7806 - 4s/epoch - 401ms/step\n",
            "Epoch 4152/5000\n",
            "\n",
            "Epoch 4152: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8244 - val_accuracy: 0.7770 - 3s/epoch - 378ms/step\n",
            "Epoch 4153/5000\n",
            "\n",
            "Epoch 4153: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8235 - val_accuracy: 0.7770 - 3s/epoch - 280ms/step\n",
            "Epoch 4154/5000\n",
            "\n",
            "Epoch 4154: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8191 - val_accuracy: 0.7734 - 2s/epoch - 273ms/step\n",
            "Epoch 4155/5000\n",
            "\n",
            "Epoch 4155: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8138 - val_accuracy: 0.7698 - 3s/epoch - 290ms/step\n",
            "Epoch 4156/5000\n",
            "\n",
            "Epoch 4156: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8121 - val_accuracy: 0.7590 - 4s/epoch - 466ms/step\n",
            "Epoch 4157/5000\n",
            "\n",
            "Epoch 4157: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8110 - val_accuracy: 0.7590 - 3s/epoch - 295ms/step\n",
            "Epoch 4158/5000\n",
            "\n",
            "Epoch 4158: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.7662 - 3s/epoch - 302ms/step\n",
            "Epoch 4159/5000\n",
            "\n",
            "Epoch 4159: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 4160/5000\n",
            "\n",
            "Epoch 4160: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8008 - val_accuracy: 0.7734 - 3s/epoch - 300ms/step\n",
            "Epoch 4161/5000\n",
            "\n",
            "Epoch 4161: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8070 - val_accuracy: 0.7662 - 4s/epoch - 451ms/step\n",
            "Epoch 4162/5000\n",
            "\n",
            "Epoch 4162: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8129 - val_accuracy: 0.7662 - 2s/epoch - 277ms/step\n",
            "Epoch 4163/5000\n",
            "\n",
            "Epoch 4163: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8190 - val_accuracy: 0.7662 - 3s/epoch - 280ms/step\n",
            "Epoch 4164/5000\n",
            "\n",
            "Epoch 4164: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.7662 - 2s/epoch - 276ms/step\n",
            "Epoch 4165/5000\n",
            "\n",
            "Epoch 4165: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.7698 - 3s/epoch - 322ms/step\n",
            "Epoch 4166/5000\n",
            "\n",
            "Epoch 4166: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.7734 - 4s/epoch - 484ms/step\n",
            "Epoch 4167/5000\n",
            "\n",
            "Epoch 4167: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.7662 - 3s/epoch - 291ms/step\n",
            "Epoch 4168/5000\n",
            "\n",
            "Epoch 4168: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8140 - val_accuracy: 0.7662 - 3s/epoch - 294ms/step\n",
            "Epoch 4169/5000\n",
            "\n",
            "Epoch 4169: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8145 - val_accuracy: 0.7662 - 3s/epoch - 290ms/step\n",
            "Epoch 4170/5000\n",
            "\n",
            "Epoch 4170: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8153 - val_accuracy: 0.7662 - 4s/epoch - 428ms/step\n",
            "Epoch 4171/5000\n",
            "\n",
            "Epoch 4171: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8135 - val_accuracy: 0.7662 - 3s/epoch - 335ms/step\n",
            "Epoch 4172/5000\n",
            "\n",
            "Epoch 4172: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8101 - val_accuracy: 0.7662 - 2s/epoch - 276ms/step\n",
            "Epoch 4173/5000\n",
            "\n",
            "Epoch 4173: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8095 - val_accuracy: 0.7662 - 3s/epoch - 282ms/step\n",
            "Epoch 4174/5000\n",
            "\n",
            "Epoch 4174: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8076 - val_accuracy: 0.7626 - 3s/epoch - 295ms/step\n",
            "Epoch 4175/5000\n",
            "\n",
            "Epoch 4175: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.7734 - 4s/epoch - 472ms/step\n",
            "Epoch 4176/5000\n",
            "\n",
            "Epoch 4176: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.7734 - 3s/epoch - 283ms/step\n",
            "Epoch 4177/5000\n",
            "\n",
            "Epoch 4177: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8007 - val_accuracy: 0.7698 - 3s/epoch - 284ms/step\n",
            "Epoch 4178/5000\n",
            "\n",
            "Epoch 4178: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.7698 - 3s/epoch - 298ms/step\n",
            "Epoch 4179/5000\n",
            "\n",
            "Epoch 4179: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8008 - val_accuracy: 0.7698 - 3s/epoch - 353ms/step\n",
            "Epoch 4180/5000\n",
            "\n",
            "Epoch 4180: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8021 - val_accuracy: 0.7698 - 4s/epoch - 427ms/step\n",
            "Epoch 4181/5000\n",
            "\n",
            "Epoch 4181: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.7698 - 3s/epoch - 297ms/step\n",
            "Epoch 4182/5000\n",
            "\n",
            "Epoch 4182: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 4183/5000\n",
            "\n",
            "Epoch 4183: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8018 - val_accuracy: 0.7698 - 3s/epoch - 294ms/step\n",
            "Epoch 4184/5000\n",
            "\n",
            "Epoch 4184: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.7698 - 4s/epoch - 410ms/step\n",
            "Epoch 4185/5000\n",
            "\n",
            "Epoch 4185: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8083 - val_accuracy: 0.7698 - 3s/epoch - 358ms/step\n",
            "Epoch 4186/5000\n",
            "\n",
            "Epoch 4186: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8035 - val_accuracy: 0.7770 - 3s/epoch - 281ms/step\n",
            "Epoch 4187/5000\n",
            "\n",
            "Epoch 4187: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4188/5000\n",
            "\n",
            "Epoch 4188: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.7934 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4189/5000\n",
            "\n",
            "Epoch 4189: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.7931 - val_accuracy: 0.7662 - 4s/epoch - 474ms/step\n",
            "Epoch 4190/5000\n",
            "\n",
            "Epoch 4190: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7954 - val_accuracy: 0.7662 - 3s/epoch - 301ms/step\n",
            "Epoch 4191/5000\n",
            "\n",
            "Epoch 4191: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7962 - val_accuracy: 0.7662 - 3s/epoch - 279ms/step\n",
            "Epoch 4192/5000\n",
            "\n",
            "Epoch 4192: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.7946 - val_accuracy: 0.7698 - 3s/epoch - 292ms/step\n",
            "Epoch 4193/5000\n",
            "\n",
            "Epoch 4193: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7942 - val_accuracy: 0.7662 - 3s/epoch - 301ms/step\n",
            "Epoch 4194/5000\n",
            "\n",
            "Epoch 4194: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.7662 - 4s/epoch - 465ms/step\n",
            "Epoch 4195/5000\n",
            "\n",
            "Epoch 4195: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7997 - val_accuracy: 0.7734 - 3s/epoch - 291ms/step\n",
            "Epoch 4196/5000\n",
            "\n",
            "Epoch 4196: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7995 - val_accuracy: 0.7770 - 3s/epoch - 279ms/step\n",
            "Epoch 4197/5000\n",
            "\n",
            "Epoch 4197: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7985 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 4198/5000\n",
            "\n",
            "Epoch 4198: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.7698 - 3s/epoch - 340ms/step\n",
            "Epoch 4199/5000\n",
            "\n",
            "Epoch 4199: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7734 - 4s/epoch - 419ms/step\n",
            "Epoch 4200/5000\n",
            "\n",
            "Epoch 4200: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8082 - val_accuracy: 0.7806 - 3s/epoch - 291ms/step\n",
            "Epoch 4201/5000\n",
            "\n",
            "Epoch 4201: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8131 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4202/5000\n",
            "\n",
            "Epoch 4202: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.7662 - 3s/epoch - 295ms/step\n",
            "Epoch 4203/5000\n",
            "\n",
            "Epoch 4203: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.7662 - 4s/epoch - 461ms/step\n",
            "Epoch 4204/5000\n",
            "\n",
            "Epoch 4204: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7968 - val_accuracy: 0.7698 - 3s/epoch - 316ms/step\n",
            "Epoch 4205/5000\n",
            "\n",
            "Epoch 4205: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7972 - val_accuracy: 0.7734 - 3s/epoch - 281ms/step\n",
            "Epoch 4206/5000\n",
            "\n",
            "Epoch 4206: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7975 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4207/5000\n",
            "\n",
            "Epoch 4207: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7977 - val_accuracy: 0.7734 - 3s/epoch - 293ms/step\n",
            "Epoch 4208/5000\n",
            "\n",
            "Epoch 4208: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8127 - val_accuracy: 0.7698 - 4s/epoch - 477ms/step\n",
            "Epoch 4209/5000\n",
            "\n",
            "Epoch 4209: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8197 - val_accuracy: 0.7698 - 3s/epoch - 300ms/step\n",
            "Epoch 4210/5000\n",
            "\n",
            "Epoch 4210: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.7770 - 3s/epoch - 279ms/step\n",
            "Epoch 4211/5000\n",
            "\n",
            "Epoch 4211: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8070 - val_accuracy: 0.7734 - 3s/epoch - 282ms/step\n",
            "Epoch 4212/5000\n",
            "\n",
            "Epoch 4212: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8073 - val_accuracy: 0.7770 - 3s/epoch - 349ms/step\n",
            "Epoch 4213/5000\n",
            "\n",
            "Epoch 4213: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8032 - val_accuracy: 0.7734 - 4s/epoch - 425ms/step\n",
            "Epoch 4214/5000\n",
            "\n",
            "Epoch 4214: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.7734 - 3s/epoch - 279ms/step\n",
            "Epoch 4215/5000\n",
            "\n",
            "Epoch 4215: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7770 - 2s/epoch - 277ms/step\n",
            "Epoch 4216/5000\n",
            "\n",
            "Epoch 4216: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8030 - val_accuracy: 0.7698 - 3s/epoch - 291ms/step\n",
            "Epoch 4217/5000\n",
            "\n",
            "Epoch 4217: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.7734 - 4s/epoch - 427ms/step\n",
            "Epoch 4218/5000\n",
            "\n",
            "Epoch 4218: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7958 - val_accuracy: 0.7698 - 3s/epoch - 325ms/step\n",
            "Epoch 4219/5000\n",
            "\n",
            "Epoch 4219: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.7698 - 3s/epoch - 300ms/step\n",
            "Epoch 4220/5000\n",
            "\n",
            "Epoch 4220: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7950 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 4221/5000\n",
            "\n",
            "Epoch 4221: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7943 - val_accuracy: 0.7698 - 3s/epoch - 279ms/step\n",
            "Epoch 4222/5000\n",
            "\n",
            "Epoch 4222: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8022 - val_accuracy: 0.7770 - 4s/epoch - 470ms/step\n",
            "Epoch 4223/5000\n",
            "\n",
            "Epoch 4223: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.7734 - 3s/epoch - 292ms/step\n",
            "Epoch 4224/5000\n",
            "\n",
            "Epoch 4224: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8089 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 4225/5000\n",
            "\n",
            "Epoch 4225: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7770 - 3s/epoch - 294ms/step\n",
            "Epoch 4226/5000\n",
            "\n",
            "Epoch 4226: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8093 - val_accuracy: 0.7806 - 3s/epoch - 336ms/step\n",
            "Epoch 4227/5000\n",
            "\n",
            "Epoch 4227: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8138 - val_accuracy: 0.7806 - 4s/epoch - 445ms/step\n",
            "Epoch 4228/5000\n",
            "\n",
            "Epoch 4228: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8112 - val_accuracy: 0.7842 - 3s/epoch - 289ms/step\n",
            "Epoch 4229/5000\n",
            "\n",
            "Epoch 4229: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8191 - val_accuracy: 0.7842 - 3s/epoch - 282ms/step\n",
            "Epoch 4230/5000\n",
            "\n",
            "Epoch 4230: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7916 - val_accuracy: 0.7770 - 3s/epoch - 278ms/step\n",
            "Epoch 4231/5000\n",
            "\n",
            "Epoch 4231: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.7770 - 4s/epoch - 398ms/step\n",
            "Epoch 4232/5000\n",
            "\n",
            "Epoch 4232: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7770 - 3s/epoch - 375ms/step\n",
            "Epoch 4233/5000\n",
            "\n",
            "Epoch 4233: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.7698 - 3s/epoch - 294ms/step\n",
            "Epoch 4234/5000\n",
            "\n",
            "Epoch 4234: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8202 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 4235/5000\n",
            "\n",
            "Epoch 4235: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8181 - val_accuracy: 0.7698 - 3s/epoch - 283ms/step\n",
            "Epoch 4236/5000\n",
            "\n",
            "Epoch 4236: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.7698 - 4s/epoch - 487ms/step\n",
            "Epoch 4237/5000\n",
            "\n",
            "Epoch 4237: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8095 - val_accuracy: 0.7698 - 3s/epoch - 278ms/step\n",
            "Epoch 4238/5000\n",
            "\n",
            "Epoch 4238: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.7698 - 3s/epoch - 294ms/step\n",
            "Epoch 4239/5000\n",
            "\n",
            "Epoch 4239: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8151 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 4240/5000\n",
            "\n",
            "Epoch 4240: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8160 - val_accuracy: 0.7770 - 3s/epoch - 314ms/step\n",
            "Epoch 4241/5000\n",
            "\n",
            "Epoch 4241: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8162 - val_accuracy: 0.7734 - 4s/epoch - 459ms/step\n",
            "Epoch 4242/5000\n",
            "\n",
            "Epoch 4242: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.7698 - 3s/epoch - 281ms/step\n",
            "Epoch 4243/5000\n",
            "\n",
            "Epoch 4243: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8090 - val_accuracy: 0.7626 - 3s/epoch - 299ms/step\n",
            "Epoch 4244/5000\n",
            "\n",
            "Epoch 4244: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.7626 - 3s/epoch - 282ms/step\n",
            "Epoch 4245/5000\n",
            "\n",
            "Epoch 4245: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.7626 - 4s/epoch - 412ms/step\n",
            "Epoch 4246/5000\n",
            "\n",
            "Epoch 4246: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.7698 - 3s/epoch - 370ms/step\n",
            "Epoch 4247/5000\n",
            "\n",
            "Epoch 4247: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7981 - val_accuracy: 0.7698 - 3s/epoch - 286ms/step\n",
            "Epoch 4248/5000\n",
            "\n",
            "Epoch 4248: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7997 - val_accuracy: 0.7734 - 3s/epoch - 282ms/step\n",
            "Epoch 4249/5000\n",
            "\n",
            "Epoch 4249: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.7662 - 3s/epoch - 296ms/step\n",
            "Epoch 4250/5000\n",
            "\n",
            "Epoch 4250: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.7734 - 4s/epoch - 458ms/step\n",
            "Epoch 4251/5000\n",
            "\n",
            "Epoch 4251: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.7662 - 3s/epoch - 302ms/step\n",
            "Epoch 4252/5000\n",
            "\n",
            "Epoch 4252: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8046 - val_accuracy: 0.7662 - 3s/epoch - 300ms/step\n",
            "Epoch 4253/5000\n",
            "\n",
            "Epoch 4253: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.7662 - 3s/epoch - 293ms/step\n",
            "Epoch 4254/5000\n",
            "\n",
            "Epoch 4254: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.7806 - 3s/epoch - 298ms/step\n",
            "Epoch 4255/5000\n",
            "\n",
            "Epoch 4255: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.7842 - 4s/epoch - 476ms/step\n",
            "Epoch 4256/5000\n",
            "\n",
            "Epoch 4256: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8101 - val_accuracy: 0.7806 - 3s/epoch - 290ms/step\n",
            "Epoch 4257/5000\n",
            "\n",
            "Epoch 4257: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.7806 - 3s/epoch - 294ms/step\n",
            "Epoch 4258/5000\n",
            "\n",
            "Epoch 4258: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8170 - val_accuracy: 0.7770 - 3s/epoch - 298ms/step\n",
            "Epoch 4259/5000\n",
            "\n",
            "Epoch 4259: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8196 - val_accuracy: 0.7806 - 4s/epoch - 398ms/step\n",
            "Epoch 4260/5000\n",
            "\n",
            "Epoch 4260: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8164 - val_accuracy: 0.7806 - 3s/epoch - 383ms/step\n",
            "Epoch 4261/5000\n",
            "\n",
            "Epoch 4261: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8091 - val_accuracy: 0.7770 - 3s/epoch - 293ms/step\n",
            "Epoch 4262/5000\n",
            "\n",
            "Epoch 4262: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8064 - val_accuracy: 0.7806 - 2s/epoch - 277ms/step\n",
            "Epoch 4263/5000\n",
            "\n",
            "Epoch 4263: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.7770 - 2s/epoch - 275ms/step\n",
            "Epoch 4264/5000\n",
            "\n",
            "Epoch 4264: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8025 - val_accuracy: 0.7734 - 4s/epoch - 442ms/step\n",
            "Epoch 4265/5000\n",
            "\n",
            "Epoch 4265: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.7698 - 3s/epoch - 334ms/step\n",
            "Epoch 4266/5000\n",
            "\n",
            "Epoch 4266: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 4267/5000\n",
            "\n",
            "Epoch 4267: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.7770 - 3s/epoch - 291ms/step\n",
            "Epoch 4268/5000\n",
            "\n",
            "Epoch 4268: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.7806 - 3s/epoch - 300ms/step\n",
            "Epoch 4269/5000\n",
            "\n",
            "Epoch 4269: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.7770 - 4s/epoch - 482ms/step\n",
            "Epoch 4270/5000\n",
            "\n",
            "Epoch 4270: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.7698 - 3s/epoch - 294ms/step\n",
            "Epoch 4271/5000\n",
            "\n",
            "Epoch 4271: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8049 - val_accuracy: 0.7698 - 3s/epoch - 292ms/step\n",
            "Epoch 4272/5000\n",
            "\n",
            "Epoch 4272: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8058 - val_accuracy: 0.7734 - 3s/epoch - 282ms/step\n",
            "Epoch 4273/5000\n",
            "\n",
            "Epoch 4273: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.7770 - 3s/epoch - 366ms/step\n",
            "Epoch 4274/5000\n",
            "\n",
            "Epoch 4274: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8055 - val_accuracy: 0.7734 - 4s/epoch - 421ms/step\n",
            "Epoch 4275/5000\n",
            "\n",
            "Epoch 4275: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8081 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4276/5000\n",
            "\n",
            "Epoch 4276: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8122 - val_accuracy: 0.7698 - 3s/epoch - 288ms/step\n",
            "Epoch 4277/5000\n",
            "\n",
            "Epoch 4277: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8026 - val_accuracy: 0.7734 - 3s/epoch - 282ms/step\n",
            "Epoch 4278/5000\n",
            "\n",
            "Epoch 4278: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7953 - val_accuracy: 0.7770 - 4s/epoch - 419ms/step\n",
            "Epoch 4279/5000\n",
            "\n",
            "Epoch 4279: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7950 - val_accuracy: 0.7770 - 3s/epoch - 346ms/step\n",
            "Epoch 4280/5000\n",
            "\n",
            "Epoch 4280: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8022 - val_accuracy: 0.7698 - 3s/epoch - 303ms/step\n",
            "Epoch 4281/5000\n",
            "\n",
            "Epoch 4281: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8052 - val_accuracy: 0.7698 - 3s/epoch - 279ms/step\n",
            "Epoch 4282/5000\n",
            "\n",
            "Epoch 4282: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8066 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4283/5000\n",
            "\n",
            "Epoch 4283: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8076 - val_accuracy: 0.7698 - 4s/epoch - 466ms/step\n",
            "Epoch 4284/5000\n",
            "\n",
            "Epoch 4284: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.7698 - 3s/epoch - 297ms/step\n",
            "Epoch 4285/5000\n",
            "\n",
            "Epoch 4285: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8086 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 4286/5000\n",
            "\n",
            "Epoch 4286: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8104 - val_accuracy: 0.7734 - 3s/epoch - 293ms/step\n",
            "Epoch 4287/5000\n",
            "\n",
            "Epoch 4287: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.7770 - 3s/epoch - 288ms/step\n",
            "Epoch 4288/5000\n",
            "\n",
            "Epoch 4288: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8088 - val_accuracy: 0.7770 - 4s/epoch - 472ms/step\n",
            "Epoch 4289/5000\n",
            "\n",
            "Epoch 4289: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8070 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 4290/5000\n",
            "\n",
            "Epoch 4290: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.7734 - 3s/epoch - 281ms/step\n",
            "Epoch 4291/5000\n",
            "\n",
            "Epoch 4291: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8095 - val_accuracy: 0.7770 - 3s/epoch - 292ms/step\n",
            "Epoch 4292/5000\n",
            "\n",
            "Epoch 4292: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8086 - val_accuracy: 0.7698 - 3s/epoch - 340ms/step\n",
            "Epoch 4293/5000\n",
            "\n",
            "Epoch 4293: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8040 - val_accuracy: 0.7770 - 4s/epoch - 415ms/step\n",
            "Epoch 4294/5000\n",
            "\n",
            "Epoch 4294: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 4295/5000\n",
            "\n",
            "Epoch 4295: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7968 - val_accuracy: 0.7734 - 3s/epoch - 291ms/step\n",
            "Epoch 4296/5000\n",
            "\n",
            "Epoch 4296: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.7770 - 3s/epoch - 280ms/step\n",
            "Epoch 4297/5000\n",
            "\n",
            "Epoch 4297: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.7770 - 4s/epoch - 424ms/step\n",
            "Epoch 4298/5000\n",
            "\n",
            "Epoch 4298: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8038 - val_accuracy: 0.7770 - 3s/epoch - 349ms/step\n",
            "Epoch 4299/5000\n",
            "\n",
            "Epoch 4299: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.7698 - 3s/epoch - 299ms/step\n",
            "Epoch 4300/5000\n",
            "\n",
            "Epoch 4300: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.7734 - 3s/epoch - 293ms/step\n",
            "Epoch 4301/5000\n",
            "\n",
            "Epoch 4301: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8089 - val_accuracy: 0.7698 - 3s/epoch - 292ms/step\n",
            "Epoch 4302/5000\n",
            "\n",
            "Epoch 4302: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8094 - val_accuracy: 0.7734 - 4s/epoch - 489ms/step\n",
            "Epoch 4303/5000\n",
            "\n",
            "Epoch 4303: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4304/5000\n",
            "\n",
            "Epoch 4304: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8116 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4305/5000\n",
            "\n",
            "Epoch 4305: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8097 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 4306/5000\n",
            "\n",
            "Epoch 4306: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.7770 - 4s/epoch - 392ms/step\n",
            "Epoch 4307/5000\n",
            "\n",
            "Epoch 4307: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.7734 - 3s/epoch - 377ms/step\n",
            "Epoch 4308/5000\n",
            "\n",
            "Epoch 4308: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 4309/5000\n",
            "\n",
            "Epoch 4309: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 4310/5000\n",
            "\n",
            "Epoch 4310: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.7734 - 3s/epoch - 278ms/step\n",
            "Epoch 4311/5000\n",
            "\n",
            "Epoch 4311: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.7734 - 4s/epoch - 437ms/step\n",
            "Epoch 4312/5000\n",
            "\n",
            "Epoch 4312: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8142 - val_accuracy: 0.7770 - 3s/epoch - 316ms/step\n",
            "Epoch 4313/5000\n",
            "\n",
            "Epoch 4313: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4314/5000\n",
            "\n",
            "Epoch 4314: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8120 - val_accuracy: 0.7734 - 2s/epoch - 278ms/step\n",
            "Epoch 4315/5000\n",
            "\n",
            "Epoch 4315: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8110 - val_accuracy: 0.7734 - 3s/epoch - 279ms/step\n",
            "Epoch 4316/5000\n",
            "\n",
            "Epoch 4316: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8103 - val_accuracy: 0.7734 - 4s/epoch - 480ms/step\n",
            "Epoch 4317/5000\n",
            "\n",
            "Epoch 4317: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8120 - val_accuracy: 0.7770 - 3s/epoch - 291ms/step\n",
            "Epoch 4318/5000\n",
            "\n",
            "Epoch 4318: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.7806 - 3s/epoch - 283ms/step\n",
            "Epoch 4319/5000\n",
            "\n",
            "Epoch 4319: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.7806 - 3s/epoch - 299ms/step\n",
            "Epoch 4320/5000\n",
            "\n",
            "Epoch 4320: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8025 - val_accuracy: 0.7806 - 3s/epoch - 342ms/step\n",
            "Epoch 4321/5000\n",
            "\n",
            "Epoch 4321: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7934 - val_accuracy: 0.7698 - 4s/epoch - 435ms/step\n",
            "Epoch 4322/5000\n",
            "\n",
            "Epoch 4322: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7933 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4323/5000\n",
            "\n",
            "Epoch 4323: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8013 - val_accuracy: 0.7698 - 3s/epoch - 282ms/step\n",
            "Epoch 4324/5000\n",
            "\n",
            "Epoch 4324: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8122 - val_accuracy: 0.7698 - 3s/epoch - 279ms/step\n",
            "Epoch 4325/5000\n",
            "\n",
            "Epoch 4325: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.7698 - 3s/epoch - 372ms/step\n",
            "Epoch 4326/5000\n",
            "\n",
            "Epoch 4326: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8097 - val_accuracy: 0.7734 - 3s/epoch - 385ms/step\n",
            "Epoch 4327/5000\n",
            "\n",
            "Epoch 4327: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8052 - val_accuracy: 0.7734 - 3s/epoch - 287ms/step\n",
            "Epoch 4328/5000\n",
            "\n",
            "Epoch 4328: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8019 - val_accuracy: 0.7698 - 3s/epoch - 290ms/step\n",
            "Epoch 4329/5000\n",
            "\n",
            "Epoch 4329: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.7698 - 2s/epoch - 273ms/step\n",
            "Epoch 4330/5000\n",
            "\n",
            "Epoch 4330: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.7698 - 4s/epoch - 448ms/step\n",
            "Epoch 4331/5000\n",
            "\n",
            "Epoch 4331: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8027 - val_accuracy: 0.7626 - 3s/epoch - 325ms/step\n",
            "Epoch 4332/5000\n",
            "\n",
            "Epoch 4332: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.7662 - 3s/epoch - 295ms/step\n",
            "Epoch 4333/5000\n",
            "\n",
            "Epoch 4333: val_accuracy did not improve from 0.78417\n",
            "9/9 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.7698 - 2s/epoch - 274ms/step\n",
            "Epoch 4334/5000\n",
            "\n",
            "Epoch 4334: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.7698 - 3s/epoch - 301ms/step\n",
            "Epoch 4335/5000\n",
            "\n",
            "Epoch 4335: val_accuracy did not improve from 0.78417\n",
            "9/9 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.7698 - 4s/epoch - 476ms/step\n",
            "Epoch 4336/5000\n",
            "\n",
            "Epoch 4336: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7806 - 3s/epoch - 293ms/step\n",
            "Epoch 4337/5000\n",
            "\n",
            "Epoch 4337: val_accuracy did not improve from 0.78417\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8110 - val_accuracy: 0.7806 - 3s/epoch - 293ms/step\n",
            "Epoch 4338/5000\n",
            "\n",
            "Epoch 4338: val_accuracy improved from 0.78417 to 0.78777, saving model to xcorr_mi_nmi_mean.best.hdf5\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8169 - val_accuracy: 0.7878 - 3s/epoch - 304ms/step\n",
            "Epoch 4339/5000\n",
            "\n",
            "Epoch 4339: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8111 - val_accuracy: 0.7878 - 4s/epoch - 400ms/step\n",
            "Epoch 4340/5000\n",
            "\n",
            "Epoch 4340: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8082 - val_accuracy: 0.7770 - 3s/epoch - 372ms/step\n",
            "Epoch 4341/5000\n",
            "\n",
            "Epoch 4341: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8066 - val_accuracy: 0.7734 - 3s/epoch - 300ms/step\n",
            "Epoch 4342/5000\n",
            "\n",
            "Epoch 4342: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8024 - val_accuracy: 0.7698 - 3s/epoch - 294ms/step\n",
            "Epoch 4343/5000\n",
            "\n",
            "Epoch 4343: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4344/5000\n",
            "\n",
            "Epoch 4344: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7698 - 4s/epoch - 472ms/step\n",
            "Epoch 4345/5000\n",
            "\n",
            "Epoch 4345: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8041 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4346/5000\n",
            "\n",
            "Epoch 4346: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4347/5000\n",
            "\n",
            "Epoch 4347: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7985 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4348/5000\n",
            "\n",
            "Epoch 4348: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8019 - val_accuracy: 0.7698 - 3s/epoch - 323ms/step\n",
            "Epoch 4349/5000\n",
            "\n",
            "Epoch 4349: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8046 - val_accuracy: 0.7662 - 4s/epoch - 447ms/step\n",
            "Epoch 4350/5000\n",
            "\n",
            "Epoch 4350: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8012 - val_accuracy: 0.7698 - 3s/epoch - 294ms/step\n",
            "Epoch 4351/5000\n",
            "\n",
            "Epoch 4351: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7974 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 4352/5000\n",
            "\n",
            "Epoch 4352: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.7734 - 3s/epoch - 280ms/step\n",
            "Epoch 4353/5000\n",
            "\n",
            "Epoch 4353: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8016 - val_accuracy: 0.7770 - 4s/epoch - 406ms/step\n",
            "Epoch 4354/5000\n",
            "\n",
            "Epoch 4354: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.7770 - 3s/epoch - 373ms/step\n",
            "Epoch 4355/5000\n",
            "\n",
            "Epoch 4355: val_accuracy did not improve from 0.78777\n",
            "9/9 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7889 - val_accuracy: 0.7770 - 2s/epoch - 275ms/step\n",
            "Epoch 4356/5000\n",
            "\n",
            "Epoch 4356: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7887 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4357/5000\n",
            "\n",
            "Epoch 4357: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7951 - val_accuracy: 0.7806 - 3s/epoch - 298ms/step\n",
            "Epoch 4358/5000\n",
            "\n",
            "Epoch 4358: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8020 - val_accuracy: 0.7806 - 4s/epoch - 497ms/step\n",
            "Epoch 4359/5000\n",
            "\n",
            "Epoch 4359: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7806 - 3s/epoch - 278ms/step\n",
            "Epoch 4360/5000\n",
            "\n",
            "Epoch 4360: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.7842 - 3s/epoch - 282ms/step\n",
            "Epoch 4361/5000\n",
            "\n",
            "Epoch 4361: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7964 - val_accuracy: 0.7770 - 3s/epoch - 280ms/step\n",
            "Epoch 4362/5000\n",
            "\n",
            "Epoch 4362: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 0.7698 - 3s/epoch - 313ms/step\n",
            "Epoch 4363/5000\n",
            "\n",
            "Epoch 4363: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7953 - val_accuracy: 0.7734 - 4s/epoch - 463ms/step\n",
            "Epoch 4364/5000\n",
            "\n",
            "Epoch 4364: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.7662 - 3s/epoch - 294ms/step\n",
            "Epoch 4365/5000\n",
            "\n",
            "Epoch 4365: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.7662 - 3s/epoch - 297ms/step\n",
            "Epoch 4366/5000\n",
            "\n",
            "Epoch 4366: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8016 - val_accuracy: 0.7698 - 3s/epoch - 279ms/step\n",
            "Epoch 4367/5000\n",
            "\n",
            "Epoch 4367: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8020 - val_accuracy: 0.7662 - 4s/epoch - 420ms/step\n",
            "Epoch 4368/5000\n",
            "\n",
            "Epoch 4368: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.7698 - 3s/epoch - 348ms/step\n",
            "Epoch 4369/5000\n",
            "\n",
            "Epoch 4369: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4370/5000\n",
            "\n",
            "Epoch 4370: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7925 - val_accuracy: 0.7806 - 3s/epoch - 282ms/step\n",
            "Epoch 4371/5000\n",
            "\n",
            "Epoch 4371: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7871 - val_accuracy: 0.7806 - 3s/epoch - 296ms/step\n",
            "Epoch 4372/5000\n",
            "\n",
            "Epoch 4372: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7879 - val_accuracy: 0.7770 - 4s/epoch - 439ms/step\n",
            "Epoch 4373/5000\n",
            "\n",
            "Epoch 4373: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7874 - val_accuracy: 0.7698 - 3s/epoch - 304ms/step\n",
            "Epoch 4374/5000\n",
            "\n",
            "Epoch 4374: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7869 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 4375/5000\n",
            "\n",
            "Epoch 4375: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7929 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 4376/5000\n",
            "\n",
            "Epoch 4376: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7869 - val_accuracy: 0.7734 - 3s/epoch - 293ms/step\n",
            "Epoch 4377/5000\n",
            "\n",
            "Epoch 4377: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7894 - val_accuracy: 0.7698 - 4s/epoch - 483ms/step\n",
            "Epoch 4378/5000\n",
            "\n",
            "Epoch 4378: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7983 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 4379/5000\n",
            "\n",
            "Epoch 4379: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7997 - val_accuracy: 0.7734 - 3s/epoch - 283ms/step\n",
            "Epoch 4380/5000\n",
            "\n",
            "Epoch 4380: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.7734 - 3s/epoch - 293ms/step\n",
            "Epoch 4381/5000\n",
            "\n",
            "Epoch 4381: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7962 - val_accuracy: 0.7662 - 3s/epoch - 371ms/step\n",
            "Epoch 4382/5000\n",
            "\n",
            "Epoch 4382: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7936 - val_accuracy: 0.7770 - 4s/epoch - 413ms/step\n",
            "Epoch 4383/5000\n",
            "\n",
            "Epoch 4383: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7947 - val_accuracy: 0.7734 - 3s/epoch - 301ms/step\n",
            "Epoch 4384/5000\n",
            "\n",
            "Epoch 4384: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7981 - val_accuracy: 0.7770 - 3s/epoch - 286ms/step\n",
            "Epoch 4385/5000\n",
            "\n",
            "Epoch 4385: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8012 - val_accuracy: 0.7806 - 3s/epoch - 301ms/step\n",
            "Epoch 4386/5000\n",
            "\n",
            "Epoch 4386: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.7770 - 4s/epoch - 477ms/step\n",
            "Epoch 4387/5000\n",
            "\n",
            "Epoch 4387: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7889 - val_accuracy: 0.7734 - 3s/epoch - 313ms/step\n",
            "Epoch 4388/5000\n",
            "\n",
            "Epoch 4388: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7905 - val_accuracy: 0.7662 - 3s/epoch - 309ms/step\n",
            "Epoch 4389/5000\n",
            "\n",
            "Epoch 4389: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.7662 - 3s/epoch - 297ms/step\n",
            "Epoch 4390/5000\n",
            "\n",
            "Epoch 4390: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8068 - val_accuracy: 0.7698 - 3s/epoch - 332ms/step\n",
            "Epoch 4391/5000\n",
            "\n",
            "Epoch 4391: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8131 - val_accuracy: 0.7662 - 4s/epoch - 408ms/step\n",
            "Epoch 4392/5000\n",
            "\n",
            "Epoch 4392: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8145 - val_accuracy: 0.7698 - 3s/epoch - 294ms/step\n",
            "Epoch 4393/5000\n",
            "\n",
            "Epoch 4393: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8129 - val_accuracy: 0.7734 - 3s/epoch - 290ms/step\n",
            "Epoch 4394/5000\n",
            "\n",
            "Epoch 4394: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8128 - val_accuracy: 0.7734 - 3s/epoch - 301ms/step\n",
            "Epoch 4395/5000\n",
            "\n",
            "Epoch 4395: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8101 - val_accuracy: 0.7734 - 4s/epoch - 394ms/step\n",
            "Epoch 4396/5000\n",
            "\n",
            "Epoch 4396: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.7698 - 3s/epoch - 385ms/step\n",
            "Epoch 4397/5000\n",
            "\n",
            "Epoch 4397: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8066 - val_accuracy: 0.7662 - 3s/epoch - 290ms/step\n",
            "Epoch 4398/5000\n",
            "\n",
            "Epoch 4398: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.7698 - 3s/epoch - 294ms/step\n",
            "Epoch 4399/5000\n",
            "\n",
            "Epoch 4399: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8108 - val_accuracy: 0.7734 - 3s/epoch - 290ms/step\n",
            "Epoch 4400/5000\n",
            "\n",
            "Epoch 4400: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8066 - val_accuracy: 0.7734 - 4s/epoch - 489ms/step\n",
            "Epoch 4401/5000\n",
            "\n",
            "Epoch 4401: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8045 - val_accuracy: 0.7734 - 3s/epoch - 299ms/step\n",
            "Epoch 4402/5000\n",
            "\n",
            "Epoch 4402: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.7698 - 3s/epoch - 281ms/step\n",
            "Epoch 4403/5000\n",
            "\n",
            "Epoch 4403: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.7698 - 3s/epoch - 298ms/step\n",
            "Epoch 4404/5000\n",
            "\n",
            "Epoch 4404: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7972 - val_accuracy: 0.7698 - 3s/epoch - 334ms/step\n",
            "Epoch 4405/5000\n",
            "\n",
            "Epoch 4405: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8075 - val_accuracy: 0.7662 - 4s/epoch - 422ms/step\n",
            "Epoch 4406/5000\n",
            "\n",
            "Epoch 4406: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.7698 - 3s/epoch - 292ms/step\n",
            "Epoch 4407/5000\n",
            "\n",
            "Epoch 4407: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.7806 - 3s/epoch - 297ms/step\n",
            "Epoch 4408/5000\n",
            "\n",
            "Epoch 4408: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7953 - val_accuracy: 0.7770 - 3s/epoch - 306ms/step\n",
            "Epoch 4409/5000\n",
            "\n",
            "Epoch 4409: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7973 - val_accuracy: 0.7770 - 4s/epoch - 390ms/step\n",
            "Epoch 4410/5000\n",
            "\n",
            "Epoch 4410: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7734 - 3s/epoch - 367ms/step\n",
            "Epoch 4411/5000\n",
            "\n",
            "Epoch 4411: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8052 - val_accuracy: 0.7770 - 3s/epoch - 293ms/step\n",
            "Epoch 4412/5000\n",
            "\n",
            "Epoch 4412: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8073 - val_accuracy: 0.7770 - 3s/epoch - 280ms/step\n",
            "Epoch 4413/5000\n",
            "\n",
            "Epoch 4413: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 4414/5000\n",
            "\n",
            "Epoch 4414: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8027 - val_accuracy: 0.7698 - 4s/epoch - 448ms/step\n",
            "Epoch 4415/5000\n",
            "\n",
            "Epoch 4415: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8043 - val_accuracy: 0.7734 - 3s/epoch - 337ms/step\n",
            "Epoch 4416/5000\n",
            "\n",
            "Epoch 4416: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8212 - val_accuracy: 0.7734 - 3s/epoch - 279ms/step\n",
            "Epoch 4417/5000\n",
            "\n",
            "Epoch 4417: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8192 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4418/5000\n",
            "\n",
            "Epoch 4418: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8049 - val_accuracy: 0.7770 - 3s/epoch - 303ms/step\n",
            "Epoch 4419/5000\n",
            "\n",
            "Epoch 4419: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7908 - val_accuracy: 0.7734 - 4s/epoch - 495ms/step\n",
            "Epoch 4420/5000\n",
            "\n",
            "Epoch 4420: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7956 - val_accuracy: 0.7662 - 3s/epoch - 301ms/step\n",
            "Epoch 4421/5000\n",
            "\n",
            "Epoch 4421: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.7698 - 3s/epoch - 301ms/step\n",
            "Epoch 4422/5000\n",
            "\n",
            "Epoch 4422: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8062 - val_accuracy: 0.7662 - 3s/epoch - 303ms/step\n",
            "Epoch 4423/5000\n",
            "\n",
            "Epoch 4423: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.7662 - 4s/epoch - 401ms/step\n",
            "Epoch 4424/5000\n",
            "\n",
            "Epoch 4424: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8062 - val_accuracy: 0.7662 - 3s/epoch - 376ms/step\n",
            "Epoch 4425/5000\n",
            "\n",
            "Epoch 4425: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7662 - 3s/epoch - 292ms/step\n",
            "Epoch 4426/5000\n",
            "\n",
            "Epoch 4426: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8038 - val_accuracy: 0.7734 - 3s/epoch - 293ms/step\n",
            "Epoch 4427/5000\n",
            "\n",
            "Epoch 4427: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7989 - val_accuracy: 0.7698 - 3s/epoch - 298ms/step\n",
            "Epoch 4428/5000\n",
            "\n",
            "Epoch 4428: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7883 - val_accuracy: 0.7698 - 4s/epoch - 471ms/step\n",
            "Epoch 4429/5000\n",
            "\n",
            "Epoch 4429: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7893 - val_accuracy: 0.7662 - 3s/epoch - 297ms/step\n",
            "Epoch 4430/5000\n",
            "\n",
            "Epoch 4430: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7935 - val_accuracy: 0.7698 - 3s/epoch - 278ms/step\n",
            "Epoch 4431/5000\n",
            "\n",
            "Epoch 4431: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7957 - val_accuracy: 0.7770 - 3s/epoch - 294ms/step\n",
            "Epoch 4432/5000\n",
            "\n",
            "Epoch 4432: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7958 - val_accuracy: 0.7662 - 3s/epoch - 295ms/step\n",
            "Epoch 4433/5000\n",
            "\n",
            "Epoch 4433: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8069 - val_accuracy: 0.7626 - 4s/epoch - 483ms/step\n",
            "Epoch 4434/5000\n",
            "\n",
            "Epoch 4434: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8262 - val_accuracy: 0.7698 - 3s/epoch - 282ms/step\n",
            "Epoch 4435/5000\n",
            "\n",
            "Epoch 4435: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8179 - val_accuracy: 0.7734 - 3s/epoch - 281ms/step\n",
            "Epoch 4436/5000\n",
            "\n",
            "Epoch 4436: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8102 - val_accuracy: 0.7806 - 3s/epoch - 295ms/step\n",
            "Epoch 4437/5000\n",
            "\n",
            "Epoch 4437: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7969 - val_accuracy: 0.7770 - 3s/epoch - 374ms/step\n",
            "Epoch 4438/5000\n",
            "\n",
            "Epoch 4438: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7864 - val_accuracy: 0.7842 - 4s/epoch - 398ms/step\n",
            "Epoch 4439/5000\n",
            "\n",
            "Epoch 4439: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7867 - val_accuracy: 0.7806 - 3s/epoch - 298ms/step\n",
            "Epoch 4440/5000\n",
            "\n",
            "Epoch 4440: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7883 - val_accuracy: 0.7806 - 3s/epoch - 294ms/step\n",
            "Epoch 4441/5000\n",
            "\n",
            "Epoch 4441: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7873 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4442/5000\n",
            "\n",
            "Epoch 4442: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7953 - val_accuracy: 0.7770 - 4s/epoch - 479ms/step\n",
            "Epoch 4443/5000\n",
            "\n",
            "Epoch 4443: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8035 - val_accuracy: 0.7734 - 3s/epoch - 301ms/step\n",
            "Epoch 4444/5000\n",
            "\n",
            "Epoch 4444: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4445/5000\n",
            "\n",
            "Epoch 4445: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7985 - val_accuracy: 0.7698 - 3s/epoch - 278ms/step\n",
            "Epoch 4446/5000\n",
            "\n",
            "Epoch 4446: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7954 - val_accuracy: 0.7770 - 3s/epoch - 299ms/step\n",
            "Epoch 4447/5000\n",
            "\n",
            "Epoch 4447: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.7770 - 4s/epoch - 471ms/step\n",
            "Epoch 4448/5000\n",
            "\n",
            "Epoch 4448: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 4449/5000\n",
            "\n",
            "Epoch 4449: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8064 - val_accuracy: 0.7698 - 3s/epoch - 300ms/step\n",
            "Epoch 4450/5000\n",
            "\n",
            "Epoch 4450: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8098 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 4451/5000\n",
            "\n",
            "Epoch 4451: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8101 - val_accuracy: 0.7734 - 3s/epoch - 384ms/step\n",
            "Epoch 4452/5000\n",
            "\n",
            "Epoch 4452: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8097 - val_accuracy: 0.7770 - 4s/epoch - 395ms/step\n",
            "Epoch 4453/5000\n",
            "\n",
            "Epoch 4453: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8073 - val_accuracy: 0.7770 - 3s/epoch - 293ms/step\n",
            "Epoch 4454/5000\n",
            "\n",
            "Epoch 4454: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7999 - val_accuracy: 0.7734 - 3s/epoch - 282ms/step\n",
            "Epoch 4455/5000\n",
            "\n",
            "Epoch 4455: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7946 - val_accuracy: 0.7842 - 3s/epoch - 302ms/step\n",
            "Epoch 4456/5000\n",
            "\n",
            "Epoch 4456: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7926 - val_accuracy: 0.7806 - 4s/epoch - 451ms/step\n",
            "Epoch 4457/5000\n",
            "\n",
            "Epoch 4457: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7975 - val_accuracy: 0.7806 - 3s/epoch - 323ms/step\n",
            "Epoch 4458/5000\n",
            "\n",
            "Epoch 4458: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8000 - val_accuracy: 0.7842 - 3s/epoch - 300ms/step\n",
            "Epoch 4459/5000\n",
            "\n",
            "Epoch 4459: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.7734 - 3s/epoch - 289ms/step\n",
            "Epoch 4460/5000\n",
            "\n",
            "Epoch 4460: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7977 - val_accuracy: 0.7770 - 3s/epoch - 311ms/step\n",
            "Epoch 4461/5000\n",
            "\n",
            "Epoch 4461: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7734 - 4s/epoch - 475ms/step\n",
            "Epoch 4462/5000\n",
            "\n",
            "Epoch 4462: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4463/5000\n",
            "\n",
            "Epoch 4463: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8188 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 4464/5000\n",
            "\n",
            "Epoch 4464: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8145 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4465/5000\n",
            "\n",
            "Epoch 4465: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8028 - val_accuracy: 0.7770 - 3s/epoch - 373ms/step\n",
            "Epoch 4466/5000\n",
            "\n",
            "Epoch 4466: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7939 - val_accuracy: 0.7734 - 4s/epoch - 392ms/step\n",
            "Epoch 4467/5000\n",
            "\n",
            "Epoch 4467: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8010 - val_accuracy: 0.7770 - 3s/epoch - 300ms/step\n",
            "Epoch 4468/5000\n",
            "\n",
            "Epoch 4468: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.7734 - 3s/epoch - 292ms/step\n",
            "Epoch 4469/5000\n",
            "\n",
            "Epoch 4469: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8062 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 4470/5000\n",
            "\n",
            "Epoch 4470: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8046 - val_accuracy: 0.7734 - 4s/epoch - 475ms/step\n",
            "Epoch 4471/5000\n",
            "\n",
            "Epoch 4471: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8013 - val_accuracy: 0.7770 - 3s/epoch - 282ms/step\n",
            "Epoch 4472/5000\n",
            "\n",
            "Epoch 4472: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.7806 - 3s/epoch - 295ms/step\n",
            "Epoch 4473/5000\n",
            "\n",
            "Epoch 4473: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.7770 - 3s/epoch - 310ms/step\n",
            "Epoch 4474/5000\n",
            "\n",
            "Epoch 4474: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.7770 - 3s/epoch - 376ms/step\n",
            "Epoch 4475/5000\n",
            "\n",
            "Epoch 4475: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8008 - val_accuracy: 0.7770 - 4s/epoch - 444ms/step\n",
            "Epoch 4476/5000\n",
            "\n",
            "Epoch 4476: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4477/5000\n",
            "\n",
            "Epoch 4477: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8007 - val_accuracy: 0.7770 - 3s/epoch - 292ms/step\n",
            "Epoch 4478/5000\n",
            "\n",
            "Epoch 4478: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8007 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4479/5000\n",
            "\n",
            "Epoch 4479: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.7662 - 4s/epoch - 465ms/step\n",
            "Epoch 4480/5000\n",
            "\n",
            "Epoch 4480: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.7698 - 3s/epoch - 316ms/step\n",
            "Epoch 4481/5000\n",
            "\n",
            "Epoch 4481: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7903 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4482/5000\n",
            "\n",
            "Epoch 4482: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7884 - val_accuracy: 0.7806 - 3s/epoch - 294ms/step\n",
            "Epoch 4483/5000\n",
            "\n",
            "Epoch 4483: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7944 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 4484/5000\n",
            "\n",
            "Epoch 4484: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8052 - val_accuracy: 0.7770 - 4s/epoch - 477ms/step\n",
            "Epoch 4485/5000\n",
            "\n",
            "Epoch 4485: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8059 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4486/5000\n",
            "\n",
            "Epoch 4486: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8060 - val_accuracy: 0.7662 - 3s/epoch - 298ms/step\n",
            "Epoch 4487/5000\n",
            "\n",
            "Epoch 4487: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8038 - val_accuracy: 0.7662 - 3s/epoch - 304ms/step\n",
            "Epoch 4488/5000\n",
            "\n",
            "Epoch 4488: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.7698 - 3s/epoch - 380ms/step\n",
            "Epoch 4489/5000\n",
            "\n",
            "Epoch 4489: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8094 - val_accuracy: 0.7698 - 4s/epoch - 397ms/step\n",
            "Epoch 4490/5000\n",
            "\n",
            "Epoch 4490: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7774 - val_accuracy: 0.7698 - 3s/epoch - 294ms/step\n",
            "Epoch 4491/5000\n",
            "\n",
            "Epoch 4491: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7818 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4492/5000\n",
            "\n",
            "Epoch 4492: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7944 - val_accuracy: 0.7734 - 3s/epoch - 279ms/step\n",
            "Epoch 4493/5000\n",
            "\n",
            "Epoch 4493: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.7770 - 4s/epoch - 488ms/step\n",
            "Epoch 4494/5000\n",
            "\n",
            "Epoch 4494: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.7734 - 3s/epoch - 308ms/step\n",
            "Epoch 4495/5000\n",
            "\n",
            "Epoch 4495: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.7842 - 3s/epoch - 296ms/step\n",
            "Epoch 4496/5000\n",
            "\n",
            "Epoch 4496: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7898 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4497/5000\n",
            "\n",
            "Epoch 4497: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7921 - val_accuracy: 0.7770 - 3s/epoch - 316ms/step\n",
            "Epoch 4498/5000\n",
            "\n",
            "Epoch 4498: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8035 - val_accuracy: 0.7734 - 4s/epoch - 467ms/step\n",
            "Epoch 4499/5000\n",
            "\n",
            "Epoch 4499: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8086 - val_accuracy: 0.7698 - 3s/epoch - 297ms/step\n",
            "Epoch 4500/5000\n",
            "\n",
            "Epoch 4500: val_accuracy did not improve from 0.78777\n",
            "9/9 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.7698 - 2s/epoch - 278ms/step\n",
            "Epoch 4501/5000\n",
            "\n",
            "Epoch 4501: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8120 - val_accuracy: 0.7662 - 3s/epoch - 297ms/step\n",
            "Epoch 4502/5000\n",
            "\n",
            "Epoch 4502: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8157 - val_accuracy: 0.7698 - 4s/epoch - 400ms/step\n",
            "Epoch 4503/5000\n",
            "\n",
            "Epoch 4503: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.7626 - 3s/epoch - 384ms/step\n",
            "Epoch 4504/5000\n",
            "\n",
            "Epoch 4504: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7895 - val_accuracy: 0.7626 - 3s/epoch - 280ms/step\n",
            "Epoch 4505/5000\n",
            "\n",
            "Epoch 4505: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7920 - val_accuracy: 0.7698 - 3s/epoch - 293ms/step\n",
            "Epoch 4506/5000\n",
            "\n",
            "Epoch 4506: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.7734 - 3s/epoch - 283ms/step\n",
            "Epoch 4507/5000\n",
            "\n",
            "Epoch 4507: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8008 - val_accuracy: 0.7734 - 4s/epoch - 453ms/step\n",
            "Epoch 4508/5000\n",
            "\n",
            "Epoch 4508: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7734 - 3s/epoch - 314ms/step\n",
            "Epoch 4509/5000\n",
            "\n",
            "Epoch 4509: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7662 - 3s/epoch - 295ms/step\n",
            "Epoch 4510/5000\n",
            "\n",
            "Epoch 4510: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7962 - val_accuracy: 0.7770 - 3s/epoch - 284ms/step\n",
            "Epoch 4511/5000\n",
            "\n",
            "Epoch 4511: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7934 - val_accuracy: 0.7770 - 3s/epoch - 288ms/step\n",
            "Epoch 4512/5000\n",
            "\n",
            "Epoch 4512: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7967 - val_accuracy: 0.7770 - 4s/epoch - 487ms/step\n",
            "Epoch 4513/5000\n",
            "\n",
            "Epoch 4513: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8238 - val_accuracy: 0.7734 - 3s/epoch - 305ms/step\n",
            "Epoch 4514/5000\n",
            "\n",
            "Epoch 4514: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8229 - val_accuracy: 0.7734 - 3s/epoch - 300ms/step\n",
            "Epoch 4515/5000\n",
            "\n",
            "Epoch 4515: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4516/5000\n",
            "\n",
            "Epoch 4516: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7698 - 4s/epoch - 408ms/step\n",
            "Epoch 4517/5000\n",
            "\n",
            "Epoch 4517: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7966 - val_accuracy: 0.7662 - 3s/epoch - 372ms/step\n",
            "Epoch 4518/5000\n",
            "\n",
            "Epoch 4518: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7964 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 4519/5000\n",
            "\n",
            "Epoch 4519: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8008 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 4520/5000\n",
            "\n",
            "Epoch 4520: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.7770 - 3s/epoch - 298ms/step\n",
            "Epoch 4521/5000\n",
            "\n",
            "Epoch 4521: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7985 - val_accuracy: 0.7806 - 4s/epoch - 468ms/step\n",
            "Epoch 4522/5000\n",
            "\n",
            "Epoch 4522: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.7770 - 3s/epoch - 283ms/step\n",
            "Epoch 4523/5000\n",
            "\n",
            "Epoch 4523: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7909 - val_accuracy: 0.7806 - 3s/epoch - 284ms/step\n",
            "Epoch 4524/5000\n",
            "\n",
            "Epoch 4524: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7880 - val_accuracy: 0.7806 - 3s/epoch - 296ms/step\n",
            "Epoch 4525/5000\n",
            "\n",
            "Epoch 4525: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.7842 - 3s/epoch - 301ms/step\n",
            "Epoch 4526/5000\n",
            "\n",
            "Epoch 4526: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.7806 - 4s/epoch - 467ms/step\n",
            "Epoch 4527/5000\n",
            "\n",
            "Epoch 4527: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8068 - val_accuracy: 0.7770 - 3s/epoch - 298ms/step\n",
            "Epoch 4528/5000\n",
            "\n",
            "Epoch 4528: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.7806 - 3s/epoch - 284ms/step\n",
            "Epoch 4529/5000\n",
            "\n",
            "Epoch 4529: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8037 - val_accuracy: 0.7806 - 3s/epoch - 305ms/step\n",
            "Epoch 4530/5000\n",
            "\n",
            "Epoch 4530: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7965 - val_accuracy: 0.7734 - 4s/epoch - 404ms/step\n",
            "Epoch 4531/5000\n",
            "\n",
            "Epoch 4531: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7953 - val_accuracy: 0.7734 - 3s/epoch - 380ms/step\n",
            "Epoch 4532/5000\n",
            "\n",
            "Epoch 4532: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7967 - val_accuracy: 0.7806 - 3s/epoch - 295ms/step\n",
            "Epoch 4533/5000\n",
            "\n",
            "Epoch 4533: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7967 - val_accuracy: 0.7806 - 3s/epoch - 299ms/step\n",
            "Epoch 4534/5000\n",
            "\n",
            "Epoch 4534: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7968 - val_accuracy: 0.7734 - 3s/epoch - 293ms/step\n",
            "Epoch 4535/5000\n",
            "\n",
            "Epoch 4535: val_accuracy did not improve from 0.78777\n",
            "9/9 - 5s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7983 - val_accuracy: 0.7662 - 5s/epoch - 508ms/step\n",
            "Epoch 4536/5000\n",
            "\n",
            "Epoch 4536: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7997 - val_accuracy: 0.7698 - 3s/epoch - 298ms/step\n",
            "Epoch 4537/5000\n",
            "\n",
            "Epoch 4537: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8012 - val_accuracy: 0.7662 - 3s/epoch - 298ms/step\n",
            "Epoch 4538/5000\n",
            "\n",
            "Epoch 4538: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.7698 - 3s/epoch - 301ms/step\n",
            "Epoch 4539/5000\n",
            "\n",
            "Epoch 4539: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8094 - val_accuracy: 0.7734 - 4s/epoch - 396ms/step\n",
            "Epoch 4540/5000\n",
            "\n",
            "Epoch 4540: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8103 - val_accuracy: 0.7698 - 3s/epoch - 379ms/step\n",
            "Epoch 4541/5000\n",
            "\n",
            "Epoch 4541: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8116 - val_accuracy: 0.7698 - 3s/epoch - 290ms/step\n",
            "Epoch 4542/5000\n",
            "\n",
            "Epoch 4542: val_accuracy did not improve from 0.78777\n",
            "9/9 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8070 - val_accuracy: 0.7770 - 2s/epoch - 278ms/step\n",
            "Epoch 4543/5000\n",
            "\n",
            "Epoch 4543: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8049 - val_accuracy: 0.7734 - 3s/epoch - 301ms/step\n",
            "Epoch 4544/5000\n",
            "\n",
            "Epoch 4544: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.7770 - 4s/epoch - 440ms/step\n",
            "Epoch 4545/5000\n",
            "\n",
            "Epoch 4545: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8132 - val_accuracy: 0.7806 - 3s/epoch - 308ms/step\n",
            "Epoch 4546/5000\n",
            "\n",
            "Epoch 4546: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8222 - val_accuracy: 0.7806 - 3s/epoch - 300ms/step\n",
            "Epoch 4547/5000\n",
            "\n",
            "Epoch 4547: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8249 - val_accuracy: 0.7842 - 3s/epoch - 286ms/step\n",
            "Epoch 4548/5000\n",
            "\n",
            "Epoch 4548: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8199 - val_accuracy: 0.7842 - 3s/epoch - 279ms/step\n",
            "Epoch 4549/5000\n",
            "\n",
            "Epoch 4549: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.7770 - 4s/epoch - 471ms/step\n",
            "Epoch 4550/5000\n",
            "\n",
            "Epoch 4550: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8065 - val_accuracy: 0.7770 - 3s/epoch - 279ms/step\n",
            "Epoch 4551/5000\n",
            "\n",
            "Epoch 4551: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.7734 - 3s/epoch - 282ms/step\n",
            "Epoch 4552/5000\n",
            "\n",
            "Epoch 4552: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7982 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 4553/5000\n",
            "\n",
            "Epoch 4553: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8007 - val_accuracy: 0.7770 - 3s/epoch - 352ms/step\n",
            "Epoch 4554/5000\n",
            "\n",
            "Epoch 4554: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8029 - val_accuracy: 0.7770 - 4s/epoch - 436ms/step\n",
            "Epoch 4555/5000\n",
            "\n",
            "Epoch 4555: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4556/5000\n",
            "\n",
            "Epoch 4556: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8047 - val_accuracy: 0.7734 - 3s/epoch - 299ms/step\n",
            "Epoch 4557/5000\n",
            "\n",
            "Epoch 4557: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8045 - val_accuracy: 0.7734 - 3s/epoch - 288ms/step\n",
            "Epoch 4558/5000\n",
            "\n",
            "Epoch 4558: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7698 - 4s/epoch - 413ms/step\n",
            "Epoch 4559/5000\n",
            "\n",
            "Epoch 4559: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.7662 - 3s/epoch - 353ms/step\n",
            "Epoch 4560/5000\n",
            "\n",
            "Epoch 4560: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8037 - val_accuracy: 0.7662 - 3s/epoch - 284ms/step\n",
            "Epoch 4561/5000\n",
            "\n",
            "Epoch 4561: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.7770 - 3s/epoch - 285ms/step\n",
            "Epoch 4562/5000\n",
            "\n",
            "Epoch 4562: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7971 - val_accuracy: 0.7806 - 3s/epoch - 281ms/step\n",
            "Epoch 4563/5000\n",
            "\n",
            "Epoch 4563: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7936 - val_accuracy: 0.7842 - 4s/epoch - 431ms/step\n",
            "Epoch 4564/5000\n",
            "\n",
            "Epoch 4564: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.7842 - 3s/epoch - 318ms/step\n",
            "Epoch 4565/5000\n",
            "\n",
            "Epoch 4565: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7942 - val_accuracy: 0.7842 - 3s/epoch - 286ms/step\n",
            "Epoch 4566/5000\n",
            "\n",
            "Epoch 4566: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7941 - val_accuracy: 0.7842 - 3s/epoch - 295ms/step\n",
            "Epoch 4567/5000\n",
            "\n",
            "Epoch 4567: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7958 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 4568/5000\n",
            "\n",
            "Epoch 4568: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7981 - val_accuracy: 0.7770 - 4s/epoch - 488ms/step\n",
            "Epoch 4569/5000\n",
            "\n",
            "Epoch 4569: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8027 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4570/5000\n",
            "\n",
            "Epoch 4570: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8041 - val_accuracy: 0.7734 - 3s/epoch - 289ms/step\n",
            "Epoch 4571/5000\n",
            "\n",
            "Epoch 4571: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8060 - val_accuracy: 0.7770 - 3s/epoch - 292ms/step\n",
            "Epoch 4572/5000\n",
            "\n",
            "Epoch 4572: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8064 - val_accuracy: 0.7734 - 3s/epoch - 325ms/step\n",
            "Epoch 4573/5000\n",
            "\n",
            "Epoch 4573: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7698 - 4s/epoch - 424ms/step\n",
            "Epoch 4574/5000\n",
            "\n",
            "Epoch 4574: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7698 - 3s/epoch - 301ms/step\n",
            "Epoch 4575/5000\n",
            "\n",
            "Epoch 4575: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4576/5000\n",
            "\n",
            "Epoch 4576: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7941 - val_accuracy: 0.7770 - 3s/epoch - 280ms/step\n",
            "Epoch 4577/5000\n",
            "\n",
            "Epoch 4577: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.7770 - 4s/epoch - 390ms/step\n",
            "Epoch 4578/5000\n",
            "\n",
            "Epoch 4578: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8026 - val_accuracy: 0.7806 - 3s/epoch - 376ms/step\n",
            "Epoch 4579/5000\n",
            "\n",
            "Epoch 4579: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.7770 - 3s/epoch - 280ms/step\n",
            "Epoch 4580/5000\n",
            "\n",
            "Epoch 4580: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8066 - val_accuracy: 0.7770 - 3s/epoch - 294ms/step\n",
            "Epoch 4581/5000\n",
            "\n",
            "Epoch 4581: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8093 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4582/5000\n",
            "\n",
            "Epoch 4582: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8064 - val_accuracy: 0.7770 - 4s/epoch - 445ms/step\n",
            "Epoch 4583/5000\n",
            "\n",
            "Epoch 4583: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8026 - val_accuracy: 0.7806 - 3s/epoch - 321ms/step\n",
            "Epoch 4584/5000\n",
            "\n",
            "Epoch 4584: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8018 - val_accuracy: 0.7770 - 3s/epoch - 302ms/step\n",
            "Epoch 4585/5000\n",
            "\n",
            "Epoch 4585: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8018 - val_accuracy: 0.7698 - 3s/epoch - 280ms/step\n",
            "Epoch 4586/5000\n",
            "\n",
            "Epoch 4586: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7899 - val_accuracy: 0.7734 - 3s/epoch - 287ms/step\n",
            "Epoch 4587/5000\n",
            "\n",
            "Epoch 4587: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7886 - val_accuracy: 0.7770 - 4s/epoch - 469ms/step\n",
            "Epoch 4588/5000\n",
            "\n",
            "Epoch 4588: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.7806 - 3s/epoch - 295ms/step\n",
            "Epoch 4589/5000\n",
            "\n",
            "Epoch 4589: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8006 - val_accuracy: 0.7842 - 3s/epoch - 293ms/step\n",
            "Epoch 4590/5000\n",
            "\n",
            "Epoch 4590: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8040 - val_accuracy: 0.7842 - 3s/epoch - 294ms/step\n",
            "Epoch 4591/5000\n",
            "\n",
            "Epoch 4591: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8092 - val_accuracy: 0.7806 - 3s/epoch - 362ms/step\n",
            "Epoch 4592/5000\n",
            "\n",
            "Epoch 4592: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8045 - val_accuracy: 0.7734 - 4s/epoch - 403ms/step\n",
            "Epoch 4593/5000\n",
            "\n",
            "Epoch 4593: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7934 - val_accuracy: 0.7806 - 3s/epoch - 286ms/step\n",
            "Epoch 4594/5000\n",
            "\n",
            "Epoch 4594: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7801 - val_accuracy: 0.7842 - 3s/epoch - 280ms/step\n",
            "Epoch 4595/5000\n",
            "\n",
            "Epoch 4595: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7819 - val_accuracy: 0.7806 - 3s/epoch - 294ms/step\n",
            "Epoch 4596/5000\n",
            "\n",
            "Epoch 4596: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7898 - val_accuracy: 0.7806 - 4s/epoch - 442ms/step\n",
            "Epoch 4597/5000\n",
            "\n",
            "Epoch 4597: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7940 - val_accuracy: 0.7770 - 3s/epoch - 333ms/step\n",
            "Epoch 4598/5000\n",
            "\n",
            "Epoch 4598: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.7806 - 3s/epoch - 281ms/step\n",
            "Epoch 4599/5000\n",
            "\n",
            "Epoch 4599: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7969 - val_accuracy: 0.7806 - 3s/epoch - 281ms/step\n",
            "Epoch 4600/5000\n",
            "\n",
            "Epoch 4600: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8061 - val_accuracy: 0.7734 - 3s/epoch - 278ms/step\n",
            "Epoch 4601/5000\n",
            "\n",
            "Epoch 4601: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8112 - val_accuracy: 0.7806 - 4s/epoch - 496ms/step\n",
            "Epoch 4602/5000\n",
            "\n",
            "Epoch 4602: val_accuracy did not improve from 0.78777\n",
            "9/9 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.7770 - 2s/epoch - 272ms/step\n",
            "Epoch 4603/5000\n",
            "\n",
            "Epoch 4603: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.7770 - 3s/epoch - 288ms/step\n",
            "Epoch 4604/5000\n",
            "\n",
            "Epoch 4604: val_accuracy did not improve from 0.78777\n",
            "9/9 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.7770 - 2s/epoch - 275ms/step\n",
            "Epoch 4605/5000\n",
            "\n",
            "Epoch 4605: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7965 - val_accuracy: 0.7734 - 3s/epoch - 310ms/step\n",
            "Epoch 4606/5000\n",
            "\n",
            "Epoch 4606: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7929 - val_accuracy: 0.7698 - 4s/epoch - 436ms/step\n",
            "Epoch 4607/5000\n",
            "\n",
            "Epoch 4607: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7845 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 4608/5000\n",
            "\n",
            "Epoch 4608: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7835 - val_accuracy: 0.7770 - 3s/epoch - 278ms/step\n",
            "Epoch 4609/5000\n",
            "\n",
            "Epoch 4609: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7913 - val_accuracy: 0.7770 - 3s/epoch - 285ms/step\n",
            "Epoch 4610/5000\n",
            "\n",
            "Epoch 4610: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.7698 - 3s/epoch - 367ms/step\n",
            "Epoch 4611/5000\n",
            "\n",
            "Epoch 4611: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.7770 - 4s/epoch - 389ms/step\n",
            "Epoch 4612/5000\n",
            "\n",
            "Epoch 4612: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4613/5000\n",
            "\n",
            "Epoch 4613: val_accuracy did not improve from 0.78777\n",
            "9/9 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8034 - val_accuracy: 0.7770 - 2s/epoch - 278ms/step\n",
            "Epoch 4614/5000\n",
            "\n",
            "Epoch 4614: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8108 - val_accuracy: 0.7698 - 3s/epoch - 281ms/step\n",
            "Epoch 4615/5000\n",
            "\n",
            "Epoch 4615: val_accuracy did not improve from 0.78777\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.7662 - 4s/epoch - 422ms/step\n",
            "Epoch 4616/5000\n",
            "\n",
            "Epoch 4616: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8152 - val_accuracy: 0.7806 - 3s/epoch - 336ms/step\n",
            "Epoch 4617/5000\n",
            "\n",
            "Epoch 4617: val_accuracy did not improve from 0.78777\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8242 - val_accuracy: 0.7842 - 3s/epoch - 292ms/step\n",
            "Epoch 4618/5000\n",
            "\n",
            "Epoch 4618: val_accuracy improved from 0.78777 to 0.79137, saving model to xcorr_mi_nmi_mean.best.hdf5\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8260 - val_accuracy: 0.7914 - 3s/epoch - 296ms/step\n",
            "Epoch 4619/5000\n",
            "\n",
            "Epoch 4619: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8157 - val_accuracy: 0.7878 - 3s/epoch - 292ms/step\n",
            "Epoch 4620/5000\n",
            "\n",
            "Epoch 4620: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8108 - val_accuracy: 0.7842 - 4s/epoch - 473ms/step\n",
            "Epoch 4621/5000\n",
            "\n",
            "Epoch 4621: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8081 - val_accuracy: 0.7806 - 3s/epoch - 279ms/step\n",
            "Epoch 4622/5000\n",
            "\n",
            "Epoch 4622: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8126 - val_accuracy: 0.7806 - 3s/epoch - 279ms/step\n",
            "Epoch 4623/5000\n",
            "\n",
            "Epoch 4623: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8203 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 4624/5000\n",
            "\n",
            "Epoch 4624: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8203 - val_accuracy: 0.7662 - 3s/epoch - 348ms/step\n",
            "Epoch 4625/5000\n",
            "\n",
            "Epoch 4625: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8089 - val_accuracy: 0.7734 - 4s/epoch - 440ms/step\n",
            "Epoch 4626/5000\n",
            "\n",
            "Epoch 4626: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4627/5000\n",
            "\n",
            "Epoch 4627: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8132 - val_accuracy: 0.7698 - 3s/epoch - 287ms/step\n",
            "Epoch 4628/5000\n",
            "\n",
            "Epoch 4628: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8181 - val_accuracy: 0.7698 - 3s/epoch - 293ms/step\n",
            "Epoch 4629/5000\n",
            "\n",
            "Epoch 4629: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8165 - val_accuracy: 0.7698 - 4s/epoch - 398ms/step\n",
            "Epoch 4630/5000\n",
            "\n",
            "Epoch 4630: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8154 - val_accuracy: 0.7734 - 3s/epoch - 352ms/step\n",
            "Epoch 4631/5000\n",
            "\n",
            "Epoch 4631: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8153 - val_accuracy: 0.7770 - 3s/epoch - 288ms/step\n",
            "Epoch 4632/5000\n",
            "\n",
            "Epoch 4632: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8060 - val_accuracy: 0.7734 - 3s/epoch - 299ms/step\n",
            "Epoch 4633/5000\n",
            "\n",
            "Epoch 4633: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8038 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 4634/5000\n",
            "\n",
            "Epoch 4634: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.7770 - 4s/epoch - 470ms/step\n",
            "Epoch 4635/5000\n",
            "\n",
            "Epoch 4635: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.7698 - 3s/epoch - 283ms/step\n",
            "Epoch 4636/5000\n",
            "\n",
            "Epoch 4636: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8086 - val_accuracy: 0.7698 - 3s/epoch - 294ms/step\n",
            "Epoch 4637/5000\n",
            "\n",
            "Epoch 4637: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7967 - val_accuracy: 0.7806 - 3s/epoch - 292ms/step\n",
            "Epoch 4638/5000\n",
            "\n",
            "Epoch 4638: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7950 - val_accuracy: 0.7806 - 3s/epoch - 283ms/step\n",
            "Epoch 4639/5000\n",
            "\n",
            "Epoch 4639: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8005 - val_accuracy: 0.7770 - 4s/epoch - 473ms/step\n",
            "Epoch 4640/5000\n",
            "\n",
            "Epoch 4640: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8085 - val_accuracy: 0.7734 - 3s/epoch - 289ms/step\n",
            "Epoch 4641/5000\n",
            "\n",
            "Epoch 4641: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 4642/5000\n",
            "\n",
            "Epoch 4642: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8206 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 4643/5000\n",
            "\n",
            "Epoch 4643: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8206 - val_accuracy: 0.7734 - 3s/epoch - 331ms/step\n",
            "Epoch 4644/5000\n",
            "\n",
            "Epoch 4644: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8136 - val_accuracy: 0.7770 - 4s/epoch - 422ms/step\n",
            "Epoch 4645/5000\n",
            "\n",
            "Epoch 4645: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8088 - val_accuracy: 0.7770 - 3s/epoch - 280ms/step\n",
            "Epoch 4646/5000\n",
            "\n",
            "Epoch 4646: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8062 - val_accuracy: 0.7770 - 3s/epoch - 280ms/step\n",
            "Epoch 4647/5000\n",
            "\n",
            "Epoch 4647: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.7698 - 3s/epoch - 292ms/step\n",
            "Epoch 4648/5000\n",
            "\n",
            "Epoch 4648: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8076 - val_accuracy: 0.7698 - 4s/epoch - 393ms/step\n",
            "Epoch 4649/5000\n",
            "\n",
            "Epoch 4649: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8074 - val_accuracy: 0.7734 - 3s/epoch - 362ms/step\n",
            "Epoch 4650/5000\n",
            "\n",
            "Epoch 4650: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8040 - val_accuracy: 0.7734 - 3s/epoch - 303ms/step\n",
            "Epoch 4651/5000\n",
            "\n",
            "Epoch 4651: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 4652/5000\n",
            "\n",
            "Epoch 4652: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7967 - val_accuracy: 0.7662 - 3s/epoch - 293ms/step\n",
            "Epoch 4653/5000\n",
            "\n",
            "Epoch 4653: val_accuracy did not improve from 0.79137\n",
            "9/9 - 5s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7980 - val_accuracy: 0.7662 - 5s/epoch - 502ms/step\n",
            "Epoch 4654/5000\n",
            "\n",
            "Epoch 4654: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.7698 - 3s/epoch - 291ms/step\n",
            "Epoch 4655/5000\n",
            "\n",
            "Epoch 4655: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8035 - val_accuracy: 0.7626 - 3s/epoch - 291ms/step\n",
            "Epoch 4656/5000\n",
            "\n",
            "Epoch 4656: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 4657/5000\n",
            "\n",
            "Epoch 4657: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8322 - val_accuracy: 0.7770 - 3s/epoch - 362ms/step\n",
            "Epoch 4658/5000\n",
            "\n",
            "Epoch 4658: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8361 - val_accuracy: 0.7770 - 4s/epoch - 393ms/step\n",
            "Epoch 4659/5000\n",
            "\n",
            "Epoch 4659: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8193 - val_accuracy: 0.7806 - 3s/epoch - 288ms/step\n",
            "Epoch 4660/5000\n",
            "\n",
            "Epoch 4660: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8095 - val_accuracy: 0.7770 - 3s/epoch - 292ms/step\n",
            "Epoch 4661/5000\n",
            "\n",
            "Epoch 4661: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8040 - val_accuracy: 0.7806 - 3s/epoch - 293ms/step\n",
            "Epoch 4662/5000\n",
            "\n",
            "Epoch 4662: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.7806 - 4s/epoch - 421ms/step\n",
            "Epoch 4663/5000\n",
            "\n",
            "Epoch 4663: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8107 - val_accuracy: 0.7770 - 3s/epoch - 349ms/step\n",
            "Epoch 4664/5000\n",
            "\n",
            "Epoch 4664: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8142 - val_accuracy: 0.7806 - 3s/epoch - 295ms/step\n",
            "Epoch 4665/5000\n",
            "\n",
            "Epoch 4665: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8119 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4666/5000\n",
            "\n",
            "Epoch 4666: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.7806 - 3s/epoch - 293ms/step\n",
            "Epoch 4667/5000\n",
            "\n",
            "Epoch 4667: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8030 - val_accuracy: 0.7770 - 4s/epoch - 485ms/step\n",
            "Epoch 4668/5000\n",
            "\n",
            "Epoch 4668: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8020 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4669/5000\n",
            "\n",
            "Epoch 4669: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.7770 - 3s/epoch - 298ms/step\n",
            "Epoch 4670/5000\n",
            "\n",
            "Epoch 4670: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7999 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4671/5000\n",
            "\n",
            "Epoch 4671: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8011 - val_accuracy: 0.7734 - 3s/epoch - 334ms/step\n",
            "Epoch 4672/5000\n",
            "\n",
            "Epoch 4672: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.7734 - 4s/epoch - 425ms/step\n",
            "Epoch 4673/5000\n",
            "\n",
            "Epoch 4673: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 4674/5000\n",
            "\n",
            "Epoch 4674: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7999 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4675/5000\n",
            "\n",
            "Epoch 4675: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7967 - val_accuracy: 0.7806 - 3s/epoch - 293ms/step\n",
            "Epoch 4676/5000\n",
            "\n",
            "Epoch 4676: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.7806 - 4s/epoch - 435ms/step\n",
            "Epoch 4677/5000\n",
            "\n",
            "Epoch 4677: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8108 - val_accuracy: 0.7806 - 3s/epoch - 318ms/step\n",
            "Epoch 4678/5000\n",
            "\n",
            "Epoch 4678: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4679/5000\n",
            "\n",
            "Epoch 4679: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8231 - val_accuracy: 0.7734 - 3s/epoch - 291ms/step\n",
            "Epoch 4680/5000\n",
            "\n",
            "Epoch 4680: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8125 - val_accuracy: 0.7770 - 3s/epoch - 282ms/step\n",
            "Epoch 4681/5000\n",
            "\n",
            "Epoch 4681: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.7698 - 4s/epoch - 486ms/step\n",
            "Epoch 4682/5000\n",
            "\n",
            "Epoch 4682: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.7698 - 3s/epoch - 292ms/step\n",
            "Epoch 4683/5000\n",
            "\n",
            "Epoch 4683: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.7770 - 3s/epoch - 288ms/step\n",
            "Epoch 4684/5000\n",
            "\n",
            "Epoch 4684: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.7734 - 3s/epoch - 288ms/step\n",
            "Epoch 4685/5000\n",
            "\n",
            "Epoch 4685: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7982 - val_accuracy: 0.7770 - 3s/epoch - 353ms/step\n",
            "Epoch 4686/5000\n",
            "\n",
            "Epoch 4686: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.7770 - 4s/epoch - 417ms/step\n",
            "Epoch 4687/5000\n",
            "\n",
            "Epoch 4687: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8066 - val_accuracy: 0.7698 - 3s/epoch - 294ms/step\n",
            "Epoch 4688/5000\n",
            "\n",
            "Epoch 4688: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8005 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4689/5000\n",
            "\n",
            "Epoch 4689: val_accuracy did not improve from 0.79137\n",
            "9/9 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8011 - val_accuracy: 0.7734 - 2s/epoch - 277ms/step\n",
            "Epoch 4690/5000\n",
            "\n",
            "Epoch 4690: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8018 - val_accuracy: 0.7770 - 4s/epoch - 427ms/step\n",
            "Epoch 4691/5000\n",
            "\n",
            "Epoch 4691: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.7734 - 3s/epoch - 337ms/step\n",
            "Epoch 4692/5000\n",
            "\n",
            "Epoch 4692: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7948 - val_accuracy: 0.7770 - 3s/epoch - 293ms/step\n",
            "Epoch 4693/5000\n",
            "\n",
            "Epoch 4693: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7980 - val_accuracy: 0.7806 - 3s/epoch - 293ms/step\n",
            "Epoch 4694/5000\n",
            "\n",
            "Epoch 4694: val_accuracy did not improve from 0.79137\n",
            "9/9 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7886 - val_accuracy: 0.7842 - 2s/epoch - 277ms/step\n",
            "Epoch 4695/5000\n",
            "\n",
            "Epoch 4695: val_accuracy did not improve from 0.79137\n",
            "9/9 - 5s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.7842 - 5s/epoch - 507ms/step\n",
            "Epoch 4696/5000\n",
            "\n",
            "Epoch 4696: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8024 - val_accuracy: 0.7770 - 3s/epoch - 282ms/step\n",
            "Epoch 4697/5000\n",
            "\n",
            "Epoch 4697: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8020 - val_accuracy: 0.7770 - 3s/epoch - 289ms/step\n",
            "Epoch 4698/5000\n",
            "\n",
            "Epoch 4698: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.7734 - 3s/epoch - 289ms/step\n",
            "Epoch 4699/5000\n",
            "\n",
            "Epoch 4699: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.7698 - 3s/epoch - 361ms/step\n",
            "Epoch 4700/5000\n",
            "\n",
            "Epoch 4700: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7974 - val_accuracy: 0.7698 - 4s/epoch - 396ms/step\n",
            "Epoch 4701/5000\n",
            "\n",
            "Epoch 4701: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 4702/5000\n",
            "\n",
            "Epoch 4702: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.7770 - 3s/epoch - 294ms/step\n",
            "Epoch 4703/5000\n",
            "\n",
            "Epoch 4703: val_accuracy did not improve from 0.79137\n",
            "9/9 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.7770 - 2s/epoch - 273ms/step\n",
            "Epoch 4704/5000\n",
            "\n",
            "Epoch 4704: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.7770 - 4s/epoch - 406ms/step\n",
            "Epoch 4705/5000\n",
            "\n",
            "Epoch 4705: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7974 - val_accuracy: 0.7698 - 3s/epoch - 352ms/step\n",
            "Epoch 4706/5000\n",
            "\n",
            "Epoch 4706: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7985 - val_accuracy: 0.7662 - 3s/epoch - 295ms/step\n",
            "Epoch 4707/5000\n",
            "\n",
            "Epoch 4707: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.7698 - 3s/epoch - 298ms/step\n",
            "Epoch 4708/5000\n",
            "\n",
            "Epoch 4708: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8092 - val_accuracy: 0.7770 - 3s/epoch - 281ms/step\n",
            "Epoch 4709/5000\n",
            "\n",
            "Epoch 4709: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8102 - val_accuracy: 0.7770 - 4s/epoch - 467ms/step\n",
            "Epoch 4710/5000\n",
            "\n",
            "Epoch 4710: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.7770 - 3s/epoch - 288ms/step\n",
            "Epoch 4711/5000\n",
            "\n",
            "Epoch 4711: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8012 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4712/5000\n",
            "\n",
            "Epoch 4712: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8006 - val_accuracy: 0.7842 - 3s/epoch - 294ms/step\n",
            "Epoch 4713/5000\n",
            "\n",
            "Epoch 4713: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8018 - val_accuracy: 0.7734 - 3s/epoch - 301ms/step\n",
            "Epoch 4714/5000\n",
            "\n",
            "Epoch 4714: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8083 - val_accuracy: 0.7734 - 4s/epoch - 478ms/step\n",
            "Epoch 4715/5000\n",
            "\n",
            "Epoch 4715: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8072 - val_accuracy: 0.7770 - 3s/epoch - 294ms/step\n",
            "Epoch 4716/5000\n",
            "\n",
            "Epoch 4716: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 4717/5000\n",
            "\n",
            "Epoch 4717: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8034 - val_accuracy: 0.7770 - 3s/epoch - 283ms/step\n",
            "Epoch 4718/5000\n",
            "\n",
            "Epoch 4718: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7979 - val_accuracy: 0.7806 - 4s/epoch - 403ms/step\n",
            "Epoch 4719/5000\n",
            "\n",
            "Epoch 4719: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7976 - val_accuracy: 0.7842 - 3s/epoch - 379ms/step\n",
            "Epoch 4720/5000\n",
            "\n",
            "Epoch 4720: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8043 - val_accuracy: 0.7806 - 3s/epoch - 299ms/step\n",
            "Epoch 4721/5000\n",
            "\n",
            "Epoch 4721: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8082 - val_accuracy: 0.7806 - 3s/epoch - 295ms/step\n",
            "Epoch 4722/5000\n",
            "\n",
            "Epoch 4722: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8118 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 4723/5000\n",
            "\n",
            "Epoch 4723: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8181 - val_accuracy: 0.7662 - 4s/epoch - 463ms/step\n",
            "Epoch 4724/5000\n",
            "\n",
            "Epoch 4724: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8208 - val_accuracy: 0.7734 - 3s/epoch - 303ms/step\n",
            "Epoch 4725/5000\n",
            "\n",
            "Epoch 4725: val_accuracy did not improve from 0.79137\n",
            "9/9 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8183 - val_accuracy: 0.7734 - 2s/epoch - 270ms/step\n",
            "Epoch 4726/5000\n",
            "\n",
            "Epoch 4726: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8065 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4727/5000\n",
            "\n",
            "Epoch 4727: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8013 - val_accuracy: 0.7770 - 3s/epoch - 293ms/step\n",
            "Epoch 4728/5000\n",
            "\n",
            "Epoch 4728: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.7770 - 4s/epoch - 479ms/step\n",
            "Epoch 4729/5000\n",
            "\n",
            "Epoch 4729: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8012 - val_accuracy: 0.7806 - 3s/epoch - 282ms/step\n",
            "Epoch 4730/5000\n",
            "\n",
            "Epoch 4730: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8011 - val_accuracy: 0.7770 - 3s/epoch - 280ms/step\n",
            "Epoch 4731/5000\n",
            "\n",
            "Epoch 4731: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7950 - val_accuracy: 0.7806 - 3s/epoch - 294ms/step\n",
            "Epoch 4732/5000\n",
            "\n",
            "Epoch 4732: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.7842 - 3s/epoch - 356ms/step\n",
            "Epoch 4733/5000\n",
            "\n",
            "Epoch 4733: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.7806 - 4s/epoch - 405ms/step\n",
            "Epoch 4734/5000\n",
            "\n",
            "Epoch 4734: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 4735/5000\n",
            "\n",
            "Epoch 4735: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8084 - val_accuracy: 0.7770 - 3s/epoch - 282ms/step\n",
            "Epoch 4736/5000\n",
            "\n",
            "Epoch 4736: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8092 - val_accuracy: 0.7734 - 3s/epoch - 279ms/step\n",
            "Epoch 4737/5000\n",
            "\n",
            "Epoch 4737: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7770 - 4s/epoch - 443ms/step\n",
            "Epoch 4738/5000\n",
            "\n",
            "Epoch 4738: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8041 - val_accuracy: 0.7878 - 3s/epoch - 335ms/step\n",
            "Epoch 4739/5000\n",
            "\n",
            "Epoch 4739: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.7842 - 3s/epoch - 282ms/step\n",
            "Epoch 4740/5000\n",
            "\n",
            "Epoch 4740: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8092 - val_accuracy: 0.7734 - 3s/epoch - 301ms/step\n",
            "Epoch 4741/5000\n",
            "\n",
            "Epoch 4741: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8068 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 4742/5000\n",
            "\n",
            "Epoch 4742: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8024 - val_accuracy: 0.7662 - 4s/epoch - 481ms/step\n",
            "Epoch 4743/5000\n",
            "\n",
            "Epoch 4743: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.7734 - 3s/epoch - 279ms/step\n",
            "Epoch 4744/5000\n",
            "\n",
            "Epoch 4744: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8111 - val_accuracy: 0.7734 - 3s/epoch - 279ms/step\n",
            "Epoch 4745/5000\n",
            "\n",
            "Epoch 4745: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8122 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4746/5000\n",
            "\n",
            "Epoch 4746: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8110 - val_accuracy: 0.7770 - 3s/epoch - 335ms/step\n",
            "Epoch 4747/5000\n",
            "\n",
            "Epoch 4747: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8104 - val_accuracy: 0.7770 - 4s/epoch - 441ms/step\n",
            "Epoch 4748/5000\n",
            "\n",
            "Epoch 4748: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8169 - val_accuracy: 0.7878 - 3s/epoch - 282ms/step\n",
            "Epoch 4749/5000\n",
            "\n",
            "Epoch 4749: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.7842 - 3s/epoch - 296ms/step\n",
            "Epoch 4750/5000\n",
            "\n",
            "Epoch 4750: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8217 - val_accuracy: 0.7770 - 3s/epoch - 301ms/step\n",
            "Epoch 4751/5000\n",
            "\n",
            "Epoch 4751: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8257 - val_accuracy: 0.7878 - 4s/epoch - 440ms/step\n",
            "Epoch 4752/5000\n",
            "\n",
            "Epoch 4752: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8223 - val_accuracy: 0.7878 - 3s/epoch - 332ms/step\n",
            "Epoch 4753/5000\n",
            "\n",
            "Epoch 4753: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.7770 - 3s/epoch - 298ms/step\n",
            "Epoch 4754/5000\n",
            "\n",
            "Epoch 4754: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 4755/5000\n",
            "\n",
            "Epoch 4755: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8069 - val_accuracy: 0.7734 - 3s/epoch - 300ms/step\n",
            "Epoch 4756/5000\n",
            "\n",
            "Epoch 4756: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8024 - val_accuracy: 0.7770 - 4s/epoch - 460ms/step\n",
            "Epoch 4757/5000\n",
            "\n",
            "Epoch 4757: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.7842 - 3s/epoch - 293ms/step\n",
            "Epoch 4758/5000\n",
            "\n",
            "Epoch 4758: val_accuracy did not improve from 0.79137\n",
            "9/9 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8034 - val_accuracy: 0.7842 - 2s/epoch - 275ms/step\n",
            "Epoch 4759/5000\n",
            "\n",
            "Epoch 4759: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8103 - val_accuracy: 0.7806 - 3s/epoch - 297ms/step\n",
            "Epoch 4760/5000\n",
            "\n",
            "Epoch 4760: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8116 - val_accuracy: 0.7770 - 3s/epoch - 374ms/step\n",
            "Epoch 4761/5000\n",
            "\n",
            "Epoch 4761: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8211 - val_accuracy: 0.7770 - 3s/epoch - 387ms/step\n",
            "Epoch 4762/5000\n",
            "\n",
            "Epoch 4762: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8202 - val_accuracy: 0.7770 - 3s/epoch - 301ms/step\n",
            "Epoch 4763/5000\n",
            "\n",
            "Epoch 4763: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8167 - val_accuracy: 0.7770 - 3s/epoch - 279ms/step\n",
            "Epoch 4764/5000\n",
            "\n",
            "Epoch 4764: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8203 - val_accuracy: 0.7842 - 3s/epoch - 293ms/step\n",
            "Epoch 4765/5000\n",
            "\n",
            "Epoch 4765: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8222 - val_accuracy: 0.7770 - 4s/epoch - 459ms/step\n",
            "Epoch 4766/5000\n",
            "\n",
            "Epoch 4766: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8187 - val_accuracy: 0.7806 - 3s/epoch - 317ms/step\n",
            "Epoch 4767/5000\n",
            "\n",
            "Epoch 4767: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.7842 - 3s/epoch - 294ms/step\n",
            "Epoch 4768/5000\n",
            "\n",
            "Epoch 4768: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8041 - val_accuracy: 0.7842 - 3s/epoch - 301ms/step\n",
            "Epoch 4769/5000\n",
            "\n",
            "Epoch 4769: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7806 - 3s/epoch - 299ms/step\n",
            "Epoch 4770/5000\n",
            "\n",
            "Epoch 4770: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8065 - val_accuracy: 0.7770 - 4s/epoch - 471ms/step\n",
            "Epoch 4771/5000\n",
            "\n",
            "Epoch 4771: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8076 - val_accuracy: 0.7842 - 3s/epoch - 292ms/step\n",
            "Epoch 4772/5000\n",
            "\n",
            "Epoch 4772: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8047 - val_accuracy: 0.7842 - 3s/epoch - 299ms/step\n",
            "Epoch 4773/5000\n",
            "\n",
            "Epoch 4773: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7981 - val_accuracy: 0.7842 - 3s/epoch - 283ms/step\n",
            "Epoch 4774/5000\n",
            "\n",
            "Epoch 4774: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8073 - val_accuracy: 0.7842 - 4s/epoch - 393ms/step\n",
            "Epoch 4775/5000\n",
            "\n",
            "Epoch 4775: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8095 - val_accuracy: 0.7842 - 3s/epoch - 388ms/step\n",
            "Epoch 4776/5000\n",
            "\n",
            "Epoch 4776: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.7662 - 3s/epoch - 286ms/step\n",
            "Epoch 4777/5000\n",
            "\n",
            "Epoch 4777: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 4778/5000\n",
            "\n",
            "Epoch 4778: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.7770 - 3s/epoch - 307ms/step\n",
            "Epoch 4779/5000\n",
            "\n",
            "Epoch 4779: val_accuracy did not improve from 0.79137\n",
            "9/9 - 5s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.7806 - 5s/epoch - 522ms/step\n",
            "Epoch 4780/5000\n",
            "\n",
            "Epoch 4780: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8083 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 4781/5000\n",
            "\n",
            "Epoch 4781: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8082 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4782/5000\n",
            "\n",
            "Epoch 4782: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8076 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 4783/5000\n",
            "\n",
            "Epoch 4783: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.7770 - 3s/epoch - 372ms/step\n",
            "Epoch 4784/5000\n",
            "\n",
            "Epoch 4784: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8027 - val_accuracy: 0.7842 - 3s/epoch - 384ms/step\n",
            "Epoch 4785/5000\n",
            "\n",
            "Epoch 4785: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7953 - val_accuracy: 0.7842 - 3s/epoch - 299ms/step\n",
            "Epoch 4786/5000\n",
            "\n",
            "Epoch 4786: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7976 - val_accuracy: 0.7842 - 3s/epoch - 301ms/step\n",
            "Epoch 4787/5000\n",
            "\n",
            "Epoch 4787: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.7842 - 3s/epoch - 300ms/step\n",
            "Epoch 4788/5000\n",
            "\n",
            "Epoch 4788: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.7770 - 4s/epoch - 455ms/step\n",
            "Epoch 4789/5000\n",
            "\n",
            "Epoch 4789: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8136 - val_accuracy: 0.7770 - 3s/epoch - 305ms/step\n",
            "Epoch 4790/5000\n",
            "\n",
            "Epoch 4790: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.7734 - 3s/epoch - 299ms/step\n",
            "Epoch 4791/5000\n",
            "\n",
            "Epoch 4791: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8061 - val_accuracy: 0.7770 - 3s/epoch - 291ms/step\n",
            "Epoch 4792/5000\n",
            "\n",
            "Epoch 4792: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8066 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4793/5000\n",
            "\n",
            "Epoch 4793: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8000 - val_accuracy: 0.7806 - 4s/epoch - 468ms/step\n",
            "Epoch 4794/5000\n",
            "\n",
            "Epoch 4794: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.7878 - 3s/epoch - 300ms/step\n",
            "Epoch 4795/5000\n",
            "\n",
            "Epoch 4795: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.7770 - 3s/epoch - 285ms/step\n",
            "Epoch 4796/5000\n",
            "\n",
            "Epoch 4796: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8026 - val_accuracy: 0.7770 - 3s/epoch - 283ms/step\n",
            "Epoch 4797/5000\n",
            "\n",
            "Epoch 4797: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7806 - 3s/epoch - 341ms/step\n",
            "Epoch 4798/5000\n",
            "\n",
            "Epoch 4798: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.7806 - 4s/epoch - 434ms/step\n",
            "Epoch 4799/5000\n",
            "\n",
            "Epoch 4799: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8042 - val_accuracy: 0.7806 - 3s/epoch - 298ms/step\n",
            "Epoch 4800/5000\n",
            "\n",
            "Epoch 4800: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.7842 - 3s/epoch - 299ms/step\n",
            "Epoch 4801/5000\n",
            "\n",
            "Epoch 4801: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.7734 - 3s/epoch - 299ms/step\n",
            "Epoch 4802/5000\n",
            "\n",
            "Epoch 4802: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8024 - val_accuracy: 0.7806 - 4s/epoch - 440ms/step\n",
            "Epoch 4803/5000\n",
            "\n",
            "Epoch 4803: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8046 - val_accuracy: 0.7842 - 3s/epoch - 343ms/step\n",
            "Epoch 4804/5000\n",
            "\n",
            "Epoch 4804: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.7878 - 3s/epoch - 298ms/step\n",
            "Epoch 4805/5000\n",
            "\n",
            "Epoch 4805: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8188 - val_accuracy: 0.7734 - 3s/epoch - 299ms/step\n",
            "Epoch 4806/5000\n",
            "\n",
            "Epoch 4806: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8238 - val_accuracy: 0.7734 - 3s/epoch - 302ms/step\n",
            "Epoch 4807/5000\n",
            "\n",
            "Epoch 4807: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8213 - val_accuracy: 0.7734 - 4s/epoch - 478ms/step\n",
            "Epoch 4808/5000\n",
            "\n",
            "Epoch 4808: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8077 - val_accuracy: 0.7770 - 3s/epoch - 302ms/step\n",
            "Epoch 4809/5000\n",
            "\n",
            "Epoch 4809: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.7842 - 3s/epoch - 297ms/step\n",
            "Epoch 4810/5000\n",
            "\n",
            "Epoch 4810: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8029 - val_accuracy: 0.7842 - 3s/epoch - 298ms/step\n",
            "Epoch 4811/5000\n",
            "\n",
            "Epoch 4811: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8065 - val_accuracy: 0.7806 - 4s/epoch - 406ms/step\n",
            "Epoch 4812/5000\n",
            "\n",
            "Epoch 4812: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8065 - val_accuracy: 0.7806 - 4s/epoch - 391ms/step\n",
            "Epoch 4813/5000\n",
            "\n",
            "Epoch 4813: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8141 - val_accuracy: 0.7878 - 3s/epoch - 301ms/step\n",
            "Epoch 4814/5000\n",
            "\n",
            "Epoch 4814: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.7806 - 3s/epoch - 298ms/step\n",
            "Epoch 4815/5000\n",
            "\n",
            "Epoch 4815: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8063 - val_accuracy: 0.7842 - 3s/epoch - 296ms/step\n",
            "Epoch 4816/5000\n",
            "\n",
            "Epoch 4816: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7878 - 4s/epoch - 469ms/step\n",
            "Epoch 4817/5000\n",
            "\n",
            "Epoch 4817: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7842 - 3s/epoch - 281ms/step\n",
            "Epoch 4818/5000\n",
            "\n",
            "Epoch 4818: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.7770 - 3s/epoch - 285ms/step\n",
            "Epoch 4819/5000\n",
            "\n",
            "Epoch 4819: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.7770 - 3s/epoch - 283ms/step\n",
            "Epoch 4820/5000\n",
            "\n",
            "Epoch 4820: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 4821/5000\n",
            "\n",
            "Epoch 4821: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8073 - val_accuracy: 0.7698 - 4s/epoch - 455ms/step\n",
            "Epoch 4822/5000\n",
            "\n",
            "Epoch 4822: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8019 - val_accuracy: 0.7734 - 3s/epoch - 279ms/step\n",
            "Epoch 4823/5000\n",
            "\n",
            "Epoch 4823: val_accuracy did not improve from 0.79137\n",
            "9/9 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.7770 - 2s/epoch - 278ms/step\n",
            "Epoch 4824/5000\n",
            "\n",
            "Epoch 4824: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.7770 - 3s/epoch - 280ms/step\n",
            "Epoch 4825/5000\n",
            "\n",
            "Epoch 4825: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.7770 - 3s/epoch - 354ms/step\n",
            "Epoch 4826/5000\n",
            "\n",
            "Epoch 4826: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8005 - val_accuracy: 0.7842 - 4s/epoch - 422ms/step\n",
            "Epoch 4827/5000\n",
            "\n",
            "Epoch 4827: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.7770 - 3s/epoch - 294ms/step\n",
            "Epoch 4828/5000\n",
            "\n",
            "Epoch 4828: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8104 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4829/5000\n",
            "\n",
            "Epoch 4829: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8195 - val_accuracy: 0.7770 - 3s/epoch - 299ms/step\n",
            "Epoch 4830/5000\n",
            "\n",
            "Epoch 4830: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8192 - val_accuracy: 0.7662 - 4s/epoch - 430ms/step\n",
            "Epoch 4831/5000\n",
            "\n",
            "Epoch 4831: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8182 - val_accuracy: 0.7698 - 3s/epoch - 324ms/step\n",
            "Epoch 4832/5000\n",
            "\n",
            "Epoch 4832: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 4833/5000\n",
            "\n",
            "Epoch 4833: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8119 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 4834/5000\n",
            "\n",
            "Epoch 4834: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8122 - val_accuracy: 0.7698 - 3s/epoch - 281ms/step\n",
            "Epoch 4835/5000\n",
            "\n",
            "Epoch 4835: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8201 - val_accuracy: 0.7734 - 4s/epoch - 487ms/step\n",
            "Epoch 4836/5000\n",
            "\n",
            "Epoch 4836: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8311 - val_accuracy: 0.7662 - 3s/epoch - 304ms/step\n",
            "Epoch 4837/5000\n",
            "\n",
            "Epoch 4837: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8260 - val_accuracy: 0.7626 - 3s/epoch - 297ms/step\n",
            "Epoch 4838/5000\n",
            "\n",
            "Epoch 4838: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8224 - val_accuracy: 0.7698 - 3s/epoch - 305ms/step\n",
            "Epoch 4839/5000\n",
            "\n",
            "Epoch 4839: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.7698 - 4s/epoch - 411ms/step\n",
            "Epoch 4840/5000\n",
            "\n",
            "Epoch 4840: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8166 - val_accuracy: 0.7734 - 3s/epoch - 375ms/step\n",
            "Epoch 4841/5000\n",
            "\n",
            "Epoch 4841: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8152 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 4842/5000\n",
            "\n",
            "Epoch 4842: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4843/5000\n",
            "\n",
            "Epoch 4843: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8158 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4844/5000\n",
            "\n",
            "Epoch 4844: val_accuracy did not improve from 0.79137\n",
            "9/9 - 5s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8163 - val_accuracy: 0.7770 - 5s/epoch - 507ms/step\n",
            "Epoch 4845/5000\n",
            "\n",
            "Epoch 4845: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8168 - val_accuracy: 0.7698 - 3s/epoch - 297ms/step\n",
            "Epoch 4846/5000\n",
            "\n",
            "Epoch 4846: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8129 - val_accuracy: 0.7662 - 3s/epoch - 296ms/step\n",
            "Epoch 4847/5000\n",
            "\n",
            "Epoch 4847: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8093 - val_accuracy: 0.7662 - 3s/epoch - 297ms/step\n",
            "Epoch 4848/5000\n",
            "\n",
            "Epoch 4848: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.7698 - 3s/epoch - 350ms/step\n",
            "Epoch 4849/5000\n",
            "\n",
            "Epoch 4849: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8028 - val_accuracy: 0.7734 - 4s/epoch - 418ms/step\n",
            "Epoch 4850/5000\n",
            "\n",
            "Epoch 4850: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.7770 - 3s/epoch - 303ms/step\n",
            "Epoch 4851/5000\n",
            "\n",
            "Epoch 4851: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8029 - val_accuracy: 0.7770 - 3s/epoch - 305ms/step\n",
            "Epoch 4852/5000\n",
            "\n",
            "Epoch 4852: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8077 - val_accuracy: 0.7734 - 3s/epoch - 298ms/step\n",
            "Epoch 4853/5000\n",
            "\n",
            "Epoch 4853: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8545 - val_accuracy: 0.7662 - 4s/epoch - 433ms/step\n",
            "Epoch 4854/5000\n",
            "\n",
            "Epoch 4854: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8239 - val_accuracy: 0.7662 - 3s/epoch - 333ms/step\n",
            "Epoch 4855/5000\n",
            "\n",
            "Epoch 4855: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8139 - val_accuracy: 0.7842 - 3s/epoch - 294ms/step\n",
            "Epoch 4856/5000\n",
            "\n",
            "Epoch 4856: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8124 - val_accuracy: 0.7878 - 3s/epoch - 292ms/step\n",
            "Epoch 4857/5000\n",
            "\n",
            "Epoch 4857: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8148 - val_accuracy: 0.7842 - 3s/epoch - 283ms/step\n",
            "Epoch 4858/5000\n",
            "\n",
            "Epoch 4858: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8111 - val_accuracy: 0.7806 - 4s/epoch - 487ms/step\n",
            "Epoch 4859/5000\n",
            "\n",
            "Epoch 4859: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8096 - val_accuracy: 0.7770 - 3s/epoch - 287ms/step\n",
            "Epoch 4860/5000\n",
            "\n",
            "Epoch 4860: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7912 - val_accuracy: 0.7734 - 3s/epoch - 284ms/step\n",
            "Epoch 4861/5000\n",
            "\n",
            "Epoch 4861: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 4862/5000\n",
            "\n",
            "Epoch 4862: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7968 - val_accuracy: 0.7734 - 3s/epoch - 350ms/step\n",
            "Epoch 4863/5000\n",
            "\n",
            "Epoch 4863: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8116 - val_accuracy: 0.7626 - 4s/epoch - 427ms/step\n",
            "Epoch 4864/5000\n",
            "\n",
            "Epoch 4864: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.7662 - 3s/epoch - 280ms/step\n",
            "Epoch 4865/5000\n",
            "\n",
            "Epoch 4865: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8115 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4866/5000\n",
            "\n",
            "Epoch 4866: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8095 - val_accuracy: 0.7698 - 3s/epoch - 284ms/step\n",
            "Epoch 4867/5000\n",
            "\n",
            "Epoch 4867: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7939 - val_accuracy: 0.7770 - 4s/epoch - 444ms/step\n",
            "Epoch 4868/5000\n",
            "\n",
            "Epoch 4868: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.7698 - 3s/epoch - 337ms/step\n",
            "Epoch 4869/5000\n",
            "\n",
            "Epoch 4869: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8294 - val_accuracy: 0.7626 - 3s/epoch - 303ms/step\n",
            "Epoch 4870/5000\n",
            "\n",
            "Epoch 4870: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8444 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 4871/5000\n",
            "\n",
            "Epoch 4871: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8431 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 4872/5000\n",
            "\n",
            "Epoch 4872: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8372 - val_accuracy: 0.7770 - 4s/epoch - 474ms/step\n",
            "Epoch 4873/5000\n",
            "\n",
            "Epoch 4873: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8308 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 4874/5000\n",
            "\n",
            "Epoch 4874: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8340 - val_accuracy: 0.7770 - 3s/epoch - 293ms/step\n",
            "Epoch 4875/5000\n",
            "\n",
            "Epoch 4875: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8463 - val_accuracy: 0.7698 - 3s/epoch - 301ms/step\n",
            "Epoch 4876/5000\n",
            "\n",
            "Epoch 4876: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8505 - val_accuracy: 0.7698 - 4s/epoch - 404ms/step\n",
            "Epoch 4877/5000\n",
            "\n",
            "Epoch 4877: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8476 - val_accuracy: 0.7698 - 3s/epoch - 373ms/step\n",
            "Epoch 4878/5000\n",
            "\n",
            "Epoch 4878: val_accuracy did not improve from 0.79137\n",
            "9/9 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8470 - val_accuracy: 0.7734 - 2s/epoch - 278ms/step\n",
            "Epoch 4879/5000\n",
            "\n",
            "Epoch 4879: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8423 - val_accuracy: 0.7734 - 3s/epoch - 303ms/step\n",
            "Epoch 4880/5000\n",
            "\n",
            "Epoch 4880: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8358 - val_accuracy: 0.7698 - 3s/epoch - 291ms/step\n",
            "Epoch 4881/5000\n",
            "\n",
            "Epoch 4881: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8270 - val_accuracy: 0.7698 - 4s/epoch - 495ms/step\n",
            "Epoch 4882/5000\n",
            "\n",
            "Epoch 4882: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8210 - val_accuracy: 0.7806 - 3s/epoch - 286ms/step\n",
            "Epoch 4883/5000\n",
            "\n",
            "Epoch 4883: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8174 - val_accuracy: 0.7734 - 3s/epoch - 289ms/step\n",
            "Epoch 4884/5000\n",
            "\n",
            "Epoch 4884: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8158 - val_accuracy: 0.7734 - 3s/epoch - 290ms/step\n",
            "Epoch 4885/5000\n",
            "\n",
            "Epoch 4885: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8161 - val_accuracy: 0.7698 - 3s/epoch - 325ms/step\n",
            "Epoch 4886/5000\n",
            "\n",
            "Epoch 4886: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8174 - val_accuracy: 0.7698 - 4s/epoch - 436ms/step\n",
            "Epoch 4887/5000\n",
            "\n",
            "Epoch 4887: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8187 - val_accuracy: 0.7698 - 3s/epoch - 300ms/step\n",
            "Epoch 4888/5000\n",
            "\n",
            "Epoch 4888: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8198 - val_accuracy: 0.7698 - 3s/epoch - 298ms/step\n",
            "Epoch 4889/5000\n",
            "\n",
            "Epoch 4889: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8188 - val_accuracy: 0.7806 - 3s/epoch - 306ms/step\n",
            "Epoch 4890/5000\n",
            "\n",
            "Epoch 4890: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8187 - val_accuracy: 0.7770 - 4s/epoch - 447ms/step\n",
            "Epoch 4891/5000\n",
            "\n",
            "Epoch 4891: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8206 - val_accuracy: 0.7698 - 3s/epoch - 335ms/step\n",
            "Epoch 4892/5000\n",
            "\n",
            "Epoch 4892: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8246 - val_accuracy: 0.7698 - 3s/epoch - 281ms/step\n",
            "Epoch 4893/5000\n",
            "\n",
            "Epoch 4893: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8274 - val_accuracy: 0.7734 - 3s/epoch - 280ms/step\n",
            "Epoch 4894/5000\n",
            "\n",
            "Epoch 4894: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8296 - val_accuracy: 0.7734 - 3s/epoch - 299ms/step\n",
            "Epoch 4895/5000\n",
            "\n",
            "Epoch 4895: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8311 - val_accuracy: 0.7734 - 4s/epoch - 492ms/step\n",
            "Epoch 4896/5000\n",
            "\n",
            "Epoch 4896: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8313 - val_accuracy: 0.7770 - 3s/epoch - 297ms/step\n",
            "Epoch 4897/5000\n",
            "\n",
            "Epoch 4897: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8330 - val_accuracy: 0.7806 - 3s/epoch - 282ms/step\n",
            "Epoch 4898/5000\n",
            "\n",
            "Epoch 4898: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8237 - val_accuracy: 0.7662 - 3s/epoch - 279ms/step\n",
            "Epoch 4899/5000\n",
            "\n",
            "Epoch 4899: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8201 - val_accuracy: 0.7734 - 3s/epoch - 356ms/step\n",
            "Epoch 4900/5000\n",
            "\n",
            "Epoch 4900: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8229 - val_accuracy: 0.7698 - 4s/epoch - 431ms/step\n",
            "Epoch 4901/5000\n",
            "\n",
            "Epoch 4901: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8351 - val_accuracy: 0.7662 - 3s/epoch - 300ms/step\n",
            "Epoch 4902/5000\n",
            "\n",
            "Epoch 4902: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8381 - val_accuracy: 0.7662 - 3s/epoch - 300ms/step\n",
            "Epoch 4903/5000\n",
            "\n",
            "Epoch 4903: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8375 - val_accuracy: 0.7662 - 3s/epoch - 297ms/step\n",
            "Epoch 4904/5000\n",
            "\n",
            "Epoch 4904: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8331 - val_accuracy: 0.7698 - 4s/epoch - 451ms/step\n",
            "Epoch 4905/5000\n",
            "\n",
            "Epoch 4905: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8321 - val_accuracy: 0.7626 - 3s/epoch - 327ms/step\n",
            "Epoch 4906/5000\n",
            "\n",
            "Epoch 4906: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8327 - val_accuracy: 0.7698 - 3s/epoch - 281ms/step\n",
            "Epoch 4907/5000\n",
            "\n",
            "Epoch 4907: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8320 - val_accuracy: 0.7698 - 3s/epoch - 290ms/step\n",
            "Epoch 4908/5000\n",
            "\n",
            "Epoch 4908: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8364 - val_accuracy: 0.7626 - 3s/epoch - 289ms/step\n",
            "Epoch 4909/5000\n",
            "\n",
            "Epoch 4909: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8363 - val_accuracy: 0.7626 - 4s/epoch - 479ms/step\n",
            "Epoch 4910/5000\n",
            "\n",
            "Epoch 4910: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8331 - val_accuracy: 0.7662 - 3s/epoch - 299ms/step\n",
            "Epoch 4911/5000\n",
            "\n",
            "Epoch 4911: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8295 - val_accuracy: 0.7734 - 3s/epoch - 278ms/step\n",
            "Epoch 4912/5000\n",
            "\n",
            "Epoch 4912: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8278 - val_accuracy: 0.7662 - 3s/epoch - 297ms/step\n",
            "Epoch 4913/5000\n",
            "\n",
            "Epoch 4913: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8287 - val_accuracy: 0.7626 - 3s/epoch - 353ms/step\n",
            "Epoch 4914/5000\n",
            "\n",
            "Epoch 4914: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8297 - val_accuracy: 0.7626 - 4s/epoch - 407ms/step\n",
            "Epoch 4915/5000\n",
            "\n",
            "Epoch 4915: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8305 - val_accuracy: 0.7626 - 3s/epoch - 300ms/step\n",
            "Epoch 4916/5000\n",
            "\n",
            "Epoch 4916: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8344 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4917/5000\n",
            "\n",
            "Epoch 4917: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8336 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 4918/5000\n",
            "\n",
            "Epoch 4918: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8267 - val_accuracy: 0.7734 - 4s/epoch - 422ms/step\n",
            "Epoch 4919/5000\n",
            "\n",
            "Epoch 4919: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8229 - val_accuracy: 0.7662 - 3s/epoch - 353ms/step\n",
            "Epoch 4920/5000\n",
            "\n",
            "Epoch 4920: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8227 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4921/5000\n",
            "\n",
            "Epoch 4921: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8227 - val_accuracy: 0.7734 - 3s/epoch - 281ms/step\n",
            "Epoch 4922/5000\n",
            "\n",
            "Epoch 4922: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8223 - val_accuracy: 0.7734 - 3s/epoch - 281ms/step\n",
            "Epoch 4923/5000\n",
            "\n",
            "Epoch 4923: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8261 - val_accuracy: 0.7734 - 4s/epoch - 498ms/step\n",
            "Epoch 4924/5000\n",
            "\n",
            "Epoch 4924: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8249 - val_accuracy: 0.7734 - 3s/epoch - 286ms/step\n",
            "Epoch 4925/5000\n",
            "\n",
            "Epoch 4925: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8230 - val_accuracy: 0.7734 - 3s/epoch - 297ms/step\n",
            "Epoch 4926/5000\n",
            "\n",
            "Epoch 4926: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 4927/5000\n",
            "\n",
            "Epoch 4927: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8211 - val_accuracy: 0.7734 - 3s/epoch - 376ms/step\n",
            "Epoch 4928/5000\n",
            "\n",
            "Epoch 4928: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8166 - val_accuracy: 0.7734 - 4s/epoch - 402ms/step\n",
            "Epoch 4929/5000\n",
            "\n",
            "Epoch 4929: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8116 - val_accuracy: 0.7698 - 3s/epoch - 286ms/step\n",
            "Epoch 4930/5000\n",
            "\n",
            "Epoch 4930: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8115 - val_accuracy: 0.7698 - 3s/epoch - 294ms/step\n",
            "Epoch 4931/5000\n",
            "\n",
            "Epoch 4931: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8143 - val_accuracy: 0.7734 - 3s/epoch - 279ms/step\n",
            "Epoch 4932/5000\n",
            "\n",
            "Epoch 4932: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8165 - val_accuracy: 0.7698 - 4s/epoch - 451ms/step\n",
            "Epoch 4933/5000\n",
            "\n",
            "Epoch 4933: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.7698 - 3s/epoch - 317ms/step\n",
            "Epoch 4934/5000\n",
            "\n",
            "Epoch 4934: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.7698 - 3s/epoch - 297ms/step\n",
            "Epoch 4935/5000\n",
            "\n",
            "Epoch 4935: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8164 - val_accuracy: 0.7698 - 3s/epoch - 301ms/step\n",
            "Epoch 4936/5000\n",
            "\n",
            "Epoch 4936: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4937/5000\n",
            "\n",
            "Epoch 4937: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8124 - val_accuracy: 0.7698 - 4s/epoch - 476ms/step\n",
            "Epoch 4938/5000\n",
            "\n",
            "Epoch 4938: val_accuracy did not improve from 0.79137\n",
            "9/9 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8143 - val_accuracy: 0.7662 - 2s/epoch - 276ms/step\n",
            "Epoch 4939/5000\n",
            "\n",
            "Epoch 4939: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8143 - val_accuracy: 0.7662 - 3s/epoch - 289ms/step\n",
            "Epoch 4940/5000\n",
            "\n",
            "Epoch 4940: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8152 - val_accuracy: 0.7662 - 3s/epoch - 288ms/step\n",
            "Epoch 4941/5000\n",
            "\n",
            "Epoch 4941: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8146 - val_accuracy: 0.7662 - 3s/epoch - 369ms/step\n",
            "Epoch 4942/5000\n",
            "\n",
            "Epoch 4942: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8110 - val_accuracy: 0.7626 - 4s/epoch - 406ms/step\n",
            "Epoch 4943/5000\n",
            "\n",
            "Epoch 4943: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8094 - val_accuracy: 0.7626 - 3s/epoch - 293ms/step\n",
            "Epoch 4944/5000\n",
            "\n",
            "Epoch 4944: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8074 - val_accuracy: 0.7662 - 3s/epoch - 292ms/step\n",
            "Epoch 4945/5000\n",
            "\n",
            "Epoch 4945: val_accuracy did not improve from 0.79137\n",
            "9/9 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.7662 - 2s/epoch - 275ms/step\n",
            "Epoch 4946/5000\n",
            "\n",
            "Epoch 4946: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8065 - val_accuracy: 0.7698 - 4s/epoch - 464ms/step\n",
            "Epoch 4947/5000\n",
            "\n",
            "Epoch 4947: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.7734 - 3s/epoch - 298ms/step\n",
            "Epoch 4948/5000\n",
            "\n",
            "Epoch 4948: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.7734 - 3s/epoch - 295ms/step\n",
            "Epoch 4949/5000\n",
            "\n",
            "Epoch 4949: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8077 - val_accuracy: 0.7698 - 3s/epoch - 295ms/step\n",
            "Epoch 4950/5000\n",
            "\n",
            "Epoch 4950: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8081 - val_accuracy: 0.7698 - 3s/epoch - 298ms/step\n",
            "Epoch 4951/5000\n",
            "\n",
            "Epoch 4951: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8089 - val_accuracy: 0.7662 - 4s/epoch - 472ms/step\n",
            "Epoch 4952/5000\n",
            "\n",
            "Epoch 4952: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.7734 - 3s/epoch - 280ms/step\n",
            "Epoch 4953/5000\n",
            "\n",
            "Epoch 4953: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8102 - val_accuracy: 0.7734 - 3s/epoch - 294ms/step\n",
            "Epoch 4954/5000\n",
            "\n",
            "Epoch 4954: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8059 - val_accuracy: 0.7770 - 3s/epoch - 298ms/step\n",
            "Epoch 4955/5000\n",
            "\n",
            "Epoch 4955: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8041 - val_accuracy: 0.7734 - 4s/epoch - 415ms/step\n",
            "Epoch 4956/5000\n",
            "\n",
            "Epoch 4956: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8058 - val_accuracy: 0.7770 - 4s/epoch - 392ms/step\n",
            "Epoch 4957/5000\n",
            "\n",
            "Epoch 4957: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.7734 - 3s/epoch - 304ms/step\n",
            "Epoch 4958/5000\n",
            "\n",
            "Epoch 4958: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8183 - val_accuracy: 0.7734 - 3s/epoch - 298ms/step\n",
            "Epoch 4959/5000\n",
            "\n",
            "Epoch 4959: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8202 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4960/5000\n",
            "\n",
            "Epoch 4960: val_accuracy did not improve from 0.79137\n",
            "9/9 - 5s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8195 - val_accuracy: 0.7770 - 5s/epoch - 501ms/step\n",
            "Epoch 4961/5000\n",
            "\n",
            "Epoch 4961: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4962/5000\n",
            "\n",
            "Epoch 4962: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.7770 - 3s/epoch - 282ms/step\n",
            "Epoch 4963/5000\n",
            "\n",
            "Epoch 4963: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.7734 - 3s/epoch - 281ms/step\n",
            "Epoch 4964/5000\n",
            "\n",
            "Epoch 4964: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8060 - val_accuracy: 0.7770 - 3s/epoch - 342ms/step\n",
            "Epoch 4965/5000\n",
            "\n",
            "Epoch 4965: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.7698 - 4s/epoch - 427ms/step\n",
            "Epoch 4966/5000\n",
            "\n",
            "Epoch 4966: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.7698 - 3s/epoch - 296ms/step\n",
            "Epoch 4967/5000\n",
            "\n",
            "Epoch 4967: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8055 - val_accuracy: 0.7770 - 3s/epoch - 296ms/step\n",
            "Epoch 4968/5000\n",
            "\n",
            "Epoch 4968: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8066 - val_accuracy: 0.7770 - 3s/epoch - 300ms/step\n",
            "Epoch 4969/5000\n",
            "\n",
            "Epoch 4969: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.7770 - 4s/epoch - 446ms/step\n",
            "Epoch 4970/5000\n",
            "\n",
            "Epoch 4970: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8025 - val_accuracy: 0.7734 - 3s/epoch - 323ms/step\n",
            "Epoch 4971/5000\n",
            "\n",
            "Epoch 4971: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.7734 - 3s/epoch - 281ms/step\n",
            "Epoch 4972/5000\n",
            "\n",
            "Epoch 4972: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8120 - val_accuracy: 0.7698 - 3s/epoch - 283ms/step\n",
            "Epoch 4973/5000\n",
            "\n",
            "Epoch 4973: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8382 - val_accuracy: 0.7806 - 3s/epoch - 283ms/step\n",
            "Epoch 4974/5000\n",
            "\n",
            "Epoch 4974: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8435 - val_accuracy: 0.7806 - 4s/epoch - 480ms/step\n",
            "Epoch 4975/5000\n",
            "\n",
            "Epoch 4975: val_accuracy did not improve from 0.79137\n",
            "9/9 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8363 - val_accuracy: 0.7806 - 2s/epoch - 276ms/step\n",
            "Epoch 4976/5000\n",
            "\n",
            "Epoch 4976: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8244 - val_accuracy: 0.7734 - 3s/epoch - 296ms/step\n",
            "Epoch 4977/5000\n",
            "\n",
            "Epoch 4977: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8182 - val_accuracy: 0.7770 - 3s/epoch - 291ms/step\n",
            "Epoch 4978/5000\n",
            "\n",
            "Epoch 4978: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8136 - val_accuracy: 0.7770 - 3s/epoch - 308ms/step\n",
            "Epoch 4979/5000\n",
            "\n",
            "Epoch 4979: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8148 - val_accuracy: 0.7698 - 4s/epoch - 459ms/step\n",
            "Epoch 4980/5000\n",
            "\n",
            "Epoch 4980: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8185 - val_accuracy: 0.7698 - 3s/epoch - 281ms/step\n",
            "Epoch 4981/5000\n",
            "\n",
            "Epoch 4981: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8231 - val_accuracy: 0.7662 - 3s/epoch - 289ms/step\n",
            "Epoch 4982/5000\n",
            "\n",
            "Epoch 4982: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8217 - val_accuracy: 0.7698 - 3s/epoch - 278ms/step\n",
            "Epoch 4983/5000\n",
            "\n",
            "Epoch 4983: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8164 - val_accuracy: 0.7770 - 3s/epoch - 357ms/step\n",
            "Epoch 4984/5000\n",
            "\n",
            "Epoch 4984: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.7770 - 4s/epoch - 392ms/step\n",
            "Epoch 4985/5000\n",
            "\n",
            "Epoch 4985: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8203 - val_accuracy: 0.7842 - 3s/epoch - 288ms/step\n",
            "Epoch 4986/5000\n",
            "\n",
            "Epoch 4986: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8235 - val_accuracy: 0.7806 - 3s/epoch - 286ms/step\n",
            "Epoch 4987/5000\n",
            "\n",
            "Epoch 4987: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8223 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4988/5000\n",
            "\n",
            "Epoch 4988: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.7734 - 4s/epoch - 433ms/step\n",
            "Epoch 4989/5000\n",
            "\n",
            "Epoch 4989: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8129 - val_accuracy: 0.7734 - 3s/epoch - 328ms/step\n",
            "Epoch 4990/5000\n",
            "\n",
            "Epoch 4990: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.7806 - 3s/epoch - 293ms/step\n",
            "Epoch 4991/5000\n",
            "\n",
            "Epoch 4991: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8115 - val_accuracy: 0.7806 - 3s/epoch - 300ms/step\n",
            "Epoch 4992/5000\n",
            "\n",
            "Epoch 4992: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8122 - val_accuracy: 0.7806 - 3s/epoch - 281ms/step\n",
            "Epoch 4993/5000\n",
            "\n",
            "Epoch 4993: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.7842 - 4s/epoch - 467ms/step\n",
            "Epoch 4994/5000\n",
            "\n",
            "Epoch 4994: val_accuracy did not improve from 0.79137\n",
            "9/9 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.7806 - 2s/epoch - 276ms/step\n",
            "Epoch 4995/5000\n",
            "\n",
            "Epoch 4995: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8178 - val_accuracy: 0.7770 - 3s/epoch - 295ms/step\n",
            "Epoch 4996/5000\n",
            "\n",
            "Epoch 4996: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8192 - val_accuracy: 0.7770 - 3s/epoch - 280ms/step\n",
            "Epoch 4997/5000\n",
            "\n",
            "Epoch 4997: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8205 - val_accuracy: 0.7734 - 3s/epoch - 283ms/step\n",
            "Epoch 4998/5000\n",
            "\n",
            "Epoch 4998: val_accuracy did not improve from 0.79137\n",
            "9/9 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8202 - val_accuracy: 0.7734 - 4s/epoch - 462ms/step\n",
            "Epoch 4999/5000\n",
            "\n",
            "Epoch 4999: val_accuracy did not improve from 0.79137\n",
            "9/9 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8162 - val_accuracy: 0.7842 - 2s/epoch - 269ms/step\n",
            "Epoch 5000/5000\n",
            "\n",
            "Epoch 5000: val_accuracy did not improve from 0.79137\n",
            "9/9 - 3s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8139 - val_accuracy: 0.7806 - 3s/epoch - 287ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "modelp = keras.models.load_model(\"xcorr_mi_nmi_mean.best.hdf5\")\n",
        "y_pred = modelp.predict(X_test)\n",
        "y_pred=np.argmax(y_pred,axis=1)\n",
        "print(\"Test Accuracy\",accuracy_score(y_test, y_pred)*100,\"%\")\n",
        "\n",
        "scores = modelp.evaluate(X_train, y_train)\n",
        "print(\"Train %s: %.2f%%\" % (modelp.metrics_names[1], scores[1]*100))\n",
        "\n",
        "scores = modelp.evaluate(X_test, y_test)\n",
        "print(\"test %s: %.2f%%\" % (modelp.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQE9Q1qnKiwQ",
        "outputId": "95fc0d0c-9ad0-4422-8962-cef80bf8eacb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 43ms/step\n",
            "Test Accuracy 79.13669064748201 %\n",
            "35/35 [==============================] - 3s 68ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Train accuracy: 100.00%\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.8260 - accuracy: 0.7914\n",
            "test accuracy: 79.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "srt=\"xcorr_mi_nmi_mean Model\"\n",
        "plot_accuracy(history8, no_of_epoch,srt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "5YhNQXocKkyS",
        "outputId": "d2ad8c81-8e28-478e-82e6-864ce51686f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history8,no_of_epoch, srt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "o5vDdPixKmsO",
        "outputId": "18684ac6-85aa-412b-87ee-c52dc62f9d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title=\"Confusion Matrix of xcorr_mi_nmi_mean\"\n",
        "cm=confusion(y_pred,y_test)\n",
        "conf_mat2(cm,class_names,title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "djHaW1d5KosY",
        "outputId": "ae872a63-526e-4acb-b00e-b25a7884c9a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA00AAAHqCAYAAADYhaVTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABmLklEQVR4nO3dd5wU9fnA8c8dHnAU4bCADRHLN2oSe09EjQqJGjuKSX4RYy9RQ0zU2I3G2FDRGHuNvcYGVtTYe4n6DagUu5RDerv7/TF7uBzH3S67x9ztfd689sXNd2Znn7u5vd1nn+88U1ZbW4skSZIkqWHlaQcgSZIkSS2ZSZMkSZIkNcKkSZIkSZIaYdIkSZIkSY0waZIkSZKkRpg0SZIkSVIjlkk7AElLLoSwN3AUsDFQCYwFHgYujDF+0QyPtw0wDFgP6BBjLCvSfs8Ajo4xLl+M/eX4eKcDo2OMazewfhSwFnBmjPGMPPa7OfCLXO8TQtgOeAb4UYzx/VwfZ0mFENYFrib5fekErBFjHNPcj9vSLe3fv6a0tHgkSVaapFYrhHARcBfwCfAbYGdgKPAz4IpmetirgGqgP7BVEfd7bWafS9MsYI0QwqbZgyGEzYA+mfX52pwkGcvVmyQ/x4+X4LGWxAVAd+CXmcf9cik9bkuXxu9fY1paPJLU5llpklqhEMJuwB+A38UYr89a9WwI4WqSBKo5/AC4Osb4bDF3GmP8DPismPvMwXSSpGV/4PWs8f2Bp4FNmuuBQwhlJJW674CXm+txGvAD4N8xxqeW4mPmLIRQGWOcmet4saT0+7dYLS0eSRKU1dbWph2DpDyFEJ4GusUYm3xjH0JYHrgI2JVkCt+rwB9jjK9nbTMGuAf4HBgCdAZGAIfHGKuzppFluynGeGAIoRY4JsZ4edb+ziBrelEIoTtwIfALoAfwDTAixnhIQ9tnxtYgqZztAJQBI4HjY4yjs7apBY4DegKHALXA3cAfYoyzG/mZnAEcDfwJOANYPcZYm0lmxgGnkVRlLq+bahdC2Ao4CdgMWBYYBVwQY/xXZv2BwA31HurZGON2WY+3R+Z7+jFwMDCerOl5IYR9gTuBneoSmxBCH+BdYFiM8S+NfE8bkhznrYDZwKOZn8PXmX182lBsDewnpxhCCKsD5wE7kUz1Gw2cF2O8LbM+19+7e0mql4cBPWOMFYsbX9z3nhXjp8AgkirN3sB3wIkxxltDCH8i+V2pAK4HToox1mTuewZ5TIcLIYwEJgD3AWcBKwIvAIdkEp604nmE5Hd3BeB+kt+xDYDLSabUvg78X4xxXNZ9O2a+h0GZ7+OjTCyPZm3zf8ChmX2UAW8DJ9Q7ljcCPyR5jlwErAm8BRwWY/xvLt+HJLVkTs+TWpkQQgWwNTA8x7s8QPKm7Y/AfiTP+2dCCGvV224gydS+Q4E/k7zZPTezrm4aGXz/xvzsPMK+GPgJcHwmlpNJEpwGhRA6AE8B65IkQwcCa5BU0nrU23wIsDLwa5JE5zDg2Bzjuo8k4fpJZvmnJG8472tg29VJ3hj/DtiN5E39DSGEQZn1j5D8bCD5+WwFHJl1/07ATSRTrwaQJBELiTHeTZKwXB9CWDaTxN1A8ub7zMV9EyGEFUiSyk7AAcAxQD/giRBCe5JpeFsBXwG3NRBbXjGEEFYEXiJJIP+Y+XlcB6yWtasHyO337oBMrEdmtmtqvCl/z3y/ewPPAzdlprJuDhwEXEKSLA/MY58N2YIkER5C8pzZmOR8sbTi2RL4Lcmxr9vfMOAa4FKS50ffBmK8h+T5dS7JcXwN+HcmCa/TB7gZ2JfkuIwHng8h9K23r94kz8Fz+D4JuzPzOyRJrZrT86TWZzmgA0lFpFEhhAHANsB2dVPqMlWqMcAJJAlGnbnAHjHGeZnt1iOZqnZk3TSyEALAmBhjvlPKNgeuiDHemTV2ayPbDyZ5A7ZOjPGTTDyvkJy/dRjwt6xtx8QYD8x8PSLTrGIv4PymgspU0YaTfJ/PZ/4fHmOckvles7e9o+7rzJvA54BVSZK622OM32YqJCzm51NJUvl5MGs/KzWw3VHA+yQVqXdIEuTNY4xzGvlWhmT+7585VnXNLF4G9o4x3k5y/GYDX+Zw/JqK4XigG7BJjLHuvKgFU/7y/L0D2DXG2NA5ZIsbb8zTMcaTM4/5CrAPyTlcP4gxzgeGhxB2B/YE7lj8bpq0LLBLjHFy5rF6AUMbmEq4tOLpAuweY5ySeaztSH43+8UYn8uMrQxcEULoFGOcEUL4GbALWccJeDyEsA7wF5IkiRjjWXUPEkIoB54geU7/mqRKVacHsE2McVTWtvcDgaSCJUmtlpUmqfXKZW7t5sA32ecgxRink3TY+0m9bZ+pS5gyPgBWzFS2CvU2cEII4cjMG7KmbA68WZcwwYLzPF5g0bgfr7f8AUkyk6s7gH0y1a19WMwb1xBCVQjhshDCWJIEcy5JhSGX7weS4/VYUxvFGCeRvNk9iORT+7NijO80cbfNgcfrEqbMfl4hSVLq/7yalEMMO5Akl4trJJHP791Ti0mMFjfelAXJW+bn8S3JVMT5WduMBlZZgn1ne60uYcr4IPN//f0urXher0uYsvY5B/hPvTFIKrMAO5JUH18IISxTd8vEvKBBSghh3RDC/SGEr4H5JL/7gUV/98fUJUwZdT+TfJ6PktQimTRJrc9EknNWeuew7Uok5w/V9zXJp8LZqustzyE5f6FDnvE15GiS6VqnATGEMCqEsH8j26+UibG+XOPumEds/yb5lP4cknO5HlrMdjeSTBO7gKTRxmYk56Lk+liTm6gWZXua5HstJ5le1ZR8fl65aiyG5Wi8814+v3cNxd3YeFOq6y3PWcxYPr8juT4ODew3zXim1p0nlTVG1mMtD/Ti+w8B6m5nkJlqGULoSvLBxGokzWd+SvK7/04DMTcUAw1sJ0mtjtPzpFYmxjg3hPACyfkipzSx+Zck5xXU1xOYVKSQZgPt641VZS/EGKuB3wO/DyH8mOSci3+FEN6NMX7Aor4E1m9gvJhx18U2PYTwMMmUs7szFZGFZE6W3xU4Ksb4z6zxfD54yqfrznlAO5IqwCUk55E0prHj/EYej5trDBNJEqMliaf+8Vvcz8UuRc1vEknzlz0a2WYrkkrRTjHGBVPsQgjdmjc0SWpZrDRJrdMlwKYhhN/WXxFCKM+cUwLwCskUu22z1nciOY/hP/Xvu4Q+I2nYsODxSRpKNCjG+C7JeS3lJC2wG/IKsEmmg17dflchObemWHFnu5KkwvTPxazvQBLvgo58mU/gf1lvuzmZdUv8yXrmXJRjgCNImk4MCslFjBvzCtA/E1PdfuquN5X3zyuHGJ7KPF7PRuJp7t87Fe4pkkrTtBjj6/VvmW0qM/9n/+5vTfK7JUlthpUmqRWKMT4UQrgYuC7T+OBBYBpJEnI4ybksw2OMI0IIL5J0sDqRpELwR5I3QhcUKZz7gaNCCG+RNGo4mOQk+QVCCP/JbPc+SQXhEJLrJC3SQS7jRpIOfo+FEE4jOY/idJK2ylcVKe4FYowjSbrPLW79lBDCa8BpIYTvgBrgRGAKC3+vdZ/EH5tpfPBdjDHmGkcIoQvJlL87Y4z3ZMauAq4MITwXY/x2MXe9mCTBGRFC+DvJdMPzgPdIuvzlLMcYhgL/R9JB7RySbmrrAp1jjOcvpd87Fe4JkksLPJH5vfkvye/zhkDHGONJJM1EpgHXhBDOJ6k6nUFSoZKkNsNKk9RKxRiHkJxjszZJG+knSLqoPUXyBrrOHpl1l5Bcw6gM2CH7ekcFOjOz37+SJDtvs+j1il4iaWt8D3AXybkUP6+7pk19mWss7UiShFxH0qp7HEmXr6JOz8vDASRJ4c0kLZzvzXyd7XmSpOBYkmpLvgneRSSJxVFZY38kedO6uCoYmURme2AWcDtwRSaWnfI4jyrnGDKPtw3JdXguIWnwcCgLd3Tcg+b9vVOBYoy1JJ0mrye5ZtQIkt/ZrchUBGOMX5N00etF8uHMcSQfzHgcJbUpXtxWkiRJkhphpUmSJEmSGuE5TZKkFi9z/aDFqanXWruQx2lHMpWwQfWuZdbsWlo8ktRWWWmSJLVoIYQ+LHotoezb9UV8uKeaeKylraXFI0ltkpUmSVJL9wXJBVUXZ0IRH+swoGuTWy09LS0eSWqT0m4EYRcKSZIkaVGLnZrbUs2d8EnR39tXLN+3RfwcUq80zRxZzFkVagkqtzsIgB/23DLlSFRs73/9MgCVlaunHImKbebMsYDP21JU97zt0XXtlCNRsU2aOgqAZdqvknIkKrZ5c7wUWkuTetIkSZIkqQTUzE87gmZjIwhJkiRJaoSVJkmSJEmFqy3K1R9aJCtNkiRJktQIK02SJEmSCldTupUmkyZJkiRJBat1ep4kSZIktU1WmiRJkiQVroSn51lpkiRJkqRGWGmSJEmSVLgSPqfJpEmSJElS4Wrmpx1Bs3F6niRJkiQ1wkqTJEmSpMKV8PQ8K02SJEmS1AgrTZIkSZIKV8Itx02aJEmSJBWs1ul5kiRJktQ2WWmSJEmSVLgSnp5npUmSJEmSGmGlSZIkSVLhPKdJkiRJktomK02SJEmSClczP+0Imo1JkyRJkqTCOT1PkiRJktomK02SJEmSCtfWW46HENYJIdweQli2gXXdQgi3hRDWLH54kiRJkpSuXKfn/RkYH2P8rv6KGOMUYHxmG0mSJEltUW1N8W8tRK7T834K/KqR9XcBdxQejiRJkqRWqYSn5+WaNK0GfNPI+gnAqoWH03o98cZH3PLka4z9ehIzZ89lpeW6sesW63Ng/y2oWKYdAN/NmMVFdz/NM2+PYu78+Wy81qr8ef+d6L1iVcrRK1+777cL51x26iLjZ53wd+66+f4UIlKx9O27OscffxhbbLEx6623Di+88Cr9+++fdlgqAp+3pWv3PQYwcNAebLDh+iy7bFdGj/qUyy+7jvvueTjt0FQE6667NpcO/StbbrkJ1dVTuP6G2znr7IupKeE36Gp5ck2aJgFrAWMXs34tYHJRImqlpkyfxeZhdQ7ceQu6durA+59+yT8ffoEJ303npEE7AfDnax5k9BcT+NN+P6NLZQeuefQlDht6B3efdhBdKjuk/B1oSQze60hmz5q9YPmzsV+kGI2KYb311mHAgO159dW3qKioSDscNQOft6XnyGMOYuyYzzjlxHOZOHEyO/Xvx7U3DGW55aq45qpb0g5PBejevRsjHruDDz8cxV57D6Zv3z5ccP5plJeXc9rp56cdnuqprfU6TU8DxwJPLWb9cZlt2qx9tt1woeXNwupMmzWHO0e+yYn778i7n3zBSx+M4arj9mOLdfsA8KM1VmaXk//Jvc+/zW933mLpB62Cvf/Wh8ycMTPtMFREjzzyJA8//AQAt912JcstZyW41Pi8LT2DBh7GpInff3b7/HMv06tXT448erBJUyt32KG/obKyI/sMPJipU6fBU8+z7LJdOO3UIVxw4T+SMWkpyLURxF+B7UII94cQtsh0zOsWQtgyhPAAsF1mG2Xp3rkj8+YlGXf87BuWaVfOpqH3gvXLLduZdVZdkeff+yStECXVU1tbm3YIkvKUnTDVee/dD+i1Us8UolExDei/PY8/8exCydGddz1Ip06V9Nt2qxQjU4NKuBFETklTjDEC/YEAvEQyXW8S8GJmrH+M8aPmCrI1mV9Tw8w5c3lr9Gfc9swb7NtvI8rKypg9dx7tystpV77wj7ximXZ8+tXElKJVoYa/ei9vf/4fHnrhTvb9zR5phyMpBz5v24ZNN9+Ij0d/mnYYKlAIaxHj6IXGxo//gunTZ+DVblqgmpri31qInC9uG2N8CVgvhLARsHZmeBTwdozRj2YztjrmYuZkqku7bvlDjt97ewB6r1DF7LnzGPX5t6y9ygoAzJozl9FffMv0WXNSi1dL5tuvJ3DZeVfx/pv/pbxdO36+x46cfuGJdOzUkVuuspGk1BL5vG07tu23FbvsuiPHHHlS2qGoQFVV3aiuXuSKN0yePIWqqu5LPyC1WTknTXVijG8BbwGEECqAzoATSjNu+vOvmTVnHu9/+gVXPfIif7vjCf5ywM5svf4arLJ8N86+dThn/fYXdK7swKX3Pcu0mbMXqT6p5Xtx5Cu8OPKVBcv/efolOnTswGHHDebWq+90ipfUAvm8bRtW670KV19/MY8+8iS3/+u+tMOR2pYWNJ0uhHAlcDhwTIzx8sxYD2AYsBswH7gXODbGOL2p/eX0bj2EsFsI4bf1xk4jSZaqQwhPZIJo89bt3YuN1lqV3+y0OX/eb0fufvYtxn87mYpl2nHewb9k0ncz2OP0a9npT1fw+YRqdt3yhyzXrXPaYasIHn/oabr36MYqvVdKOxRJOfJ5W1q6V3Xj7vuuY/y4zznsd0PSDkdFMHnyFLp167rIeFVVNyZPrl76AalVCCHsCmwF1G+P+i9gfWAnksSpH3BlLvvMtdI0BLgzK5CfAqcDpwAROCezfGyO+2sT1u2dnID6+YQprLZCFT9aY2Ue+uuhjP16Eu3albPaClUcc/k9/HiNlVOOVMVQ9ym1n1ZLrYfP29JRWdmRO+6+moqKCgbteygzZ85KOyQVQYyjCWGthcZWXXVlOnfuRIwfpxSVFqsm/ZbjIYSeJInQL4CHssbXBQYAm8YY38iMHQM8EkI4Icb4dWP7zTVpWp+k6UOdfYARMca/ZR5wJkmpy6Qpy9sffw7AKst3WzBWVlZGn17LATD260m88uEYLj1q71TiU3HtvNsOTJowmS/Gf5V2KJJy5PO2NLRr144bbhlG3zX7MGDHgUyYMCntkFQkw0c8w5A/HE6XLp2ZNi2ZQTVw392YMWMmzz73UsrRaRHNMD0vhNAd6N7AquoYY3UD4zcAl8UY3wshZI9vBUysS5gyngRqgc3JSrAakmvS1BnIDuqnJOWtOv8F2nS55MhL72KLdVdnzZWXp7y8nLdHf8YtT75G/01/wGorJNd5ufqRF+jTazmqulQy6vNvueaRF+m/2bpstd4aKUevfA297m+899YH/O+D0bRrV86A3Xfk53vsxLknX+Qn1q1cZWVHBgzYAYCVV+5F165d2HPPXwAwfPjTfnrdivm8LV0XDj2Dnftvx4knnE2PHlX06PH99dXefecD5syx4VJrddXVt3D0UQdxz13XcsGF/2CNNXpz2qlDuOTSq71GU9txHMmMtvrOBM7IHgghHE2St1zUwPa9gG+yB2KM80IIkzLrGpVr0jQe2BAYmzl36UfAf7LWrwgs2tqkDVm/Ty/+/dL7fDFxCu3Ky1l1+e78fo9+7NNvwwXbVE+byQV3PUX1tJn0qurK/+20Ob/ZafP0gtYSG/PxWPYctCu9Vu5JWRl8/L8xnHTUGTx0z/C0Q1OBVlhheW67beHpzXXLIWzDuHGfpRGWisDnbenafoefAHDeBacusm6D9bdj/LjPl3ZIKpLq6insPGA/LrvkHB64/waqq7/j0suu4cyzGnpPrNQ1T4vwS4AbGxivzl4IIfwAOBXYIsZY9EDKcvl0LYRwCnAEcDnwM2DVGOMPstYfA+wRY/xZno9fO3Pk9XneRS1d5XYHAfDDnlumHImK7f2vXwagsnL1lCNRsc2cORbweVuK6p63Pbqu3cSWam0mTR0FwDLtV0k5EhXbvDmfA5SlHUe+Zr18Z9HL9h233C+nn0MI4UDgeiA7YWqXWR4FnA+cH2NcPus+ywCzgD1jjEWZnvc3oBIYCHwN1D8J56fA7TnuS5IkSVKpSbfl+APA6/XGRpBUqW4kyXuWCyFsHGN8M7N+B5Lk9NWmdp5T0hRjnA/8JYRwSt2FbEMIXUmSqI7AKTHG/+WyL0mSJEkqpkxTiOrssRDCXODLGOOozPJw4NoQwuFABcksutua6pwHOSZNIYQ1gbuAH4cQXgd+AwwHepKUvC4IIfwixjgyt29LkiRJUklpnnOaiulXJInSUyQ5zD3A73O5Y67T8y4CJgN7APuTlLpGAodk1g8j6WDRL8f9SZIkSSolLSxpijH2qbc8CThgSfaVa9K0NdA/xvhWCOF5ktLXwLrOFCGEYSx8HSdJkiRJKgnlOW63PPAFQIzxO2A6SeWpzmSgWwP3kyRJktQG1NbOL/qtpcg1aYKF2/dBcvVcSZIkSSppuU7Pg6TTxOzM1x2By0MI0zPLHYobliRJkqRWpYWd01RMuSZNN9VbvrXe8nTg5sLDkSRJktQqpXudpmaV63WaBjd3IJIkSZLUEuUzPU+SJEmSGlbC0/PyaQQhSZIkSW2OlSZJkiRJhWvr5zRJkiRJUqOcnidJkiRJbZOVJkmSJEmFK+HpeVaaJEmSJKkRVpokSZIkFc5zmiRJkiSpbbLSJEmSJKlwJVxpMmmSJEmSVDgbQUiSJElS22SlSZIkSVLhSnh6npUmSZIkSWqElSZJkiRJhSvhc5pMmiRJkiQVzul5kiRJktQ2WWmSJEmSVLgSnp5npUmSJEmSGlFWW1ub5uOn+uCSJElSC1WWdgD5mnnPX4v+3r5yn1NaxM/B6XmSJEmSClfCjSBST5o2XemnaYegInv9y+cBmPbH3VOORMXW5cIHAaisXD3lSFRsM2eOBTy2paju2K65/MYpR6Ji+3jCmwD06Lp2ypGo2CZNHZV2CKon9aRJkiRJUglI97SfZmUjCEmSJElqhJUmSZIkSYUr4XOarDRJkiRJUiOsNEmSJEkqXAlXmkyaJEmSJBWutnSTJqfnSZIkSVIjrDRJkiRJKlwJT8+z0iRJkiRJjbDSJEmSJKlwJXxxW5MmSZIkSYUr4el5Jk2SJEmSWr0QwqHA0UCfzNB/gbNijI9l1o8E+tW721UxxsOb2rdJkyRJkqTCpV9p+gI4CfgfUAb8BngwhLBBjPHDzDZXAmdl3WdGLjs2aZIkSZLUIoUQugPdG1hVHWOszh6IMT5cb5tTQwhHAZsDdUnTjBjjV/nGYdIkSZIkqXDNc3Hb44DTGxg/EzhjcXcKIbQD9gU6AS9nrfptCOFA4CvgQeCvMcaZTQVh0iRJkiSpYLU1zdI97xLgxgbGqxvaOITwI+AloCMwDdgjxhgzq28DxpJM49sAOA9YGxjYVBAmTZIkSZJapMwUvOp87gJsCHQD9gFuDiH8NCauztruvRDCF8BTIYTVY4xjG9upSZMkSZKkwqXfCIIY4xxgdGbxjRDCZsDvgaMa2PyVzP9rkVSgFqu8aBFKkiRJUstSBnRYzLoNM/9/2dROrDRJkiRJKlzzNILIWQjhHOBxkqpRF2AQsB1wbghhTeAA4FFgIvBjYCjwdIzxg6b2baVJkiRJUilYHriJ5Lymp4EtgAExxqeAOcCOJEnVR8BFwN3AHrns2EqTJEmSpMI1T/e8nMUYD2tk3Xig35Lu26RJkiRJUuFaQCOI5uL0PEmSJElqhJUmSZIkSYWz0iRJkiRJbZOVJkmSJEmFq023EURzajJpCiGcn+vOYox/Kiyc0tKuXTt+fcT+7D5oF3qt0pPJE6t56uGRXHz6sLRDUx7a/Xhr2m+7O+UrrAztO1I7+VvmvvEMc0feD/PnAbDM1j9nmXU3pV3vdSjrvCwzr/wL8z9+P+XItST69l2d448/jC222Jj11luHF154lf799087LBWBx7Zt6NlrBZ54+X46d+nEj1bfhhnTZ6Ydkgqw+x4DGDhoDzbYcH2WXbYro0d9yuWXXcd99zycdmhqSAlPz8ul0rRZjvsq3dRyCZ1+6clsts3GXHPxDYwZPY6eK6/IGuv0STss5amsU1fmj36XOSPvh5nTKe+9Nu133p+yZauYc//VAFRssj3U1jIvvkXFxkvczVItwHrrrcOAAdvz6qtvUVFRkXY4KiKPbdtw4pnHMWP6DDp36ZR2KCqCI485iLFjPuOUE89l4sTJ7NS/H9feMJTllqvimqtuSTs8tSFNJk0xxu2XRiClZqvtN2fnX+7AoB0H8+n/xqQdjgow7+URCy3P//g9yjp0omKbny9ImmZe/meoraW8V2+TplbukUee5OGHnwDgttuuZLnlqlKOSMXisS19m221MdvusDVXXnI9J515fNrhqAgGDTyMSRMnL1h+/rmX6dWrJ0cePdikqSVK+TpNzclGEM3kl/vvwmsvvGnCVKJqZ3wH7bI+qS7hObxtTa3HsmR5bEtbeXk5p//tTwy78BomT6xOOxwVSXbCVOe9dz+g10o9U4hGbVku5zTdlevOYowDCwundPxw4/V4bsQL/Omc4/jFvgNYZpl2vPjMK5x/8lAmfD0x7fC0JMrKYZllKF9lTSp+sitzX3os7YgkSRkHHLgP7TtUcOt1d7H7Pj9POxw1o00334iPR3+adhhqSG3bPqdperNHUYKWW6EHu+73c0Z9MJq/HH4Gnbp04venHsGF15/LgbsclnZ4WgKdz72Tsor2AMx9/WnmPHxjugFJkgDoXtWN4086giFHnMK8efPSDkfNaNt+W7HLrjtyzJEnpR2KGlLC0/NyOadp8NIIpNSUlZVRVgZDDjyJKZO/A2DCNxO55v7L2ewnm/Daf95IOULla+blf4aKDrTrvTbtd9oP9jyU2fddlXZYktTmDfnLUbz9+nuMfPKFtENRM1qt9ypcff3FPPrIk9z+r/vSDkdtjNdpaibfTZnK52O/WJAwAbz9yrvMmT2Hvuv0MWlqhWo+/yT5f8yH1E6fSsdBxzHn2QepnfhVypFJUtu1dujLPgfszqDdDqbrsl0A6FjZEYCuXbswf34Ns2fNTjNEFUH3qm7cfd91jB/3OYf9bkja4Wgxatt4y/GFhBAOBgYCvYH22etijH2LFFerN2bUWNp3aL/IeFlZGTUl/AvVVtR8/jEA5T16Mt+kSZJS06dvb9q3r+DeETctsu7F90dw5633c/JxZ6cQmYqlsrIjd9x9NRUVFQza91BmzpyVdkhqg/JKmkIIJwPHA5cD2wJDgTWA/sB5RY+uFXv+iRc57ISD6NajG1MmTQFg4y03oKJ9Bf/7YHTK0alQ5X3WBaBm0tcpRyJJbdvrr7zNAbsfstDYtjtszeHHDuag/Y5m3NjPU4pMxdCuXTtuuGUYfdfsw4AdBzJhwqS0Q1Jj2vI5TfUcBBwSY3wghPBH4NoY48eZr39U/PBar/tv/Tf7H7wPQ286jxsuu4VOXTpxzF8O55VnX+OdV99LOzzloePBpzN/1DvUfD0Oampo12ddKvrtzty3nl8wNa981bUo67Ei5d2WT5b7rg+dl6V20jfUfGaS3JpUVnZkwIAdAFh55V507dqFPff8BQDDhz/tJ5ytmMe2NE2eVM0rLyw85X3V1VYG4LWX32LG9JlphKUiuXDoGezcfztOPOFsevSookeP76+v9u47HzBnzpwUo1Nbkm/StDLwZubr6cCyma/vA04pVlClYPq0GRy+z7Gc8NdjOfefZzB3zjyeHfEfLj79srRDU55qxo9imc12oLxqRaiZT83Er5nz6C3MfWn4gm0qtvkFFZv9bMFyh/4HADD3taeYfafHvDVZYYXlue22Kxcaq1sOYRvGjfssjbBUBB5bqfXZfoefAHDeBacusm6D9bdj/DgriS1KG285nu0zoBcwDvgY2BF4C9gEMNWv57Mxn3Psr/+Udhgq0JwRt8GI2xrdZvadl5kclYhx4z6jsnL1tMNQM/DYth333vEQ997xUNphqAg2/OH2aYegfJTw9LzyXDYKIfTIfPkgsFPm68uAc0MIHwK3ANcXPzxJkiRJSleulaZvQwgrxRhPAAghXA/8maQZxFbAqBijH+lIkiRJbVUJd4jONWkqq7e8D/DXGONLwEvFDUmSJEmSWo4lvbht/SRKkiRJUltWwuc05Zo01WZu9cckSZIkye55JJWla0MIszPLHYHLQwjTszeKMQ4sZnCSJEmSlLZck6ab6i3fWuxAJEmSJLVibX16XoxxcHMHIkmSJEkt0ZI2gpAkSZKkBWptOS5JkiRJjSjh6XnlaQcgSZIkSS2ZlSZJkiRJhbPSJEmSJEltk5UmSZIkSYUr4YvbWmmSJEmSpEZYaZIkSZJUuBI+p8mkSZIkSVLBaks4aXJ6niRJkiQ1wkqTJEmSpMJZaZIkSZKktslKkyRJkqTC1aTbcjyEcChwNNAnM/Rf4KwY42OZ9R2Bi4D9gQ7ACOCIGOM3Te3bSpMkSZKkwtXUFv+Wny+Ak4BNgE2BJ4EHQwjrZtYPBXYD9gX6ASsD9+SyYytNkiRJklq9GOPD9YZODSEcBWweQvgC+B0wKMb4NEAIYTDwYQhh0xjj643t26RJkiRJUuGaoRFECKE70L2BVdUxxupG7teOpKLUCXiZpPpUATxet02M8aMQwjhgK6DRpMnpeZIkSZJaquOATxu4HdfQxiGEH4UQpgGzgX8Ce8QYI9ALmBljnFrvLl9n1jXKSpMkSZKkgtXWNkvL8UuAGxsYr17M9hHYEOgG7APcHEL4aaFBmDRJkiRJKlwzTM/LTMGrzmP7OcDozOIbIYTNgN8D9wKVIYSu9apNPYGvmtqv0/MkSZIklaoykvbibwBzgZ3qVoQQAtAbeKmpnVhpkiRJklS4Zqg05SOEcA5Jo4exQBdgELAdcG6McUoI4TpgaAhhMvAdMAx4vqnOedACkqbXv3w+7RDUTLpc+GDaIaiZzJw5Nu0Q1Ew8tqXr4wlvph2CmsmkqaPSDkFqKZYHbgJWAqYA7wIDYoxPZdYfD9SQTNXrAAwHjsxlx2XNdMJWrtJNRyVJkqSWqSztAPI1ZfCORX9v3+2GJ1vEzyH1SlOPrmunHYKKrO4Tr2Xar5JyJCq2eXM+B2DuhE9SjkTFVrF8XwDWXH7jlCNRsdVVmHy9LT2+3pauutdbtRypJ02SJEmSSkDK5zQ1J5MmSZIkSYWrSTuA5mPLcUmSJElqhJUmSZIkSQWrLeHpeVaaJEmSJKkRVpokSZIkFa6EK00mTZIkSZIKZyMISZIkSWqbrDRJkiRJKpiNICRJkiSpjbLSJEmSJKlwJXxOk0mTJEmSpII5PU+SJEmS2igrTZIkSZIKV8LT86w0SZIkSVIjrDRJkiRJKlhtCVea8kqaQgjbLmZVLTAL+CTGOLHgqCRJkiSphci30jSSJEECKMv8n71cE0J4BPh1jHFq4eFJkiRJahVKuNKU7zlNPwfeAfYCVsnc9gLeAvYEdgHWBc4vYoySJEmSWrjamuLfWop8K03nA8fEGJ/LGnswhFANDIsx/jiE8HvgqmIFKEmSJElpyjdpWgeY0MD4RGDtzNcfASsUEpQkSZKkVqYFVYaKLd/peW8Cfw8hLFc3kPn6POCNzFBf4PPihCdJkiRJ6cq30vQ74AHg8xDCmMzY6sAYYI/McnfgnIIjkyRJktRqtKRzkIotr6QpxvhRCGE9YGeSqXoAEXgixliT2ea+4oYoSZIkqaUzacqSSY6GZ26SJEmSVNLyTppCCDsB2wMrUu+cqBjjQUWKS5IkSVIrUsqVprwaQYQQziapMPUjOXepa72bJEmSJJWUfCtNhwK/jjHe3hzBSJIkSWqlasvSjqDZ5NtyHOD1okdRonbfYwD/uvOfvB+fZ9yXb/P0c/ez1z67ph2WimTdddfm8eF38l31aMaNeYMzTv8j5eVL8pRSS/D1txPYbMc9+eE2P2fGjJkNbvP3S6/ih9v8nAsuv2YpR6di69lrBd4d8x8+nvAmnTpXph2OCuTrbWnz9bb1qK0p/q2lyLfSdAlwBPCH4odSeo485iDGjvmMU048l4kTJ7NT/35ce8NQlluuimuuuiXt8FSA7t27MeKxO/jww1Hstfdg+vbtwwXnn0Z5eTmnnX5+2uFpCVx0xXV0qqxk5sxZDa7/+NOx3PfwCLp07rSUI1NzOPHM45gxfQadu3g8S4Gvt6XL11u1FPkmTRsDO4UQdgX+C8zNXhljHFiswErBoIGHMWni5AXLzz/3Mr169eTIowf7R7yVO+zQ31BZ2ZF9Bh7M1KnT4KnnWXbZLpx26hAuuPAfyZhajdfffo//vPw6h/zfflx0xXUNbnPu0Cv59b578NCIp5ZydCq2zbbamG132JorL7mek848Pu1wVAS+3pYuX29bl9oap+fVmQbcD7wAVAPT692UJfsPeJ333v2AXiv1TCEaFdOA/tvz+BPPLvTH+s67HqRTp0r6bbtVipEpX/Pnz+fcoVdyxOADqOrWrcFtHn/meT4d+xm/+42fC7V25eXlnP63PzHswmuYPLE67XBUJL7eli5fb9VS5Htx28HNFUhbsenmG/Hx6E/TDkMFCmEtnhn5wkJj48d/wfTpMwhhTR5+5ImUIlO+7nrgUebOmcv+e+/GIyOeWWT9rNmzuWDYtRx3xGA6VXZMIUIV0wEH7kP7DhXcet1d7L7Pz9MOR83I19vS4Ott69KSzkEqNs+iW4q27bcVu+y6I1cMuz7tUFSgqqpuVFd/t8j45MlTqKrqvvQD0hKpnvIdw665mROOOYSKZRr+DOnam+9kheWq2K3/Dks5OhVb96puHH/SEZx76sXMmzcv7XDUjHy9LR2+3rYutbVlRb+1FE1WmkIIrwL9Y4yTQwivAbWL2zbGuHkxgyslq/Vehauvv5hHH3mS2/91X9rhSAIuveomNlj/B2y7dcN/uj774ituvP0+rh92HmVlLecPt5bMkL8cxduvv8fIJ19oemO1Wr7eSmoOuUzPewSYnfX1YpMmNax7VTfuvu86xo/7nMN+NyTtcFQEkydPoVu3Ra/nXFXVjcmTq5d+QMrb6E/Gcv8jj3PTFefzXWau/KzZyZ+6qdOnU96unKFX3sBPttyUPr1XXbBNTW0tc+fM5bup0+japbPJVCuxdujLPgfszqDdDqbrsl0A6JiZbtm1axfmz69h9qzZje1CrYCvt6XH19vWpZSn5zWZNMUYz8z6+oxmjaYEVVZ25I67r6aiooJB+x662HbGal1iHE0Iay00tuqqK9O5cydi/DilqJSPsZ99zrx58/jVYYteQeFne/yGvXbtz5hxnxFHf8KTzy5cmbjt3oe47d6HePL+m+m14gpLK2QVoE/f3rRvX8G9I25aZN2L74/gzlvv5+Tjzk4hMhWLr7elyddbtRR5NYIIITwIXA88HGOc3zwhlY527dpxwy3D6LtmHwbsOJAJEyalHZKKZPiIZxjyh8Pp0qUz06YljSMH7rsbM2bM5NnnXko5OuVi4x+vz/XD/r7Q2AuvvM51t97NlReexaorr8T0GTOYUe+N1wmnn8emG/6I/fbchR7dG+62p5bn9Vfe5oDdD1lobNsdtubwYwdz0H5HM27s5ylFpmLw9bZ0+XrbuqTdcjyEcBKwF/ADYCbwH+DPMcZRWduMBPrVu+tVMcbDG9t3vtdp+ha4CZgdQvgXcH2M8f0899FmXDj0DHbuvx0nnnA2PXpU0aNH1YJ1777zAXPmzEkxOhXiqqtv4eijDuKeu67lggv/wRpr9Oa0U4dwyaVXe82IVqKqezc23/jHC4198eXXAGyywQ/p1Kmywft1aF9Br57LL3JftWyTJ1XzygtvLDS26morA/Day28xY/rMNMJSkfh6W7p8vVWe+gFXAK+R5DnnAo+HENaLMWb/ob8SOCtreUZTO8635fjBIYRjgL2B3wJvhxDeJqk+3R5jXPRCCW3Y9jv8BIDzLjh1kXUbrL8d48f5yWZrVV09hZ0H7Mdll5zDA/ffQHX1d1x62TWcedZFaYcmSW2Or7ely9fb1qU25c4HMcYB2cshhAOBb4CNgBezVs2IMX6Vz77Lagv47kIIqwKHAH/KDD0IXBZjfHHx91pIbY+uay/x46tlmjQ1qYAu036VlCNRsc2bk7zxmDvhk5QjUbFVLN8XgDWX3zjlSFRsH094EwBfb0uPr7elK/N62+o6DY3deMeip007Tx9fBXRvYFV1jLG6sfuG5IS4UcC6McaPMmMjgfVJfr5fkeQvf61XiVrEEl+nKYSwAfBH4EhgEnApSZe9J0MI5yzpfiVJkiQp4zjg0wZuxzV2pxBCGTAUeLYuYcq4Dfg1sD1wHsnsuUW7BNWTbyOI5YBfAQcCPyRpQT4YeDTGWJPZ5rrM+F/y2bckSZKk1quZGkFcAtzYwHh1E/e7nCRf2SZ7MMZ4ddbieyGEL4CnQgirxxjHLm5n+TaC+AL4mOQcpptjjN80sM3bwOt57leSJEmSFpKZgledz31CCMOAXwLbxhi/aGLzVzL/rwUULWnavqnzlWKM35GUuyRJkiS1EWk3gshMyRsG7AlsF2P8NIe7bZj5/8vGNsq3e16uDR4kSZIktSFpX6eJpN34AcDuwNQQQq/M+JQY48wQwpqZ9Y8CE4Efk5z39HSM8YPGdpxvpYkQwsHAQKA30D57XYyxb777kyRJkqQiOCLz/8h644NJzouaA+xI0kSiMzAeuBtosoldvo0gTgaOJzmxaluSzGwNoD9J9wlJkiRJbVBtbbqVphhjowHEGMeTXAA3b/m2HD8IOCTGeCYwF7g2xrg/SXa23pIEIEmSJEktWb7T81YG3sx8PR1YNvP1fcApxQpKkiRJUutSW5N2BM0n36TpM6AXMI6k9fiOwFvAJiSVJ0mSJEltUE3K0/OaU77T8x4Edsp8fRlwbgjhQ+AW4LpiBiZJkiRJLUG+LcdPyPr6zhDCOGArYALf9ziXJEmS1Mak3QiiOeVbaVpIjPGlGOPFwDvAscUJSZIkSZJajryv0yRJkiRJ9bWAi9s2m4IqTZIkSZJU6qw0SZIkSSpYbW3aETSfnJKmEMJdTWzSvfBQJEmSJLVWpTw9L9dK0/Qc1t9cYCySJEmS1OLklDTFGAc3dyCSJEmSWi8vbitJkiRJbZSNICRJkiQVrJQvbmvSJEmSJKlgpdw9z+l5kiRJktQIK02SJEmSCmYjCEmSJElqo6w0SZIkSSqYjSAkSZIkqRE2gpAkSZKkNspKkyRJkqSClXIjiLLadOtoJVzEkyRJkpZYq8tAXl91j6K/t9/0swdaxM/BSpMkSZKkgtkIohn16Lp22iGoyCZNHQXAMu1XSTkSFdu8OZ8DsObyG6cciYrt4wlvAjD9tP1TjkTF1vmsOwCft6Wo7nnr623pqXu9VcuRetIkSZIkqfUr5XOaTJokSZIkFayUmxXYclySJEmSGmGlSZIkSVLBSnl6npUmSZIkSWqElSZJkiRJBbPluCRJkiQ1oibtAJqR0/MkSZIkqRFWmiRJkiQVrJbSnZ5npUmSJEmSGmGlSZIkSVLBakr46rYmTZIkSZIKVuP0PEmSJElqm6w0SZIkSSpYKTeCMGmSJEmS1OqFEE4C9gJ+AMwE/gP8OcY4KmubjsBFwP5AB2AEcESM8ZvG9p1z0hRCOG0xq2qBWcBoYHiMcWau+5QkSZJUGlrAxW37AVcAr5HkOecCj4cQ1svKUYYCuwD7AlOAy4F7gG0b23E+labdgHWAjsCYzFgfkoRpPLAGUB1C6BdjHJ3HfiVJkiSpIDHGAdnLIYQDgW+AjYAXQwjdgN8Bg2KMT2e2GQx8GELYNMb4+uL2nU/SdC1J4jQ4xvht5kFWAK4HHgLuBO4ALgF2zWO/kiRJklq55jinKYTQHejewKrqGGN1E3fvlvl/Uub/TYAK4PG6DWKMH4UQxgFbAYtNmvLpnncKyZzAb7Me5FvgZODUGOMU4DRgizz2KUmSJKkE1DTDDTgO+LSB23GNxRJCKCOZivdsjPGjzHAvYGaMcWq9zb/OrFusfCpNVUCPxYxXZb6eSHJClSRJkiQV6hLgxgbGq5u43+XAD4FtihFEPknTv4HrQwh/IDm5CmAz4GLgwazlUQ3cV5IkSVIJa45GEJkpeNX53CeEMAz4JbBtjPGLrFVfAZUhhK71qk09M+sWK5+k6VCSEtc9WfebB9wE/CGzPCqznSRJkiQtNZkpecOAPYHtYoyf1tvkDWAusBNwX+Y+AegNvNTYvnNOmmKM04BDQgjHA30zw59kxuu2eTPX/UmSJEkqHS3g4rZXAAcAuwNTQwh15ylNiTHOjDFOCSFcBwwNIUwGviNJsp5vrHMeLMHFbTNJ0rv53k+SJElS6apJPWfiiMz/I+uND+b786KOJ5lJeC9JL4bhwJFN7Tifi9t2BU4EtgdWpF7nvRhj34buJ0mSJEnNLcbYZNoWY5wFHJW55SyfStP1JP3LbwK+BGrzeSBJkiRJpasm/el5zSafpGlnoH+M8eXmCkaSJEmSWpp8Lm77FTC9uQIpRbvvMYB/3flP3o/PM+7Lt3n6ufvZa59d0w5LRbLuumvz+PA7+a56NOPGvMEZp/+R8vJ8nlJq6Xr2WoF3x/yHjye8SafOlWmHozy0W28LOh58Fp1OvIZOp95M5e8vpqLfntCuHQBlXbpTsfOv6Hjk3+n0lxupHHIF7fc8grKuVU3sWS2dz9vS4+tt61HbDLeWIp9K0/HAeSGEQ2OMnzdXQKXkyGMOYuyYzzjlxHOZOHEyO/Xvx7U3DGW55aq45qpb0g5PBejevRsjHruDDz8cxV57D6Zv3z5ccP5plJeXc9rp56cdnorkxDOPY8b0GXTu0intUJSnsk5dmP/p+8x94SFqZ02n3SprUbH9PpR16c6cR26gfOW+LLPuZsx782nmfDaass7daL/9PrQ7+CxmXvFHmDM77W9BS8jnbWnx9bZ1aY7rNLUU+SRNNwFdgXEhhO9IepwvEGNcsZiBlYJBAw9j0sTJC5aff+5levXqyZFHDzZpauUOO/Q3VFZ2ZJ+BBzN16jR46nmWXbYLp506hAsu/EcyplZts602ZtsdtubKS67npDOPTzsc5Wne608ttFzz6QfQoZKKzXdmziM3MH/cR8wc9geo+f4lftaXY+h07FCWWW8L5r393NIOWUXg87b0+HqrliKf2uYfgcOAg4DjgBPq3VRPdsJU5713P6DXSj1TiEbFNKD/9jz+xLML/bG+864H6dSpkn7bbpViZCqG8vJyTv/bnxh24TVMnliddjgqktqZU6Fd5rPCWTMWSpgAaid+Se2cWU7Ra6V83pYmX29bl5qysqLfWop8Lm57U3MG0lZsuvlGfDy6/sWJ1dqEsBbPjHxhobHx479g+vQZhLAmDz/yREqRqRgOOHAf2neo4Nbr7mL3fX6edjgqRFkZLFNB+UprULHFz5n32uKfm2U9e1PWviM1E79cigGqWHzeliZfb9VSNJo0hRA6xRhn1H3d2LZ122nxtu23FbvsuiPHHHlS2qGoQFVV3aiu/m6R8cmTp1BV1X3pB6Si6V7VjeNPOoIhR5zCvHnz0g5HBep0yk2UVbQHYO5bzzLn8X81vGFZGR1+8VtqJnzJ/I/eWIoRqhh83pYuX29bl5bUuKHYmqo0TQ0hrBRj/AaYRsM/i7LMeLtiB1dKVuu9CldffzGPPvIkt//rvrTDkbQYQ/5yFG+//h4jn3yh6Y3V4s269jSo6ED5qmvSvt/esMtg5jx8/SLbVew4iPJV12bWDWdBzfwUIlUhfN5Kam5NJU07AJMyX2/fzLGUrO5V3bj7vusYP+5zDvvdkLTDURFMnjyFbt26LjJeVdWNyZOrl35AKoq1Q1/2OWB3Bu12MF2X7QJAx8qOAHTt2oX582uYPcuuaq1JzZdjkv/HRZg+lQ57H8XcFx6hdvLXC7ZZZrOdqNhmV2bfM4yaz0anFKmWlM/b0ubrbevSZrvnxRifzVr8FBgfY1yo2hRCKANWa4bYSkJlZUfuuPtqKioqGLTvocycOSvtkFQEMY4mhLUWGlt11ZXp3LkTMX6cUlQqVJ++vWnfvoJ7Ryx6CueL74/gzlvv5+Tjzk4hMhXD/C+T80nLqlZYkDS1W29z2u8ymDlP3Mb8919KMzwtIZ+3pc3X29alpuX0bSi6fFqOfwqsBHxTb7xHZp3T8+pp164dN9wyjL5r9mHAjgOZMGFS03dSqzB8xDMM+cPhdOnSmWnTkms+D9x3N2bMmMmzz/nGq7V6/ZW3OWD3QxYa23aHrTn82MEctN/RjBvrJepas3a9AwC1k78FoLzPenTY+2jmvTKceS88nGZoKoDP29Lm661ainySpsXljp0ByycNuHDoGezcfztOPOFsevSookeP79vYvvvOB8yZMyfF6FSIq66+haOPOoh77rqWCy78B2us0ZvTTh3CJZde7TUjWrHJk6p55YWFmwCsutrKALz28lvMmD4zjbC0BDr85kTmf/I+td98BjU1lPdeh4qtd2Xeey9SO/lrypZfmY6DhlAz4Qvmvf8S5at+/0l27fSpC03fU8vm87a0+XrbutQsNl1o/ZpMmkIIdZdbrgVOCyFkd8lrB2wJvF380Fq/7Xf4CQDnXXDqIus2WH87xo/z06/Wqrp6CjsP2I/LLjmHB+6/gerq77j0sms486yL0g5NElDz+SdUbNiPsu4rQM18aiZ/w5wnb2fea08C0G7VtSmr7Ey7ys5UHrLw1K25bz3LnPuvTCNsSfX4equWoqy2tvHmgCGEZzJf9gNeArLLI3OAMcCFMcZRS/D4tT26rr0Ed1NLNmlq8quwTPtVUo5ExTZvTpLor7n8xilHomL7eMKbAEw/bf+UI1GxdT7rDsDnbSmqe976elt6Mq+3ra5sc+vKvy561/Fff3Fri/g5NFlpijFuDxBCuAE4Nsa4aLN8SZIkSW1aKTeCKM9j21oauE5TCKFzCGHRi15IkiRJUgnIJ2n6LVDZwHgl8H/FCUeSJElSa1TTDLeWIpdGEJ1I5lSWAZWZ5TrtgJ1ZtA25JEmSJJWEXFqOT+P7qXmfNLC+Fji9mEFJkiRJal2K3gWiBckladqepMr0NLA3kH2F1jnA2BjjF80QmyRJkqRWopQbQeTSPe9ZgBDCGsC4GGMpJ5GSJEmStJBGk6YQwnrARzHGGqAzsG4IocFtY4wfFD88SZIkSa1BS2rcUGxNVZreB3qRNHp4n2SqYkOFt1qSphCSJEmSVFKaSprWAL7N+lqSJEmSFtFmK00xxrEhhHVCCN1jjK/WjYcQdgL+QjJl74EY4znNHKckSZIkpSKXi9teAPyibiGEsBbwb2Am8CJwYghhSPOEJ0mSJKk1qC0r/q2lyKXl+CbA37KWfwV8GGP8OUAI4R3gOOCiokcnSZIkqVUo5el5uVSalgM+z1reHngoa3kksHoRY5IkSZKkFiOXpOlboDdACKEC2Ax4KWt9JaWdWEqSJElqQk0z3FqKXJKmx4G/hxC2Av4KzCapLtX5EfBx8UOTJEmSpPTlck7TycD9wAvAdGBwjHFW1vqDSRIrSZIkSW1UbdoBNKMmk6YY4zfANiGE7sDUGOP8epsMBKY1Q2ySJEmSWomaFtTtrthyqTQBEGOsXsz4pKJFI0mSJEktTM5JkyRJkiQtTktq3FBsuTSCkCRJkqQ2y0qTJEmSpIKVcqXJpEmSJElSwdp09zxJkiRJaulCCNsCJwCbACsBu8UYH85aPxLoV+9uV8UYD29q3yZNkiRJkgrWAlqOdwbeAa4H7lvMNlcCZ2Utz8hlxyZNkiRJklq9GONjwGMAIYTFbTYjxvhVvvs2aZIkSZJUsOZoBBFC6A50b2BV9eKuI9uE34YQDgS+Ah4E/hpjnNnUnUyaJEmSJLVUxwGnNzB+JnBGnvu6DRgLfAFsAJwHrA0MbOqOJk2SJEmSCtZM3fMuAW5sYLw63x3FGK/OWnwvhPAF8FQIYfUY49jG7pt60jRp6qi0Q1AzmTfn87RDUDP5eMKbaYegZtL5rDvSDkHNxOdt6fL1Vi1FTTOkTZkpeNVF33Hilcz/a5FUoBarvJkCkCRJkqSWbMPM/182tWHqlaYeXddOOwQVWV31cJn2q6QciYqt7tNMj23pqTu2q1Stn3IkKrbPJ/8XgKmHD0g5EhVb138OB6CycvWUI1GxzZzZaNGjxWqORhD5CCF0Iaka1VkjhLAhSdOHzsABwKPARODHwFDg6RjjB03t20qTJEmSpFKwKfBW5gZwWebrw4E5wI7A48BHwEXA3cAeuew49UqTJEmSpNavmRpB5CzGOBJo7BK7/ZZ03yZNkiRJkgqW9vS85uT0PEmSJElqhJUmSZIkSQWraWxiXCtnpUmSJEmSGmGlSZIkSVLBmuPiti2FSZMkSZKkgpVuypRH0hRCqGHxP4tZwGjgxhjj0GIEJkmSJEktQT6VpsOBM4E7gFczY5sD+wHnASsBZ4UQMHGSJEmS2pZSbjmeT9K0J3BCjPHWrLHbQwhvAL+KMf48hDAaGAKYNEmSJEkqCfl0z+sHvNzA+Ct8f3XdZ4A+BcYkSZIkqZWpobbot5Yin6Tpc+DABsZ/C3yW+boKmFxgTJIkSZJamdpmuLUU+UzP+yNwVwjh58BrmbHNgPWBgZnlLYF7iheeJEmSJKUr56QpxvhgCOEHwKFAyAw/DuwdYxyT2eaKokcoSZIkqcWzEURGjPFT4KRmikWSJEmSWpy8kqYQQhXJlLwVqXc+VIzx5iLGJUmSJKkVaUmNG4otn4vb7gncDFQC1Sx8blZtZp0kSZIklZR8Kk0XAFcBp8QYZzVTPJIkSZJaodKtM+WXNPUE/mHCJEmSJKm+Um4Ekc91mu7j+4vYSpIkSVKbkE+l6QPgvBDC1sD7wNzslTHGfxQzMEmSJEmtR20JT9DLJ2k6HJgB7Ji5ZasFTJokSZIklZx8Lm67RnMGIkmSJKn1KuVzmvK6TpMkSZIkNaTNXqcphHA+cGaMcXrm68WKMf6pqJFJkiRJUgvQVKVpM6Ai6+vFKd20UpIkSVKTSjkhaDRpijFu39DXkiRJktRW5HOdJuVp9z0G8K87/8n78XnGffk2Tz93P3vts2vaYalI1l13bR4ffiffVY9m3Jg3OOP0P1Je7lOqFHhsS9Muv9yZB0fcyvsfv8DHX77Jc68+zLFDDqOioqLpO6vFWGbjn9DphIvpcuFddBn2bzqfcS3tfz4I2i38OXD7AfvR+dxb6HLZg1QOuYDyVfumFLEK0bfv6gwbdi6vvjqcadM+YcSIO9IOSY2oobbot5aiqXOaniHHSluMcYeiRFRCjjzmIMaO+YxTTjyXiRMns1P/flx7w1CWW66Ka666Je3wVIDu3bsx4rE7+PDDUey192D69u3DBeefRnl5Oaed3ujpf2rhPLalq6pHN1547lWuvOwGvpsylQ03+RF/+PORrNBzeU750zlph6cclXVelnnxHWqeuIfaGdNo1yfQftdfU9atitl3JFc/ad9/P9r/4gBm33ctNV99Rvsd96TyuL8x46zDqf1ucsrfgfKx3nrrMGDA9rz66lt+wNEKtOXuea9nfV0BDAbGAi9nxrYA+gDXFz2yEjBo4GFMmvj9H+fnn3uZXr16cuTRg02aWrnDDv0NlZUd2WfgwUydOg2eep5ll+3CaacO4YIL/5GMqVXy2JauW2+8e6HlF//zKl27dua3Bw8yaWpF5j7/6ELL8//3LlR2on2/3ZKkaZkK2g8YyJzhdzJ35EMAzPzkAzqfcxMV2/2SOf++KY2wtYQeeeRJHn74CQBuu+1KlluuKuWI1FY1Ot8kxnhC3Y0kabo6xvjjGOOhmdsGwFVA5dIItrXJTpjqvPfuB/RaqWcK0aiYBvTfnsefeHahN9B33vUgnTpV0m/brVKMTIXy2LYtkydNob2fXrd6tdOmwjLJ58Dt1lyPssrOzHvjue83mDOb+e++wjLrb5pShFpStbUtZ3qWmlbbDP9ainwm6R8AXN3A+DXA/sUJp/RtuvlGfDz607TDUIFCWIsYRy80Nn78F0yfPoMQ1kwpKhWDx7b0lZeX07GyI5ttuTEHHfYrbr7+zrRD0pIoK4eKDrRbc33a77A7c599BIDyXqtRO38+Nd98sdDm878aT3mv1dKIVFIJyOfitnOALYFR9ca3zKxTE7bttxW77Lojxxx5UtqhqEBVVd2orv5ukfHJk6dQVdV96QekovHYlr5Rn79Ox44dALj79gc5+7QLU45IS6LLZQ9QVtEegLkvPcHs+64FoKxTF5g9E2rrnV0xYxplHTomDSPmz1va4UptQls+pynbZcBVIYSNgFczY1sAhwB/K3ZgpWa13qtw9fUX8+gjT3L7v+5LOxxJarN27/8rKjtVstHGP+K4Px3OORecwsl/PDvtsJSnGef/gbL2HSjvE+iwywF02P9IZt9+RdphSSpROSdNMcZzQgifAMcAB2aGPwIOjTHe1gyxlYzuVd24+77rGD/ucw773ZC0w1ERTJ48hW7dui4yXlXVjcmTq5d+QCoaj23pe//dDwF47eU3mTRxMpf+829cdfmNjB0zPuXIlI+a8ck02vkf/5faaVOoHHwCc564j9oZ06BDZTJ9L7va1KkLtbNnWWWSmlFLOgep2PKpNBFjvB24vZliKUmVlR254+6rqaioYNC+hzJz5qy0Q1IRxDiaENZaaGzVVVemc+dOxPhxSlGpGDy2bct7734AQO/VVzFpasXqEqjy5XtR89V4ytq1o2zFlan9+rMF25T3Wo2arzzGUnNyel6WEEJ7YEXqNZGIMY4rVlClol27dtxwyzD6rtmHATsOZMKESWmHpCIZPuIZhvzhcLp06cy0adMBGLjvbsyYMZNnn3sp5ehUCI9t27LZFhsBMG7s5ylHokK0W3N9AGomfEVt9QRqZ06nYuOfMuexzOe8FR1Y5kdbMPc/j6UYpaTWLOekKYTwA+A6ksYP2cpILoDbrohxlYQLh57Bzv2348QTzqZHjyp69Pj+2gLvvvMBc+bYP6O1uurqWzj6qIO4565rueDCf7DGGr057dQhXHLp1V7Hp5Xz2JauW+++iueffYn/fTSa+fNr2GyLjTjsqAN58L5HrTK1IpXH/JV5H71FzRdjoaaGdmuuR/sd92buayOpnfAlAHOG30X7XQZRO2MaNV+Np/2Oe0F5GXOfeTDl6JWvysqODBiwAwArr9yLrl27sOeevwBg+PCnncHTwtSUcIv4fCpNNwIzgAHAl1DCkxaLZPsdfgLAeRecusi6DdbfjvHj/GSztaqunsLOA/bjskvO4YH7b6C6+jsuvewazjzrorRDU4E8tqXrnbfeZ+ABe7Daaqswb/48xo35jL+dNZRbbrgr7dCUh/lj/kfFljtRvlxPqJlPzYSvmP3ADcx97pEF28wZcSeUl9F+wEDKOi/L/LGjmHnpydROrU4vcC2RFVZYnttuu3KhsbrlELZh3LjPGrqbVHRluV40LIQwHdgoxvi/Ij5+bY+uaxdxd2oJJk1NutIv036VlCNRsc2bkyT6HtvSU3dsV6laP+VIVGyfT/4vAFMPH5ByJCq2rv8cDkBl5eopR6JimzlzLCSzuVqVX6++V9GLKreOva9F/BzyqTS9AawGFDNpkiRJklQCalKeiBZC2BY4AdgEWAnYLcb4cNb6jsBFwP5AB2AEcESM8Zum9p1P0nQxMDSE8HfgfWBu9soY4wd57EuSJEmSiqkz8A5wPdDQhVGHArsA+wJTgMuBe4Btm9pxPklT3QPfkjVWi40gJEmSpDavOa7TFELoDnRvYFV1jLE6eyDG+BjwWOZ+9ffTDfgdMCjG+HRmbDDwYQhh0xjj643FUd7YynrWaODWN+t/SZIkSSqm44BPG7gdl+d+NgEqgMfrBmKMHwHjgK2aunPOlaYY49g8A5MkSZLURjTTxW0vIeniXV91nvvpBcyMMU6tN/51Zl2j8rq4bQihAtgM6A20z14XY7w5n31JkiRJKh3N0QgiMwWvuug7zlM+F7ddD3gIWIWktDUT6ATMBqYCJk2SJEmSWqKvgMoQQtd61aaemXWNyuecpkuBF4BuJBe5/TGwHvAmMDiP/UiSJEkqMbXN8K+I3iDp/r1T3UBIukX0Bl5q6s75TM/bFNgmxjg7hFADtI8xfhRCOAG4Fnik8btLkiRJUvMIIXQB1soaWiOEsCHwVYzxqxDCdSSXUJoMfAcMA55vqnMe5Fdpmg/MyXz9NUlWBjAR6JPHfiRJkiSVmJpmuOVpU+CtzA3gsszXh2eWjwceBu4FngO+JLlmU5PyqTS9RdIEYnTmQc4MIVQB/we8l8d+JEmSJKmoYowjSa4hu7j1s4CjMre85FNp+gvwTebrk0muonsNSYu+w/J9YEmSJEmlo7a2tui3liKf6zS9mvX1N8CAZolIkiRJUqvTHC3HW4qcK00hhKdDCN0bGF82hPB0UaOSJEmSpBYin3OatqPeBW0zOgA/LUo0kiRJklqlJWjc0Go0mTRlLmpbZ50QwvJZy+1Ipul9XuzAJEmSJKklyKXS9D5Qm7k9y6IdKWYCxxQ5LkmSJEmtSJEvRtui5JI0rUGSKH0CbA58m7VuDvBNjHF+M8QmSZIkqZUo5UYQuSRNHYDuMcYFTSNCCDuRtCDvDDwAnNMs0UmSJElSynLpnncB8Iu6hRDCWsC/SablvQicGEIY0jzhSZIkSWoNSvk6TbkkTZsAw7OWfwV8GGP8eYzxWOBY4LfNEZwkSZIkpS2XpGk5Fu6Otz3wUNbySGD1IsYkSZIkqZWpaYZbS5FL0vQt0BsghFABbAa8lLW+kpb1PUmSJElaymqb4V9LkUvS9Djw9xDCVsBfgdkk1aU6PwI+Ln5okiRJkpS+XLrnnQzcD7wATAcGxxhnZa0/mCSxkiRJktRGtemW4zHGb4BtQgjdgakNXJNpIDCtGWKTJEmSpNTlUmkCIMZYvZjxSUWLRpIkSVKr1JJahBdbLuc0SZIkSVKblXOlSZIkSZIWp5TPaSpLuYxWuj9ZSZIkacmVpR1AvrZbdceiv7cf+dmTLeLn4PQ8SZIkSWpE6tPzlmm/StohqMjmzfkcgMrK1VOORMU2c+ZYwOdtKap73vbounbKkajYJk0dBcCay2+cciQqto8nvAnA3AmfpByJiq1i+b5ph7BEamwEIUmSJEltU+qVJkmSJEmtX+nWmUyaJEmSJBVBKXfPc3qeJEmSJDXCSpMkSZKkgllpkiRJkqQ2ykqTJEmSpILVlnDLcZMmSZIkSQVzep4kSZIktVFWmiRJkiQVrNZKkyRJkiS1TVaaJEmSJBWslBtBWGmSJEmSpEZYaZIkSZJUsFLunmfSJEmSJKlgTs+TJEmSpDbKSpMkSZKkgjk9T5IkSZJasBDCGcDp9YZjjPEHhe7bpEmSJElSwVrIxW3fAQZkLc8rxk5NmiRJkiQVrKZlNIKYF2P8qtg7zTlpCiEcFmO8qoHxMuCqGOOhRY1MkiRJUpsWQugOdG9gVXWMsbqB8XVDCF8CM4EXgJNijJ8VGkc+3fPODSEMamD8BuBnhQYiSZIkqfWqbYZ/wHHApw3cjmsghFeAA4H+wBHAmsBzIYTOhX5v+UzP2x14OIQwNcb4cAihHLgF2AzYrtBAJEmSJKmeS4AbGxivrj8QY3wsa/HdEMIrwFhgH+CmQoLIOWmKMf4nhLA/cEcIYSBwMLABsF2M8YtCgpAkSZLUujXHOU2ZKXjVS3rfEML/gLUKjSOvi9vGGIeTJEuPAOsD25owSZIkSWqm6XlLLITQhWSK3peFfm+NVppCCHctZtU3mduwEAIAMcaBhQYjSZIkSUsihHAh8BDJlLyVgTNJWo7fWei+m5qeN30x448X+sCSJEmSSkcLaDm+KnA7sBzwLfA8sGWMcWKhO240aYoxDi70Adqyddddm0uH/pUtt9yE6uopXH/D7Zx19sXU1NSkHZoK1Lfv6hx//GFsscXGrLfeOrzwwqv0779/2mGpSHzulqbd9xjAwEF7sMGG67Pssl0ZPepTLr/sOu675+G0Q1MR9ey1Ak+8fD+du3TiR6tvw4zpM9MOSUvo628nsOugQ5g5cxavPnEfnTpVLrLN3y+9ilvueoDfDtqLE44+JIUo1ZLEGJvtzZgXt20m3bt3Y8Rjd/Dhh6PYa+/B9O3bhwvOP43y8nJOO/38tMNTgdZbbx0GDNieV199i4qKirTDURH53C1dRx5zEGPHfMYpJ57LxImT2al/P669YSjLLVfFNVfdknZ4KpITzzyOGdNn0LlLp7RDUYEuuuI6OlVWMnPmrAbXf/zpWO57eARdOnusW4pCz0FqyZo6p+k1yO27jzFuXpSISsRhh/6GysqO7DPwYKZOnQZPPc+yy3bhtFOHcMGF/0jG1Go98siTPPzwEwDcdtuVLLdcVcoRqVh87pauQQMPY9LEyQuWn3/uZXr16smRRw82aSoRm221MdvusDVXXnI9J515fNrhqACvv/0e/3n5dQ75v/246IrrGtzm3KFX8ut99+ChEU8t5ejUFjXVPe9hkk55udyUZUD/7Xn8iWcXeoN1510P0qlTJf223SrFyFQMtenP2VUz8blburITpjrvvfsBvVbqmUI0Krby8nJO/9ufGHbhNUyeWJ12OCrA/PnzOXfolRwx+ACqunVrcJvHn3meT8d+xu9+Yx+ylqSmtrbot5aiqXOazlxagZSaENbimZEvLDQ2fvwXTJ8+gxDW5OFHnkgpMkmN8bnbtmy6+UZ8PPrTtMNQERxw4D6071DBrdfdxe77/DztcFSAux54lLlz5rL/3rvxyIhnFlk/a/ZsLhh2LccdMZhOlR1TiFCLU8rT8/K6TpNyV1XVjerq7xYZnzx5ClVV3Zd+QJJy4nO37di231bssuuOXDHs+rRDUYG6V3Xj+JOO4NxTL2bevHlph6MCVE/5jmHX3MwJxxxCxTINf7Z/7c13ssJyVezWf4elHJ3aspwbQYQQ2gOnAQOB3sBCZ7/HGNsVNzRJkprHar1X4errL+bRR57k9n/dl3Y4KtCQvxzF26+/x8gnX2h6Y7Vol151Exus/wO23brhU+U/++Irbrz9Pq4fdh5lZWVLOTo1pba2dLvM5tM972/A7sDZwJXA74HVgN8Cfyl+aK3b5MlT6Nat6yLjVVXdmDy5eukHJCknPndLX/eqbtx933WMH/c5h/1uSNrhqEBrh77sc8DuDNrtYLou2wWAjpkpW127dmH+/Bpmz5qdZojK0ehPxnL/I49z0xXn813mvNJZs5NjN3X6dMrblTP0yhv4yZab0qf3qgu2qamtZe6cuXw3dRpdu3Q2mVKzyCdp2gf4XYzxyRDC5cCIGOPoEML/gD0A5zdkiXE0Iay10Niqq65M586diPHjlKKS1BSfu6WtsrIjd9x9NRUVFQza99DFtjJW69Gnb2/at6/g3hE3LbLuxfdHcOet93PycWenEJnyNfazz5k3bx6/OuwPi6z72R6/Ya9d+zNm3GfE0Z/w5LMLVxVvu/chbrv3IZ68/2Z6rbjC0gpZ9dSU8DlN+SRNywP/y3z9HVDXY/kZ4LJiBlUKho94hiF/OJwuXTozbdp0AAbuuxszZszk2edeSjk6SYvjc7d0tWvXjhtuGUbfNfswYMeBTJgwKe2QVASvv/I2B+y+8EVNt91haw4/djAH7Xc048Z+nlJkytfGP16f64f9faGxF155netuvZsrLzyLVVdeiekzZjCj3ocdJ5x+Hptu+CP223MXenRvuNuelo5S7i6cT9L0CdAHGAd8RFJ5eg34BVBd7MBau6uuvoWjjzqIe+66lgsu/AdrrNGb004dwiWXXu11XkpAZWVHBgxITkBdeeVedO3ahT33/AUAw4c/7afXrZjP3dJ14dAz2Ln/dpx4wtn06FFFjx7fX1/t3Xc+YM6cOSlGpyU1eVI1r7zwxkJjq662MgCvvfwWM6bPTCMsLYGq7t3YfOMfLzT2xZdfA7DJBj+kU6fKBu/XoX0FvXouv8h9pWJqMmkKIXSIMc4GbgI2Ap4jOb/poRDCMUAHYNE6ahtXXT2FnQfsx2WXnMMD999AdfV3XHrZNZx51kVph6YiWGGF5bnttisXGqtbDmEbxo37LI2wVAQ+d0vX9jv8BIDzLjh1kXUbrL8d48dZkZCkQpTy9LyypspoIYRZwCsk0/BGAi/FGGeHEFYHNgFGxxjfXcLHr12m/SpLeFe1VPPmJG88KitXTzkSFdvMmWMB8Hlbeuqetz26rp1yJCq2SVNHAbDm8hunHImK7eMJbwIwd8InKUeiYqtYvi9Aq+tosWqPHxY9a/ps0vst4ueQy3WaDgYicADwNDA5hPAMcCAwgWSqniRJkqQ2rLa2tui3lqLJ6XkxxluBWwFCCCsD2wHbAvuTXLdpdgjhpRjjz5oxTkmSJEktWE0LSnKKLZ9GEMQYvwBuA24LIfyYJHE6miSRkiRJkqSSk3PSFEL4EUlytB1JpakW+A9wOvBsM8QmSZIkqZWoLeFGELl0z7uXJEmaTdI570ngtBjjf5s5NkmSJElKXS6Vpj2B8SQtx58FXowxetEDSZIkSQu0pMYNxZZL0rQS0I9kWt5lwJohhDdIEqhngRdijF7xUZIkSVJJyqV73tfAXZkbIYQVSabr9QMuBNYJIbwVY9yyOQOVJEmS1HKV8sVtc7lO00JijN8AHwOfAJ8Cc4DNihyXJEmSpFakTV+nCSCEsBHfd877KdAN+BYYCZwAPNMs0UmSJElSynLpnjcZWBaYQHIO01+AkTHGD5s5NkmSJEmtRFu/uO0pJEmSLcYlSZIktTm5NIK4YmkEIkmSJKn1aknnIBVbTuc0SZIkSVJj7J4nSZIkSW2UlSZJkiRJBSvl6XlWmiRJkiSpEVaaJEmSJBWsrbcclyRJkqRG1doIQpIkSZLaJitNkiRJkgpWytPzrDRJkiRJUiOsNEmSJEkqmC3HJUmSJKmNstIkSZIkqWCl3D3PpEmSJElSwZyeJ0mSJEltlJUmSZIkSQVrKZWmEMJRwAlAL+Bt4JgY42uF7NNKkyRJkqSSEELYD7gYOBPYGHgXGBFCWL6Q/ZalnBG2jHRUkiRJalnK0g4gX8u0X6Xo7+3XXKNLFdC9gVXVMcbq+oMhhFeAV2OMx2SWy4HxwNAY44VLGkfa0/Na3S+DJEmSpEXNm/N50d/bhxDOAE5vYNWZwBn1tm0PbAL8tW4sxlgTQngS2KqQONJOmiRJkiRpcS4BbmxgvLqBseWBdsDX9ca/BtYqJAiTJkmSJEktUmYKXnXKYdgIQpIkSVJJmADMB3rWG+8JfFXIjk2aJEmSJLV6McY5wBvATnVjmUYQPwNeKmTfTs+TJEmSVCouBm4KIbwBvAocB3Si4fOicpZ2y3FJkiRJKpoQwtEsenHbVwvZp0mTJEmSJDXCc5okSZIkqREmTZIkSZLUCJMmSZIkSWqESZNUZCGEG0MI92QtjwwhXJhmTCpMCOGMEMLracehhoUQ+oQQakMIP1yC+26XuW+X5ohNLUsI4cIQwsisZf8+t3L1/z7Xfw2WisWW40sohHAj8NusoQnAi8CQGOPoEMIywInA/wGrAdOBD4CLYowPZu3nB8ApwA5AD+Az4Dng7zHGuBS+FS1GA8e4zgoxxglLORw1IXO8usQY92mG3V8IDGuG/SpHIYSewDlAf2AFYCLwJkl3pFHASiR/hwkhbAc8A3SNMU7L2sdI4PUY4x+zdv1i5r7Tm/2baKOaOHazgE+BH8UY308hvL2AuSk8bpuU6Wj2V6BHjLEmM9YL+BJ4IMa4Z9a2vwauA7rHGGemEa+UzaSpMA8DhwBlwMrA+cDdwEbAmcBBwFHAW0B3YGuSxAiAEMJWwOPAsyRvzkcDKwL7AmcB+y2db0ONqDvG2SamEYjSk3njPa3JDdWc7iP5W/srYCywCjCA5A3VfJbwSu+ZCyEWdJV4NWmxx46Uf/YxxklpPn4bNBLoRvI+6Y3MWD9gPLBtCKEsxlibNf6qCZNaCpOmwsyOMdb9wf8yhDAUeDCE0A7YBbg8xnhf1vZv1X0RQigDrgeeiTH+MmubT4FXQgjdmzd05Sj7GAMLpnfsDqwKfEFyHP9W96mZWp7M9JsGj1kIYRuSqsQqMcZvs+5zLdAzxrhbCOEMYNcY46aZdTcCXUg+LT8uc5erY4ynZN1/XeBaYBOSSsgJwGPA9jHGkc32zZagEEIVyYdOP4kxvpAZHktSJSKE0IdMtYIkuX0ms83UEALATZnlfkC/EMKQzPIaQB+yqlIhhANJKou/BYaSXOPjceB3McYpmcfrClxF8jtVDZwNHAw8HGM8o5jfe2uXw7Gre4P8XuZYPRtj3C6EsAVJdWojoB3wOnBsjPG/mfv1ITnmewF/IHmevQcMjjF+kPX4fwGOBToA/6JeVal+9TGEMAb4J7BeZt9fAydkv5Zn/v5fRJL8PQfcC1wVYyxb8p9Um/Ff4FtgO75PmrYDbib5oPnHwDtZ47eHEE4geT72Jakm3wOcHGOclcsDhhB+Avwb+EuM8cpifBNqmzynqUhCCMuSVIbeyHzq+TXwsxDCcou5y0bAD4DzGloZY6xujjhVFFNIpl2uS/JG+A8kb5jUci32mGXeyH1C8ik4ACGETiQV3xsa2edOJJXhn5IkTieHEPpn7t8OuD/zuJsBxwB/K+Y31MZMJZk+t0cIoX0T244H9s58vSbJ1LtjM7eXgCszYytltm1IV+BoYCBJRWQrkunWdS4GtiD5cGwAsBsQ8vqO2o6mjt3mmf+3Izkme2WWu5I8/7YGfkJSkXoohNCh3v3Pztw2BmaQTOcCIIQwiGT6+58yjzMDGJxDzENIkqENgQeAm+tey0MIa5DMKLkb2IAkETsrh30KyFSRniU53nX6ZcaeqxsPIawMrEVSmZpH8nxcj+Tv9h7Aabk8XghhAPAI8HsTJhXKSlNh9ggh1E3Z6QyMIZmzDckf3fuAr0MI7wHPA/fEGJ/LrF878/+HSylWLZnsYwzJMTwwa3lMCOHHJG+url6qkSlnMcazsxYbOmbXAQcCl2SW9wLmAA81sttvgeMzbwJiZq7+9sAIkoSqL7BtjPEbgBDCmSSJlPIUY5wXQjiI5HgdFUJ4jaQ69K8Y46h6284PIdRNufqm3jlNc4AZ2dXjTHWjvvbAYTHGcZltbiI577SuyvRbYGBdxTCEMJjkfFTVk8Oxq6vuTsw+LjHGJ7P3E0L4HfAdyYcQ/8ladX6M8fHMNn8DRoQQOmaqEL8nqQDfmNn2j3UfbDThoRjjtZl9nkLyochmwHDgMOC/McaTMtv+L4SwMUlSrtw8A5wbQigHlidJjl4keV+0E3ApSfI0G3gpxvh01n3HhBDOIkmGT27sQUII+5L8bf9N9rnk0pIyaSrMEySfIANUAUcCj4UQNo4xvp9p8rAFyadkPwNGhhDOcvpGq5J9jCGZ7rMfyQvkmiTJcgXJdBO1UDkcs5tJXsQ3ijG+RZJA/SvG2NgJ4v/NmnsPyYnMK9Y9JDCmLmHKeLWw76JtizHeFUJ4mOTN1FYknzafmJkqVeymOd/VJUwZ2ce2L8nvz4LjGWP8JjOtSw1YkmOX1TyiH9CTZGZMe6B3vU3fy/r6y8z/KwLjSGZz1G/g8jLff2i5OAv2GWOcGUKoZuHn9mv1tve5nZ+RfH9eU1+SGTrTQwjPAWdnTl/oB7yS+fnvSJIg/QBYlmS6ZrsmHmNrkt+zXWOMw5vlu1Cb4/S8wkyPMY7O3F4jKRv3JPkEmxhjTYzxpRjjBTHGASSfjPwlM72g7tPRdVOJXLnKPsajSf7A/4tkfvQvSP7oDyV5MVcLlGm40ugxizF+TTKFY3AIYTWSilFjU/Ng0Y5btfg3tVnFGGfEGB+NMZ5KchxHAn9phofy2BbZEhy7m0jOUTsG2JJkqtwMFv1bm32s6j7EKPRYefybUeacs29Ikui6qXmQnO9US3JeUz+SD5r7kDRkehPYk2Qa5gkkH1w0ZlTm9rvMdGmpYP4RKK5aoAbouJj1H5F8OtIBeJvkE7YTG9rQRhAt1tbAxzHG82KMb2Sml/RJOSY1Ltdjdh1wAEm3xHdijO80sE2uIrB6CGGFrLHNCtif6slU+f5HUjmsb07m//pvluY0MJavT0jeVC84npnj3KfA/bYZ9Y7d4o7VNsAlMcbhmTfZywCd8nyoj0hme2Srv5yvyKLPZZ/b+RtJkjRtRyZpyvxe/AfYn6Si9wxJgw9ijH+MMb4SY/wfSUOfpnxLMqV2A+CWzFRAqSBOzytMh8z1BSCZnnc0yadgT4QQ7iY5j+klkk9U1gPOBUbGGL+DBXO0H89MW7iEpOX48iSVqt4kfzjUsowC1gghDCTp/LMnyYng1WkGpQW6hRA2rDc2gdyO2aMkb+D+DPyRwjxB0tnrxhDCiSSXGqg7cbl2sfdSgzIn4d9F0o3wPWAmySfRB5Fc6qG+sSQ/511DCI8DMzPnNo0BtgwhrE7SnCDvdtMxxqmZc5wuykzbmkTS5GM2HttF5HDsvsmMDQghfEnSsXQKyd/a/wshvEXy/LmQ7xOsXF0OXBNCeINkWt7BJMltIW3GrwL+EEI4h6Qatjm+Vi+JkcAFJB8iv5A1/hzJJVtmkxyzQPJe62iSv9HbkUyfblKM8csQwvYkSdkNIYTBdrlVIcy8C7MryRzqL0mSox8Du8QYPyJ507QnyZSfCFwBPElm6h4s6Nq1GcnJrbdmtruT5AXi1KX2XShnMcZ/kyS4/yBpIb8B8Pc0Y9JCdiQ5Ltm3jcjhmGW6Xt6SWbytkCAy+9qT5MOU10me/3/NrM6pTa4WMo3kPJITSN5gvU3SAfEsvv+5LhBj/Bw4neSN9tckb57JLEPSgOdbFj0/Jld/yMTzGElzgIdJzqHx2C6q0WMXY5xH0rDhKJLX0roT9n9H8iHi22QuEUDSiS9nMcZ/Ze53McnzsDtNT7ttap+fkryO7we8C/yGpAuuxz4/z5BUGt+u+yA541mSyzm8HGOclan4/4HknKb3SZr0nFJ/Z4uT+VuwA7AtcHXmfClpiZTV1vrBmCQBhBBuBjrGGAc2uXH+++5P8ia7Z/b1oNT6ZaZTf0HSpevelMPRUpbp2rdrjPFHacciqfk4PU9SmxdC6EZSgRpI0vK2GPvcm2QK4CckU0yGAY+aMLV+IYRNSDqwvUYyM+AskhkDdulqAzJTxV4GJpNMFzsGOCPFkCQtBSZNkpRMCdqM5MTz54u0z2VJpgGuSjIV7DGSKUpq/cpILpi6Dsm5F6+SXJNreqpRaWlZh2S6WA+S8+TOIJkCKKmEOT1PkiRJkhphIwhJkiRJaoRJkyRJkiQ1wqRJkiRJkhph0iRJkiRJjTBpkiRJkqRG/D/XOhHFR36nsQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnsuD7L6Kq4u",
        "outputId": "4d03e90a-fde1-4f5f-9be0-85c61655b99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.76      0.76        51\n",
            "           1       0.69      0.84      0.76        37\n",
            "           2       0.85      0.88      0.86        50\n",
            "           3       0.76      0.68      0.72        47\n",
            "           4       0.83      0.65      0.73        46\n",
            "           5       0.86      0.94      0.90        47\n",
            "\n",
            "    accuracy                           0.79       278\n",
            "   macro avg       0.79      0.79      0.79       278\n",
            "weighted avg       0.79      0.79      0.79       278\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelp.save(\"xcorr_mi_nmi_mean.h5\")\n",
        "from google.colab import files\n",
        "files.download(\"xcorr_mi_nmi_mean.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0frIjXEFKtJE",
        "outputId": "d3a6f7ac-79d2-4115-95f1-968e94fa0c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1060e935-aaa8-49af-969e-6b843b3aac72\", \"xcorr_mi_nmi_mean.h5\", 4259784)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}